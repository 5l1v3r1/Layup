name: "ResNet-1001"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "data/ilsvrc12_train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "data/ilsvrc12_val_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_conv1"  
  type: "Scale"
  bottom: "conv1"
  top: "conv1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1_top"
  top: "conv1_top"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_top"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res_1_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res_1_branch1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_1_branch1"
  type: "BatchNorm"
  bottom: "res_1_branch1"
  top: "res_1_branch1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_1_branch1"  
  type: "Scale"
  bottom: "res_1_branch1"
  top: "res_1_branch1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_1_1"
  type: "Convolution"
  bottom: "pool1"
  top: "res_stage_1_1_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_1_1"
  type: "BatchNorm"
  bottom: "res_stage_1_1_1"
  top: "res_stage_1_1_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_1_1"  
  type: "Scale"
  bottom: "res_stage_1_1_1"
  top: "res_stage_1_1_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_1_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_1_1_top"
  top: "res_stage_1_1_1_top"
}
layer {
  name: "res_stage_1_1_2"
  type: "Convolution"
  bottom: "res_stage_1_1_1_top"
  top: "res_stage_1_1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_1_2"
  type: "BatchNorm"
  bottom: "res_stage_1_1_2"
  top: "res_stage_1_1_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_1_2"  
  type: "Scale"
  bottom: "res_stage_1_1_2"
  top: "res_stage_1_1_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_1_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_1_2_top"
  top: "res_stage_1_1_2_top"
}
layer {
  name: "res_stage_1_1_3"
  type: "Convolution"
  bottom: "res_stage_1_1_2_top"
  top: "res_stage_1_1_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_1_3"
  type: "BatchNorm"
  bottom: "res_stage_1_1_3"
  top: "res_stage_1_1_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_1_3"  
  type: "Scale"
  bottom: "res_stage_1_1_3"
  top: "res_stage_1_1_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_1"
  type: "Eltwise"
  bottom: "res_1_branch1_top"
  bottom: "res_stage_1_1_3_top"
  top: "res_1_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_1_relu"
  type: "ReLU"
  bottom: "res_1_1"
  top: "res_1_1"
}
layer {
  name: "res_stage_1_2_1"
  type: "Convolution"
  bottom: "res_1_1"
  top: "res_stage_1_2_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_2_1"
  type: "BatchNorm"
  bottom: "res_stage_1_2_1"
  top: "res_stage_1_2_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_2_1"  
  type: "Scale"
  bottom: "res_stage_1_2_1"
  top: "res_stage_1_2_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_2_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_2_1_top"
  top: "res_stage_1_2_1_top"
}
layer {
  name: "res_stage_1_2_2"
  type: "Convolution"
  bottom: "res_stage_1_2_1_top"
  top: "res_stage_1_2_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_2_2"
  type: "BatchNorm"
  bottom: "res_stage_1_2_2"
  top: "res_stage_1_2_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_2_2"  
  type: "Scale"
  bottom: "res_stage_1_2_2"
  top: "res_stage_1_2_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_2_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_2_2_top"
  top: "res_stage_1_2_2_top"
}
layer {
  name: "res_stage_1_2_3"
  type: "Convolution"
  bottom: "res_stage_1_2_2_top"
  top: "res_stage_1_2_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_2_3"
  type: "BatchNorm"
  bottom: "res_stage_1_2_3"
  top: "res_stage_1_2_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_2_3"  
  type: "Scale"
  bottom: "res_stage_1_2_3"
  top: "res_stage_1_2_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_2"
  type: "Eltwise"
  bottom: "res_1_1"
  bottom: "res_stage_1_2_3_top"
  top: "res_1_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_2_relu"
  type: "ReLU"
  bottom: "res_1_2"
  top: "res_1_2"
}
layer {
  name: "res_stage_1_3_1"
  type: "Convolution"
  bottom: "res_1_2"
  top: "res_stage_1_3_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_3_1"
  type: "BatchNorm"
  bottom: "res_stage_1_3_1"
  top: "res_stage_1_3_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_3_1"  
  type: "Scale"
  bottom: "res_stage_1_3_1"
  top: "res_stage_1_3_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_3_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_3_1_top"
  top: "res_stage_1_3_1_top"
}
layer {
  name: "res_stage_1_3_2"
  type: "Convolution"
  bottom: "res_stage_1_3_1_top"
  top: "res_stage_1_3_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_3_2"
  type: "BatchNorm"
  bottom: "res_stage_1_3_2"
  top: "res_stage_1_3_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_3_2"  
  type: "Scale"
  bottom: "res_stage_1_3_2"
  top: "res_stage_1_3_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_3_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_3_2_top"
  top: "res_stage_1_3_2_top"
}
layer {
  name: "res_stage_1_3_3"
  type: "Convolution"
  bottom: "res_stage_1_3_2_top"
  top: "res_stage_1_3_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_3_3"
  type: "BatchNorm"
  bottom: "res_stage_1_3_3"
  top: "res_stage_1_3_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_3_3"  
  type: "Scale"
  bottom: "res_stage_1_3_3"
  top: "res_stage_1_3_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_3"
  type: "Eltwise"
  bottom: "res_1_2"
  bottom: "res_stage_1_3_3_top"
  top: "res_1_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_3_relu"
  type: "ReLU"
  bottom: "res_1_3"
  top: "res_1_3"
}
layer {
  name: "res_2_branch1"
  type: "Convolution"
  bottom: "res_1_3"
  top: "res_2_branch1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_2_branch1"
  type: "BatchNorm"
  bottom: "res_2_branch1"
  top: "res_2_branch1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_2_branch1"  
  type: "Scale"
  bottom: "res_2_branch1"
  top: "res_2_branch1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_1_1"
  type: "Convolution"
  bottom: "res_1_3"
  top: "res_stage_2_1_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_1_1"
  type: "BatchNorm"
  bottom: "res_stage_2_1_1"
  top: "res_stage_2_1_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_1_1"  
  type: "Scale"
  bottom: "res_stage_2_1_1"
  top: "res_stage_2_1_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_1_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_1_1_top"
  top: "res_stage_2_1_1_top"
}
layer {
  name: "res_stage_2_1_2"
  type: "Convolution"
  bottom: "res_stage_2_1_1_top"
  top: "res_stage_2_1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_1_2"
  type: "BatchNorm"
  bottom: "res_stage_2_1_2"
  top: "res_stage_2_1_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_1_2"  
  type: "Scale"
  bottom: "res_stage_2_1_2"
  top: "res_stage_2_1_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_1_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_1_2_top"
  top: "res_stage_2_1_2_top"
}
layer {
  name: "res_stage_2_1_3"
  type: "Convolution"
  bottom: "res_stage_2_1_2_top"
  top: "res_stage_2_1_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_1_3"
  type: "BatchNorm"
  bottom: "res_stage_2_1_3"
  top: "res_stage_2_1_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_1_3"  
  type: "Scale"
  bottom: "res_stage_2_1_3"
  top: "res_stage_2_1_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_1"
  type: "Eltwise"
  bottom: "res_2_branch1_top"
  bottom: "res_stage_2_1_3_top"
  top: "res_2_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_1_relu"
  type: "ReLU"
  bottom: "res_2_1"
  top: "res_2_1"
}
layer {
  name: "res_stage_2_2_1"
  type: "Convolution"
  bottom: "res_2_1"
  top: "res_stage_2_2_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_2_1"
  type: "BatchNorm"
  bottom: "res_stage_2_2_1"
  top: "res_stage_2_2_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_2_1"  
  type: "Scale"
  bottom: "res_stage_2_2_1"
  top: "res_stage_2_2_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_2_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_2_1_top"
  top: "res_stage_2_2_1_top"
}
layer {
  name: "res_stage_2_2_2"
  type: "Convolution"
  bottom: "res_stage_2_2_1_top"
  top: "res_stage_2_2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_2_2"
  type: "BatchNorm"
  bottom: "res_stage_2_2_2"
  top: "res_stage_2_2_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_2_2"  
  type: "Scale"
  bottom: "res_stage_2_2_2"
  top: "res_stage_2_2_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_2_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_2_2_top"
  top: "res_stage_2_2_2_top"
}
layer {
  name: "res_stage_2_2_3"
  type: "Convolution"
  bottom: "res_stage_2_2_2_top"
  top: "res_stage_2_2_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_2_3"
  type: "BatchNorm"
  bottom: "res_stage_2_2_3"
  top: "res_stage_2_2_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_2_3"  
  type: "Scale"
  bottom: "res_stage_2_2_3"
  top: "res_stage_2_2_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_2"
  type: "Eltwise"
  bottom: "res_2_1"
  bottom: "res_stage_2_2_3_top"
  top: "res_2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_2_relu"
  type: "ReLU"
  bottom: "res_2_2"
  top: "res_2_2"
}
layer {
  name: "res_stage_2_3_1"
  type: "Convolution"
  bottom: "res_2_2"
  top: "res_stage_2_3_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_3_1"
  type: "BatchNorm"
  bottom: "res_stage_2_3_1"
  top: "res_stage_2_3_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_3_1"  
  type: "Scale"
  bottom: "res_stage_2_3_1"
  top: "res_stage_2_3_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_3_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_3_1_top"
  top: "res_stage_2_3_1_top"
}
layer {
  name: "res_stage_2_3_2"
  type: "Convolution"
  bottom: "res_stage_2_3_1_top"
  top: "res_stage_2_3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_3_2"
  type: "BatchNorm"
  bottom: "res_stage_2_3_2"
  top: "res_stage_2_3_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_3_2"  
  type: "Scale"
  bottom: "res_stage_2_3_2"
  top: "res_stage_2_3_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_3_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_3_2_top"
  top: "res_stage_2_3_2_top"
}
layer {
  name: "res_stage_2_3_3"
  type: "Convolution"
  bottom: "res_stage_2_3_2_top"
  top: "res_stage_2_3_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_3_3"
  type: "BatchNorm"
  bottom: "res_stage_2_3_3"
  top: "res_stage_2_3_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_3_3"  
  type: "Scale"
  bottom: "res_stage_2_3_3"
  top: "res_stage_2_3_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_3"
  type: "Eltwise"
  bottom: "res_2_2"
  bottom: "res_stage_2_3_3_top"
  top: "res_2_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_3_relu"
  type: "ReLU"
  bottom: "res_2_3"
  top: "res_2_3"
}
layer {
  name: "res_stage_2_4_1"
  type: "Convolution"
  bottom: "res_2_3"
  top: "res_stage_2_4_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_4_1"
  type: "BatchNorm"
  bottom: "res_stage_2_4_1"
  top: "res_stage_2_4_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_4_1"  
  type: "Scale"
  bottom: "res_stage_2_4_1"
  top: "res_stage_2_4_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_4_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_4_1_top"
  top: "res_stage_2_4_1_top"
}
layer {
  name: "res_stage_2_4_2"
  type: "Convolution"
  bottom: "res_stage_2_4_1_top"
  top: "res_stage_2_4_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_4_2"
  type: "BatchNorm"
  bottom: "res_stage_2_4_2"
  top: "res_stage_2_4_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_4_2"  
  type: "Scale"
  bottom: "res_stage_2_4_2"
  top: "res_stage_2_4_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_4_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_4_2_top"
  top: "res_stage_2_4_2_top"
}
layer {
  name: "res_stage_2_4_3"
  type: "Convolution"
  bottom: "res_stage_2_4_2_top"
  top: "res_stage_2_4_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_4_3"
  type: "BatchNorm"
  bottom: "res_stage_2_4_3"
  top: "res_stage_2_4_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_4_3"  
  type: "Scale"
  bottom: "res_stage_2_4_3"
  top: "res_stage_2_4_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_4"
  type: "Eltwise"
  bottom: "res_2_3"
  bottom: "res_stage_2_4_3_top"
  top: "res_2_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_4_relu"
  type: "ReLU"
  bottom: "res_2_4"
  top: "res_2_4"
}
layer {
  name: "res_stage_2_5_1"
  type: "Convolution"
  bottom: "res_2_4"
  top: "res_stage_2_5_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_5_1"
  type: "BatchNorm"
  bottom: "res_stage_2_5_1"
  top: "res_stage_2_5_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_5_1"  
  type: "Scale"
  bottom: "res_stage_2_5_1"
  top: "res_stage_2_5_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_5_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_5_1_top"
  top: "res_stage_2_5_1_top"
}
layer {
  name: "res_stage_2_5_2"
  type: "Convolution"
  bottom: "res_stage_2_5_1_top"
  top: "res_stage_2_5_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_5_2"
  type: "BatchNorm"
  bottom: "res_stage_2_5_2"
  top: "res_stage_2_5_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_5_2"  
  type: "Scale"
  bottom: "res_stage_2_5_2"
  top: "res_stage_2_5_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_5_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_5_2_top"
  top: "res_stage_2_5_2_top"
}
layer {
  name: "res_stage_2_5_3"
  type: "Convolution"
  bottom: "res_stage_2_5_2_top"
  top: "res_stage_2_5_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_5_3"
  type: "BatchNorm"
  bottom: "res_stage_2_5_3"
  top: "res_stage_2_5_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_5_3"  
  type: "Scale"
  bottom: "res_stage_2_5_3"
  top: "res_stage_2_5_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_5"
  type: "Eltwise"
  bottom: "res_2_4"
  bottom: "res_stage_2_5_3_top"
  top: "res_2_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_5_relu"
  type: "ReLU"
  bottom: "res_2_5"
  top: "res_2_5"
}
layer {
  name: "res_stage_2_6_1"
  type: "Convolution"
  bottom: "res_2_5"
  top: "res_stage_2_6_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_6_1"
  type: "BatchNorm"
  bottom: "res_stage_2_6_1"
  top: "res_stage_2_6_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_6_1"  
  type: "Scale"
  bottom: "res_stage_2_6_1"
  top: "res_stage_2_6_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_6_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_6_1_top"
  top: "res_stage_2_6_1_top"
}
layer {
  name: "res_stage_2_6_2"
  type: "Convolution"
  bottom: "res_stage_2_6_1_top"
  top: "res_stage_2_6_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_6_2"
  type: "BatchNorm"
  bottom: "res_stage_2_6_2"
  top: "res_stage_2_6_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_6_2"  
  type: "Scale"
  bottom: "res_stage_2_6_2"
  top: "res_stage_2_6_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_6_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_6_2_top"
  top: "res_stage_2_6_2_top"
}
layer {
  name: "res_stage_2_6_3"
  type: "Convolution"
  bottom: "res_stage_2_6_2_top"
  top: "res_stage_2_6_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_6_3"
  type: "BatchNorm"
  bottom: "res_stage_2_6_3"
  top: "res_stage_2_6_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_6_3"  
  type: "Scale"
  bottom: "res_stage_2_6_3"
  top: "res_stage_2_6_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_6"
  type: "Eltwise"
  bottom: "res_2_5"
  bottom: "res_stage_2_6_3_top"
  top: "res_2_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_6_relu"
  type: "ReLU"
  bottom: "res_2_6"
  top: "res_2_6"
}
layer {
  name: "res_stage_2_7_1"
  type: "Convolution"
  bottom: "res_2_6"
  top: "res_stage_2_7_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_7_1"
  type: "BatchNorm"
  bottom: "res_stage_2_7_1"
  top: "res_stage_2_7_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_7_1"  
  type: "Scale"
  bottom: "res_stage_2_7_1"
  top: "res_stage_2_7_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_7_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_7_1_top"
  top: "res_stage_2_7_1_top"
}
layer {
  name: "res_stage_2_7_2"
  type: "Convolution"
  bottom: "res_stage_2_7_1_top"
  top: "res_stage_2_7_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_7_2"
  type: "BatchNorm"
  bottom: "res_stage_2_7_2"
  top: "res_stage_2_7_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_7_2"  
  type: "Scale"
  bottom: "res_stage_2_7_2"
  top: "res_stage_2_7_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_7_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_7_2_top"
  top: "res_stage_2_7_2_top"
}
layer {
  name: "res_stage_2_7_3"
  type: "Convolution"
  bottom: "res_stage_2_7_2_top"
  top: "res_stage_2_7_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_7_3"
  type: "BatchNorm"
  bottom: "res_stage_2_7_3"
  top: "res_stage_2_7_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_7_3"  
  type: "Scale"
  bottom: "res_stage_2_7_3"
  top: "res_stage_2_7_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_7"
  type: "Eltwise"
  bottom: "res_2_6"
  bottom: "res_stage_2_7_3_top"
  top: "res_2_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_7_relu"
  type: "ReLU"
  bottom: "res_2_7"
  top: "res_2_7"
}
layer {
  name: "res_stage_2_8_1"
  type: "Convolution"
  bottom: "res_2_7"
  top: "res_stage_2_8_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_8_1"
  type: "BatchNorm"
  bottom: "res_stage_2_8_1"
  top: "res_stage_2_8_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_8_1"  
  type: "Scale"
  bottom: "res_stage_2_8_1"
  top: "res_stage_2_8_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_8_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_8_1_top"
  top: "res_stage_2_8_1_top"
}
layer {
  name: "res_stage_2_8_2"
  type: "Convolution"
  bottom: "res_stage_2_8_1_top"
  top: "res_stage_2_8_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_8_2"
  type: "BatchNorm"
  bottom: "res_stage_2_8_2"
  top: "res_stage_2_8_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_8_2"  
  type: "Scale"
  bottom: "res_stage_2_8_2"
  top: "res_stage_2_8_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_8_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_8_2_top"
  top: "res_stage_2_8_2_top"
}
layer {
  name: "res_stage_2_8_3"
  type: "Convolution"
  bottom: "res_stage_2_8_2_top"
  top: "res_stage_2_8_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_8_3"
  type: "BatchNorm"
  bottom: "res_stage_2_8_3"
  top: "res_stage_2_8_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_8_3"  
  type: "Scale"
  bottom: "res_stage_2_8_3"
  top: "res_stage_2_8_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_8"
  type: "Eltwise"
  bottom: "res_2_7"
  bottom: "res_stage_2_8_3_top"
  top: "res_2_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_8_relu"
  type: "ReLU"
  bottom: "res_2_8"
  top: "res_2_8"
}
layer {
  name: "res_stage_2_9_1"
  type: "Convolution"
  bottom: "res_2_8"
  top: "res_stage_2_9_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_9_1"
  type: "BatchNorm"
  bottom: "res_stage_2_9_1"
  top: "res_stage_2_9_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_9_1"  
  type: "Scale"
  bottom: "res_stage_2_9_1"
  top: "res_stage_2_9_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_9_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_9_1_top"
  top: "res_stage_2_9_1_top"
}
layer {
  name: "res_stage_2_9_2"
  type: "Convolution"
  bottom: "res_stage_2_9_1_top"
  top: "res_stage_2_9_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_9_2"
  type: "BatchNorm"
  bottom: "res_stage_2_9_2"
  top: "res_stage_2_9_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_9_2"  
  type: "Scale"
  bottom: "res_stage_2_9_2"
  top: "res_stage_2_9_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_9_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_9_2_top"
  top: "res_stage_2_9_2_top"
}
layer {
  name: "res_stage_2_9_3"
  type: "Convolution"
  bottom: "res_stage_2_9_2_top"
  top: "res_stage_2_9_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_9_3"
  type: "BatchNorm"
  bottom: "res_stage_2_9_3"
  top: "res_stage_2_9_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_9_3"  
  type: "Scale"
  bottom: "res_stage_2_9_3"
  top: "res_stage_2_9_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_9"
  type: "Eltwise"
  bottom: "res_2_8"
  bottom: "res_stage_2_9_3_top"
  top: "res_2_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_9_relu"
  type: "ReLU"
  bottom: "res_2_9"
  top: "res_2_9"
}
layer {
  name: "res_stage_2_10_1"
  type: "Convolution"
  bottom: "res_2_9"
  top: "res_stage_2_10_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_10_1"
  type: "BatchNorm"
  bottom: "res_stage_2_10_1"
  top: "res_stage_2_10_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_10_1"  
  type: "Scale"
  bottom: "res_stage_2_10_1"
  top: "res_stage_2_10_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_10_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_10_1_top"
  top: "res_stage_2_10_1_top"
}
layer {
  name: "res_stage_2_10_2"
  type: "Convolution"
  bottom: "res_stage_2_10_1_top"
  top: "res_stage_2_10_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_10_2"
  type: "BatchNorm"
  bottom: "res_stage_2_10_2"
  top: "res_stage_2_10_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_10_2"  
  type: "Scale"
  bottom: "res_stage_2_10_2"
  top: "res_stage_2_10_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_10_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_10_2_top"
  top: "res_stage_2_10_2_top"
}
layer {
  name: "res_stage_2_10_3"
  type: "Convolution"
  bottom: "res_stage_2_10_2_top"
  top: "res_stage_2_10_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_10_3"
  type: "BatchNorm"
  bottom: "res_stage_2_10_3"
  top: "res_stage_2_10_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_10_3"  
  type: "Scale"
  bottom: "res_stage_2_10_3"
  top: "res_stage_2_10_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_10"
  type: "Eltwise"
  bottom: "res_2_9"
  bottom: "res_stage_2_10_3_top"
  top: "res_2_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_10_relu"
  type: "ReLU"
  bottom: "res_2_10"
  top: "res_2_10"
}
layer {
  name: "res_stage_2_11_1"
  type: "Convolution"
  bottom: "res_2_10"
  top: "res_stage_2_11_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_11_1"
  type: "BatchNorm"
  bottom: "res_stage_2_11_1"
  top: "res_stage_2_11_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_11_1"  
  type: "Scale"
  bottom: "res_stage_2_11_1"
  top: "res_stage_2_11_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_11_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_11_1_top"
  top: "res_stage_2_11_1_top"
}
layer {
  name: "res_stage_2_11_2"
  type: "Convolution"
  bottom: "res_stage_2_11_1_top"
  top: "res_stage_2_11_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_11_2"
  type: "BatchNorm"
  bottom: "res_stage_2_11_2"
  top: "res_stage_2_11_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_11_2"  
  type: "Scale"
  bottom: "res_stage_2_11_2"
  top: "res_stage_2_11_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_11_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_11_2_top"
  top: "res_stage_2_11_2_top"
}
layer {
  name: "res_stage_2_11_3"
  type: "Convolution"
  bottom: "res_stage_2_11_2_top"
  top: "res_stage_2_11_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_11_3"
  type: "BatchNorm"
  bottom: "res_stage_2_11_3"
  top: "res_stage_2_11_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_11_3"  
  type: "Scale"
  bottom: "res_stage_2_11_3"
  top: "res_stage_2_11_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_11"
  type: "Eltwise"
  bottom: "res_2_10"
  bottom: "res_stage_2_11_3_top"
  top: "res_2_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_11_relu"
  type: "ReLU"
  bottom: "res_2_11"
  top: "res_2_11"
}
layer {
  name: "res_stage_2_12_1"
  type: "Convolution"
  bottom: "res_2_11"
  top: "res_stage_2_12_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_12_1"
  type: "BatchNorm"
  bottom: "res_stage_2_12_1"
  top: "res_stage_2_12_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_12_1"  
  type: "Scale"
  bottom: "res_stage_2_12_1"
  top: "res_stage_2_12_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_12_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_12_1_top"
  top: "res_stage_2_12_1_top"
}
layer {
  name: "res_stage_2_12_2"
  type: "Convolution"
  bottom: "res_stage_2_12_1_top"
  top: "res_stage_2_12_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_12_2"
  type: "BatchNorm"
  bottom: "res_stage_2_12_2"
  top: "res_stage_2_12_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_12_2"  
  type: "Scale"
  bottom: "res_stage_2_12_2"
  top: "res_stage_2_12_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_12_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_12_2_top"
  top: "res_stage_2_12_2_top"
}
layer {
  name: "res_stage_2_12_3"
  type: "Convolution"
  bottom: "res_stage_2_12_2_top"
  top: "res_stage_2_12_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_12_3"
  type: "BatchNorm"
  bottom: "res_stage_2_12_3"
  top: "res_stage_2_12_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_12_3"  
  type: "Scale"
  bottom: "res_stage_2_12_3"
  top: "res_stage_2_12_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_12"
  type: "Eltwise"
  bottom: "res_2_11"
  bottom: "res_stage_2_12_3_top"
  top: "res_2_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_12_relu"
  type: "ReLU"
  bottom: "res_2_12"
  top: "res_2_12"
}
layer {
  name: "res_stage_2_13_1"
  type: "Convolution"
  bottom: "res_2_12"
  top: "res_stage_2_13_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_13_1"
  type: "BatchNorm"
  bottom: "res_stage_2_13_1"
  top: "res_stage_2_13_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_13_1"  
  type: "Scale"
  bottom: "res_stage_2_13_1"
  top: "res_stage_2_13_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_13_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_13_1_top"
  top: "res_stage_2_13_1_top"
}
layer {
  name: "res_stage_2_13_2"
  type: "Convolution"
  bottom: "res_stage_2_13_1_top"
  top: "res_stage_2_13_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_13_2"
  type: "BatchNorm"
  bottom: "res_stage_2_13_2"
  top: "res_stage_2_13_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_13_2"  
  type: "Scale"
  bottom: "res_stage_2_13_2"
  top: "res_stage_2_13_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_13_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_13_2_top"
  top: "res_stage_2_13_2_top"
}
layer {
  name: "res_stage_2_13_3"
  type: "Convolution"
  bottom: "res_stage_2_13_2_top"
  top: "res_stage_2_13_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_13_3"
  type: "BatchNorm"
  bottom: "res_stage_2_13_3"
  top: "res_stage_2_13_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_13_3"  
  type: "Scale"
  bottom: "res_stage_2_13_3"
  top: "res_stage_2_13_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_13"
  type: "Eltwise"
  bottom: "res_2_12"
  bottom: "res_stage_2_13_3_top"
  top: "res_2_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_13_relu"
  type: "ReLU"
  bottom: "res_2_13"
  top: "res_2_13"
}
layer {
  name: "res_stage_2_14_1"
  type: "Convolution"
  bottom: "res_2_13"
  top: "res_stage_2_14_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_14_1"
  type: "BatchNorm"
  bottom: "res_stage_2_14_1"
  top: "res_stage_2_14_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_14_1"  
  type: "Scale"
  bottom: "res_stage_2_14_1"
  top: "res_stage_2_14_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_14_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_14_1_top"
  top: "res_stage_2_14_1_top"
}
layer {
  name: "res_stage_2_14_2"
  type: "Convolution"
  bottom: "res_stage_2_14_1_top"
  top: "res_stage_2_14_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_14_2"
  type: "BatchNorm"
  bottom: "res_stage_2_14_2"
  top: "res_stage_2_14_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_14_2"  
  type: "Scale"
  bottom: "res_stage_2_14_2"
  top: "res_stage_2_14_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_14_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_14_2_top"
  top: "res_stage_2_14_2_top"
}
layer {
  name: "res_stage_2_14_3"
  type: "Convolution"
  bottom: "res_stage_2_14_2_top"
  top: "res_stage_2_14_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_14_3"
  type: "BatchNorm"
  bottom: "res_stage_2_14_3"
  top: "res_stage_2_14_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_14_3"  
  type: "Scale"
  bottom: "res_stage_2_14_3"
  top: "res_stage_2_14_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_14"
  type: "Eltwise"
  bottom: "res_2_13"
  bottom: "res_stage_2_14_3_top"
  top: "res_2_14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_14_relu"
  type: "ReLU"
  bottom: "res_2_14"
  top: "res_2_14"
}
layer {
  name: "res_stage_2_15_1"
  type: "Convolution"
  bottom: "res_2_14"
  top: "res_stage_2_15_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_15_1"
  type: "BatchNorm"
  bottom: "res_stage_2_15_1"
  top: "res_stage_2_15_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_15_1"  
  type: "Scale"
  bottom: "res_stage_2_15_1"
  top: "res_stage_2_15_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_15_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_15_1_top"
  top: "res_stage_2_15_1_top"
}
layer {
  name: "res_stage_2_15_2"
  type: "Convolution"
  bottom: "res_stage_2_15_1_top"
  top: "res_stage_2_15_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_15_2"
  type: "BatchNorm"
  bottom: "res_stage_2_15_2"
  top: "res_stage_2_15_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_15_2"  
  type: "Scale"
  bottom: "res_stage_2_15_2"
  top: "res_stage_2_15_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_15_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_15_2_top"
  top: "res_stage_2_15_2_top"
}
layer {
  name: "res_stage_2_15_3"
  type: "Convolution"
  bottom: "res_stage_2_15_2_top"
  top: "res_stage_2_15_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_15_3"
  type: "BatchNorm"
  bottom: "res_stage_2_15_3"
  top: "res_stage_2_15_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_15_3"  
  type: "Scale"
  bottom: "res_stage_2_15_3"
  top: "res_stage_2_15_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_15"
  type: "Eltwise"
  bottom: "res_2_14"
  bottom: "res_stage_2_15_3_top"
  top: "res_2_15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_15_relu"
  type: "ReLU"
  bottom: "res_2_15"
  top: "res_2_15"
}
layer {
  name: "res_stage_2_16_1"
  type: "Convolution"
  bottom: "res_2_15"
  top: "res_stage_2_16_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_16_1"
  type: "BatchNorm"
  bottom: "res_stage_2_16_1"
  top: "res_stage_2_16_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_16_1"  
  type: "Scale"
  bottom: "res_stage_2_16_1"
  top: "res_stage_2_16_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_16_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_16_1_top"
  top: "res_stage_2_16_1_top"
}
layer {
  name: "res_stage_2_16_2"
  type: "Convolution"
  bottom: "res_stage_2_16_1_top"
  top: "res_stage_2_16_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_16_2"
  type: "BatchNorm"
  bottom: "res_stage_2_16_2"
  top: "res_stage_2_16_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_16_2"  
  type: "Scale"
  bottom: "res_stage_2_16_2"
  top: "res_stage_2_16_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_16_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_16_2_top"
  top: "res_stage_2_16_2_top"
}
layer {
  name: "res_stage_2_16_3"
  type: "Convolution"
  bottom: "res_stage_2_16_2_top"
  top: "res_stage_2_16_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_16_3"
  type: "BatchNorm"
  bottom: "res_stage_2_16_3"
  top: "res_stage_2_16_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_16_3"  
  type: "Scale"
  bottom: "res_stage_2_16_3"
  top: "res_stage_2_16_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_16"
  type: "Eltwise"
  bottom: "res_2_15"
  bottom: "res_stage_2_16_3_top"
  top: "res_2_16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_16_relu"
  type: "ReLU"
  bottom: "res_2_16"
  top: "res_2_16"
}
layer {
  name: "res_stage_2_17_1"
  type: "Convolution"
  bottom: "res_2_16"
  top: "res_stage_2_17_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_17_1"
  type: "BatchNorm"
  bottom: "res_stage_2_17_1"
  top: "res_stage_2_17_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_17_1"  
  type: "Scale"
  bottom: "res_stage_2_17_1"
  top: "res_stage_2_17_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_17_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_17_1_top"
  top: "res_stage_2_17_1_top"
}
layer {
  name: "res_stage_2_17_2"
  type: "Convolution"
  bottom: "res_stage_2_17_1_top"
  top: "res_stage_2_17_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_17_2"
  type: "BatchNorm"
  bottom: "res_stage_2_17_2"
  top: "res_stage_2_17_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_17_2"  
  type: "Scale"
  bottom: "res_stage_2_17_2"
  top: "res_stage_2_17_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_17_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_17_2_top"
  top: "res_stage_2_17_2_top"
}
layer {
  name: "res_stage_2_17_3"
  type: "Convolution"
  bottom: "res_stage_2_17_2_top"
  top: "res_stage_2_17_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_17_3"
  type: "BatchNorm"
  bottom: "res_stage_2_17_3"
  top: "res_stage_2_17_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_17_3"  
  type: "Scale"
  bottom: "res_stage_2_17_3"
  top: "res_stage_2_17_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_17"
  type: "Eltwise"
  bottom: "res_2_16"
  bottom: "res_stage_2_17_3_top"
  top: "res_2_17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_17_relu"
  type: "ReLU"
  bottom: "res_2_17"
  top: "res_2_17"
}
layer {
  name: "res_stage_2_18_1"
  type: "Convolution"
  bottom: "res_2_17"
  top: "res_stage_2_18_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_18_1"
  type: "BatchNorm"
  bottom: "res_stage_2_18_1"
  top: "res_stage_2_18_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_18_1"  
  type: "Scale"
  bottom: "res_stage_2_18_1"
  top: "res_stage_2_18_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_18_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_18_1_top"
  top: "res_stage_2_18_1_top"
}
layer {
  name: "res_stage_2_18_2"
  type: "Convolution"
  bottom: "res_stage_2_18_1_top"
  top: "res_stage_2_18_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_18_2"
  type: "BatchNorm"
  bottom: "res_stage_2_18_2"
  top: "res_stage_2_18_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_18_2"  
  type: "Scale"
  bottom: "res_stage_2_18_2"
  top: "res_stage_2_18_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_18_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_18_2_top"
  top: "res_stage_2_18_2_top"
}
layer {
  name: "res_stage_2_18_3"
  type: "Convolution"
  bottom: "res_stage_2_18_2_top"
  top: "res_stage_2_18_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_18_3"
  type: "BatchNorm"
  bottom: "res_stage_2_18_3"
  top: "res_stage_2_18_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_18_3"  
  type: "Scale"
  bottom: "res_stage_2_18_3"
  top: "res_stage_2_18_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_18"
  type: "Eltwise"
  bottom: "res_2_17"
  bottom: "res_stage_2_18_3_top"
  top: "res_2_18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_18_relu"
  type: "ReLU"
  bottom: "res_2_18"
  top: "res_2_18"
}
layer {
  name: "res_stage_2_19_1"
  type: "Convolution"
  bottom: "res_2_18"
  top: "res_stage_2_19_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_19_1"
  type: "BatchNorm"
  bottom: "res_stage_2_19_1"
  top: "res_stage_2_19_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_19_1"  
  type: "Scale"
  bottom: "res_stage_2_19_1"
  top: "res_stage_2_19_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_19_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_19_1_top"
  top: "res_stage_2_19_1_top"
}
layer {
  name: "res_stage_2_19_2"
  type: "Convolution"
  bottom: "res_stage_2_19_1_top"
  top: "res_stage_2_19_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_19_2"
  type: "BatchNorm"
  bottom: "res_stage_2_19_2"
  top: "res_stage_2_19_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_19_2"  
  type: "Scale"
  bottom: "res_stage_2_19_2"
  top: "res_stage_2_19_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_19_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_19_2_top"
  top: "res_stage_2_19_2_top"
}
layer {
  name: "res_stage_2_19_3"
  type: "Convolution"
  bottom: "res_stage_2_19_2_top"
  top: "res_stage_2_19_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_19_3"
  type: "BatchNorm"
  bottom: "res_stage_2_19_3"
  top: "res_stage_2_19_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_19_3"  
  type: "Scale"
  bottom: "res_stage_2_19_3"
  top: "res_stage_2_19_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_19"
  type: "Eltwise"
  bottom: "res_2_18"
  bottom: "res_stage_2_19_3_top"
  top: "res_2_19"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_19_relu"
  type: "ReLU"
  bottom: "res_2_19"
  top: "res_2_19"
}
layer {
  name: "res_stage_2_20_1"
  type: "Convolution"
  bottom: "res_2_19"
  top: "res_stage_2_20_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_20_1"
  type: "BatchNorm"
  bottom: "res_stage_2_20_1"
  top: "res_stage_2_20_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_20_1"  
  type: "Scale"
  bottom: "res_stage_2_20_1"
  top: "res_stage_2_20_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_20_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_20_1_top"
  top: "res_stage_2_20_1_top"
}
layer {
  name: "res_stage_2_20_2"
  type: "Convolution"
  bottom: "res_stage_2_20_1_top"
  top: "res_stage_2_20_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_20_2"
  type: "BatchNorm"
  bottom: "res_stage_2_20_2"
  top: "res_stage_2_20_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_20_2"  
  type: "Scale"
  bottom: "res_stage_2_20_2"
  top: "res_stage_2_20_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_20_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_20_2_top"
  top: "res_stage_2_20_2_top"
}
layer {
  name: "res_stage_2_20_3"
  type: "Convolution"
  bottom: "res_stage_2_20_2_top"
  top: "res_stage_2_20_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_20_3"
  type: "BatchNorm"
  bottom: "res_stage_2_20_3"
  top: "res_stage_2_20_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_20_3"  
  type: "Scale"
  bottom: "res_stage_2_20_3"
  top: "res_stage_2_20_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_20"
  type: "Eltwise"
  bottom: "res_2_19"
  bottom: "res_stage_2_20_3_top"
  top: "res_2_20"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_20_relu"
  type: "ReLU"
  bottom: "res_2_20"
  top: "res_2_20"
}
layer {
  name: "res_stage_2_21_1"
  type: "Convolution"
  bottom: "res_2_20"
  top: "res_stage_2_21_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_21_1"
  type: "BatchNorm"
  bottom: "res_stage_2_21_1"
  top: "res_stage_2_21_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_21_1"  
  type: "Scale"
  bottom: "res_stage_2_21_1"
  top: "res_stage_2_21_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_21_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_21_1_top"
  top: "res_stage_2_21_1_top"
}
layer {
  name: "res_stage_2_21_2"
  type: "Convolution"
  bottom: "res_stage_2_21_1_top"
  top: "res_stage_2_21_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_21_2"
  type: "BatchNorm"
  bottom: "res_stage_2_21_2"
  top: "res_stage_2_21_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_21_2"  
  type: "Scale"
  bottom: "res_stage_2_21_2"
  top: "res_stage_2_21_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_21_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_21_2_top"
  top: "res_stage_2_21_2_top"
}
layer {
  name: "res_stage_2_21_3"
  type: "Convolution"
  bottom: "res_stage_2_21_2_top"
  top: "res_stage_2_21_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_21_3"
  type: "BatchNorm"
  bottom: "res_stage_2_21_3"
  top: "res_stage_2_21_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_21_3"  
  type: "Scale"
  bottom: "res_stage_2_21_3"
  top: "res_stage_2_21_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_21"
  type: "Eltwise"
  bottom: "res_2_20"
  bottom: "res_stage_2_21_3_top"
  top: "res_2_21"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_21_relu"
  type: "ReLU"
  bottom: "res_2_21"
  top: "res_2_21"
}
layer {
  name: "res_stage_2_22_1"
  type: "Convolution"
  bottom: "res_2_21"
  top: "res_stage_2_22_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_22_1"
  type: "BatchNorm"
  bottom: "res_stage_2_22_1"
  top: "res_stage_2_22_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_22_1"  
  type: "Scale"
  bottom: "res_stage_2_22_1"
  top: "res_stage_2_22_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_22_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_22_1_top"
  top: "res_stage_2_22_1_top"
}
layer {
  name: "res_stage_2_22_2"
  type: "Convolution"
  bottom: "res_stage_2_22_1_top"
  top: "res_stage_2_22_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_22_2"
  type: "BatchNorm"
  bottom: "res_stage_2_22_2"
  top: "res_stage_2_22_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_22_2"  
  type: "Scale"
  bottom: "res_stage_2_22_2"
  top: "res_stage_2_22_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_22_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_22_2_top"
  top: "res_stage_2_22_2_top"
}
layer {
  name: "res_stage_2_22_3"
  type: "Convolution"
  bottom: "res_stage_2_22_2_top"
  top: "res_stage_2_22_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_22_3"
  type: "BatchNorm"
  bottom: "res_stage_2_22_3"
  top: "res_stage_2_22_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_22_3"  
  type: "Scale"
  bottom: "res_stage_2_22_3"
  top: "res_stage_2_22_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_22"
  type: "Eltwise"
  bottom: "res_2_21"
  bottom: "res_stage_2_22_3_top"
  top: "res_2_22"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_22_relu"
  type: "ReLU"
  bottom: "res_2_22"
  top: "res_2_22"
}
layer {
  name: "res_stage_2_23_1"
  type: "Convolution"
  bottom: "res_2_22"
  top: "res_stage_2_23_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_23_1"
  type: "BatchNorm"
  bottom: "res_stage_2_23_1"
  top: "res_stage_2_23_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_23_1"  
  type: "Scale"
  bottom: "res_stage_2_23_1"
  top: "res_stage_2_23_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_23_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_23_1_top"
  top: "res_stage_2_23_1_top"
}
layer {
  name: "res_stage_2_23_2"
  type: "Convolution"
  bottom: "res_stage_2_23_1_top"
  top: "res_stage_2_23_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_23_2"
  type: "BatchNorm"
  bottom: "res_stage_2_23_2"
  top: "res_stage_2_23_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_23_2"  
  type: "Scale"
  bottom: "res_stage_2_23_2"
  top: "res_stage_2_23_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_23_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_23_2_top"
  top: "res_stage_2_23_2_top"
}
layer {
  name: "res_stage_2_23_3"
  type: "Convolution"
  bottom: "res_stage_2_23_2_top"
  top: "res_stage_2_23_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_23_3"
  type: "BatchNorm"
  bottom: "res_stage_2_23_3"
  top: "res_stage_2_23_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_23_3"  
  type: "Scale"
  bottom: "res_stage_2_23_3"
  top: "res_stage_2_23_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_23"
  type: "Eltwise"
  bottom: "res_2_22"
  bottom: "res_stage_2_23_3_top"
  top: "res_2_23"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_23_relu"
  type: "ReLU"
  bottom: "res_2_23"
  top: "res_2_23"
}
layer {
  name: "res_stage_2_24_1"
  type: "Convolution"
  bottom: "res_2_23"
  top: "res_stage_2_24_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_24_1"
  type: "BatchNorm"
  bottom: "res_stage_2_24_1"
  top: "res_stage_2_24_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_24_1"  
  type: "Scale"
  bottom: "res_stage_2_24_1"
  top: "res_stage_2_24_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_24_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_24_1_top"
  top: "res_stage_2_24_1_top"
}
layer {
  name: "res_stage_2_24_2"
  type: "Convolution"
  bottom: "res_stage_2_24_1_top"
  top: "res_stage_2_24_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_24_2"
  type: "BatchNorm"
  bottom: "res_stage_2_24_2"
  top: "res_stage_2_24_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_24_2"  
  type: "Scale"
  bottom: "res_stage_2_24_2"
  top: "res_stage_2_24_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_24_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_24_2_top"
  top: "res_stage_2_24_2_top"
}
layer {
  name: "res_stage_2_24_3"
  type: "Convolution"
  bottom: "res_stage_2_24_2_top"
  top: "res_stage_2_24_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_24_3"
  type: "BatchNorm"
  bottom: "res_stage_2_24_3"
  top: "res_stage_2_24_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_24_3"  
  type: "Scale"
  bottom: "res_stage_2_24_3"
  top: "res_stage_2_24_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_24"
  type: "Eltwise"
  bottom: "res_2_23"
  bottom: "res_stage_2_24_3_top"
  top: "res_2_24"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_24_relu"
  type: "ReLU"
  bottom: "res_2_24"
  top: "res_2_24"
}
layer {
  name: "res_stage_2_25_1"
  type: "Convolution"
  bottom: "res_2_24"
  top: "res_stage_2_25_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_25_1"
  type: "BatchNorm"
  bottom: "res_stage_2_25_1"
  top: "res_stage_2_25_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_25_1"  
  type: "Scale"
  bottom: "res_stage_2_25_1"
  top: "res_stage_2_25_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_25_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_25_1_top"
  top: "res_stage_2_25_1_top"
}
layer {
  name: "res_stage_2_25_2"
  type: "Convolution"
  bottom: "res_stage_2_25_1_top"
  top: "res_stage_2_25_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_25_2"
  type: "BatchNorm"
  bottom: "res_stage_2_25_2"
  top: "res_stage_2_25_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_25_2"  
  type: "Scale"
  bottom: "res_stage_2_25_2"
  top: "res_stage_2_25_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_25_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_25_2_top"
  top: "res_stage_2_25_2_top"
}
layer {
  name: "res_stage_2_25_3"
  type: "Convolution"
  bottom: "res_stage_2_25_2_top"
  top: "res_stage_2_25_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_25_3"
  type: "BatchNorm"
  bottom: "res_stage_2_25_3"
  top: "res_stage_2_25_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_25_3"  
  type: "Scale"
  bottom: "res_stage_2_25_3"
  top: "res_stage_2_25_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_25"
  type: "Eltwise"
  bottom: "res_2_24"
  bottom: "res_stage_2_25_3_top"
  top: "res_2_25"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_25_relu"
  type: "ReLU"
  bottom: "res_2_25"
  top: "res_2_25"
}
layer {
  name: "res_stage_2_26_1"
  type: "Convolution"
  bottom: "res_2_25"
  top: "res_stage_2_26_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_26_1"
  type: "BatchNorm"
  bottom: "res_stage_2_26_1"
  top: "res_stage_2_26_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_26_1"  
  type: "Scale"
  bottom: "res_stage_2_26_1"
  top: "res_stage_2_26_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_26_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_26_1_top"
  top: "res_stage_2_26_1_top"
}
layer {
  name: "res_stage_2_26_2"
  type: "Convolution"
  bottom: "res_stage_2_26_1_top"
  top: "res_stage_2_26_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_26_2"
  type: "BatchNorm"
  bottom: "res_stage_2_26_2"
  top: "res_stage_2_26_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_26_2"  
  type: "Scale"
  bottom: "res_stage_2_26_2"
  top: "res_stage_2_26_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_26_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_26_2_top"
  top: "res_stage_2_26_2_top"
}
layer {
  name: "res_stage_2_26_3"
  type: "Convolution"
  bottom: "res_stage_2_26_2_top"
  top: "res_stage_2_26_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_26_3"
  type: "BatchNorm"
  bottom: "res_stage_2_26_3"
  top: "res_stage_2_26_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_26_3"  
  type: "Scale"
  bottom: "res_stage_2_26_3"
  top: "res_stage_2_26_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_26"
  type: "Eltwise"
  bottom: "res_2_25"
  bottom: "res_stage_2_26_3_top"
  top: "res_2_26"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_26_relu"
  type: "ReLU"
  bottom: "res_2_26"
  top: "res_2_26"
}
layer {
  name: "res_stage_2_27_1"
  type: "Convolution"
  bottom: "res_2_26"
  top: "res_stage_2_27_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_27_1"
  type: "BatchNorm"
  bottom: "res_stage_2_27_1"
  top: "res_stage_2_27_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_27_1"  
  type: "Scale"
  bottom: "res_stage_2_27_1"
  top: "res_stage_2_27_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_27_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_27_1_top"
  top: "res_stage_2_27_1_top"
}
layer {
  name: "res_stage_2_27_2"
  type: "Convolution"
  bottom: "res_stage_2_27_1_top"
  top: "res_stage_2_27_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_27_2"
  type: "BatchNorm"
  bottom: "res_stage_2_27_2"
  top: "res_stage_2_27_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_27_2"  
  type: "Scale"
  bottom: "res_stage_2_27_2"
  top: "res_stage_2_27_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_27_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_27_2_top"
  top: "res_stage_2_27_2_top"
}
layer {
  name: "res_stage_2_27_3"
  type: "Convolution"
  bottom: "res_stage_2_27_2_top"
  top: "res_stage_2_27_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_27_3"
  type: "BatchNorm"
  bottom: "res_stage_2_27_3"
  top: "res_stage_2_27_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_27_3"  
  type: "Scale"
  bottom: "res_stage_2_27_3"
  top: "res_stage_2_27_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_27"
  type: "Eltwise"
  bottom: "res_2_26"
  bottom: "res_stage_2_27_3_top"
  top: "res_2_27"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_27_relu"
  type: "ReLU"
  bottom: "res_2_27"
  top: "res_2_27"
}
layer {
  name: "res_stage_2_28_1"
  type: "Convolution"
  bottom: "res_2_27"
  top: "res_stage_2_28_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_28_1"
  type: "BatchNorm"
  bottom: "res_stage_2_28_1"
  top: "res_stage_2_28_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_28_1"  
  type: "Scale"
  bottom: "res_stage_2_28_1"
  top: "res_stage_2_28_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_28_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_28_1_top"
  top: "res_stage_2_28_1_top"
}
layer {
  name: "res_stage_2_28_2"
  type: "Convolution"
  bottom: "res_stage_2_28_1_top"
  top: "res_stage_2_28_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_28_2"
  type: "BatchNorm"
  bottom: "res_stage_2_28_2"
  top: "res_stage_2_28_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_28_2"  
  type: "Scale"
  bottom: "res_stage_2_28_2"
  top: "res_stage_2_28_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_28_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_28_2_top"
  top: "res_stage_2_28_2_top"
}
layer {
  name: "res_stage_2_28_3"
  type: "Convolution"
  bottom: "res_stage_2_28_2_top"
  top: "res_stage_2_28_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_28_3"
  type: "BatchNorm"
  bottom: "res_stage_2_28_3"
  top: "res_stage_2_28_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_28_3"  
  type: "Scale"
  bottom: "res_stage_2_28_3"
  top: "res_stage_2_28_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_28"
  type: "Eltwise"
  bottom: "res_2_27"
  bottom: "res_stage_2_28_3_top"
  top: "res_2_28"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_28_relu"
  type: "ReLU"
  bottom: "res_2_28"
  top: "res_2_28"
}
layer {
  name: "res_stage_2_29_1"
  type: "Convolution"
  bottom: "res_2_28"
  top: "res_stage_2_29_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_29_1"
  type: "BatchNorm"
  bottom: "res_stage_2_29_1"
  top: "res_stage_2_29_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_29_1"  
  type: "Scale"
  bottom: "res_stage_2_29_1"
  top: "res_stage_2_29_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_29_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_29_1_top"
  top: "res_stage_2_29_1_top"
}
layer {
  name: "res_stage_2_29_2"
  type: "Convolution"
  bottom: "res_stage_2_29_1_top"
  top: "res_stage_2_29_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_29_2"
  type: "BatchNorm"
  bottom: "res_stage_2_29_2"
  top: "res_stage_2_29_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_29_2"  
  type: "Scale"
  bottom: "res_stage_2_29_2"
  top: "res_stage_2_29_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_29_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_29_2_top"
  top: "res_stage_2_29_2_top"
}
layer {
  name: "res_stage_2_29_3"
  type: "Convolution"
  bottom: "res_stage_2_29_2_top"
  top: "res_stage_2_29_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_29_3"
  type: "BatchNorm"
  bottom: "res_stage_2_29_3"
  top: "res_stage_2_29_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_29_3"  
  type: "Scale"
  bottom: "res_stage_2_29_3"
  top: "res_stage_2_29_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_29"
  type: "Eltwise"
  bottom: "res_2_28"
  bottom: "res_stage_2_29_3_top"
  top: "res_2_29"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_29_relu"
  type: "ReLU"
  bottom: "res_2_29"
  top: "res_2_29"
}
layer {
  name: "res_stage_2_30_1"
  type: "Convolution"
  bottom: "res_2_29"
  top: "res_stage_2_30_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_30_1"
  type: "BatchNorm"
  bottom: "res_stage_2_30_1"
  top: "res_stage_2_30_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_30_1"  
  type: "Scale"
  bottom: "res_stage_2_30_1"
  top: "res_stage_2_30_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_30_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_30_1_top"
  top: "res_stage_2_30_1_top"
}
layer {
  name: "res_stage_2_30_2"
  type: "Convolution"
  bottom: "res_stage_2_30_1_top"
  top: "res_stage_2_30_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_30_2"
  type: "BatchNorm"
  bottom: "res_stage_2_30_2"
  top: "res_stage_2_30_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_30_2"  
  type: "Scale"
  bottom: "res_stage_2_30_2"
  top: "res_stage_2_30_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_30_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_30_2_top"
  top: "res_stage_2_30_2_top"
}
layer {
  name: "res_stage_2_30_3"
  type: "Convolution"
  bottom: "res_stage_2_30_2_top"
  top: "res_stage_2_30_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_30_3"
  type: "BatchNorm"
  bottom: "res_stage_2_30_3"
  top: "res_stage_2_30_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_30_3"  
  type: "Scale"
  bottom: "res_stage_2_30_3"
  top: "res_stage_2_30_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_30"
  type: "Eltwise"
  bottom: "res_2_29"
  bottom: "res_stage_2_30_3_top"
  top: "res_2_30"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_30_relu"
  type: "ReLU"
  bottom: "res_2_30"
  top: "res_2_30"
}
layer {
  name: "res_stage_2_31_1"
  type: "Convolution"
  bottom: "res_2_30"
  top: "res_stage_2_31_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_31_1"
  type: "BatchNorm"
  bottom: "res_stage_2_31_1"
  top: "res_stage_2_31_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_31_1"  
  type: "Scale"
  bottom: "res_stage_2_31_1"
  top: "res_stage_2_31_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_31_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_31_1_top"
  top: "res_stage_2_31_1_top"
}
layer {
  name: "res_stage_2_31_2"
  type: "Convolution"
  bottom: "res_stage_2_31_1_top"
  top: "res_stage_2_31_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_31_2"
  type: "BatchNorm"
  bottom: "res_stage_2_31_2"
  top: "res_stage_2_31_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_31_2"  
  type: "Scale"
  bottom: "res_stage_2_31_2"
  top: "res_stage_2_31_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_31_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_31_2_top"
  top: "res_stage_2_31_2_top"
}
layer {
  name: "res_stage_2_31_3"
  type: "Convolution"
  bottom: "res_stage_2_31_2_top"
  top: "res_stage_2_31_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_31_3"
  type: "BatchNorm"
  bottom: "res_stage_2_31_3"
  top: "res_stage_2_31_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_31_3"  
  type: "Scale"
  bottom: "res_stage_2_31_3"
  top: "res_stage_2_31_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_31"
  type: "Eltwise"
  bottom: "res_2_30"
  bottom: "res_stage_2_31_3_top"
  top: "res_2_31"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_31_relu"
  type: "ReLU"
  bottom: "res_2_31"
  top: "res_2_31"
}
layer {
  name: "res_stage_2_32_1"
  type: "Convolution"
  bottom: "res_2_31"
  top: "res_stage_2_32_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_32_1"
  type: "BatchNorm"
  bottom: "res_stage_2_32_1"
  top: "res_stage_2_32_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_32_1"  
  type: "Scale"
  bottom: "res_stage_2_32_1"
  top: "res_stage_2_32_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_32_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_32_1_top"
  top: "res_stage_2_32_1_top"
}
layer {
  name: "res_stage_2_32_2"
  type: "Convolution"
  bottom: "res_stage_2_32_1_top"
  top: "res_stage_2_32_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_32_2"
  type: "BatchNorm"
  bottom: "res_stage_2_32_2"
  top: "res_stage_2_32_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_32_2"  
  type: "Scale"
  bottom: "res_stage_2_32_2"
  top: "res_stage_2_32_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_32_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_32_2_top"
  top: "res_stage_2_32_2_top"
}
layer {
  name: "res_stage_2_32_3"
  type: "Convolution"
  bottom: "res_stage_2_32_2_top"
  top: "res_stage_2_32_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_32_3"
  type: "BatchNorm"
  bottom: "res_stage_2_32_3"
  top: "res_stage_2_32_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_32_3"  
  type: "Scale"
  bottom: "res_stage_2_32_3"
  top: "res_stage_2_32_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_32"
  type: "Eltwise"
  bottom: "res_2_31"
  bottom: "res_stage_2_32_3_top"
  top: "res_2_32"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_32_relu"
  type: "ReLU"
  bottom: "res_2_32"
  top: "res_2_32"
}
layer {
  name: "res_stage_2_33_1"
  type: "Convolution"
  bottom: "res_2_32"
  top: "res_stage_2_33_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_33_1"
  type: "BatchNorm"
  bottom: "res_stage_2_33_1"
  top: "res_stage_2_33_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_33_1"  
  type: "Scale"
  bottom: "res_stage_2_33_1"
  top: "res_stage_2_33_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_33_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_33_1_top"
  top: "res_stage_2_33_1_top"
}
layer {
  name: "res_stage_2_33_2"
  type: "Convolution"
  bottom: "res_stage_2_33_1_top"
  top: "res_stage_2_33_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_33_2"
  type: "BatchNorm"
  bottom: "res_stage_2_33_2"
  top: "res_stage_2_33_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_33_2"  
  type: "Scale"
  bottom: "res_stage_2_33_2"
  top: "res_stage_2_33_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_33_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_33_2_top"
  top: "res_stage_2_33_2_top"
}
layer {
  name: "res_stage_2_33_3"
  type: "Convolution"
  bottom: "res_stage_2_33_2_top"
  top: "res_stage_2_33_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_33_3"
  type: "BatchNorm"
  bottom: "res_stage_2_33_3"
  top: "res_stage_2_33_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_33_3"  
  type: "Scale"
  bottom: "res_stage_2_33_3"
  top: "res_stage_2_33_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_33"
  type: "Eltwise"
  bottom: "res_2_32"
  bottom: "res_stage_2_33_3_top"
  top: "res_2_33"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_33_relu"
  type: "ReLU"
  bottom: "res_2_33"
  top: "res_2_33"
}
layer {
  name: "res_stage_2_34_1"
  type: "Convolution"
  bottom: "res_2_33"
  top: "res_stage_2_34_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_34_1"
  type: "BatchNorm"
  bottom: "res_stage_2_34_1"
  top: "res_stage_2_34_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_34_1"  
  type: "Scale"
  bottom: "res_stage_2_34_1"
  top: "res_stage_2_34_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_34_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_34_1_top"
  top: "res_stage_2_34_1_top"
}
layer {
  name: "res_stage_2_34_2"
  type: "Convolution"
  bottom: "res_stage_2_34_1_top"
  top: "res_stage_2_34_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_34_2"
  type: "BatchNorm"
  bottom: "res_stage_2_34_2"
  top: "res_stage_2_34_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_34_2"  
  type: "Scale"
  bottom: "res_stage_2_34_2"
  top: "res_stage_2_34_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_34_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_34_2_top"
  top: "res_stage_2_34_2_top"
}
layer {
  name: "res_stage_2_34_3"
  type: "Convolution"
  bottom: "res_stage_2_34_2_top"
  top: "res_stage_2_34_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_34_3"
  type: "BatchNorm"
  bottom: "res_stage_2_34_3"
  top: "res_stage_2_34_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_34_3"  
  type: "Scale"
  bottom: "res_stage_2_34_3"
  top: "res_stage_2_34_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_34"
  type: "Eltwise"
  bottom: "res_2_33"
  bottom: "res_stage_2_34_3_top"
  top: "res_2_34"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_34_relu"
  type: "ReLU"
  bottom: "res_2_34"
  top: "res_2_34"
}
layer {
  name: "res_stage_2_35_1"
  type: "Convolution"
  bottom: "res_2_34"
  top: "res_stage_2_35_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_35_1"
  type: "BatchNorm"
  bottom: "res_stage_2_35_1"
  top: "res_stage_2_35_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_35_1"  
  type: "Scale"
  bottom: "res_stage_2_35_1"
  top: "res_stage_2_35_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_35_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_35_1_top"
  top: "res_stage_2_35_1_top"
}
layer {
  name: "res_stage_2_35_2"
  type: "Convolution"
  bottom: "res_stage_2_35_1_top"
  top: "res_stage_2_35_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_35_2"
  type: "BatchNorm"
  bottom: "res_stage_2_35_2"
  top: "res_stage_2_35_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_35_2"  
  type: "Scale"
  bottom: "res_stage_2_35_2"
  top: "res_stage_2_35_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_35_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_35_2_top"
  top: "res_stage_2_35_2_top"
}
layer {
  name: "res_stage_2_35_3"
  type: "Convolution"
  bottom: "res_stage_2_35_2_top"
  top: "res_stage_2_35_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_35_3"
  type: "BatchNorm"
  bottom: "res_stage_2_35_3"
  top: "res_stage_2_35_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_35_3"  
  type: "Scale"
  bottom: "res_stage_2_35_3"
  top: "res_stage_2_35_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_35"
  type: "Eltwise"
  bottom: "res_2_34"
  bottom: "res_stage_2_35_3_top"
  top: "res_2_35"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_35_relu"
  type: "ReLU"
  bottom: "res_2_35"
  top: "res_2_35"
}
layer {
  name: "res_stage_2_36_1"
  type: "Convolution"
  bottom: "res_2_35"
  top: "res_stage_2_36_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_36_1"
  type: "BatchNorm"
  bottom: "res_stage_2_36_1"
  top: "res_stage_2_36_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_36_1"  
  type: "Scale"
  bottom: "res_stage_2_36_1"
  top: "res_stage_2_36_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_36_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_36_1_top"
  top: "res_stage_2_36_1_top"
}
layer {
  name: "res_stage_2_36_2"
  type: "Convolution"
  bottom: "res_stage_2_36_1_top"
  top: "res_stage_2_36_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_36_2"
  type: "BatchNorm"
  bottom: "res_stage_2_36_2"
  top: "res_stage_2_36_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_36_2"  
  type: "Scale"
  bottom: "res_stage_2_36_2"
  top: "res_stage_2_36_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_36_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_36_2_top"
  top: "res_stage_2_36_2_top"
}
layer {
  name: "res_stage_2_36_3"
  type: "Convolution"
  bottom: "res_stage_2_36_2_top"
  top: "res_stage_2_36_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_36_3"
  type: "BatchNorm"
  bottom: "res_stage_2_36_3"
  top: "res_stage_2_36_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_36_3"  
  type: "Scale"
  bottom: "res_stage_2_36_3"
  top: "res_stage_2_36_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_36"
  type: "Eltwise"
  bottom: "res_2_35"
  bottom: "res_stage_2_36_3_top"
  top: "res_2_36"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_36_relu"
  type: "ReLU"
  bottom: "res_2_36"
  top: "res_2_36"
}
layer {
  name: "res_stage_2_37_1"
  type: "Convolution"
  bottom: "res_2_36"
  top: "res_stage_2_37_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_37_1"
  type: "BatchNorm"
  bottom: "res_stage_2_37_1"
  top: "res_stage_2_37_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_37_1"  
  type: "Scale"
  bottom: "res_stage_2_37_1"
  top: "res_stage_2_37_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_37_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_37_1_top"
  top: "res_stage_2_37_1_top"
}
layer {
  name: "res_stage_2_37_2"
  type: "Convolution"
  bottom: "res_stage_2_37_1_top"
  top: "res_stage_2_37_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_37_2"
  type: "BatchNorm"
  bottom: "res_stage_2_37_2"
  top: "res_stage_2_37_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_37_2"  
  type: "Scale"
  bottom: "res_stage_2_37_2"
  top: "res_stage_2_37_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_37_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_37_2_top"
  top: "res_stage_2_37_2_top"
}
layer {
  name: "res_stage_2_37_3"
  type: "Convolution"
  bottom: "res_stage_2_37_2_top"
  top: "res_stage_2_37_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_37_3"
  type: "BatchNorm"
  bottom: "res_stage_2_37_3"
  top: "res_stage_2_37_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_37_3"  
  type: "Scale"
  bottom: "res_stage_2_37_3"
  top: "res_stage_2_37_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_37"
  type: "Eltwise"
  bottom: "res_2_36"
  bottom: "res_stage_2_37_3_top"
  top: "res_2_37"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_37_relu"
  type: "ReLU"
  bottom: "res_2_37"
  top: "res_2_37"
}
layer {
  name: "res_stage_2_38_1"
  type: "Convolution"
  bottom: "res_2_37"
  top: "res_stage_2_38_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_38_1"
  type: "BatchNorm"
  bottom: "res_stage_2_38_1"
  top: "res_stage_2_38_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_38_1"  
  type: "Scale"
  bottom: "res_stage_2_38_1"
  top: "res_stage_2_38_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_38_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_38_1_top"
  top: "res_stage_2_38_1_top"
}
layer {
  name: "res_stage_2_38_2"
  type: "Convolution"
  bottom: "res_stage_2_38_1_top"
  top: "res_stage_2_38_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_38_2"
  type: "BatchNorm"
  bottom: "res_stage_2_38_2"
  top: "res_stage_2_38_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_38_2"  
  type: "Scale"
  bottom: "res_stage_2_38_2"
  top: "res_stage_2_38_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_38_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_38_2_top"
  top: "res_stage_2_38_2_top"
}
layer {
  name: "res_stage_2_38_3"
  type: "Convolution"
  bottom: "res_stage_2_38_2_top"
  top: "res_stage_2_38_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_38_3"
  type: "BatchNorm"
  bottom: "res_stage_2_38_3"
  top: "res_stage_2_38_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_38_3"  
  type: "Scale"
  bottom: "res_stage_2_38_3"
  top: "res_stage_2_38_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_38"
  type: "Eltwise"
  bottom: "res_2_37"
  bottom: "res_stage_2_38_3_top"
  top: "res_2_38"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_38_relu"
  type: "ReLU"
  bottom: "res_2_38"
  top: "res_2_38"
}
layer {
  name: "res_stage_2_39_1"
  type: "Convolution"
  bottom: "res_2_38"
  top: "res_stage_2_39_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_39_1"
  type: "BatchNorm"
  bottom: "res_stage_2_39_1"
  top: "res_stage_2_39_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_39_1"  
  type: "Scale"
  bottom: "res_stage_2_39_1"
  top: "res_stage_2_39_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_39_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_39_1_top"
  top: "res_stage_2_39_1_top"
}
layer {
  name: "res_stage_2_39_2"
  type: "Convolution"
  bottom: "res_stage_2_39_1_top"
  top: "res_stage_2_39_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_39_2"
  type: "BatchNorm"
  bottom: "res_stage_2_39_2"
  top: "res_stage_2_39_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_39_2"  
  type: "Scale"
  bottom: "res_stage_2_39_2"
  top: "res_stage_2_39_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_39_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_39_2_top"
  top: "res_stage_2_39_2_top"
}
layer {
  name: "res_stage_2_39_3"
  type: "Convolution"
  bottom: "res_stage_2_39_2_top"
  top: "res_stage_2_39_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_39_3"
  type: "BatchNorm"
  bottom: "res_stage_2_39_3"
  top: "res_stage_2_39_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_39_3"  
  type: "Scale"
  bottom: "res_stage_2_39_3"
  top: "res_stage_2_39_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_39"
  type: "Eltwise"
  bottom: "res_2_38"
  bottom: "res_stage_2_39_3_top"
  top: "res_2_39"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_39_relu"
  type: "ReLU"
  bottom: "res_2_39"
  top: "res_2_39"
}
layer {
  name: "res_stage_2_40_1"
  type: "Convolution"
  bottom: "res_2_39"
  top: "res_stage_2_40_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_40_1"
  type: "BatchNorm"
  bottom: "res_stage_2_40_1"
  top: "res_stage_2_40_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_40_1"  
  type: "Scale"
  bottom: "res_stage_2_40_1"
  top: "res_stage_2_40_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_40_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_40_1_top"
  top: "res_stage_2_40_1_top"
}
layer {
  name: "res_stage_2_40_2"
  type: "Convolution"
  bottom: "res_stage_2_40_1_top"
  top: "res_stage_2_40_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_40_2"
  type: "BatchNorm"
  bottom: "res_stage_2_40_2"
  top: "res_stage_2_40_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_40_2"  
  type: "Scale"
  bottom: "res_stage_2_40_2"
  top: "res_stage_2_40_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_40_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_40_2_top"
  top: "res_stage_2_40_2_top"
}
layer {
  name: "res_stage_2_40_3"
  type: "Convolution"
  bottom: "res_stage_2_40_2_top"
  top: "res_stage_2_40_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_40_3"
  type: "BatchNorm"
  bottom: "res_stage_2_40_3"
  top: "res_stage_2_40_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_40_3"  
  type: "Scale"
  bottom: "res_stage_2_40_3"
  top: "res_stage_2_40_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_40"
  type: "Eltwise"
  bottom: "res_2_39"
  bottom: "res_stage_2_40_3_top"
  top: "res_2_40"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_40_relu"
  type: "ReLU"
  bottom: "res_2_40"
  top: "res_2_40"
}
layer {
  name: "res_stage_2_41_1"
  type: "Convolution"
  bottom: "res_2_40"
  top: "res_stage_2_41_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_41_1"
  type: "BatchNorm"
  bottom: "res_stage_2_41_1"
  top: "res_stage_2_41_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_41_1"  
  type: "Scale"
  bottom: "res_stage_2_41_1"
  top: "res_stage_2_41_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_41_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_41_1_top"
  top: "res_stage_2_41_1_top"
}
layer {
  name: "res_stage_2_41_2"
  type: "Convolution"
  bottom: "res_stage_2_41_1_top"
  top: "res_stage_2_41_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_41_2"
  type: "BatchNorm"
  bottom: "res_stage_2_41_2"
  top: "res_stage_2_41_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_41_2"  
  type: "Scale"
  bottom: "res_stage_2_41_2"
  top: "res_stage_2_41_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_41_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_41_2_top"
  top: "res_stage_2_41_2_top"
}
layer {
  name: "res_stage_2_41_3"
  type: "Convolution"
  bottom: "res_stage_2_41_2_top"
  top: "res_stage_2_41_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_41_3"
  type: "BatchNorm"
  bottom: "res_stage_2_41_3"
  top: "res_stage_2_41_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_41_3"  
  type: "Scale"
  bottom: "res_stage_2_41_3"
  top: "res_stage_2_41_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_41"
  type: "Eltwise"
  bottom: "res_2_40"
  bottom: "res_stage_2_41_3_top"
  top: "res_2_41"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_41_relu"
  type: "ReLU"
  bottom: "res_2_41"
  top: "res_2_41"
}
layer {
  name: "res_stage_2_42_1"
  type: "Convolution"
  bottom: "res_2_41"
  top: "res_stage_2_42_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_42_1"
  type: "BatchNorm"
  bottom: "res_stage_2_42_1"
  top: "res_stage_2_42_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_42_1"  
  type: "Scale"
  bottom: "res_stage_2_42_1"
  top: "res_stage_2_42_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_42_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_42_1_top"
  top: "res_stage_2_42_1_top"
}
layer {
  name: "res_stage_2_42_2"
  type: "Convolution"
  bottom: "res_stage_2_42_1_top"
  top: "res_stage_2_42_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_42_2"
  type: "BatchNorm"
  bottom: "res_stage_2_42_2"
  top: "res_stage_2_42_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_42_2"  
  type: "Scale"
  bottom: "res_stage_2_42_2"
  top: "res_stage_2_42_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_42_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_42_2_top"
  top: "res_stage_2_42_2_top"
}
layer {
  name: "res_stage_2_42_3"
  type: "Convolution"
  bottom: "res_stage_2_42_2_top"
  top: "res_stage_2_42_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_42_3"
  type: "BatchNorm"
  bottom: "res_stage_2_42_3"
  top: "res_stage_2_42_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_42_3"  
  type: "Scale"
  bottom: "res_stage_2_42_3"
  top: "res_stage_2_42_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_42"
  type: "Eltwise"
  bottom: "res_2_41"
  bottom: "res_stage_2_42_3_top"
  top: "res_2_42"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_42_relu"
  type: "ReLU"
  bottom: "res_2_42"
  top: "res_2_42"
}
layer {
  name: "res_stage_2_43_1"
  type: "Convolution"
  bottom: "res_2_42"
  top: "res_stage_2_43_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_43_1"
  type: "BatchNorm"
  bottom: "res_stage_2_43_1"
  top: "res_stage_2_43_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_43_1"  
  type: "Scale"
  bottom: "res_stage_2_43_1"
  top: "res_stage_2_43_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_43_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_43_1_top"
  top: "res_stage_2_43_1_top"
}
layer {
  name: "res_stage_2_43_2"
  type: "Convolution"
  bottom: "res_stage_2_43_1_top"
  top: "res_stage_2_43_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_43_2"
  type: "BatchNorm"
  bottom: "res_stage_2_43_2"
  top: "res_stage_2_43_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_43_2"  
  type: "Scale"
  bottom: "res_stage_2_43_2"
  top: "res_stage_2_43_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_43_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_43_2_top"
  top: "res_stage_2_43_2_top"
}
layer {
  name: "res_stage_2_43_3"
  type: "Convolution"
  bottom: "res_stage_2_43_2_top"
  top: "res_stage_2_43_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_43_3"
  type: "BatchNorm"
  bottom: "res_stage_2_43_3"
  top: "res_stage_2_43_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_43_3"  
  type: "Scale"
  bottom: "res_stage_2_43_3"
  top: "res_stage_2_43_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_43"
  type: "Eltwise"
  bottom: "res_2_42"
  bottom: "res_stage_2_43_3_top"
  top: "res_2_43"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_43_relu"
  type: "ReLU"
  bottom: "res_2_43"
  top: "res_2_43"
}
layer {
  name: "res_stage_2_44_1"
  type: "Convolution"
  bottom: "res_2_43"
  top: "res_stage_2_44_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_44_1"
  type: "BatchNorm"
  bottom: "res_stage_2_44_1"
  top: "res_stage_2_44_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_44_1"  
  type: "Scale"
  bottom: "res_stage_2_44_1"
  top: "res_stage_2_44_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_44_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_44_1_top"
  top: "res_stage_2_44_1_top"
}
layer {
  name: "res_stage_2_44_2"
  type: "Convolution"
  bottom: "res_stage_2_44_1_top"
  top: "res_stage_2_44_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_44_2"
  type: "BatchNorm"
  bottom: "res_stage_2_44_2"
  top: "res_stage_2_44_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_44_2"  
  type: "Scale"
  bottom: "res_stage_2_44_2"
  top: "res_stage_2_44_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_44_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_44_2_top"
  top: "res_stage_2_44_2_top"
}
layer {
  name: "res_stage_2_44_3"
  type: "Convolution"
  bottom: "res_stage_2_44_2_top"
  top: "res_stage_2_44_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_44_3"
  type: "BatchNorm"
  bottom: "res_stage_2_44_3"
  top: "res_stage_2_44_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_44_3"  
  type: "Scale"
  bottom: "res_stage_2_44_3"
  top: "res_stage_2_44_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_44"
  type: "Eltwise"
  bottom: "res_2_43"
  bottom: "res_stage_2_44_3_top"
  top: "res_2_44"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_44_relu"
  type: "ReLU"
  bottom: "res_2_44"
  top: "res_2_44"
}
layer {
  name: "res_stage_2_45_1"
  type: "Convolution"
  bottom: "res_2_44"
  top: "res_stage_2_45_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_45_1"
  type: "BatchNorm"
  bottom: "res_stage_2_45_1"
  top: "res_stage_2_45_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_45_1"  
  type: "Scale"
  bottom: "res_stage_2_45_1"
  top: "res_stage_2_45_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_45_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_45_1_top"
  top: "res_stage_2_45_1_top"
}
layer {
  name: "res_stage_2_45_2"
  type: "Convolution"
  bottom: "res_stage_2_45_1_top"
  top: "res_stage_2_45_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_45_2"
  type: "BatchNorm"
  bottom: "res_stage_2_45_2"
  top: "res_stage_2_45_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_45_2"  
  type: "Scale"
  bottom: "res_stage_2_45_2"
  top: "res_stage_2_45_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_45_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_45_2_top"
  top: "res_stage_2_45_2_top"
}
layer {
  name: "res_stage_2_45_3"
  type: "Convolution"
  bottom: "res_stage_2_45_2_top"
  top: "res_stage_2_45_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_45_3"
  type: "BatchNorm"
  bottom: "res_stage_2_45_3"
  top: "res_stage_2_45_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_45_3"  
  type: "Scale"
  bottom: "res_stage_2_45_3"
  top: "res_stage_2_45_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_45"
  type: "Eltwise"
  bottom: "res_2_44"
  bottom: "res_stage_2_45_3_top"
  top: "res_2_45"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_45_relu"
  type: "ReLU"
  bottom: "res_2_45"
  top: "res_2_45"
}
layer {
  name: "res_stage_2_46_1"
  type: "Convolution"
  bottom: "res_2_45"
  top: "res_stage_2_46_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_46_1"
  type: "BatchNorm"
  bottom: "res_stage_2_46_1"
  top: "res_stage_2_46_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_46_1"  
  type: "Scale"
  bottom: "res_stage_2_46_1"
  top: "res_stage_2_46_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_46_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_46_1_top"
  top: "res_stage_2_46_1_top"
}
layer {
  name: "res_stage_2_46_2"
  type: "Convolution"
  bottom: "res_stage_2_46_1_top"
  top: "res_stage_2_46_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_46_2"
  type: "BatchNorm"
  bottom: "res_stage_2_46_2"
  top: "res_stage_2_46_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_46_2"  
  type: "Scale"
  bottom: "res_stage_2_46_2"
  top: "res_stage_2_46_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_46_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_46_2_top"
  top: "res_stage_2_46_2_top"
}
layer {
  name: "res_stage_2_46_3"
  type: "Convolution"
  bottom: "res_stage_2_46_2_top"
  top: "res_stage_2_46_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_46_3"
  type: "BatchNorm"
  bottom: "res_stage_2_46_3"
  top: "res_stage_2_46_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_46_3"  
  type: "Scale"
  bottom: "res_stage_2_46_3"
  top: "res_stage_2_46_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_46"
  type: "Eltwise"
  bottom: "res_2_45"
  bottom: "res_stage_2_46_3_top"
  top: "res_2_46"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_46_relu"
  type: "ReLU"
  bottom: "res_2_46"
  top: "res_2_46"
}
layer {
  name: "res_stage_2_47_1"
  type: "Convolution"
  bottom: "res_2_46"
  top: "res_stage_2_47_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_47_1"
  type: "BatchNorm"
  bottom: "res_stage_2_47_1"
  top: "res_stage_2_47_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_47_1"  
  type: "Scale"
  bottom: "res_stage_2_47_1"
  top: "res_stage_2_47_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_47_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_47_1_top"
  top: "res_stage_2_47_1_top"
}
layer {
  name: "res_stage_2_47_2"
  type: "Convolution"
  bottom: "res_stage_2_47_1_top"
  top: "res_stage_2_47_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_47_2"
  type: "BatchNorm"
  bottom: "res_stage_2_47_2"
  top: "res_stage_2_47_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_47_2"  
  type: "Scale"
  bottom: "res_stage_2_47_2"
  top: "res_stage_2_47_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_47_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_47_2_top"
  top: "res_stage_2_47_2_top"
}
layer {
  name: "res_stage_2_47_3"
  type: "Convolution"
  bottom: "res_stage_2_47_2_top"
  top: "res_stage_2_47_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_47_3"
  type: "BatchNorm"
  bottom: "res_stage_2_47_3"
  top: "res_stage_2_47_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_47_3"  
  type: "Scale"
  bottom: "res_stage_2_47_3"
  top: "res_stage_2_47_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_47"
  type: "Eltwise"
  bottom: "res_2_46"
  bottom: "res_stage_2_47_3_top"
  top: "res_2_47"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_47_relu"
  type: "ReLU"
  bottom: "res_2_47"
  top: "res_2_47"
}
layer {
  name: "res_stage_2_48_1"
  type: "Convolution"
  bottom: "res_2_47"
  top: "res_stage_2_48_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_48_1"
  type: "BatchNorm"
  bottom: "res_stage_2_48_1"
  top: "res_stage_2_48_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_48_1"  
  type: "Scale"
  bottom: "res_stage_2_48_1"
  top: "res_stage_2_48_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_48_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_48_1_top"
  top: "res_stage_2_48_1_top"
}
layer {
  name: "res_stage_2_48_2"
  type: "Convolution"
  bottom: "res_stage_2_48_1_top"
  top: "res_stage_2_48_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_48_2"
  type: "BatchNorm"
  bottom: "res_stage_2_48_2"
  top: "res_stage_2_48_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_48_2"  
  type: "Scale"
  bottom: "res_stage_2_48_2"
  top: "res_stage_2_48_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_48_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_48_2_top"
  top: "res_stage_2_48_2_top"
}
layer {
  name: "res_stage_2_48_3"
  type: "Convolution"
  bottom: "res_stage_2_48_2_top"
  top: "res_stage_2_48_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_48_3"
  type: "BatchNorm"
  bottom: "res_stage_2_48_3"
  top: "res_stage_2_48_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_48_3"  
  type: "Scale"
  bottom: "res_stage_2_48_3"
  top: "res_stage_2_48_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_48"
  type: "Eltwise"
  bottom: "res_2_47"
  bottom: "res_stage_2_48_3_top"
  top: "res_2_48"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_48_relu"
  type: "ReLU"
  bottom: "res_2_48"
  top: "res_2_48"
}
layer {
  name: "res_stage_2_49_1"
  type: "Convolution"
  bottom: "res_2_48"
  top: "res_stage_2_49_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_49_1"
  type: "BatchNorm"
  bottom: "res_stage_2_49_1"
  top: "res_stage_2_49_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_49_1"  
  type: "Scale"
  bottom: "res_stage_2_49_1"
  top: "res_stage_2_49_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_49_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_49_1_top"
  top: "res_stage_2_49_1_top"
}
layer {
  name: "res_stage_2_49_2"
  type: "Convolution"
  bottom: "res_stage_2_49_1_top"
  top: "res_stage_2_49_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_49_2"
  type: "BatchNorm"
  bottom: "res_stage_2_49_2"
  top: "res_stage_2_49_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_49_2"  
  type: "Scale"
  bottom: "res_stage_2_49_2"
  top: "res_stage_2_49_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_49_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_49_2_top"
  top: "res_stage_2_49_2_top"
}
layer {
  name: "res_stage_2_49_3"
  type: "Convolution"
  bottom: "res_stage_2_49_2_top"
  top: "res_stage_2_49_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_49_3"
  type: "BatchNorm"
  bottom: "res_stage_2_49_3"
  top: "res_stage_2_49_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_49_3"  
  type: "Scale"
  bottom: "res_stage_2_49_3"
  top: "res_stage_2_49_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_49"
  type: "Eltwise"
  bottom: "res_2_48"
  bottom: "res_stage_2_49_3_top"
  top: "res_2_49"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_49_relu"
  type: "ReLU"
  bottom: "res_2_49"
  top: "res_2_49"
}
layer {
  name: "res_stage_2_50_1"
  type: "Convolution"
  bottom: "res_2_49"
  top: "res_stage_2_50_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_50_1"
  type: "BatchNorm"
  bottom: "res_stage_2_50_1"
  top: "res_stage_2_50_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_50_1"  
  type: "Scale"
  bottom: "res_stage_2_50_1"
  top: "res_stage_2_50_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_50_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_50_1_top"
  top: "res_stage_2_50_1_top"
}
layer {
  name: "res_stage_2_50_2"
  type: "Convolution"
  bottom: "res_stage_2_50_1_top"
  top: "res_stage_2_50_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_50_2"
  type: "BatchNorm"
  bottom: "res_stage_2_50_2"
  top: "res_stage_2_50_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_50_2"  
  type: "Scale"
  bottom: "res_stage_2_50_2"
  top: "res_stage_2_50_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_50_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_50_2_top"
  top: "res_stage_2_50_2_top"
}
layer {
  name: "res_stage_2_50_3"
  type: "Convolution"
  bottom: "res_stage_2_50_2_top"
  top: "res_stage_2_50_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_50_3"
  type: "BatchNorm"
  bottom: "res_stage_2_50_3"
  top: "res_stage_2_50_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_50_3"  
  type: "Scale"
  bottom: "res_stage_2_50_3"
  top: "res_stage_2_50_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_50"
  type: "Eltwise"
  bottom: "res_2_49"
  bottom: "res_stage_2_50_3_top"
  top: "res_2_50"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_50_relu"
  type: "ReLU"
  bottom: "res_2_50"
  top: "res_2_50"
}
layer {
  name: "res_stage_2_51_1"
  type: "Convolution"
  bottom: "res_2_50"
  top: "res_stage_2_51_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_51_1"
  type: "BatchNorm"
  bottom: "res_stage_2_51_1"
  top: "res_stage_2_51_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_51_1"  
  type: "Scale"
  bottom: "res_stage_2_51_1"
  top: "res_stage_2_51_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_51_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_51_1_top"
  top: "res_stage_2_51_1_top"
}
layer {
  name: "res_stage_2_51_2"
  type: "Convolution"
  bottom: "res_stage_2_51_1_top"
  top: "res_stage_2_51_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_51_2"
  type: "BatchNorm"
  bottom: "res_stage_2_51_2"
  top: "res_stage_2_51_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_51_2"  
  type: "Scale"
  bottom: "res_stage_2_51_2"
  top: "res_stage_2_51_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_51_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_51_2_top"
  top: "res_stage_2_51_2_top"
}
layer {
  name: "res_stage_2_51_3"
  type: "Convolution"
  bottom: "res_stage_2_51_2_top"
  top: "res_stage_2_51_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_51_3"
  type: "BatchNorm"
  bottom: "res_stage_2_51_3"
  top: "res_stage_2_51_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_51_3"  
  type: "Scale"
  bottom: "res_stage_2_51_3"
  top: "res_stage_2_51_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_51"
  type: "Eltwise"
  bottom: "res_2_50"
  bottom: "res_stage_2_51_3_top"
  top: "res_2_51"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_51_relu"
  type: "ReLU"
  bottom: "res_2_51"
  top: "res_2_51"
}
layer {
  name: "res_stage_2_52_1"
  type: "Convolution"
  bottom: "res_2_51"
  top: "res_stage_2_52_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_52_1"
  type: "BatchNorm"
  bottom: "res_stage_2_52_1"
  top: "res_stage_2_52_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_52_1"  
  type: "Scale"
  bottom: "res_stage_2_52_1"
  top: "res_stage_2_52_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_52_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_52_1_top"
  top: "res_stage_2_52_1_top"
}
layer {
  name: "res_stage_2_52_2"
  type: "Convolution"
  bottom: "res_stage_2_52_1_top"
  top: "res_stage_2_52_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_52_2"
  type: "BatchNorm"
  bottom: "res_stage_2_52_2"
  top: "res_stage_2_52_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_52_2"  
  type: "Scale"
  bottom: "res_stage_2_52_2"
  top: "res_stage_2_52_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_52_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_52_2_top"
  top: "res_stage_2_52_2_top"
}
layer {
  name: "res_stage_2_52_3"
  type: "Convolution"
  bottom: "res_stage_2_52_2_top"
  top: "res_stage_2_52_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_52_3"
  type: "BatchNorm"
  bottom: "res_stage_2_52_3"
  top: "res_stage_2_52_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_52_3"  
  type: "Scale"
  bottom: "res_stage_2_52_3"
  top: "res_stage_2_52_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_52"
  type: "Eltwise"
  bottom: "res_2_51"
  bottom: "res_stage_2_52_3_top"
  top: "res_2_52"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_52_relu"
  type: "ReLU"
  bottom: "res_2_52"
  top: "res_2_52"
}
layer {
  name: "res_stage_2_53_1"
  type: "Convolution"
  bottom: "res_2_52"
  top: "res_stage_2_53_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_53_1"
  type: "BatchNorm"
  bottom: "res_stage_2_53_1"
  top: "res_stage_2_53_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_53_1"  
  type: "Scale"
  bottom: "res_stage_2_53_1"
  top: "res_stage_2_53_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_53_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_53_1_top"
  top: "res_stage_2_53_1_top"
}
layer {
  name: "res_stage_2_53_2"
  type: "Convolution"
  bottom: "res_stage_2_53_1_top"
  top: "res_stage_2_53_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_53_2"
  type: "BatchNorm"
  bottom: "res_stage_2_53_2"
  top: "res_stage_2_53_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_53_2"  
  type: "Scale"
  bottom: "res_stage_2_53_2"
  top: "res_stage_2_53_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_53_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_53_2_top"
  top: "res_stage_2_53_2_top"
}
layer {
  name: "res_stage_2_53_3"
  type: "Convolution"
  bottom: "res_stage_2_53_2_top"
  top: "res_stage_2_53_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_53_3"
  type: "BatchNorm"
  bottom: "res_stage_2_53_3"
  top: "res_stage_2_53_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_53_3"  
  type: "Scale"
  bottom: "res_stage_2_53_3"
  top: "res_stage_2_53_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_53"
  type: "Eltwise"
  bottom: "res_2_52"
  bottom: "res_stage_2_53_3_top"
  top: "res_2_53"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_53_relu"
  type: "ReLU"
  bottom: "res_2_53"
  top: "res_2_53"
}
layer {
  name: "res_stage_2_54_1"
  type: "Convolution"
  bottom: "res_2_53"
  top: "res_stage_2_54_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_54_1"
  type: "BatchNorm"
  bottom: "res_stage_2_54_1"
  top: "res_stage_2_54_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_54_1"  
  type: "Scale"
  bottom: "res_stage_2_54_1"
  top: "res_stage_2_54_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_54_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_54_1_top"
  top: "res_stage_2_54_1_top"
}
layer {
  name: "res_stage_2_54_2"
  type: "Convolution"
  bottom: "res_stage_2_54_1_top"
  top: "res_stage_2_54_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_54_2"
  type: "BatchNorm"
  bottom: "res_stage_2_54_2"
  top: "res_stage_2_54_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_54_2"  
  type: "Scale"
  bottom: "res_stage_2_54_2"
  top: "res_stage_2_54_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_54_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_54_2_top"
  top: "res_stage_2_54_2_top"
}
layer {
  name: "res_stage_2_54_3"
  type: "Convolution"
  bottom: "res_stage_2_54_2_top"
  top: "res_stage_2_54_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_54_3"
  type: "BatchNorm"
  bottom: "res_stage_2_54_3"
  top: "res_stage_2_54_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_54_3"  
  type: "Scale"
  bottom: "res_stage_2_54_3"
  top: "res_stage_2_54_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_54"
  type: "Eltwise"
  bottom: "res_2_53"
  bottom: "res_stage_2_54_3_top"
  top: "res_2_54"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_54_relu"
  type: "ReLU"
  bottom: "res_2_54"
  top: "res_2_54"
}
layer {
  name: "res_stage_2_55_1"
  type: "Convolution"
  bottom: "res_2_54"
  top: "res_stage_2_55_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_55_1"
  type: "BatchNorm"
  bottom: "res_stage_2_55_1"
  top: "res_stage_2_55_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_55_1"  
  type: "Scale"
  bottom: "res_stage_2_55_1"
  top: "res_stage_2_55_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_55_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_55_1_top"
  top: "res_stage_2_55_1_top"
}
layer {
  name: "res_stage_2_55_2"
  type: "Convolution"
  bottom: "res_stage_2_55_1_top"
  top: "res_stage_2_55_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_55_2"
  type: "BatchNorm"
  bottom: "res_stage_2_55_2"
  top: "res_stage_2_55_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_55_2"  
  type: "Scale"
  bottom: "res_stage_2_55_2"
  top: "res_stage_2_55_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_55_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_55_2_top"
  top: "res_stage_2_55_2_top"
}
layer {
  name: "res_stage_2_55_3"
  type: "Convolution"
  bottom: "res_stage_2_55_2_top"
  top: "res_stage_2_55_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_55_3"
  type: "BatchNorm"
  bottom: "res_stage_2_55_3"
  top: "res_stage_2_55_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_55_3"  
  type: "Scale"
  bottom: "res_stage_2_55_3"
  top: "res_stage_2_55_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_55"
  type: "Eltwise"
  bottom: "res_2_54"
  bottom: "res_stage_2_55_3_top"
  top: "res_2_55"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_55_relu"
  type: "ReLU"
  bottom: "res_2_55"
  top: "res_2_55"
}
layer {
  name: "res_stage_2_56_1"
  type: "Convolution"
  bottom: "res_2_55"
  top: "res_stage_2_56_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_56_1"
  type: "BatchNorm"
  bottom: "res_stage_2_56_1"
  top: "res_stage_2_56_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_56_1"  
  type: "Scale"
  bottom: "res_stage_2_56_1"
  top: "res_stage_2_56_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_56_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_56_1_top"
  top: "res_stage_2_56_1_top"
}
layer {
  name: "res_stage_2_56_2"
  type: "Convolution"
  bottom: "res_stage_2_56_1_top"
  top: "res_stage_2_56_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_56_2"
  type: "BatchNorm"
  bottom: "res_stage_2_56_2"
  top: "res_stage_2_56_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_56_2"  
  type: "Scale"
  bottom: "res_stage_2_56_2"
  top: "res_stage_2_56_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_56_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_56_2_top"
  top: "res_stage_2_56_2_top"
}
layer {
  name: "res_stage_2_56_3"
  type: "Convolution"
  bottom: "res_stage_2_56_2_top"
  top: "res_stage_2_56_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_56_3"
  type: "BatchNorm"
  bottom: "res_stage_2_56_3"
  top: "res_stage_2_56_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_56_3"  
  type: "Scale"
  bottom: "res_stage_2_56_3"
  top: "res_stage_2_56_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_56"
  type: "Eltwise"
  bottom: "res_2_55"
  bottom: "res_stage_2_56_3_top"
  top: "res_2_56"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_56_relu"
  type: "ReLU"
  bottom: "res_2_56"
  top: "res_2_56"
}
layer {
  name: "res_stage_2_57_1"
  type: "Convolution"
  bottom: "res_2_56"
  top: "res_stage_2_57_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_57_1"
  type: "BatchNorm"
  bottom: "res_stage_2_57_1"
  top: "res_stage_2_57_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_57_1"  
  type: "Scale"
  bottom: "res_stage_2_57_1"
  top: "res_stage_2_57_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_57_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_57_1_top"
  top: "res_stage_2_57_1_top"
}
layer {
  name: "res_stage_2_57_2"
  type: "Convolution"
  bottom: "res_stage_2_57_1_top"
  top: "res_stage_2_57_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_57_2"
  type: "BatchNorm"
  bottom: "res_stage_2_57_2"
  top: "res_stage_2_57_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_57_2"  
  type: "Scale"
  bottom: "res_stage_2_57_2"
  top: "res_stage_2_57_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_57_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_57_2_top"
  top: "res_stage_2_57_2_top"
}
layer {
  name: "res_stage_2_57_3"
  type: "Convolution"
  bottom: "res_stage_2_57_2_top"
  top: "res_stage_2_57_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_57_3"
  type: "BatchNorm"
  bottom: "res_stage_2_57_3"
  top: "res_stage_2_57_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_57_3"  
  type: "Scale"
  bottom: "res_stage_2_57_3"
  top: "res_stage_2_57_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_57"
  type: "Eltwise"
  bottom: "res_2_56"
  bottom: "res_stage_2_57_3_top"
  top: "res_2_57"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_57_relu"
  type: "ReLU"
  bottom: "res_2_57"
  top: "res_2_57"
}
layer {
  name: "res_3_branch1"
  type: "Convolution"
  bottom: "res_2_57"
  top: "res_3_branch1"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_3_branch1"
  type: "BatchNorm"
  bottom: "res_3_branch1"
  top: "res_3_branch1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_3_branch1"  
  type: "Scale"
  bottom: "res_3_branch1"
  top: "res_3_branch1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_1_1"
  type: "Convolution"
  bottom: "res_2_57"
  top: "res_stage_3_1_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_1_1"
  type: "BatchNorm"
  bottom: "res_stage_3_1_1"
  top: "res_stage_3_1_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_1_1"  
  type: "Scale"
  bottom: "res_stage_3_1_1"
  top: "res_stage_3_1_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_1_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_1_1_top"
  top: "res_stage_3_1_1_top"
}
layer {
  name: "res_stage_3_1_2"
  type: "Convolution"
  bottom: "res_stage_3_1_1_top"
  top: "res_stage_3_1_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_1_2"
  type: "BatchNorm"
  bottom: "res_stage_3_1_2"
  top: "res_stage_3_1_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_1_2"  
  type: "Scale"
  bottom: "res_stage_3_1_2"
  top: "res_stage_3_1_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_1_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_1_2_top"
  top: "res_stage_3_1_2_top"
}
layer {
  name: "res_stage_3_1_3"
  type: "Convolution"
  bottom: "res_stage_3_1_2_top"
  top: "res_stage_3_1_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_1_3"
  type: "BatchNorm"
  bottom: "res_stage_3_1_3"
  top: "res_stage_3_1_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_1_3"  
  type: "Scale"
  bottom: "res_stage_3_1_3"
  top: "res_stage_3_1_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_1"
  type: "Eltwise"
  bottom: "res_3_branch1_top"
  bottom: "res_stage_3_1_3_top"
  top: "res_3_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_1_relu"
  type: "ReLU"
  bottom: "res_3_1"
  top: "res_3_1"
}
layer {
  name: "res_stage_3_2_1"
  type: "Convolution"
  bottom: "res_3_1"
  top: "res_stage_3_2_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_2_1"
  type: "BatchNorm"
  bottom: "res_stage_3_2_1"
  top: "res_stage_3_2_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_2_1"  
  type: "Scale"
  bottom: "res_stage_3_2_1"
  top: "res_stage_3_2_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_2_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_2_1_top"
  top: "res_stage_3_2_1_top"
}
layer {
  name: "res_stage_3_2_2"
  type: "Convolution"
  bottom: "res_stage_3_2_1_top"
  top: "res_stage_3_2_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_2_2"
  type: "BatchNorm"
  bottom: "res_stage_3_2_2"
  top: "res_stage_3_2_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_2_2"  
  type: "Scale"
  bottom: "res_stage_3_2_2"
  top: "res_stage_3_2_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_2_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_2_2_top"
  top: "res_stage_3_2_2_top"
}
layer {
  name: "res_stage_3_2_3"
  type: "Convolution"
  bottom: "res_stage_3_2_2_top"
  top: "res_stage_3_2_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_2_3"
  type: "BatchNorm"
  bottom: "res_stage_3_2_3"
  top: "res_stage_3_2_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_2_3"  
  type: "Scale"
  bottom: "res_stage_3_2_3"
  top: "res_stage_3_2_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_2"
  type: "Eltwise"
  bottom: "res_3_1"
  bottom: "res_stage_3_2_3_top"
  top: "res_3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_2_relu"
  type: "ReLU"
  bottom: "res_3_2"
  top: "res_3_2"
}
layer {
  name: "res_stage_3_3_1"
  type: "Convolution"
  bottom: "res_3_2"
  top: "res_stage_3_3_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_3_1"
  type: "BatchNorm"
  bottom: "res_stage_3_3_1"
  top: "res_stage_3_3_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_3_1"  
  type: "Scale"
  bottom: "res_stage_3_3_1"
  top: "res_stage_3_3_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_3_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_3_1_top"
  top: "res_stage_3_3_1_top"
}
layer {
  name: "res_stage_3_3_2"
  type: "Convolution"
  bottom: "res_stage_3_3_1_top"
  top: "res_stage_3_3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_3_2"
  type: "BatchNorm"
  bottom: "res_stage_3_3_2"
  top: "res_stage_3_3_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_3_2"  
  type: "Scale"
  bottom: "res_stage_3_3_2"
  top: "res_stage_3_3_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_3_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_3_2_top"
  top: "res_stage_3_3_2_top"
}
layer {
  name: "res_stage_3_3_3"
  type: "Convolution"
  bottom: "res_stage_3_3_2_top"
  top: "res_stage_3_3_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_3_3"
  type: "BatchNorm"
  bottom: "res_stage_3_3_3"
  top: "res_stage_3_3_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_3_3"  
  type: "Scale"
  bottom: "res_stage_3_3_3"
  top: "res_stage_3_3_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_3"
  type: "Eltwise"
  bottom: "res_3_2"
  bottom: "res_stage_3_3_3_top"
  top: "res_3_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_3_relu"
  type: "ReLU"
  bottom: "res_3_3"
  top: "res_3_3"
}
layer {
  name: "res_stage_3_4_1"
  type: "Convolution"
  bottom: "res_3_3"
  top: "res_stage_3_4_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_4_1"
  type: "BatchNorm"
  bottom: "res_stage_3_4_1"
  top: "res_stage_3_4_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_4_1"  
  type: "Scale"
  bottom: "res_stage_3_4_1"
  top: "res_stage_3_4_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_4_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_4_1_top"
  top: "res_stage_3_4_1_top"
}
layer {
  name: "res_stage_3_4_2"
  type: "Convolution"
  bottom: "res_stage_3_4_1_top"
  top: "res_stage_3_4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_4_2"
  type: "BatchNorm"
  bottom: "res_stage_3_4_2"
  top: "res_stage_3_4_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_4_2"  
  type: "Scale"
  bottom: "res_stage_3_4_2"
  top: "res_stage_3_4_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_4_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_4_2_top"
  top: "res_stage_3_4_2_top"
}
layer {
  name: "res_stage_3_4_3"
  type: "Convolution"
  bottom: "res_stage_3_4_2_top"
  top: "res_stage_3_4_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_4_3"
  type: "BatchNorm"
  bottom: "res_stage_3_4_3"
  top: "res_stage_3_4_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_4_3"  
  type: "Scale"
  bottom: "res_stage_3_4_3"
  top: "res_stage_3_4_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_4"
  type: "Eltwise"
  bottom: "res_3_3"
  bottom: "res_stage_3_4_3_top"
  top: "res_3_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_4_relu"
  type: "ReLU"
  bottom: "res_3_4"
  top: "res_3_4"
}
layer {
  name: "res_stage_3_5_1"
  type: "Convolution"
  bottom: "res_3_4"
  top: "res_stage_3_5_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_5_1"
  type: "BatchNorm"
  bottom: "res_stage_3_5_1"
  top: "res_stage_3_5_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_5_1"  
  type: "Scale"
  bottom: "res_stage_3_5_1"
  top: "res_stage_3_5_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_5_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_5_1_top"
  top: "res_stage_3_5_1_top"
}
layer {
  name: "res_stage_3_5_2"
  type: "Convolution"
  bottom: "res_stage_3_5_1_top"
  top: "res_stage_3_5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_5_2"
  type: "BatchNorm"
  bottom: "res_stage_3_5_2"
  top: "res_stage_3_5_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_5_2"  
  type: "Scale"
  bottom: "res_stage_3_5_2"
  top: "res_stage_3_5_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_5_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_5_2_top"
  top: "res_stage_3_5_2_top"
}
layer {
  name: "res_stage_3_5_3"
  type: "Convolution"
  bottom: "res_stage_3_5_2_top"
  top: "res_stage_3_5_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_5_3"
  type: "BatchNorm"
  bottom: "res_stage_3_5_3"
  top: "res_stage_3_5_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_5_3"  
  type: "Scale"
  bottom: "res_stage_3_5_3"
  top: "res_stage_3_5_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_5"
  type: "Eltwise"
  bottom: "res_3_4"
  bottom: "res_stage_3_5_3_top"
  top: "res_3_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_5_relu"
  type: "ReLU"
  bottom: "res_3_5"
  top: "res_3_5"
}
layer {
  name: "res_stage_3_6_1"
  type: "Convolution"
  bottom: "res_3_5"
  top: "res_stage_3_6_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_6_1"
  type: "BatchNorm"
  bottom: "res_stage_3_6_1"
  top: "res_stage_3_6_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_6_1"  
  type: "Scale"
  bottom: "res_stage_3_6_1"
  top: "res_stage_3_6_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_6_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_6_1_top"
  top: "res_stage_3_6_1_top"
}
layer {
  name: "res_stage_3_6_2"
  type: "Convolution"
  bottom: "res_stage_3_6_1_top"
  top: "res_stage_3_6_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_6_2"
  type: "BatchNorm"
  bottom: "res_stage_3_6_2"
  top: "res_stage_3_6_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_6_2"  
  type: "Scale"
  bottom: "res_stage_3_6_2"
  top: "res_stage_3_6_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_6_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_6_2_top"
  top: "res_stage_3_6_2_top"
}
layer {
  name: "res_stage_3_6_3"
  type: "Convolution"
  bottom: "res_stage_3_6_2_top"
  top: "res_stage_3_6_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_6_3"
  type: "BatchNorm"
  bottom: "res_stage_3_6_3"
  top: "res_stage_3_6_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_6_3"  
  type: "Scale"
  bottom: "res_stage_3_6_3"
  top: "res_stage_3_6_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_6"
  type: "Eltwise"
  bottom: "res_3_5"
  bottom: "res_stage_3_6_3_top"
  top: "res_3_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_6_relu"
  type: "ReLU"
  bottom: "res_3_6"
  top: "res_3_6"
}
layer {
  name: "res_stage_3_7_1"
  type: "Convolution"
  bottom: "res_3_6"
  top: "res_stage_3_7_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_7_1"
  type: "BatchNorm"
  bottom: "res_stage_3_7_1"
  top: "res_stage_3_7_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_7_1"  
  type: "Scale"
  bottom: "res_stage_3_7_1"
  top: "res_stage_3_7_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_7_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_7_1_top"
  top: "res_stage_3_7_1_top"
}
layer {
  name: "res_stage_3_7_2"
  type: "Convolution"
  bottom: "res_stage_3_7_1_top"
  top: "res_stage_3_7_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_7_2"
  type: "BatchNorm"
  bottom: "res_stage_3_7_2"
  top: "res_stage_3_7_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_7_2"  
  type: "Scale"
  bottom: "res_stage_3_7_2"
  top: "res_stage_3_7_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_7_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_7_2_top"
  top: "res_stage_3_7_2_top"
}
layer {
  name: "res_stage_3_7_3"
  type: "Convolution"
  bottom: "res_stage_3_7_2_top"
  top: "res_stage_3_7_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_7_3"
  type: "BatchNorm"
  bottom: "res_stage_3_7_3"
  top: "res_stage_3_7_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_7_3"  
  type: "Scale"
  bottom: "res_stage_3_7_3"
  top: "res_stage_3_7_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_7"
  type: "Eltwise"
  bottom: "res_3_6"
  bottom: "res_stage_3_7_3_top"
  top: "res_3_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_7_relu"
  type: "ReLU"
  bottom: "res_3_7"
  top: "res_3_7"
}
layer {
  name: "res_stage_3_8_1"
  type: "Convolution"
  bottom: "res_3_7"
  top: "res_stage_3_8_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_8_1"
  type: "BatchNorm"
  bottom: "res_stage_3_8_1"
  top: "res_stage_3_8_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_8_1"  
  type: "Scale"
  bottom: "res_stage_3_8_1"
  top: "res_stage_3_8_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_8_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_8_1_top"
  top: "res_stage_3_8_1_top"
}
layer {
  name: "res_stage_3_8_2"
  type: "Convolution"
  bottom: "res_stage_3_8_1_top"
  top: "res_stage_3_8_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_8_2"
  type: "BatchNorm"
  bottom: "res_stage_3_8_2"
  top: "res_stage_3_8_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_8_2"  
  type: "Scale"
  bottom: "res_stage_3_8_2"
  top: "res_stage_3_8_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_8_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_8_2_top"
  top: "res_stage_3_8_2_top"
}
layer {
  name: "res_stage_3_8_3"
  type: "Convolution"
  bottom: "res_stage_3_8_2_top"
  top: "res_stage_3_8_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_8_3"
  type: "BatchNorm"
  bottom: "res_stage_3_8_3"
  top: "res_stage_3_8_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_8_3"  
  type: "Scale"
  bottom: "res_stage_3_8_3"
  top: "res_stage_3_8_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_8"
  type: "Eltwise"
  bottom: "res_3_7"
  bottom: "res_stage_3_8_3_top"
  top: "res_3_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_8_relu"
  type: "ReLU"
  bottom: "res_3_8"
  top: "res_3_8"
}
layer {
  name: "res_stage_3_9_1"
  type: "Convolution"
  bottom: "res_3_8"
  top: "res_stage_3_9_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_9_1"
  type: "BatchNorm"
  bottom: "res_stage_3_9_1"
  top: "res_stage_3_9_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_9_1"  
  type: "Scale"
  bottom: "res_stage_3_9_1"
  top: "res_stage_3_9_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_9_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_9_1_top"
  top: "res_stage_3_9_1_top"
}
layer {
  name: "res_stage_3_9_2"
  type: "Convolution"
  bottom: "res_stage_3_9_1_top"
  top: "res_stage_3_9_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_9_2"
  type: "BatchNorm"
  bottom: "res_stage_3_9_2"
  top: "res_stage_3_9_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_9_2"  
  type: "Scale"
  bottom: "res_stage_3_9_2"
  top: "res_stage_3_9_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_9_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_9_2_top"
  top: "res_stage_3_9_2_top"
}
layer {
  name: "res_stage_3_9_3"
  type: "Convolution"
  bottom: "res_stage_3_9_2_top"
  top: "res_stage_3_9_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_9_3"
  type: "BatchNorm"
  bottom: "res_stage_3_9_3"
  top: "res_stage_3_9_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_9_3"  
  type: "Scale"
  bottom: "res_stage_3_9_3"
  top: "res_stage_3_9_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_9"
  type: "Eltwise"
  bottom: "res_3_8"
  bottom: "res_stage_3_9_3_top"
  top: "res_3_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_9_relu"
  type: "ReLU"
  bottom: "res_3_9"
  top: "res_3_9"
}
layer {
  name: "res_stage_3_10_1"
  type: "Convolution"
  bottom: "res_3_9"
  top: "res_stage_3_10_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_10_1"
  type: "BatchNorm"
  bottom: "res_stage_3_10_1"
  top: "res_stage_3_10_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_10_1"  
  type: "Scale"
  bottom: "res_stage_3_10_1"
  top: "res_stage_3_10_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_10_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_10_1_top"
  top: "res_stage_3_10_1_top"
}
layer {
  name: "res_stage_3_10_2"
  type: "Convolution"
  bottom: "res_stage_3_10_1_top"
  top: "res_stage_3_10_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_10_2"
  type: "BatchNorm"
  bottom: "res_stage_3_10_2"
  top: "res_stage_3_10_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_10_2"  
  type: "Scale"
  bottom: "res_stage_3_10_2"
  top: "res_stage_3_10_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_10_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_10_2_top"
  top: "res_stage_3_10_2_top"
}
layer {
  name: "res_stage_3_10_3"
  type: "Convolution"
  bottom: "res_stage_3_10_2_top"
  top: "res_stage_3_10_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_10_3"
  type: "BatchNorm"
  bottom: "res_stage_3_10_3"
  top: "res_stage_3_10_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_10_3"  
  type: "Scale"
  bottom: "res_stage_3_10_3"
  top: "res_stage_3_10_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_10"
  type: "Eltwise"
  bottom: "res_3_9"
  bottom: "res_stage_3_10_3_top"
  top: "res_3_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_10_relu"
  type: "ReLU"
  bottom: "res_3_10"
  top: "res_3_10"
}
layer {
  name: "res_stage_3_11_1"
  type: "Convolution"
  bottom: "res_3_10"
  top: "res_stage_3_11_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_11_1"
  type: "BatchNorm"
  bottom: "res_stage_3_11_1"
  top: "res_stage_3_11_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_11_1"  
  type: "Scale"
  bottom: "res_stage_3_11_1"
  top: "res_stage_3_11_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_11_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_11_1_top"
  top: "res_stage_3_11_1_top"
}
layer {
  name: "res_stage_3_11_2"
  type: "Convolution"
  bottom: "res_stage_3_11_1_top"
  top: "res_stage_3_11_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_11_2"
  type: "BatchNorm"
  bottom: "res_stage_3_11_2"
  top: "res_stage_3_11_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_11_2"  
  type: "Scale"
  bottom: "res_stage_3_11_2"
  top: "res_stage_3_11_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_11_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_11_2_top"
  top: "res_stage_3_11_2_top"
}
layer {
  name: "res_stage_3_11_3"
  type: "Convolution"
  bottom: "res_stage_3_11_2_top"
  top: "res_stage_3_11_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_11_3"
  type: "BatchNorm"
  bottom: "res_stage_3_11_3"
  top: "res_stage_3_11_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_11_3"  
  type: "Scale"
  bottom: "res_stage_3_11_3"
  top: "res_stage_3_11_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_11"
  type: "Eltwise"
  bottom: "res_3_10"
  bottom: "res_stage_3_11_3_top"
  top: "res_3_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_11_relu"
  type: "ReLU"
  bottom: "res_3_11"
  top: "res_3_11"
}
layer {
  name: "res_stage_3_12_1"
  type: "Convolution"
  bottom: "res_3_11"
  top: "res_stage_3_12_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_12_1"
  type: "BatchNorm"
  bottom: "res_stage_3_12_1"
  top: "res_stage_3_12_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_12_1"  
  type: "Scale"
  bottom: "res_stage_3_12_1"
  top: "res_stage_3_12_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_12_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_12_1_top"
  top: "res_stage_3_12_1_top"
}
layer {
  name: "res_stage_3_12_2"
  type: "Convolution"
  bottom: "res_stage_3_12_1_top"
  top: "res_stage_3_12_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_12_2"
  type: "BatchNorm"
  bottom: "res_stage_3_12_2"
  top: "res_stage_3_12_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_12_2"  
  type: "Scale"
  bottom: "res_stage_3_12_2"
  top: "res_stage_3_12_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_12_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_12_2_top"
  top: "res_stage_3_12_2_top"
}
layer {
  name: "res_stage_3_12_3"
  type: "Convolution"
  bottom: "res_stage_3_12_2_top"
  top: "res_stage_3_12_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_12_3"
  type: "BatchNorm"
  bottom: "res_stage_3_12_3"
  top: "res_stage_3_12_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_12_3"  
  type: "Scale"
  bottom: "res_stage_3_12_3"
  top: "res_stage_3_12_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_12"
  type: "Eltwise"
  bottom: "res_3_11"
  bottom: "res_stage_3_12_3_top"
  top: "res_3_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_12_relu"
  type: "ReLU"
  bottom: "res_3_12"
  top: "res_3_12"
}
layer {
  name: "res_stage_3_13_1"
  type: "Convolution"
  bottom: "res_3_12"
  top: "res_stage_3_13_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_13_1"
  type: "BatchNorm"
  bottom: "res_stage_3_13_1"
  top: "res_stage_3_13_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_13_1"  
  type: "Scale"
  bottom: "res_stage_3_13_1"
  top: "res_stage_3_13_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_13_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_13_1_top"
  top: "res_stage_3_13_1_top"
}
layer {
  name: "res_stage_3_13_2"
  type: "Convolution"
  bottom: "res_stage_3_13_1_top"
  top: "res_stage_3_13_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_13_2"
  type: "BatchNorm"
  bottom: "res_stage_3_13_2"
  top: "res_stage_3_13_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_13_2"  
  type: "Scale"
  bottom: "res_stage_3_13_2"
  top: "res_stage_3_13_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_13_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_13_2_top"
  top: "res_stage_3_13_2_top"
}
layer {
  name: "res_stage_3_13_3"
  type: "Convolution"
  bottom: "res_stage_3_13_2_top"
  top: "res_stage_3_13_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_13_3"
  type: "BatchNorm"
  bottom: "res_stage_3_13_3"
  top: "res_stage_3_13_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_13_3"  
  type: "Scale"
  bottom: "res_stage_3_13_3"
  top: "res_stage_3_13_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_13"
  type: "Eltwise"
  bottom: "res_3_12"
  bottom: "res_stage_3_13_3_top"
  top: "res_3_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_13_relu"
  type: "ReLU"
  bottom: "res_3_13"
  top: "res_3_13"
}
layer {
  name: "res_stage_3_14_1"
  type: "Convolution"
  bottom: "res_3_13"
  top: "res_stage_3_14_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_14_1"
  type: "BatchNorm"
  bottom: "res_stage_3_14_1"
  top: "res_stage_3_14_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_14_1"  
  type: "Scale"
  bottom: "res_stage_3_14_1"
  top: "res_stage_3_14_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_14_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_14_1_top"
  top: "res_stage_3_14_1_top"
}
layer {
  name: "res_stage_3_14_2"
  type: "Convolution"
  bottom: "res_stage_3_14_1_top"
  top: "res_stage_3_14_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_14_2"
  type: "BatchNorm"
  bottom: "res_stage_3_14_2"
  top: "res_stage_3_14_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_14_2"  
  type: "Scale"
  bottom: "res_stage_3_14_2"
  top: "res_stage_3_14_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_14_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_14_2_top"
  top: "res_stage_3_14_2_top"
}
layer {
  name: "res_stage_3_14_3"
  type: "Convolution"
  bottom: "res_stage_3_14_2_top"
  top: "res_stage_3_14_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_14_3"
  type: "BatchNorm"
  bottom: "res_stage_3_14_3"
  top: "res_stage_3_14_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_14_3"  
  type: "Scale"
  bottom: "res_stage_3_14_3"
  top: "res_stage_3_14_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_14"
  type: "Eltwise"
  bottom: "res_3_13"
  bottom: "res_stage_3_14_3_top"
  top: "res_3_14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_14_relu"
  type: "ReLU"
  bottom: "res_3_14"
  top: "res_3_14"
}
layer {
  name: "res_stage_3_15_1"
  type: "Convolution"
  bottom: "res_3_14"
  top: "res_stage_3_15_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_15_1"
  type: "BatchNorm"
  bottom: "res_stage_3_15_1"
  top: "res_stage_3_15_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_15_1"  
  type: "Scale"
  bottom: "res_stage_3_15_1"
  top: "res_stage_3_15_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_15_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_15_1_top"
  top: "res_stage_3_15_1_top"
}
layer {
  name: "res_stage_3_15_2"
  type: "Convolution"
  bottom: "res_stage_3_15_1_top"
  top: "res_stage_3_15_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_15_2"
  type: "BatchNorm"
  bottom: "res_stage_3_15_2"
  top: "res_stage_3_15_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_15_2"  
  type: "Scale"
  bottom: "res_stage_3_15_2"
  top: "res_stage_3_15_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_15_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_15_2_top"
  top: "res_stage_3_15_2_top"
}
layer {
  name: "res_stage_3_15_3"
  type: "Convolution"
  bottom: "res_stage_3_15_2_top"
  top: "res_stage_3_15_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_15_3"
  type: "BatchNorm"
  bottom: "res_stage_3_15_3"
  top: "res_stage_3_15_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_15_3"  
  type: "Scale"
  bottom: "res_stage_3_15_3"
  top: "res_stage_3_15_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_15"
  type: "Eltwise"
  bottom: "res_3_14"
  bottom: "res_stage_3_15_3_top"
  top: "res_3_15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_15_relu"
  type: "ReLU"
  bottom: "res_3_15"
  top: "res_3_15"
}
layer {
  name: "res_stage_3_16_1"
  type: "Convolution"
  bottom: "res_3_15"
  top: "res_stage_3_16_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_16_1"
  type: "BatchNorm"
  bottom: "res_stage_3_16_1"
  top: "res_stage_3_16_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_16_1"  
  type: "Scale"
  bottom: "res_stage_3_16_1"
  top: "res_stage_3_16_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_16_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_16_1_top"
  top: "res_stage_3_16_1_top"
}
layer {
  name: "res_stage_3_16_2"
  type: "Convolution"
  bottom: "res_stage_3_16_1_top"
  top: "res_stage_3_16_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_16_2"
  type: "BatchNorm"
  bottom: "res_stage_3_16_2"
  top: "res_stage_3_16_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_16_2"  
  type: "Scale"
  bottom: "res_stage_3_16_2"
  top: "res_stage_3_16_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_16_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_16_2_top"
  top: "res_stage_3_16_2_top"
}
layer {
  name: "res_stage_3_16_3"
  type: "Convolution"
  bottom: "res_stage_3_16_2_top"
  top: "res_stage_3_16_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_16_3"
  type: "BatchNorm"
  bottom: "res_stage_3_16_3"
  top: "res_stage_3_16_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_16_3"  
  type: "Scale"
  bottom: "res_stage_3_16_3"
  top: "res_stage_3_16_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_16"
  type: "Eltwise"
  bottom: "res_3_15"
  bottom: "res_stage_3_16_3_top"
  top: "res_3_16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_16_relu"
  type: "ReLU"
  bottom: "res_3_16"
  top: "res_3_16"
}
layer {
  name: "res_stage_3_17_1"
  type: "Convolution"
  bottom: "res_3_16"
  top: "res_stage_3_17_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_17_1"
  type: "BatchNorm"
  bottom: "res_stage_3_17_1"
  top: "res_stage_3_17_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_17_1"  
  type: "Scale"
  bottom: "res_stage_3_17_1"
  top: "res_stage_3_17_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_17_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_17_1_top"
  top: "res_stage_3_17_1_top"
}
layer {
  name: "res_stage_3_17_2"
  type: "Convolution"
  bottom: "res_stage_3_17_1_top"
  top: "res_stage_3_17_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_17_2"
  type: "BatchNorm"
  bottom: "res_stage_3_17_2"
  top: "res_stage_3_17_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_17_2"  
  type: "Scale"
  bottom: "res_stage_3_17_2"
  top: "res_stage_3_17_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_17_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_17_2_top"
  top: "res_stage_3_17_2_top"
}
layer {
  name: "res_stage_3_17_3"
  type: "Convolution"
  bottom: "res_stage_3_17_2_top"
  top: "res_stage_3_17_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_17_3"
  type: "BatchNorm"
  bottom: "res_stage_3_17_3"
  top: "res_stage_3_17_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_17_3"  
  type: "Scale"
  bottom: "res_stage_3_17_3"
  top: "res_stage_3_17_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_17"
  type: "Eltwise"
  bottom: "res_3_16"
  bottom: "res_stage_3_17_3_top"
  top: "res_3_17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_17_relu"
  type: "ReLU"
  bottom: "res_3_17"
  top: "res_3_17"
}
layer {
  name: "res_stage_3_18_1"
  type: "Convolution"
  bottom: "res_3_17"
  top: "res_stage_3_18_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_18_1"
  type: "BatchNorm"
  bottom: "res_stage_3_18_1"
  top: "res_stage_3_18_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_18_1"  
  type: "Scale"
  bottom: "res_stage_3_18_1"
  top: "res_stage_3_18_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_18_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_18_1_top"
  top: "res_stage_3_18_1_top"
}
layer {
  name: "res_stage_3_18_2"
  type: "Convolution"
  bottom: "res_stage_3_18_1_top"
  top: "res_stage_3_18_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_18_2"
  type: "BatchNorm"
  bottom: "res_stage_3_18_2"
  top: "res_stage_3_18_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_18_2"  
  type: "Scale"
  bottom: "res_stage_3_18_2"
  top: "res_stage_3_18_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_18_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_18_2_top"
  top: "res_stage_3_18_2_top"
}
layer {
  name: "res_stage_3_18_3"
  type: "Convolution"
  bottom: "res_stage_3_18_2_top"
  top: "res_stage_3_18_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_18_3"
  type: "BatchNorm"
  bottom: "res_stage_3_18_3"
  top: "res_stage_3_18_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_18_3"  
  type: "Scale"
  bottom: "res_stage_3_18_3"
  top: "res_stage_3_18_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_18"
  type: "Eltwise"
  bottom: "res_3_17"
  bottom: "res_stage_3_18_3_top"
  top: "res_3_18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_18_relu"
  type: "ReLU"
  bottom: "res_3_18"
  top: "res_3_18"
}
layer {
  name: "res_stage_3_19_1"
  type: "Convolution"
  bottom: "res_3_18"
  top: "res_stage_3_19_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_19_1"
  type: "BatchNorm"
  bottom: "res_stage_3_19_1"
  top: "res_stage_3_19_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_19_1"  
  type: "Scale"
  bottom: "res_stage_3_19_1"
  top: "res_stage_3_19_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_19_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_19_1_top"
  top: "res_stage_3_19_1_top"
}
layer {
  name: "res_stage_3_19_2"
  type: "Convolution"
  bottom: "res_stage_3_19_1_top"
  top: "res_stage_3_19_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_19_2"
  type: "BatchNorm"
  bottom: "res_stage_3_19_2"
  top: "res_stage_3_19_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_19_2"  
  type: "Scale"
  bottom: "res_stage_3_19_2"
  top: "res_stage_3_19_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_19_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_19_2_top"
  top: "res_stage_3_19_2_top"
}
layer {
  name: "res_stage_3_19_3"
  type: "Convolution"
  bottom: "res_stage_3_19_2_top"
  top: "res_stage_3_19_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_19_3"
  type: "BatchNorm"
  bottom: "res_stage_3_19_3"
  top: "res_stage_3_19_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_19_3"  
  type: "Scale"
  bottom: "res_stage_3_19_3"
  top: "res_stage_3_19_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_19"
  type: "Eltwise"
  bottom: "res_3_18"
  bottom: "res_stage_3_19_3_top"
  top: "res_3_19"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_19_relu"
  type: "ReLU"
  bottom: "res_3_19"
  top: "res_3_19"
}
layer {
  name: "res_stage_3_20_1"
  type: "Convolution"
  bottom: "res_3_19"
  top: "res_stage_3_20_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_20_1"
  type: "BatchNorm"
  bottom: "res_stage_3_20_1"
  top: "res_stage_3_20_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_20_1"  
  type: "Scale"
  bottom: "res_stage_3_20_1"
  top: "res_stage_3_20_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_20_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_20_1_top"
  top: "res_stage_3_20_1_top"
}
layer {
  name: "res_stage_3_20_2"
  type: "Convolution"
  bottom: "res_stage_3_20_1_top"
  top: "res_stage_3_20_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_20_2"
  type: "BatchNorm"
  bottom: "res_stage_3_20_2"
  top: "res_stage_3_20_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_20_2"  
  type: "Scale"
  bottom: "res_stage_3_20_2"
  top: "res_stage_3_20_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_20_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_20_2_top"
  top: "res_stage_3_20_2_top"
}
layer {
  name: "res_stage_3_20_3"
  type: "Convolution"
  bottom: "res_stage_3_20_2_top"
  top: "res_stage_3_20_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_20_3"
  type: "BatchNorm"
  bottom: "res_stage_3_20_3"
  top: "res_stage_3_20_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_20_3"  
  type: "Scale"
  bottom: "res_stage_3_20_3"
  top: "res_stage_3_20_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_20"
  type: "Eltwise"
  bottom: "res_3_19"
  bottom: "res_stage_3_20_3_top"
  top: "res_3_20"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_20_relu"
  type: "ReLU"
  bottom: "res_3_20"
  top: "res_3_20"
}
layer {
  name: "res_stage_3_21_1"
  type: "Convolution"
  bottom: "res_3_20"
  top: "res_stage_3_21_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_21_1"
  type: "BatchNorm"
  bottom: "res_stage_3_21_1"
  top: "res_stage_3_21_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_21_1"  
  type: "Scale"
  bottom: "res_stage_3_21_1"
  top: "res_stage_3_21_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_21_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_21_1_top"
  top: "res_stage_3_21_1_top"
}
layer {
  name: "res_stage_3_21_2"
  type: "Convolution"
  bottom: "res_stage_3_21_1_top"
  top: "res_stage_3_21_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_21_2"
  type: "BatchNorm"
  bottom: "res_stage_3_21_2"
  top: "res_stage_3_21_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_21_2"  
  type: "Scale"
  bottom: "res_stage_3_21_2"
  top: "res_stage_3_21_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_21_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_21_2_top"
  top: "res_stage_3_21_2_top"
}
layer {
  name: "res_stage_3_21_3"
  type: "Convolution"
  bottom: "res_stage_3_21_2_top"
  top: "res_stage_3_21_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_21_3"
  type: "BatchNorm"
  bottom: "res_stage_3_21_3"
  top: "res_stage_3_21_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_21_3"  
  type: "Scale"
  bottom: "res_stage_3_21_3"
  top: "res_stage_3_21_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_21"
  type: "Eltwise"
  bottom: "res_3_20"
  bottom: "res_stage_3_21_3_top"
  top: "res_3_21"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_21_relu"
  type: "ReLU"
  bottom: "res_3_21"
  top: "res_3_21"
}
layer {
  name: "res_stage_3_22_1"
  type: "Convolution"
  bottom: "res_3_21"
  top: "res_stage_3_22_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_22_1"
  type: "BatchNorm"
  bottom: "res_stage_3_22_1"
  top: "res_stage_3_22_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_22_1"  
  type: "Scale"
  bottom: "res_stage_3_22_1"
  top: "res_stage_3_22_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_22_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_22_1_top"
  top: "res_stage_3_22_1_top"
}
layer {
  name: "res_stage_3_22_2"
  type: "Convolution"
  bottom: "res_stage_3_22_1_top"
  top: "res_stage_3_22_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_22_2"
  type: "BatchNorm"
  bottom: "res_stage_3_22_2"
  top: "res_stage_3_22_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_22_2"  
  type: "Scale"
  bottom: "res_stage_3_22_2"
  top: "res_stage_3_22_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_22_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_22_2_top"
  top: "res_stage_3_22_2_top"
}
layer {
  name: "res_stage_3_22_3"
  type: "Convolution"
  bottom: "res_stage_3_22_2_top"
  top: "res_stage_3_22_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_22_3"
  type: "BatchNorm"
  bottom: "res_stage_3_22_3"
  top: "res_stage_3_22_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_22_3"  
  type: "Scale"
  bottom: "res_stage_3_22_3"
  top: "res_stage_3_22_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_22"
  type: "Eltwise"
  bottom: "res_3_21"
  bottom: "res_stage_3_22_3_top"
  top: "res_3_22"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_22_relu"
  type: "ReLU"
  bottom: "res_3_22"
  top: "res_3_22"
}
layer {
  name: "res_stage_3_23_1"
  type: "Convolution"
  bottom: "res_3_22"
  top: "res_stage_3_23_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_23_1"
  type: "BatchNorm"
  bottom: "res_stage_3_23_1"
  top: "res_stage_3_23_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_23_1"  
  type: "Scale"
  bottom: "res_stage_3_23_1"
  top: "res_stage_3_23_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_23_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_23_1_top"
  top: "res_stage_3_23_1_top"
}
layer {
  name: "res_stage_3_23_2"
  type: "Convolution"
  bottom: "res_stage_3_23_1_top"
  top: "res_stage_3_23_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_23_2"
  type: "BatchNorm"
  bottom: "res_stage_3_23_2"
  top: "res_stage_3_23_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_23_2"  
  type: "Scale"
  bottom: "res_stage_3_23_2"
  top: "res_stage_3_23_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_23_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_23_2_top"
  top: "res_stage_3_23_2_top"
}
layer {
  name: "res_stage_3_23_3"
  type: "Convolution"
  bottom: "res_stage_3_23_2_top"
  top: "res_stage_3_23_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_23_3"
  type: "BatchNorm"
  bottom: "res_stage_3_23_3"
  top: "res_stage_3_23_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_23_3"  
  type: "Scale"
  bottom: "res_stage_3_23_3"
  top: "res_stage_3_23_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_23"
  type: "Eltwise"
  bottom: "res_3_22"
  bottom: "res_stage_3_23_3_top"
  top: "res_3_23"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_23_relu"
  type: "ReLU"
  bottom: "res_3_23"
  top: "res_3_23"
}
layer {
  name: "res_stage_3_24_1"
  type: "Convolution"
  bottom: "res_3_23"
  top: "res_stage_3_24_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_24_1"
  type: "BatchNorm"
  bottom: "res_stage_3_24_1"
  top: "res_stage_3_24_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_24_1"  
  type: "Scale"
  bottom: "res_stage_3_24_1"
  top: "res_stage_3_24_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_24_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_24_1_top"
  top: "res_stage_3_24_1_top"
}
layer {
  name: "res_stage_3_24_2"
  type: "Convolution"
  bottom: "res_stage_3_24_1_top"
  top: "res_stage_3_24_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_24_2"
  type: "BatchNorm"
  bottom: "res_stage_3_24_2"
  top: "res_stage_3_24_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_24_2"  
  type: "Scale"
  bottom: "res_stage_3_24_2"
  top: "res_stage_3_24_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_24_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_24_2_top"
  top: "res_stage_3_24_2_top"
}
layer {
  name: "res_stage_3_24_3"
  type: "Convolution"
  bottom: "res_stage_3_24_2_top"
  top: "res_stage_3_24_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_24_3"
  type: "BatchNorm"
  bottom: "res_stage_3_24_3"
  top: "res_stage_3_24_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_24_3"  
  type: "Scale"
  bottom: "res_stage_3_24_3"
  top: "res_stage_3_24_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_24"
  type: "Eltwise"
  bottom: "res_3_23"
  bottom: "res_stage_3_24_3_top"
  top: "res_3_24"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_24_relu"
  type: "ReLU"
  bottom: "res_3_24"
  top: "res_3_24"
}
layer {
  name: "res_stage_3_25_1"
  type: "Convolution"
  bottom: "res_3_24"
  top: "res_stage_3_25_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_25_1"
  type: "BatchNorm"
  bottom: "res_stage_3_25_1"
  top: "res_stage_3_25_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_25_1"  
  type: "Scale"
  bottom: "res_stage_3_25_1"
  top: "res_stage_3_25_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_25_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_25_1_top"
  top: "res_stage_3_25_1_top"
}
layer {
  name: "res_stage_3_25_2"
  type: "Convolution"
  bottom: "res_stage_3_25_1_top"
  top: "res_stage_3_25_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_25_2"
  type: "BatchNorm"
  bottom: "res_stage_3_25_2"
  top: "res_stage_3_25_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_25_2"  
  type: "Scale"
  bottom: "res_stage_3_25_2"
  top: "res_stage_3_25_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_25_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_25_2_top"
  top: "res_stage_3_25_2_top"
}
layer {
  name: "res_stage_3_25_3"
  type: "Convolution"
  bottom: "res_stage_3_25_2_top"
  top: "res_stage_3_25_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_25_3"
  type: "BatchNorm"
  bottom: "res_stage_3_25_3"
  top: "res_stage_3_25_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_25_3"  
  type: "Scale"
  bottom: "res_stage_3_25_3"
  top: "res_stage_3_25_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_25"
  type: "Eltwise"
  bottom: "res_3_24"
  bottom: "res_stage_3_25_3_top"
  top: "res_3_25"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_25_relu"
  type: "ReLU"
  bottom: "res_3_25"
  top: "res_3_25"
}
layer {
  name: "res_stage_3_26_1"
  type: "Convolution"
  bottom: "res_3_25"
  top: "res_stage_3_26_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_26_1"
  type: "BatchNorm"
  bottom: "res_stage_3_26_1"
  top: "res_stage_3_26_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_26_1"  
  type: "Scale"
  bottom: "res_stage_3_26_1"
  top: "res_stage_3_26_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_26_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_26_1_top"
  top: "res_stage_3_26_1_top"
}
layer {
  name: "res_stage_3_26_2"
  type: "Convolution"
  bottom: "res_stage_3_26_1_top"
  top: "res_stage_3_26_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_26_2"
  type: "BatchNorm"
  bottom: "res_stage_3_26_2"
  top: "res_stage_3_26_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_26_2"  
  type: "Scale"
  bottom: "res_stage_3_26_2"
  top: "res_stage_3_26_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_26_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_26_2_top"
  top: "res_stage_3_26_2_top"
}
layer {
  name: "res_stage_3_26_3"
  type: "Convolution"
  bottom: "res_stage_3_26_2_top"
  top: "res_stage_3_26_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_26_3"
  type: "BatchNorm"
  bottom: "res_stage_3_26_3"
  top: "res_stage_3_26_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_26_3"  
  type: "Scale"
  bottom: "res_stage_3_26_3"
  top: "res_stage_3_26_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_26"
  type: "Eltwise"
  bottom: "res_3_25"
  bottom: "res_stage_3_26_3_top"
  top: "res_3_26"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_26_relu"
  type: "ReLU"
  bottom: "res_3_26"
  top: "res_3_26"
}
layer {
  name: "res_stage_3_27_1"
  type: "Convolution"
  bottom: "res_3_26"
  top: "res_stage_3_27_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_27_1"
  type: "BatchNorm"
  bottom: "res_stage_3_27_1"
  top: "res_stage_3_27_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_27_1"  
  type: "Scale"
  bottom: "res_stage_3_27_1"
  top: "res_stage_3_27_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_27_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_27_1_top"
  top: "res_stage_3_27_1_top"
}
layer {
  name: "res_stage_3_27_2"
  type: "Convolution"
  bottom: "res_stage_3_27_1_top"
  top: "res_stage_3_27_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_27_2"
  type: "BatchNorm"
  bottom: "res_stage_3_27_2"
  top: "res_stage_3_27_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_27_2"  
  type: "Scale"
  bottom: "res_stage_3_27_2"
  top: "res_stage_3_27_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_27_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_27_2_top"
  top: "res_stage_3_27_2_top"
}
layer {
  name: "res_stage_3_27_3"
  type: "Convolution"
  bottom: "res_stage_3_27_2_top"
  top: "res_stage_3_27_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_27_3"
  type: "BatchNorm"
  bottom: "res_stage_3_27_3"
  top: "res_stage_3_27_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_27_3"  
  type: "Scale"
  bottom: "res_stage_3_27_3"
  top: "res_stage_3_27_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_27"
  type: "Eltwise"
  bottom: "res_3_26"
  bottom: "res_stage_3_27_3_top"
  top: "res_3_27"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_27_relu"
  type: "ReLU"
  bottom: "res_3_27"
  top: "res_3_27"
}
layer {
  name: "res_stage_3_28_1"
  type: "Convolution"
  bottom: "res_3_27"
  top: "res_stage_3_28_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_28_1"
  type: "BatchNorm"
  bottom: "res_stage_3_28_1"
  top: "res_stage_3_28_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_28_1"  
  type: "Scale"
  bottom: "res_stage_3_28_1"
  top: "res_stage_3_28_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_28_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_28_1_top"
  top: "res_stage_3_28_1_top"
}
layer {
  name: "res_stage_3_28_2"
  type: "Convolution"
  bottom: "res_stage_3_28_1_top"
  top: "res_stage_3_28_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_28_2"
  type: "BatchNorm"
  bottom: "res_stage_3_28_2"
  top: "res_stage_3_28_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_28_2"  
  type: "Scale"
  bottom: "res_stage_3_28_2"
  top: "res_stage_3_28_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_28_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_28_2_top"
  top: "res_stage_3_28_2_top"
}
layer {
  name: "res_stage_3_28_3"
  type: "Convolution"
  bottom: "res_stage_3_28_2_top"
  top: "res_stage_3_28_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_28_3"
  type: "BatchNorm"
  bottom: "res_stage_3_28_3"
  top: "res_stage_3_28_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_28_3"  
  type: "Scale"
  bottom: "res_stage_3_28_3"
  top: "res_stage_3_28_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_28"
  type: "Eltwise"
  bottom: "res_3_27"
  bottom: "res_stage_3_28_3_top"
  top: "res_3_28"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_28_relu"
  type: "ReLU"
  bottom: "res_3_28"
  top: "res_3_28"
}
layer {
  name: "res_stage_3_29_1"
  type: "Convolution"
  bottom: "res_3_28"
  top: "res_stage_3_29_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_29_1"
  type: "BatchNorm"
  bottom: "res_stage_3_29_1"
  top: "res_stage_3_29_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_29_1"  
  type: "Scale"
  bottom: "res_stage_3_29_1"
  top: "res_stage_3_29_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_29_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_29_1_top"
  top: "res_stage_3_29_1_top"
}
layer {
  name: "res_stage_3_29_2"
  type: "Convolution"
  bottom: "res_stage_3_29_1_top"
  top: "res_stage_3_29_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_29_2"
  type: "BatchNorm"
  bottom: "res_stage_3_29_2"
  top: "res_stage_3_29_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_29_2"  
  type: "Scale"
  bottom: "res_stage_3_29_2"
  top: "res_stage_3_29_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_29_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_29_2_top"
  top: "res_stage_3_29_2_top"
}
layer {
  name: "res_stage_3_29_3"
  type: "Convolution"
  bottom: "res_stage_3_29_2_top"
  top: "res_stage_3_29_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_29_3"
  type: "BatchNorm"
  bottom: "res_stage_3_29_3"
  top: "res_stage_3_29_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_29_3"  
  type: "Scale"
  bottom: "res_stage_3_29_3"
  top: "res_stage_3_29_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_29"
  type: "Eltwise"
  bottom: "res_3_28"
  bottom: "res_stage_3_29_3_top"
  top: "res_3_29"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_29_relu"
  type: "ReLU"
  bottom: "res_3_29"
  top: "res_3_29"
}
layer {
  name: "res_stage_3_30_1"
  type: "Convolution"
  bottom: "res_3_29"
  top: "res_stage_3_30_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_30_1"
  type: "BatchNorm"
  bottom: "res_stage_3_30_1"
  top: "res_stage_3_30_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_30_1"  
  type: "Scale"
  bottom: "res_stage_3_30_1"
  top: "res_stage_3_30_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_30_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_30_1_top"
  top: "res_stage_3_30_1_top"
}
layer {
  name: "res_stage_3_30_2"
  type: "Convolution"
  bottom: "res_stage_3_30_1_top"
  top: "res_stage_3_30_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_30_2"
  type: "BatchNorm"
  bottom: "res_stage_3_30_2"
  top: "res_stage_3_30_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_30_2"  
  type: "Scale"
  bottom: "res_stage_3_30_2"
  top: "res_stage_3_30_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_30_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_30_2_top"
  top: "res_stage_3_30_2_top"
}
layer {
  name: "res_stage_3_30_3"
  type: "Convolution"
  bottom: "res_stage_3_30_2_top"
  top: "res_stage_3_30_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_30_3"
  type: "BatchNorm"
  bottom: "res_stage_3_30_3"
  top: "res_stage_3_30_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_30_3"  
  type: "Scale"
  bottom: "res_stage_3_30_3"
  top: "res_stage_3_30_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_30"
  type: "Eltwise"
  bottom: "res_3_29"
  bottom: "res_stage_3_30_3_top"
  top: "res_3_30"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_30_relu"
  type: "ReLU"
  bottom: "res_3_30"
  top: "res_3_30"
}
layer {
  name: "res_stage_3_31_1"
  type: "Convolution"
  bottom: "res_3_30"
  top: "res_stage_3_31_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_31_1"
  type: "BatchNorm"
  bottom: "res_stage_3_31_1"
  top: "res_stage_3_31_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_31_1"  
  type: "Scale"
  bottom: "res_stage_3_31_1"
  top: "res_stage_3_31_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_31_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_31_1_top"
  top: "res_stage_3_31_1_top"
}
layer {
  name: "res_stage_3_31_2"
  type: "Convolution"
  bottom: "res_stage_3_31_1_top"
  top: "res_stage_3_31_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_31_2"
  type: "BatchNorm"
  bottom: "res_stage_3_31_2"
  top: "res_stage_3_31_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_31_2"  
  type: "Scale"
  bottom: "res_stage_3_31_2"
  top: "res_stage_3_31_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_31_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_31_2_top"
  top: "res_stage_3_31_2_top"
}
layer {
  name: "res_stage_3_31_3"
  type: "Convolution"
  bottom: "res_stage_3_31_2_top"
  top: "res_stage_3_31_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_31_3"
  type: "BatchNorm"
  bottom: "res_stage_3_31_3"
  top: "res_stage_3_31_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_31_3"  
  type: "Scale"
  bottom: "res_stage_3_31_3"
  top: "res_stage_3_31_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_31"
  type: "Eltwise"
  bottom: "res_3_30"
  bottom: "res_stage_3_31_3_top"
  top: "res_3_31"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_31_relu"
  type: "ReLU"
  bottom: "res_3_31"
  top: "res_3_31"
}
layer {
  name: "res_stage_3_32_1"
  type: "Convolution"
  bottom: "res_3_31"
  top: "res_stage_3_32_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_32_1"
  type: "BatchNorm"
  bottom: "res_stage_3_32_1"
  top: "res_stage_3_32_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_32_1"  
  type: "Scale"
  bottom: "res_stage_3_32_1"
  top: "res_stage_3_32_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_32_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_32_1_top"
  top: "res_stage_3_32_1_top"
}
layer {
  name: "res_stage_3_32_2"
  type: "Convolution"
  bottom: "res_stage_3_32_1_top"
  top: "res_stage_3_32_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_32_2"
  type: "BatchNorm"
  bottom: "res_stage_3_32_2"
  top: "res_stage_3_32_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_32_2"  
  type: "Scale"
  bottom: "res_stage_3_32_2"
  top: "res_stage_3_32_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_32_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_32_2_top"
  top: "res_stage_3_32_2_top"
}
layer {
  name: "res_stage_3_32_3"
  type: "Convolution"
  bottom: "res_stage_3_32_2_top"
  top: "res_stage_3_32_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_32_3"
  type: "BatchNorm"
  bottom: "res_stage_3_32_3"
  top: "res_stage_3_32_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_32_3"  
  type: "Scale"
  bottom: "res_stage_3_32_3"
  top: "res_stage_3_32_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_32"
  type: "Eltwise"
  bottom: "res_3_31"
  bottom: "res_stage_3_32_3_top"
  top: "res_3_32"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_32_relu"
  type: "ReLU"
  bottom: "res_3_32"
  top: "res_3_32"
}
layer {
  name: "res_stage_3_33_1"
  type: "Convolution"
  bottom: "res_3_32"
  top: "res_stage_3_33_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_33_1"
  type: "BatchNorm"
  bottom: "res_stage_3_33_1"
  top: "res_stage_3_33_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_33_1"  
  type: "Scale"
  bottom: "res_stage_3_33_1"
  top: "res_stage_3_33_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_33_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_33_1_top"
  top: "res_stage_3_33_1_top"
}
layer {
  name: "res_stage_3_33_2"
  type: "Convolution"
  bottom: "res_stage_3_33_1_top"
  top: "res_stage_3_33_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_33_2"
  type: "BatchNorm"
  bottom: "res_stage_3_33_2"
  top: "res_stage_3_33_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_33_2"  
  type: "Scale"
  bottom: "res_stage_3_33_2"
  top: "res_stage_3_33_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_33_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_33_2_top"
  top: "res_stage_3_33_2_top"
}
layer {
  name: "res_stage_3_33_3"
  type: "Convolution"
  bottom: "res_stage_3_33_2_top"
  top: "res_stage_3_33_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_33_3"
  type: "BatchNorm"
  bottom: "res_stage_3_33_3"
  top: "res_stage_3_33_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_33_3"  
  type: "Scale"
  bottom: "res_stage_3_33_3"
  top: "res_stage_3_33_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_33"
  type: "Eltwise"
  bottom: "res_3_32"
  bottom: "res_stage_3_33_3_top"
  top: "res_3_33"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_33_relu"
  type: "ReLU"
  bottom: "res_3_33"
  top: "res_3_33"
}
layer {
  name: "res_stage_3_34_1"
  type: "Convolution"
  bottom: "res_3_33"
  top: "res_stage_3_34_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_34_1"
  type: "BatchNorm"
  bottom: "res_stage_3_34_1"
  top: "res_stage_3_34_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_34_1"  
  type: "Scale"
  bottom: "res_stage_3_34_1"
  top: "res_stage_3_34_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_34_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_34_1_top"
  top: "res_stage_3_34_1_top"
}
layer {
  name: "res_stage_3_34_2"
  type: "Convolution"
  bottom: "res_stage_3_34_1_top"
  top: "res_stage_3_34_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_34_2"
  type: "BatchNorm"
  bottom: "res_stage_3_34_2"
  top: "res_stage_3_34_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_34_2"  
  type: "Scale"
  bottom: "res_stage_3_34_2"
  top: "res_stage_3_34_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_34_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_34_2_top"
  top: "res_stage_3_34_2_top"
}
layer {
  name: "res_stage_3_34_3"
  type: "Convolution"
  bottom: "res_stage_3_34_2_top"
  top: "res_stage_3_34_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_34_3"
  type: "BatchNorm"
  bottom: "res_stage_3_34_3"
  top: "res_stage_3_34_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_34_3"  
  type: "Scale"
  bottom: "res_stage_3_34_3"
  top: "res_stage_3_34_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_34"
  type: "Eltwise"
  bottom: "res_3_33"
  bottom: "res_stage_3_34_3_top"
  top: "res_3_34"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_34_relu"
  type: "ReLU"
  bottom: "res_3_34"
  top: "res_3_34"
}
layer {
  name: "res_stage_3_35_1"
  type: "Convolution"
  bottom: "res_3_34"
  top: "res_stage_3_35_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_35_1"
  type: "BatchNorm"
  bottom: "res_stage_3_35_1"
  top: "res_stage_3_35_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_35_1"  
  type: "Scale"
  bottom: "res_stage_3_35_1"
  top: "res_stage_3_35_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_35_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_35_1_top"
  top: "res_stage_3_35_1_top"
}
layer {
  name: "res_stage_3_35_2"
  type: "Convolution"
  bottom: "res_stage_3_35_1_top"
  top: "res_stage_3_35_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_35_2"
  type: "BatchNorm"
  bottom: "res_stage_3_35_2"
  top: "res_stage_3_35_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_35_2"  
  type: "Scale"
  bottom: "res_stage_3_35_2"
  top: "res_stage_3_35_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_35_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_35_2_top"
  top: "res_stage_3_35_2_top"
}
layer {
  name: "res_stage_3_35_3"
  type: "Convolution"
  bottom: "res_stage_3_35_2_top"
  top: "res_stage_3_35_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_35_3"
  type: "BatchNorm"
  bottom: "res_stage_3_35_3"
  top: "res_stage_3_35_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_35_3"  
  type: "Scale"
  bottom: "res_stage_3_35_3"
  top: "res_stage_3_35_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_35"
  type: "Eltwise"
  bottom: "res_3_34"
  bottom: "res_stage_3_35_3_top"
  top: "res_3_35"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_35_relu"
  type: "ReLU"
  bottom: "res_3_35"
  top: "res_3_35"
}
layer {
  name: "res_stage_3_36_1"
  type: "Convolution"
  bottom: "res_3_35"
  top: "res_stage_3_36_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_36_1"
  type: "BatchNorm"
  bottom: "res_stage_3_36_1"
  top: "res_stage_3_36_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_36_1"  
  type: "Scale"
  bottom: "res_stage_3_36_1"
  top: "res_stage_3_36_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_36_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_36_1_top"
  top: "res_stage_3_36_1_top"
}
layer {
  name: "res_stage_3_36_2"
  type: "Convolution"
  bottom: "res_stage_3_36_1_top"
  top: "res_stage_3_36_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_36_2"
  type: "BatchNorm"
  bottom: "res_stage_3_36_2"
  top: "res_stage_3_36_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_36_2"  
  type: "Scale"
  bottom: "res_stage_3_36_2"
  top: "res_stage_3_36_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_36_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_36_2_top"
  top: "res_stage_3_36_2_top"
}
layer {
  name: "res_stage_3_36_3"
  type: "Convolution"
  bottom: "res_stage_3_36_2_top"
  top: "res_stage_3_36_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_36_3"
  type: "BatchNorm"
  bottom: "res_stage_3_36_3"
  top: "res_stage_3_36_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_36_3"  
  type: "Scale"
  bottom: "res_stage_3_36_3"
  top: "res_stage_3_36_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_36"
  type: "Eltwise"
  bottom: "res_3_35"
  bottom: "res_stage_3_36_3_top"
  top: "res_3_36"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_36_relu"
  type: "ReLU"
  bottom: "res_3_36"
  top: "res_3_36"
}
layer {
  name: "res_stage_3_37_1"
  type: "Convolution"
  bottom: "res_3_36"
  top: "res_stage_3_37_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_37_1"
  type: "BatchNorm"
  bottom: "res_stage_3_37_1"
  top: "res_stage_3_37_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_37_1"  
  type: "Scale"
  bottom: "res_stage_3_37_1"
  top: "res_stage_3_37_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_37_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_37_1_top"
  top: "res_stage_3_37_1_top"
}
layer {
  name: "res_stage_3_37_2"
  type: "Convolution"
  bottom: "res_stage_3_37_1_top"
  top: "res_stage_3_37_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_37_2"
  type: "BatchNorm"
  bottom: "res_stage_3_37_2"
  top: "res_stage_3_37_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_37_2"  
  type: "Scale"
  bottom: "res_stage_3_37_2"
  top: "res_stage_3_37_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_37_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_37_2_top"
  top: "res_stage_3_37_2_top"
}
layer {
  name: "res_stage_3_37_3"
  type: "Convolution"
  bottom: "res_stage_3_37_2_top"
  top: "res_stage_3_37_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_37_3"
  type: "BatchNorm"
  bottom: "res_stage_3_37_3"
  top: "res_stage_3_37_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_37_3"  
  type: "Scale"
  bottom: "res_stage_3_37_3"
  top: "res_stage_3_37_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_37"
  type: "Eltwise"
  bottom: "res_3_36"
  bottom: "res_stage_3_37_3_top"
  top: "res_3_37"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_37_relu"
  type: "ReLU"
  bottom: "res_3_37"
  top: "res_3_37"
}
layer {
  name: "res_stage_3_38_1"
  type: "Convolution"
  bottom: "res_3_37"
  top: "res_stage_3_38_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_38_1"
  type: "BatchNorm"
  bottom: "res_stage_3_38_1"
  top: "res_stage_3_38_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_38_1"  
  type: "Scale"
  bottom: "res_stage_3_38_1"
  top: "res_stage_3_38_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_38_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_38_1_top"
  top: "res_stage_3_38_1_top"
}
layer {
  name: "res_stage_3_38_2"
  type: "Convolution"
  bottom: "res_stage_3_38_1_top"
  top: "res_stage_3_38_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_38_2"
  type: "BatchNorm"
  bottom: "res_stage_3_38_2"
  top: "res_stage_3_38_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_38_2"  
  type: "Scale"
  bottom: "res_stage_3_38_2"
  top: "res_stage_3_38_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_38_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_38_2_top"
  top: "res_stage_3_38_2_top"
}
layer {
  name: "res_stage_3_38_3"
  type: "Convolution"
  bottom: "res_stage_3_38_2_top"
  top: "res_stage_3_38_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_38_3"
  type: "BatchNorm"
  bottom: "res_stage_3_38_3"
  top: "res_stage_3_38_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_38_3"  
  type: "Scale"
  bottom: "res_stage_3_38_3"
  top: "res_stage_3_38_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_38"
  type: "Eltwise"
  bottom: "res_3_37"
  bottom: "res_stage_3_38_3_top"
  top: "res_3_38"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_38_relu"
  type: "ReLU"
  bottom: "res_3_38"
  top: "res_3_38"
}
layer {
  name: "res_stage_3_39_1"
  type: "Convolution"
  bottom: "res_3_38"
  top: "res_stage_3_39_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_39_1"
  type: "BatchNorm"
  bottom: "res_stage_3_39_1"
  top: "res_stage_3_39_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_39_1"  
  type: "Scale"
  bottom: "res_stage_3_39_1"
  top: "res_stage_3_39_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_39_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_39_1_top"
  top: "res_stage_3_39_1_top"
}
layer {
  name: "res_stage_3_39_2"
  type: "Convolution"
  bottom: "res_stage_3_39_1_top"
  top: "res_stage_3_39_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_39_2"
  type: "BatchNorm"
  bottom: "res_stage_3_39_2"
  top: "res_stage_3_39_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_39_2"  
  type: "Scale"
  bottom: "res_stage_3_39_2"
  top: "res_stage_3_39_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_39_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_39_2_top"
  top: "res_stage_3_39_2_top"
}
layer {
  name: "res_stage_3_39_3"
  type: "Convolution"
  bottom: "res_stage_3_39_2_top"
  top: "res_stage_3_39_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_39_3"
  type: "BatchNorm"
  bottom: "res_stage_3_39_3"
  top: "res_stage_3_39_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_39_3"  
  type: "Scale"
  bottom: "res_stage_3_39_3"
  top: "res_stage_3_39_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_39"
  type: "Eltwise"
  bottom: "res_3_38"
  bottom: "res_stage_3_39_3_top"
  top: "res_3_39"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_39_relu"
  type: "ReLU"
  bottom: "res_3_39"
  top: "res_3_39"
}
layer {
  name: "res_stage_3_40_1"
  type: "Convolution"
  bottom: "res_3_39"
  top: "res_stage_3_40_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_40_1"
  type: "BatchNorm"
  bottom: "res_stage_3_40_1"
  top: "res_stage_3_40_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_40_1"  
  type: "Scale"
  bottom: "res_stage_3_40_1"
  top: "res_stage_3_40_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_40_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_40_1_top"
  top: "res_stage_3_40_1_top"
}
layer {
  name: "res_stage_3_40_2"
  type: "Convolution"
  bottom: "res_stage_3_40_1_top"
  top: "res_stage_3_40_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_40_2"
  type: "BatchNorm"
  bottom: "res_stage_3_40_2"
  top: "res_stage_3_40_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_40_2"  
  type: "Scale"
  bottom: "res_stage_3_40_2"
  top: "res_stage_3_40_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_40_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_40_2_top"
  top: "res_stage_3_40_2_top"
}
layer {
  name: "res_stage_3_40_3"
  type: "Convolution"
  bottom: "res_stage_3_40_2_top"
  top: "res_stage_3_40_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_40_3"
  type: "BatchNorm"
  bottom: "res_stage_3_40_3"
  top: "res_stage_3_40_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_40_3"  
  type: "Scale"
  bottom: "res_stage_3_40_3"
  top: "res_stage_3_40_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_40"
  type: "Eltwise"
  bottom: "res_3_39"
  bottom: "res_stage_3_40_3_top"
  top: "res_3_40"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_40_relu"
  type: "ReLU"
  bottom: "res_3_40"
  top: "res_3_40"
}
layer {
  name: "res_stage_3_41_1"
  type: "Convolution"
  bottom: "res_3_40"
  top: "res_stage_3_41_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_41_1"
  type: "BatchNorm"
  bottom: "res_stage_3_41_1"
  top: "res_stage_3_41_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_41_1"  
  type: "Scale"
  bottom: "res_stage_3_41_1"
  top: "res_stage_3_41_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_41_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_41_1_top"
  top: "res_stage_3_41_1_top"
}
layer {
  name: "res_stage_3_41_2"
  type: "Convolution"
  bottom: "res_stage_3_41_1_top"
  top: "res_stage_3_41_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_41_2"
  type: "BatchNorm"
  bottom: "res_stage_3_41_2"
  top: "res_stage_3_41_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_41_2"  
  type: "Scale"
  bottom: "res_stage_3_41_2"
  top: "res_stage_3_41_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_41_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_41_2_top"
  top: "res_stage_3_41_2_top"
}
layer {
  name: "res_stage_3_41_3"
  type: "Convolution"
  bottom: "res_stage_3_41_2_top"
  top: "res_stage_3_41_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_41_3"
  type: "BatchNorm"
  bottom: "res_stage_3_41_3"
  top: "res_stage_3_41_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_41_3"  
  type: "Scale"
  bottom: "res_stage_3_41_3"
  top: "res_stage_3_41_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_41"
  type: "Eltwise"
  bottom: "res_3_40"
  bottom: "res_stage_3_41_3_top"
  top: "res_3_41"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_41_relu"
  type: "ReLU"
  bottom: "res_3_41"
  top: "res_3_41"
}
layer {
  name: "res_stage_3_42_1"
  type: "Convolution"
  bottom: "res_3_41"
  top: "res_stage_3_42_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_42_1"
  type: "BatchNorm"
  bottom: "res_stage_3_42_1"
  top: "res_stage_3_42_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_42_1"  
  type: "Scale"
  bottom: "res_stage_3_42_1"
  top: "res_stage_3_42_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_42_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_42_1_top"
  top: "res_stage_3_42_1_top"
}
layer {
  name: "res_stage_3_42_2"
  type: "Convolution"
  bottom: "res_stage_3_42_1_top"
  top: "res_stage_3_42_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_42_2"
  type: "BatchNorm"
  bottom: "res_stage_3_42_2"
  top: "res_stage_3_42_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_42_2"  
  type: "Scale"
  bottom: "res_stage_3_42_2"
  top: "res_stage_3_42_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_42_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_42_2_top"
  top: "res_stage_3_42_2_top"
}
layer {
  name: "res_stage_3_42_3"
  type: "Convolution"
  bottom: "res_stage_3_42_2_top"
  top: "res_stage_3_42_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_42_3"
  type: "BatchNorm"
  bottom: "res_stage_3_42_3"
  top: "res_stage_3_42_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_42_3"  
  type: "Scale"
  bottom: "res_stage_3_42_3"
  top: "res_stage_3_42_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_42"
  type: "Eltwise"
  bottom: "res_3_41"
  bottom: "res_stage_3_42_3_top"
  top: "res_3_42"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_42_relu"
  type: "ReLU"
  bottom: "res_3_42"
  top: "res_3_42"
}
layer {
  name: "res_stage_3_43_1"
  type: "Convolution"
  bottom: "res_3_42"
  top: "res_stage_3_43_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_43_1"
  type: "BatchNorm"
  bottom: "res_stage_3_43_1"
  top: "res_stage_3_43_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_43_1"  
  type: "Scale"
  bottom: "res_stage_3_43_1"
  top: "res_stage_3_43_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_43_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_43_1_top"
  top: "res_stage_3_43_1_top"
}
layer {
  name: "res_stage_3_43_2"
  type: "Convolution"
  bottom: "res_stage_3_43_1_top"
  top: "res_stage_3_43_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_43_2"
  type: "BatchNorm"
  bottom: "res_stage_3_43_2"
  top: "res_stage_3_43_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_43_2"  
  type: "Scale"
  bottom: "res_stage_3_43_2"
  top: "res_stage_3_43_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_43_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_43_2_top"
  top: "res_stage_3_43_2_top"
}
layer {
  name: "res_stage_3_43_3"
  type: "Convolution"
  bottom: "res_stage_3_43_2_top"
  top: "res_stage_3_43_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_43_3"
  type: "BatchNorm"
  bottom: "res_stage_3_43_3"
  top: "res_stage_3_43_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_43_3"  
  type: "Scale"
  bottom: "res_stage_3_43_3"
  top: "res_stage_3_43_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_43"
  type: "Eltwise"
  bottom: "res_3_42"
  bottom: "res_stage_3_43_3_top"
  top: "res_3_43"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_43_relu"
  type: "ReLU"
  bottom: "res_3_43"
  top: "res_3_43"
}
layer {
  name: "res_stage_3_44_1"
  type: "Convolution"
  bottom: "res_3_43"
  top: "res_stage_3_44_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_44_1"
  type: "BatchNorm"
  bottom: "res_stage_3_44_1"
  top: "res_stage_3_44_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_44_1"  
  type: "Scale"
  bottom: "res_stage_3_44_1"
  top: "res_stage_3_44_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_44_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_44_1_top"
  top: "res_stage_3_44_1_top"
}
layer {
  name: "res_stage_3_44_2"
  type: "Convolution"
  bottom: "res_stage_3_44_1_top"
  top: "res_stage_3_44_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_44_2"
  type: "BatchNorm"
  bottom: "res_stage_3_44_2"
  top: "res_stage_3_44_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_44_2"  
  type: "Scale"
  bottom: "res_stage_3_44_2"
  top: "res_stage_3_44_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_44_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_44_2_top"
  top: "res_stage_3_44_2_top"
}
layer {
  name: "res_stage_3_44_3"
  type: "Convolution"
  bottom: "res_stage_3_44_2_top"
  top: "res_stage_3_44_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_44_3"
  type: "BatchNorm"
  bottom: "res_stage_3_44_3"
  top: "res_stage_3_44_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_44_3"  
  type: "Scale"
  bottom: "res_stage_3_44_3"
  top: "res_stage_3_44_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_44"
  type: "Eltwise"
  bottom: "res_3_43"
  bottom: "res_stage_3_44_3_top"
  top: "res_3_44"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_44_relu"
  type: "ReLU"
  bottom: "res_3_44"
  top: "res_3_44"
}
layer {
  name: "res_stage_3_45_1"
  type: "Convolution"
  bottom: "res_3_44"
  top: "res_stage_3_45_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_45_1"
  type: "BatchNorm"
  bottom: "res_stage_3_45_1"
  top: "res_stage_3_45_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_45_1"  
  type: "Scale"
  bottom: "res_stage_3_45_1"
  top: "res_stage_3_45_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_45_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_45_1_top"
  top: "res_stage_3_45_1_top"
}
layer {
  name: "res_stage_3_45_2"
  type: "Convolution"
  bottom: "res_stage_3_45_1_top"
  top: "res_stage_3_45_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_45_2"
  type: "BatchNorm"
  bottom: "res_stage_3_45_2"
  top: "res_stage_3_45_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_45_2"  
  type: "Scale"
  bottom: "res_stage_3_45_2"
  top: "res_stage_3_45_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_45_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_45_2_top"
  top: "res_stage_3_45_2_top"
}
layer {
  name: "res_stage_3_45_3"
  type: "Convolution"
  bottom: "res_stage_3_45_2_top"
  top: "res_stage_3_45_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_45_3"
  type: "BatchNorm"
  bottom: "res_stage_3_45_3"
  top: "res_stage_3_45_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_45_3"  
  type: "Scale"
  bottom: "res_stage_3_45_3"
  top: "res_stage_3_45_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_45"
  type: "Eltwise"
  bottom: "res_3_44"
  bottom: "res_stage_3_45_3_top"
  top: "res_3_45"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_45_relu"
  type: "ReLU"
  bottom: "res_3_45"
  top: "res_3_45"
}
layer {
  name: "res_stage_3_46_1"
  type: "Convolution"
  bottom: "res_3_45"
  top: "res_stage_3_46_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_46_1"
  type: "BatchNorm"
  bottom: "res_stage_3_46_1"
  top: "res_stage_3_46_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_46_1"  
  type: "Scale"
  bottom: "res_stage_3_46_1"
  top: "res_stage_3_46_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_46_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_46_1_top"
  top: "res_stage_3_46_1_top"
}
layer {
  name: "res_stage_3_46_2"
  type: "Convolution"
  bottom: "res_stage_3_46_1_top"
  top: "res_stage_3_46_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_46_2"
  type: "BatchNorm"
  bottom: "res_stage_3_46_2"
  top: "res_stage_3_46_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_46_2"  
  type: "Scale"
  bottom: "res_stage_3_46_2"
  top: "res_stage_3_46_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_46_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_46_2_top"
  top: "res_stage_3_46_2_top"
}
layer {
  name: "res_stage_3_46_3"
  type: "Convolution"
  bottom: "res_stage_3_46_2_top"
  top: "res_stage_3_46_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_46_3"
  type: "BatchNorm"
  bottom: "res_stage_3_46_3"
  top: "res_stage_3_46_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_46_3"  
  type: "Scale"
  bottom: "res_stage_3_46_3"
  top: "res_stage_3_46_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_46"
  type: "Eltwise"
  bottom: "res_3_45"
  bottom: "res_stage_3_46_3_top"
  top: "res_3_46"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_46_relu"
  type: "ReLU"
  bottom: "res_3_46"
  top: "res_3_46"
}
layer {
  name: "res_stage_3_47_1"
  type: "Convolution"
  bottom: "res_3_46"
  top: "res_stage_3_47_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_47_1"
  type: "BatchNorm"
  bottom: "res_stage_3_47_1"
  top: "res_stage_3_47_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_47_1"  
  type: "Scale"
  bottom: "res_stage_3_47_1"
  top: "res_stage_3_47_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_47_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_47_1_top"
  top: "res_stage_3_47_1_top"
}
layer {
  name: "res_stage_3_47_2"
  type: "Convolution"
  bottom: "res_stage_3_47_1_top"
  top: "res_stage_3_47_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_47_2"
  type: "BatchNorm"
  bottom: "res_stage_3_47_2"
  top: "res_stage_3_47_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_47_2"  
  type: "Scale"
  bottom: "res_stage_3_47_2"
  top: "res_stage_3_47_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_47_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_47_2_top"
  top: "res_stage_3_47_2_top"
}
layer {
  name: "res_stage_3_47_3"
  type: "Convolution"
  bottom: "res_stage_3_47_2_top"
  top: "res_stage_3_47_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_47_3"
  type: "BatchNorm"
  bottom: "res_stage_3_47_3"
  top: "res_stage_3_47_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_47_3"  
  type: "Scale"
  bottom: "res_stage_3_47_3"
  top: "res_stage_3_47_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_47"
  type: "Eltwise"
  bottom: "res_3_46"
  bottom: "res_stage_3_47_3_top"
  top: "res_3_47"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_47_relu"
  type: "ReLU"
  bottom: "res_3_47"
  top: "res_3_47"
}
layer {
  name: "res_stage_3_48_1"
  type: "Convolution"
  bottom: "res_3_47"
  top: "res_stage_3_48_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_48_1"
  type: "BatchNorm"
  bottom: "res_stage_3_48_1"
  top: "res_stage_3_48_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_48_1"  
  type: "Scale"
  bottom: "res_stage_3_48_1"
  top: "res_stage_3_48_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_48_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_48_1_top"
  top: "res_stage_3_48_1_top"
}
layer {
  name: "res_stage_3_48_2"
  type: "Convolution"
  bottom: "res_stage_3_48_1_top"
  top: "res_stage_3_48_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_48_2"
  type: "BatchNorm"
  bottom: "res_stage_3_48_2"
  top: "res_stage_3_48_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_48_2"  
  type: "Scale"
  bottom: "res_stage_3_48_2"
  top: "res_stage_3_48_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_48_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_48_2_top"
  top: "res_stage_3_48_2_top"
}
layer {
  name: "res_stage_3_48_3"
  type: "Convolution"
  bottom: "res_stage_3_48_2_top"
  top: "res_stage_3_48_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_48_3"
  type: "BatchNorm"
  bottom: "res_stage_3_48_3"
  top: "res_stage_3_48_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_48_3"  
  type: "Scale"
  bottom: "res_stage_3_48_3"
  top: "res_stage_3_48_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_48"
  type: "Eltwise"
  bottom: "res_3_47"
  bottom: "res_stage_3_48_3_top"
  top: "res_3_48"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_48_relu"
  type: "ReLU"
  bottom: "res_3_48"
  top: "res_3_48"
}
layer {
  name: "res_stage_3_49_1"
  type: "Convolution"
  bottom: "res_3_48"
  top: "res_stage_3_49_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_49_1"
  type: "BatchNorm"
  bottom: "res_stage_3_49_1"
  top: "res_stage_3_49_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_49_1"  
  type: "Scale"
  bottom: "res_stage_3_49_1"
  top: "res_stage_3_49_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_49_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_49_1_top"
  top: "res_stage_3_49_1_top"
}
layer {
  name: "res_stage_3_49_2"
  type: "Convolution"
  bottom: "res_stage_3_49_1_top"
  top: "res_stage_3_49_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_49_2"
  type: "BatchNorm"
  bottom: "res_stage_3_49_2"
  top: "res_stage_3_49_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_49_2"  
  type: "Scale"
  bottom: "res_stage_3_49_2"
  top: "res_stage_3_49_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_49_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_49_2_top"
  top: "res_stage_3_49_2_top"
}
layer {
  name: "res_stage_3_49_3"
  type: "Convolution"
  bottom: "res_stage_3_49_2_top"
  top: "res_stage_3_49_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_49_3"
  type: "BatchNorm"
  bottom: "res_stage_3_49_3"
  top: "res_stage_3_49_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_49_3"  
  type: "Scale"
  bottom: "res_stage_3_49_3"
  top: "res_stage_3_49_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_49"
  type: "Eltwise"
  bottom: "res_3_48"
  bottom: "res_stage_3_49_3_top"
  top: "res_3_49"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_49_relu"
  type: "ReLU"
  bottom: "res_3_49"
  top: "res_3_49"
}
layer {
  name: "res_stage_3_50_1"
  type: "Convolution"
  bottom: "res_3_49"
  top: "res_stage_3_50_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_50_1"
  type: "BatchNorm"
  bottom: "res_stage_3_50_1"
  top: "res_stage_3_50_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_50_1"  
  type: "Scale"
  bottom: "res_stage_3_50_1"
  top: "res_stage_3_50_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_50_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_50_1_top"
  top: "res_stage_3_50_1_top"
}
layer {
  name: "res_stage_3_50_2"
  type: "Convolution"
  bottom: "res_stage_3_50_1_top"
  top: "res_stage_3_50_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_50_2"
  type: "BatchNorm"
  bottom: "res_stage_3_50_2"
  top: "res_stage_3_50_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_50_2"  
  type: "Scale"
  bottom: "res_stage_3_50_2"
  top: "res_stage_3_50_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_50_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_50_2_top"
  top: "res_stage_3_50_2_top"
}
layer {
  name: "res_stage_3_50_3"
  type: "Convolution"
  bottom: "res_stage_3_50_2_top"
  top: "res_stage_3_50_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_50_3"
  type: "BatchNorm"
  bottom: "res_stage_3_50_3"
  top: "res_stage_3_50_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_50_3"  
  type: "Scale"
  bottom: "res_stage_3_50_3"
  top: "res_stage_3_50_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_50"
  type: "Eltwise"
  bottom: "res_3_49"
  bottom: "res_stage_3_50_3_top"
  top: "res_3_50"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_50_relu"
  type: "ReLU"
  bottom: "res_3_50"
  top: "res_3_50"
}
layer {
  name: "res_stage_3_51_1"
  type: "Convolution"
  bottom: "res_3_50"
  top: "res_stage_3_51_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_51_1"
  type: "BatchNorm"
  bottom: "res_stage_3_51_1"
  top: "res_stage_3_51_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_51_1"  
  type: "Scale"
  bottom: "res_stage_3_51_1"
  top: "res_stage_3_51_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_51_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_51_1_top"
  top: "res_stage_3_51_1_top"
}
layer {
  name: "res_stage_3_51_2"
  type: "Convolution"
  bottom: "res_stage_3_51_1_top"
  top: "res_stage_3_51_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_51_2"
  type: "BatchNorm"
  bottom: "res_stage_3_51_2"
  top: "res_stage_3_51_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_51_2"  
  type: "Scale"
  bottom: "res_stage_3_51_2"
  top: "res_stage_3_51_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_51_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_51_2_top"
  top: "res_stage_3_51_2_top"
}
layer {
  name: "res_stage_3_51_3"
  type: "Convolution"
  bottom: "res_stage_3_51_2_top"
  top: "res_stage_3_51_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_51_3"
  type: "BatchNorm"
  bottom: "res_stage_3_51_3"
  top: "res_stage_3_51_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_51_3"  
  type: "Scale"
  bottom: "res_stage_3_51_3"
  top: "res_stage_3_51_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_51"
  type: "Eltwise"
  bottom: "res_3_50"
  bottom: "res_stage_3_51_3_top"
  top: "res_3_51"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_51_relu"
  type: "ReLU"
  bottom: "res_3_51"
  top: "res_3_51"
}
layer {
  name: "res_stage_3_52_1"
  type: "Convolution"
  bottom: "res_3_51"
  top: "res_stage_3_52_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_52_1"
  type: "BatchNorm"
  bottom: "res_stage_3_52_1"
  top: "res_stage_3_52_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_52_1"  
  type: "Scale"
  bottom: "res_stage_3_52_1"
  top: "res_stage_3_52_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_52_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_52_1_top"
  top: "res_stage_3_52_1_top"
}
layer {
  name: "res_stage_3_52_2"
  type: "Convolution"
  bottom: "res_stage_3_52_1_top"
  top: "res_stage_3_52_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_52_2"
  type: "BatchNorm"
  bottom: "res_stage_3_52_2"
  top: "res_stage_3_52_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_52_2"  
  type: "Scale"
  bottom: "res_stage_3_52_2"
  top: "res_stage_3_52_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_52_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_52_2_top"
  top: "res_stage_3_52_2_top"
}
layer {
  name: "res_stage_3_52_3"
  type: "Convolution"
  bottom: "res_stage_3_52_2_top"
  top: "res_stage_3_52_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_52_3"
  type: "BatchNorm"
  bottom: "res_stage_3_52_3"
  top: "res_stage_3_52_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_52_3"  
  type: "Scale"
  bottom: "res_stage_3_52_3"
  top: "res_stage_3_52_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_52"
  type: "Eltwise"
  bottom: "res_3_51"
  bottom: "res_stage_3_52_3_top"
  top: "res_3_52"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_52_relu"
  type: "ReLU"
  bottom: "res_3_52"
  top: "res_3_52"
}
layer {
  name: "res_stage_3_53_1"
  type: "Convolution"
  bottom: "res_3_52"
  top: "res_stage_3_53_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_53_1"
  type: "BatchNorm"
  bottom: "res_stage_3_53_1"
  top: "res_stage_3_53_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_53_1"  
  type: "Scale"
  bottom: "res_stage_3_53_1"
  top: "res_stage_3_53_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_53_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_53_1_top"
  top: "res_stage_3_53_1_top"
}
layer {
  name: "res_stage_3_53_2"
  type: "Convolution"
  bottom: "res_stage_3_53_1_top"
  top: "res_stage_3_53_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_53_2"
  type: "BatchNorm"
  bottom: "res_stage_3_53_2"
  top: "res_stage_3_53_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_53_2"  
  type: "Scale"
  bottom: "res_stage_3_53_2"
  top: "res_stage_3_53_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_53_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_53_2_top"
  top: "res_stage_3_53_2_top"
}
layer {
  name: "res_stage_3_53_3"
  type: "Convolution"
  bottom: "res_stage_3_53_2_top"
  top: "res_stage_3_53_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_53_3"
  type: "BatchNorm"
  bottom: "res_stage_3_53_3"
  top: "res_stage_3_53_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_53_3"  
  type: "Scale"
  bottom: "res_stage_3_53_3"
  top: "res_stage_3_53_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_53"
  type: "Eltwise"
  bottom: "res_3_52"
  bottom: "res_stage_3_53_3_top"
  top: "res_3_53"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_53_relu"
  type: "ReLU"
  bottom: "res_3_53"
  top: "res_3_53"
}
layer {
  name: "res_stage_3_54_1"
  type: "Convolution"
  bottom: "res_3_53"
  top: "res_stage_3_54_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_54_1"
  type: "BatchNorm"
  bottom: "res_stage_3_54_1"
  top: "res_stage_3_54_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_54_1"  
  type: "Scale"
  bottom: "res_stage_3_54_1"
  top: "res_stage_3_54_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_54_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_54_1_top"
  top: "res_stage_3_54_1_top"
}
layer {
  name: "res_stage_3_54_2"
  type: "Convolution"
  bottom: "res_stage_3_54_1_top"
  top: "res_stage_3_54_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_54_2"
  type: "BatchNorm"
  bottom: "res_stage_3_54_2"
  top: "res_stage_3_54_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_54_2"  
  type: "Scale"
  bottom: "res_stage_3_54_2"
  top: "res_stage_3_54_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_54_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_54_2_top"
  top: "res_stage_3_54_2_top"
}
layer {
  name: "res_stage_3_54_3"
  type: "Convolution"
  bottom: "res_stage_3_54_2_top"
  top: "res_stage_3_54_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_54_3"
  type: "BatchNorm"
  bottom: "res_stage_3_54_3"
  top: "res_stage_3_54_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_54_3"  
  type: "Scale"
  bottom: "res_stage_3_54_3"
  top: "res_stage_3_54_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_54"
  type: "Eltwise"
  bottom: "res_3_53"
  bottom: "res_stage_3_54_3_top"
  top: "res_3_54"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_54_relu"
  type: "ReLU"
  bottom: "res_3_54"
  top: "res_3_54"
}
layer {
  name: "res_stage_3_55_1"
  type: "Convolution"
  bottom: "res_3_54"
  top: "res_stage_3_55_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_55_1"
  type: "BatchNorm"
  bottom: "res_stage_3_55_1"
  top: "res_stage_3_55_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_55_1"  
  type: "Scale"
  bottom: "res_stage_3_55_1"
  top: "res_stage_3_55_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_55_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_55_1_top"
  top: "res_stage_3_55_1_top"
}
layer {
  name: "res_stage_3_55_2"
  type: "Convolution"
  bottom: "res_stage_3_55_1_top"
  top: "res_stage_3_55_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_55_2"
  type: "BatchNorm"
  bottom: "res_stage_3_55_2"
  top: "res_stage_3_55_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_55_2"  
  type: "Scale"
  bottom: "res_stage_3_55_2"
  top: "res_stage_3_55_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_55_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_55_2_top"
  top: "res_stage_3_55_2_top"
}
layer {
  name: "res_stage_3_55_3"
  type: "Convolution"
  bottom: "res_stage_3_55_2_top"
  top: "res_stage_3_55_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_55_3"
  type: "BatchNorm"
  bottom: "res_stage_3_55_3"
  top: "res_stage_3_55_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_55_3"  
  type: "Scale"
  bottom: "res_stage_3_55_3"
  top: "res_stage_3_55_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_55"
  type: "Eltwise"
  bottom: "res_3_54"
  bottom: "res_stage_3_55_3_top"
  top: "res_3_55"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_55_relu"
  type: "ReLU"
  bottom: "res_3_55"
  top: "res_3_55"
}
layer {
  name: "res_stage_3_56_1"
  type: "Convolution"
  bottom: "res_3_55"
  top: "res_stage_3_56_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_56_1"
  type: "BatchNorm"
  bottom: "res_stage_3_56_1"
  top: "res_stage_3_56_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_56_1"  
  type: "Scale"
  bottom: "res_stage_3_56_1"
  top: "res_stage_3_56_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_56_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_56_1_top"
  top: "res_stage_3_56_1_top"
}
layer {
  name: "res_stage_3_56_2"
  type: "Convolution"
  bottom: "res_stage_3_56_1_top"
  top: "res_stage_3_56_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_56_2"
  type: "BatchNorm"
  bottom: "res_stage_3_56_2"
  top: "res_stage_3_56_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_56_2"  
  type: "Scale"
  bottom: "res_stage_3_56_2"
  top: "res_stage_3_56_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_56_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_56_2_top"
  top: "res_stage_3_56_2_top"
}
layer {
  name: "res_stage_3_56_3"
  type: "Convolution"
  bottom: "res_stage_3_56_2_top"
  top: "res_stage_3_56_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_56_3"
  type: "BatchNorm"
  bottom: "res_stage_3_56_3"
  top: "res_stage_3_56_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_56_3"  
  type: "Scale"
  bottom: "res_stage_3_56_3"
  top: "res_stage_3_56_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_56"
  type: "Eltwise"
  bottom: "res_3_55"
  bottom: "res_stage_3_56_3_top"
  top: "res_3_56"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_56_relu"
  type: "ReLU"
  bottom: "res_3_56"
  top: "res_3_56"
}
layer {
  name: "res_stage_3_57_1"
  type: "Convolution"
  bottom: "res_3_56"
  top: "res_stage_3_57_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_57_1"
  type: "BatchNorm"
  bottom: "res_stage_3_57_1"
  top: "res_stage_3_57_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_57_1"  
  type: "Scale"
  bottom: "res_stage_3_57_1"
  top: "res_stage_3_57_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_57_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_57_1_top"
  top: "res_stage_3_57_1_top"
}
layer {
  name: "res_stage_3_57_2"
  type: "Convolution"
  bottom: "res_stage_3_57_1_top"
  top: "res_stage_3_57_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_57_2"
  type: "BatchNorm"
  bottom: "res_stage_3_57_2"
  top: "res_stage_3_57_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_57_2"  
  type: "Scale"
  bottom: "res_stage_3_57_2"
  top: "res_stage_3_57_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_57_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_57_2_top"
  top: "res_stage_3_57_2_top"
}
layer {
  name: "res_stage_3_57_3"
  type: "Convolution"
  bottom: "res_stage_3_57_2_top"
  top: "res_stage_3_57_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_57_3"
  type: "BatchNorm"
  bottom: "res_stage_3_57_3"
  top: "res_stage_3_57_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_57_3"  
  type: "Scale"
  bottom: "res_stage_3_57_3"
  top: "res_stage_3_57_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_57"
  type: "Eltwise"
  bottom: "res_3_56"
  bottom: "res_stage_3_57_3_top"
  top: "res_3_57"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_57_relu"
  type: "ReLU"
  bottom: "res_3_57"
  top: "res_3_57"
}
layer {
  name: "res_stage_3_58_1"
  type: "Convolution"
  bottom: "res_3_57"
  top: "res_stage_3_58_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_58_1"
  type: "BatchNorm"
  bottom: "res_stage_3_58_1"
  top: "res_stage_3_58_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_58_1"  
  type: "Scale"
  bottom: "res_stage_3_58_1"
  top: "res_stage_3_58_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_58_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_58_1_top"
  top: "res_stage_3_58_1_top"
}
layer {
  name: "res_stage_3_58_2"
  type: "Convolution"
  bottom: "res_stage_3_58_1_top"
  top: "res_stage_3_58_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_58_2"
  type: "BatchNorm"
  bottom: "res_stage_3_58_2"
  top: "res_stage_3_58_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_58_2"  
  type: "Scale"
  bottom: "res_stage_3_58_2"
  top: "res_stage_3_58_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_58_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_58_2_top"
  top: "res_stage_3_58_2_top"
}
layer {
  name: "res_stage_3_58_3"
  type: "Convolution"
  bottom: "res_stage_3_58_2_top"
  top: "res_stage_3_58_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_58_3"
  type: "BatchNorm"
  bottom: "res_stage_3_58_3"
  top: "res_stage_3_58_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_58_3"  
  type: "Scale"
  bottom: "res_stage_3_58_3"
  top: "res_stage_3_58_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_58"
  type: "Eltwise"
  bottom: "res_3_57"
  bottom: "res_stage_3_58_3_top"
  top: "res_3_58"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_58_relu"
  type: "ReLU"
  bottom: "res_3_58"
  top: "res_3_58"
}
layer {
  name: "res_stage_3_59_1"
  type: "Convolution"
  bottom: "res_3_58"
  top: "res_stage_3_59_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_59_1"
  type: "BatchNorm"
  bottom: "res_stage_3_59_1"
  top: "res_stage_3_59_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_59_1"  
  type: "Scale"
  bottom: "res_stage_3_59_1"
  top: "res_stage_3_59_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_59_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_59_1_top"
  top: "res_stage_3_59_1_top"
}
layer {
  name: "res_stage_3_59_2"
  type: "Convolution"
  bottom: "res_stage_3_59_1_top"
  top: "res_stage_3_59_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_59_2"
  type: "BatchNorm"
  bottom: "res_stage_3_59_2"
  top: "res_stage_3_59_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_59_2"  
  type: "Scale"
  bottom: "res_stage_3_59_2"
  top: "res_stage_3_59_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_59_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_59_2_top"
  top: "res_stage_3_59_2_top"
}
layer {
  name: "res_stage_3_59_3"
  type: "Convolution"
  bottom: "res_stage_3_59_2_top"
  top: "res_stage_3_59_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_59_3"
  type: "BatchNorm"
  bottom: "res_stage_3_59_3"
  top: "res_stage_3_59_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_59_3"  
  type: "Scale"
  bottom: "res_stage_3_59_3"
  top: "res_stage_3_59_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_59"
  type: "Eltwise"
  bottom: "res_3_58"
  bottom: "res_stage_3_59_3_top"
  top: "res_3_59"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_59_relu"
  type: "ReLU"
  bottom: "res_3_59"
  top: "res_3_59"
}
layer {
  name: "res_stage_3_60_1"
  type: "Convolution"
  bottom: "res_3_59"
  top: "res_stage_3_60_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_60_1"
  type: "BatchNorm"
  bottom: "res_stage_3_60_1"
  top: "res_stage_3_60_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_60_1"  
  type: "Scale"
  bottom: "res_stage_3_60_1"
  top: "res_stage_3_60_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_60_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_60_1_top"
  top: "res_stage_3_60_1_top"
}
layer {
  name: "res_stage_3_60_2"
  type: "Convolution"
  bottom: "res_stage_3_60_1_top"
  top: "res_stage_3_60_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_60_2"
  type: "BatchNorm"
  bottom: "res_stage_3_60_2"
  top: "res_stage_3_60_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_60_2"  
  type: "Scale"
  bottom: "res_stage_3_60_2"
  top: "res_stage_3_60_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_60_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_60_2_top"
  top: "res_stage_3_60_2_top"
}
layer {
  name: "res_stage_3_60_3"
  type: "Convolution"
  bottom: "res_stage_3_60_2_top"
  top: "res_stage_3_60_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_60_3"
  type: "BatchNorm"
  bottom: "res_stage_3_60_3"
  top: "res_stage_3_60_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_60_3"  
  type: "Scale"
  bottom: "res_stage_3_60_3"
  top: "res_stage_3_60_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_60"
  type: "Eltwise"
  bottom: "res_3_59"
  bottom: "res_stage_3_60_3_top"
  top: "res_3_60"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_60_relu"
  type: "ReLU"
  bottom: "res_3_60"
  top: "res_3_60"
}
layer {
  name: "res_stage_3_61_1"
  type: "Convolution"
  bottom: "res_3_60"
  top: "res_stage_3_61_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_61_1"
  type: "BatchNorm"
  bottom: "res_stage_3_61_1"
  top: "res_stage_3_61_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_61_1"  
  type: "Scale"
  bottom: "res_stage_3_61_1"
  top: "res_stage_3_61_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_61_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_61_1_top"
  top: "res_stage_3_61_1_top"
}
layer {
  name: "res_stage_3_61_2"
  type: "Convolution"
  bottom: "res_stage_3_61_1_top"
  top: "res_stage_3_61_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_61_2"
  type: "BatchNorm"
  bottom: "res_stage_3_61_2"
  top: "res_stage_3_61_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_61_2"  
  type: "Scale"
  bottom: "res_stage_3_61_2"
  top: "res_stage_3_61_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_61_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_61_2_top"
  top: "res_stage_3_61_2_top"
}
layer {
  name: "res_stage_3_61_3"
  type: "Convolution"
  bottom: "res_stage_3_61_2_top"
  top: "res_stage_3_61_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_61_3"
  type: "BatchNorm"
  bottom: "res_stage_3_61_3"
  top: "res_stage_3_61_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_61_3"  
  type: "Scale"
  bottom: "res_stage_3_61_3"
  top: "res_stage_3_61_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_61"
  type: "Eltwise"
  bottom: "res_3_60"
  bottom: "res_stage_3_61_3_top"
  top: "res_3_61"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_61_relu"
  type: "ReLU"
  bottom: "res_3_61"
  top: "res_3_61"
}
layer {
  name: "res_stage_3_62_1"
  type: "Convolution"
  bottom: "res_3_61"
  top: "res_stage_3_62_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_62_1"
  type: "BatchNorm"
  bottom: "res_stage_3_62_1"
  top: "res_stage_3_62_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_62_1"  
  type: "Scale"
  bottom: "res_stage_3_62_1"
  top: "res_stage_3_62_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_62_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_62_1_top"
  top: "res_stage_3_62_1_top"
}
layer {
  name: "res_stage_3_62_2"
  type: "Convolution"
  bottom: "res_stage_3_62_1_top"
  top: "res_stage_3_62_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_62_2"
  type: "BatchNorm"
  bottom: "res_stage_3_62_2"
  top: "res_stage_3_62_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_62_2"  
  type: "Scale"
  bottom: "res_stage_3_62_2"
  top: "res_stage_3_62_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_62_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_62_2_top"
  top: "res_stage_3_62_2_top"
}
layer {
  name: "res_stage_3_62_3"
  type: "Convolution"
  bottom: "res_stage_3_62_2_top"
  top: "res_stage_3_62_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_62_3"
  type: "BatchNorm"
  bottom: "res_stage_3_62_3"
  top: "res_stage_3_62_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_62_3"  
  type: "Scale"
  bottom: "res_stage_3_62_3"
  top: "res_stage_3_62_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_62"
  type: "Eltwise"
  bottom: "res_3_61"
  bottom: "res_stage_3_62_3_top"
  top: "res_3_62"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_62_relu"
  type: "ReLU"
  bottom: "res_3_62"
  top: "res_3_62"
}
layer {
  name: "res_stage_3_63_1"
  type: "Convolution"
  bottom: "res_3_62"
  top: "res_stage_3_63_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_63_1"
  type: "BatchNorm"
  bottom: "res_stage_3_63_1"
  top: "res_stage_3_63_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_63_1"  
  type: "Scale"
  bottom: "res_stage_3_63_1"
  top: "res_stage_3_63_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_63_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_63_1_top"
  top: "res_stage_3_63_1_top"
}
layer {
  name: "res_stage_3_63_2"
  type: "Convolution"
  bottom: "res_stage_3_63_1_top"
  top: "res_stage_3_63_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_63_2"
  type: "BatchNorm"
  bottom: "res_stage_3_63_2"
  top: "res_stage_3_63_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_63_2"  
  type: "Scale"
  bottom: "res_stage_3_63_2"
  top: "res_stage_3_63_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_63_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_63_2_top"
  top: "res_stage_3_63_2_top"
}
layer {
  name: "res_stage_3_63_3"
  type: "Convolution"
  bottom: "res_stage_3_63_2_top"
  top: "res_stage_3_63_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_63_3"
  type: "BatchNorm"
  bottom: "res_stage_3_63_3"
  top: "res_stage_3_63_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_63_3"  
  type: "Scale"
  bottom: "res_stage_3_63_3"
  top: "res_stage_3_63_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_63"
  type: "Eltwise"
  bottom: "res_3_62"
  bottom: "res_stage_3_63_3_top"
  top: "res_3_63"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_63_relu"
  type: "ReLU"
  bottom: "res_3_63"
  top: "res_3_63"
}
layer {
  name: "res_stage_3_64_1"
  type: "Convolution"
  bottom: "res_3_63"
  top: "res_stage_3_64_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_64_1"
  type: "BatchNorm"
  bottom: "res_stage_3_64_1"
  top: "res_stage_3_64_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_64_1"  
  type: "Scale"
  bottom: "res_stage_3_64_1"
  top: "res_stage_3_64_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_64_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_64_1_top"
  top: "res_stage_3_64_1_top"
}
layer {
  name: "res_stage_3_64_2"
  type: "Convolution"
  bottom: "res_stage_3_64_1_top"
  top: "res_stage_3_64_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_64_2"
  type: "BatchNorm"
  bottom: "res_stage_3_64_2"
  top: "res_stage_3_64_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_64_2"  
  type: "Scale"
  bottom: "res_stage_3_64_2"
  top: "res_stage_3_64_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_64_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_64_2_top"
  top: "res_stage_3_64_2_top"
}
layer {
  name: "res_stage_3_64_3"
  type: "Convolution"
  bottom: "res_stage_3_64_2_top"
  top: "res_stage_3_64_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_64_3"
  type: "BatchNorm"
  bottom: "res_stage_3_64_3"
  top: "res_stage_3_64_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_64_3"  
  type: "Scale"
  bottom: "res_stage_3_64_3"
  top: "res_stage_3_64_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_64"
  type: "Eltwise"
  bottom: "res_3_63"
  bottom: "res_stage_3_64_3_top"
  top: "res_3_64"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_64_relu"
  type: "ReLU"
  bottom: "res_3_64"
  top: "res_3_64"
}
layer {
  name: "res_stage_3_65_1"
  type: "Convolution"
  bottom: "res_3_64"
  top: "res_stage_3_65_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_65_1"
  type: "BatchNorm"
  bottom: "res_stage_3_65_1"
  top: "res_stage_3_65_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_65_1"  
  type: "Scale"
  bottom: "res_stage_3_65_1"
  top: "res_stage_3_65_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_65_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_65_1_top"
  top: "res_stage_3_65_1_top"
}
layer {
  name: "res_stage_3_65_2"
  type: "Convolution"
  bottom: "res_stage_3_65_1_top"
  top: "res_stage_3_65_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_65_2"
  type: "BatchNorm"
  bottom: "res_stage_3_65_2"
  top: "res_stage_3_65_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_65_2"  
  type: "Scale"
  bottom: "res_stage_3_65_2"
  top: "res_stage_3_65_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_65_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_65_2_top"
  top: "res_stage_3_65_2_top"
}
layer {
  name: "res_stage_3_65_3"
  type: "Convolution"
  bottom: "res_stage_3_65_2_top"
  top: "res_stage_3_65_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_65_3"
  type: "BatchNorm"
  bottom: "res_stage_3_65_3"
  top: "res_stage_3_65_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_65_3"  
  type: "Scale"
  bottom: "res_stage_3_65_3"
  top: "res_stage_3_65_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_65"
  type: "Eltwise"
  bottom: "res_3_64"
  bottom: "res_stage_3_65_3_top"
  top: "res_3_65"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_65_relu"
  type: "ReLU"
  bottom: "res_3_65"
  top: "res_3_65"
}
layer {
  name: "res_stage_3_66_1"
  type: "Convolution"
  bottom: "res_3_65"
  top: "res_stage_3_66_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_66_1"
  type: "BatchNorm"
  bottom: "res_stage_3_66_1"
  top: "res_stage_3_66_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_66_1"  
  type: "Scale"
  bottom: "res_stage_3_66_1"
  top: "res_stage_3_66_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_66_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_66_1_top"
  top: "res_stage_3_66_1_top"
}
layer {
  name: "res_stage_3_66_2"
  type: "Convolution"
  bottom: "res_stage_3_66_1_top"
  top: "res_stage_3_66_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_66_2"
  type: "BatchNorm"
  bottom: "res_stage_3_66_2"
  top: "res_stage_3_66_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_66_2"  
  type: "Scale"
  bottom: "res_stage_3_66_2"
  top: "res_stage_3_66_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_66_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_66_2_top"
  top: "res_stage_3_66_2_top"
}
layer {
  name: "res_stage_3_66_3"
  type: "Convolution"
  bottom: "res_stage_3_66_2_top"
  top: "res_stage_3_66_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_66_3"
  type: "BatchNorm"
  bottom: "res_stage_3_66_3"
  top: "res_stage_3_66_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_66_3"  
  type: "Scale"
  bottom: "res_stage_3_66_3"
  top: "res_stage_3_66_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_66"
  type: "Eltwise"
  bottom: "res_3_65"
  bottom: "res_stage_3_66_3_top"
  top: "res_3_66"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_66_relu"
  type: "ReLU"
  bottom: "res_3_66"
  top: "res_3_66"
}
layer {
  name: "res_stage_3_67_1"
  type: "Convolution"
  bottom: "res_3_66"
  top: "res_stage_3_67_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_67_1"
  type: "BatchNorm"
  bottom: "res_stage_3_67_1"
  top: "res_stage_3_67_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_67_1"  
  type: "Scale"
  bottom: "res_stage_3_67_1"
  top: "res_stage_3_67_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_67_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_67_1_top"
  top: "res_stage_3_67_1_top"
}
layer {
  name: "res_stage_3_67_2"
  type: "Convolution"
  bottom: "res_stage_3_67_1_top"
  top: "res_stage_3_67_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_67_2"
  type: "BatchNorm"
  bottom: "res_stage_3_67_2"
  top: "res_stage_3_67_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_67_2"  
  type: "Scale"
  bottom: "res_stage_3_67_2"
  top: "res_stage_3_67_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_67_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_67_2_top"
  top: "res_stage_3_67_2_top"
}
layer {
  name: "res_stage_3_67_3"
  type: "Convolution"
  bottom: "res_stage_3_67_2_top"
  top: "res_stage_3_67_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_67_3"
  type: "BatchNorm"
  bottom: "res_stage_3_67_3"
  top: "res_stage_3_67_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_67_3"  
  type: "Scale"
  bottom: "res_stage_3_67_3"
  top: "res_stage_3_67_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_67"
  type: "Eltwise"
  bottom: "res_3_66"
  bottom: "res_stage_3_67_3_top"
  top: "res_3_67"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_67_relu"
  type: "ReLU"
  bottom: "res_3_67"
  top: "res_3_67"
}
layer {
  name: "res_stage_3_68_1"
  type: "Convolution"
  bottom: "res_3_67"
  top: "res_stage_3_68_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_68_1"
  type: "BatchNorm"
  bottom: "res_stage_3_68_1"
  top: "res_stage_3_68_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_68_1"  
  type: "Scale"
  bottom: "res_stage_3_68_1"
  top: "res_stage_3_68_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_68_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_68_1_top"
  top: "res_stage_3_68_1_top"
}
layer {
  name: "res_stage_3_68_2"
  type: "Convolution"
  bottom: "res_stage_3_68_1_top"
  top: "res_stage_3_68_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_68_2"
  type: "BatchNorm"
  bottom: "res_stage_3_68_2"
  top: "res_stage_3_68_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_68_2"  
  type: "Scale"
  bottom: "res_stage_3_68_2"
  top: "res_stage_3_68_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_68_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_68_2_top"
  top: "res_stage_3_68_2_top"
}
layer {
  name: "res_stage_3_68_3"
  type: "Convolution"
  bottom: "res_stage_3_68_2_top"
  top: "res_stage_3_68_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_68_3"
  type: "BatchNorm"
  bottom: "res_stage_3_68_3"
  top: "res_stage_3_68_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_68_3"  
  type: "Scale"
  bottom: "res_stage_3_68_3"
  top: "res_stage_3_68_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_68"
  type: "Eltwise"
  bottom: "res_3_67"
  bottom: "res_stage_3_68_3_top"
  top: "res_3_68"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_68_relu"
  type: "ReLU"
  bottom: "res_3_68"
  top: "res_3_68"
}
layer {
  name: "res_stage_3_69_1"
  type: "Convolution"
  bottom: "res_3_68"
  top: "res_stage_3_69_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_69_1"
  type: "BatchNorm"
  bottom: "res_stage_3_69_1"
  top: "res_stage_3_69_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_69_1"  
  type: "Scale"
  bottom: "res_stage_3_69_1"
  top: "res_stage_3_69_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_69_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_69_1_top"
  top: "res_stage_3_69_1_top"
}
layer {
  name: "res_stage_3_69_2"
  type: "Convolution"
  bottom: "res_stage_3_69_1_top"
  top: "res_stage_3_69_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_69_2"
  type: "BatchNorm"
  bottom: "res_stage_3_69_2"
  top: "res_stage_3_69_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_69_2"  
  type: "Scale"
  bottom: "res_stage_3_69_2"
  top: "res_stage_3_69_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_69_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_69_2_top"
  top: "res_stage_3_69_2_top"
}
layer {
  name: "res_stage_3_69_3"
  type: "Convolution"
  bottom: "res_stage_3_69_2_top"
  top: "res_stage_3_69_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_69_3"
  type: "BatchNorm"
  bottom: "res_stage_3_69_3"
  top: "res_stage_3_69_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_69_3"  
  type: "Scale"
  bottom: "res_stage_3_69_3"
  top: "res_stage_3_69_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_69"
  type: "Eltwise"
  bottom: "res_3_68"
  bottom: "res_stage_3_69_3_top"
  top: "res_3_69"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_69_relu"
  type: "ReLU"
  bottom: "res_3_69"
  top: "res_3_69"
}
layer {
  name: "res_stage_3_70_1"
  type: "Convolution"
  bottom: "res_3_69"
  top: "res_stage_3_70_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_70_1"
  type: "BatchNorm"
  bottom: "res_stage_3_70_1"
  top: "res_stage_3_70_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_70_1"  
  type: "Scale"
  bottom: "res_stage_3_70_1"
  top: "res_stage_3_70_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_70_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_70_1_top"
  top: "res_stage_3_70_1_top"
}
layer {
  name: "res_stage_3_70_2"
  type: "Convolution"
  bottom: "res_stage_3_70_1_top"
  top: "res_stage_3_70_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_70_2"
  type: "BatchNorm"
  bottom: "res_stage_3_70_2"
  top: "res_stage_3_70_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_70_2"  
  type: "Scale"
  bottom: "res_stage_3_70_2"
  top: "res_stage_3_70_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_70_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_70_2_top"
  top: "res_stage_3_70_2_top"
}
layer {
  name: "res_stage_3_70_3"
  type: "Convolution"
  bottom: "res_stage_3_70_2_top"
  top: "res_stage_3_70_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_70_3"
  type: "BatchNorm"
  bottom: "res_stage_3_70_3"
  top: "res_stage_3_70_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_70_3"  
  type: "Scale"
  bottom: "res_stage_3_70_3"
  top: "res_stage_3_70_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_70"
  type: "Eltwise"
  bottom: "res_3_69"
  bottom: "res_stage_3_70_3_top"
  top: "res_3_70"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_70_relu"
  type: "ReLU"
  bottom: "res_3_70"
  top: "res_3_70"
}
layer {
  name: "res_stage_3_71_1"
  type: "Convolution"
  bottom: "res_3_70"
  top: "res_stage_3_71_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_71_1"
  type: "BatchNorm"
  bottom: "res_stage_3_71_1"
  top: "res_stage_3_71_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_71_1"  
  type: "Scale"
  bottom: "res_stage_3_71_1"
  top: "res_stage_3_71_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_71_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_71_1_top"
  top: "res_stage_3_71_1_top"
}
layer {
  name: "res_stage_3_71_2"
  type: "Convolution"
  bottom: "res_stage_3_71_1_top"
  top: "res_stage_3_71_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_71_2"
  type: "BatchNorm"
  bottom: "res_stage_3_71_2"
  top: "res_stage_3_71_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_71_2"  
  type: "Scale"
  bottom: "res_stage_3_71_2"
  top: "res_stage_3_71_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_71_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_71_2_top"
  top: "res_stage_3_71_2_top"
}
layer {
  name: "res_stage_3_71_3"
  type: "Convolution"
  bottom: "res_stage_3_71_2_top"
  top: "res_stage_3_71_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_71_3"
  type: "BatchNorm"
  bottom: "res_stage_3_71_3"
  top: "res_stage_3_71_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_71_3"  
  type: "Scale"
  bottom: "res_stage_3_71_3"
  top: "res_stage_3_71_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_71"
  type: "Eltwise"
  bottom: "res_3_70"
  bottom: "res_stage_3_71_3_top"
  top: "res_3_71"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_71_relu"
  type: "ReLU"
  bottom: "res_3_71"
  top: "res_3_71"
}
layer {
  name: "res_stage_3_72_1"
  type: "Convolution"
  bottom: "res_3_71"
  top: "res_stage_3_72_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_72_1"
  type: "BatchNorm"
  bottom: "res_stage_3_72_1"
  top: "res_stage_3_72_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_72_1"  
  type: "Scale"
  bottom: "res_stage_3_72_1"
  top: "res_stage_3_72_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_72_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_72_1_top"
  top: "res_stage_3_72_1_top"
}
layer {
  name: "res_stage_3_72_2"
  type: "Convolution"
  bottom: "res_stage_3_72_1_top"
  top: "res_stage_3_72_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_72_2"
  type: "BatchNorm"
  bottom: "res_stage_3_72_2"
  top: "res_stage_3_72_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_72_2"  
  type: "Scale"
  bottom: "res_stage_3_72_2"
  top: "res_stage_3_72_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_72_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_72_2_top"
  top: "res_stage_3_72_2_top"
}
layer {
  name: "res_stage_3_72_3"
  type: "Convolution"
  bottom: "res_stage_3_72_2_top"
  top: "res_stage_3_72_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_72_3"
  type: "BatchNorm"
  bottom: "res_stage_3_72_3"
  top: "res_stage_3_72_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_72_3"  
  type: "Scale"
  bottom: "res_stage_3_72_3"
  top: "res_stage_3_72_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_72"
  type: "Eltwise"
  bottom: "res_3_71"
  bottom: "res_stage_3_72_3_top"
  top: "res_3_72"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_72_relu"
  type: "ReLU"
  bottom: "res_3_72"
  top: "res_3_72"
}
layer {
  name: "res_stage_3_73_1"
  type: "Convolution"
  bottom: "res_3_72"
  top: "res_stage_3_73_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_73_1"
  type: "BatchNorm"
  bottom: "res_stage_3_73_1"
  top: "res_stage_3_73_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_73_1"  
  type: "Scale"
  bottom: "res_stage_3_73_1"
  top: "res_stage_3_73_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_73_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_73_1_top"
  top: "res_stage_3_73_1_top"
}
layer {
  name: "res_stage_3_73_2"
  type: "Convolution"
  bottom: "res_stage_3_73_1_top"
  top: "res_stage_3_73_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_73_2"
  type: "BatchNorm"
  bottom: "res_stage_3_73_2"
  top: "res_stage_3_73_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_73_2"  
  type: "Scale"
  bottom: "res_stage_3_73_2"
  top: "res_stage_3_73_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_73_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_73_2_top"
  top: "res_stage_3_73_2_top"
}
layer {
  name: "res_stage_3_73_3"
  type: "Convolution"
  bottom: "res_stage_3_73_2_top"
  top: "res_stage_3_73_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_73_3"
  type: "BatchNorm"
  bottom: "res_stage_3_73_3"
  top: "res_stage_3_73_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_73_3"  
  type: "Scale"
  bottom: "res_stage_3_73_3"
  top: "res_stage_3_73_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_73"
  type: "Eltwise"
  bottom: "res_3_72"
  bottom: "res_stage_3_73_3_top"
  top: "res_3_73"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_73_relu"
  type: "ReLU"
  bottom: "res_3_73"
  top: "res_3_73"
}
layer {
  name: "res_stage_3_74_1"
  type: "Convolution"
  bottom: "res_3_73"
  top: "res_stage_3_74_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_74_1"
  type: "BatchNorm"
  bottom: "res_stage_3_74_1"
  top: "res_stage_3_74_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_74_1"  
  type: "Scale"
  bottom: "res_stage_3_74_1"
  top: "res_stage_3_74_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_74_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_74_1_top"
  top: "res_stage_3_74_1_top"
}
layer {
  name: "res_stage_3_74_2"
  type: "Convolution"
  bottom: "res_stage_3_74_1_top"
  top: "res_stage_3_74_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_74_2"
  type: "BatchNorm"
  bottom: "res_stage_3_74_2"
  top: "res_stage_3_74_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_74_2"  
  type: "Scale"
  bottom: "res_stage_3_74_2"
  top: "res_stage_3_74_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_74_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_74_2_top"
  top: "res_stage_3_74_2_top"
}
layer {
  name: "res_stage_3_74_3"
  type: "Convolution"
  bottom: "res_stage_3_74_2_top"
  top: "res_stage_3_74_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_74_3"
  type: "BatchNorm"
  bottom: "res_stage_3_74_3"
  top: "res_stage_3_74_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_74_3"  
  type: "Scale"
  bottom: "res_stage_3_74_3"
  top: "res_stage_3_74_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_74"
  type: "Eltwise"
  bottom: "res_3_73"
  bottom: "res_stage_3_74_3_top"
  top: "res_3_74"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_74_relu"
  type: "ReLU"
  bottom: "res_3_74"
  top: "res_3_74"
}
layer {
  name: "res_stage_3_75_1"
  type: "Convolution"
  bottom: "res_3_74"
  top: "res_stage_3_75_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_75_1"
  type: "BatchNorm"
  bottom: "res_stage_3_75_1"
  top: "res_stage_3_75_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_75_1"  
  type: "Scale"
  bottom: "res_stage_3_75_1"
  top: "res_stage_3_75_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_75_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_75_1_top"
  top: "res_stage_3_75_1_top"
}
layer {
  name: "res_stage_3_75_2"
  type: "Convolution"
  bottom: "res_stage_3_75_1_top"
  top: "res_stage_3_75_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_75_2"
  type: "BatchNorm"
  bottom: "res_stage_3_75_2"
  top: "res_stage_3_75_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_75_2"  
  type: "Scale"
  bottom: "res_stage_3_75_2"
  top: "res_stage_3_75_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_75_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_75_2_top"
  top: "res_stage_3_75_2_top"
}
layer {
  name: "res_stage_3_75_3"
  type: "Convolution"
  bottom: "res_stage_3_75_2_top"
  top: "res_stage_3_75_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_75_3"
  type: "BatchNorm"
  bottom: "res_stage_3_75_3"
  top: "res_stage_3_75_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_75_3"  
  type: "Scale"
  bottom: "res_stage_3_75_3"
  top: "res_stage_3_75_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_75"
  type: "Eltwise"
  bottom: "res_3_74"
  bottom: "res_stage_3_75_3_top"
  top: "res_3_75"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_75_relu"
  type: "ReLU"
  bottom: "res_3_75"
  top: "res_3_75"
}
layer {
  name: "res_stage_3_76_1"
  type: "Convolution"
  bottom: "res_3_75"
  top: "res_stage_3_76_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_76_1"
  type: "BatchNorm"
  bottom: "res_stage_3_76_1"
  top: "res_stage_3_76_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_76_1"  
  type: "Scale"
  bottom: "res_stage_3_76_1"
  top: "res_stage_3_76_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_76_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_76_1_top"
  top: "res_stage_3_76_1_top"
}
layer {
  name: "res_stage_3_76_2"
  type: "Convolution"
  bottom: "res_stage_3_76_1_top"
  top: "res_stage_3_76_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_76_2"
  type: "BatchNorm"
  bottom: "res_stage_3_76_2"
  top: "res_stage_3_76_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_76_2"  
  type: "Scale"
  bottom: "res_stage_3_76_2"
  top: "res_stage_3_76_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_76_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_76_2_top"
  top: "res_stage_3_76_2_top"
}
layer {
  name: "res_stage_3_76_3"
  type: "Convolution"
  bottom: "res_stage_3_76_2_top"
  top: "res_stage_3_76_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_76_3"
  type: "BatchNorm"
  bottom: "res_stage_3_76_3"
  top: "res_stage_3_76_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_76_3"  
  type: "Scale"
  bottom: "res_stage_3_76_3"
  top: "res_stage_3_76_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_76"
  type: "Eltwise"
  bottom: "res_3_75"
  bottom: "res_stage_3_76_3_top"
  top: "res_3_76"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_76_relu"
  type: "ReLU"
  bottom: "res_3_76"
  top: "res_3_76"
}
layer {
  name: "res_stage_3_77_1"
  type: "Convolution"
  bottom: "res_3_76"
  top: "res_stage_3_77_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_77_1"
  type: "BatchNorm"
  bottom: "res_stage_3_77_1"
  top: "res_stage_3_77_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_77_1"  
  type: "Scale"
  bottom: "res_stage_3_77_1"
  top: "res_stage_3_77_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_77_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_77_1_top"
  top: "res_stage_3_77_1_top"
}
layer {
  name: "res_stage_3_77_2"
  type: "Convolution"
  bottom: "res_stage_3_77_1_top"
  top: "res_stage_3_77_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_77_2"
  type: "BatchNorm"
  bottom: "res_stage_3_77_2"
  top: "res_stage_3_77_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_77_2"  
  type: "Scale"
  bottom: "res_stage_3_77_2"
  top: "res_stage_3_77_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_77_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_77_2_top"
  top: "res_stage_3_77_2_top"
}
layer {
  name: "res_stage_3_77_3"
  type: "Convolution"
  bottom: "res_stage_3_77_2_top"
  top: "res_stage_3_77_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_77_3"
  type: "BatchNorm"
  bottom: "res_stage_3_77_3"
  top: "res_stage_3_77_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_77_3"  
  type: "Scale"
  bottom: "res_stage_3_77_3"
  top: "res_stage_3_77_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_77"
  type: "Eltwise"
  bottom: "res_3_76"
  bottom: "res_stage_3_77_3_top"
  top: "res_3_77"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_77_relu"
  type: "ReLU"
  bottom: "res_3_77"
  top: "res_3_77"
}
layer {
  name: "res_stage_3_78_1"
  type: "Convolution"
  bottom: "res_3_77"
  top: "res_stage_3_78_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_78_1"
  type: "BatchNorm"
  bottom: "res_stage_3_78_1"
  top: "res_stage_3_78_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_78_1"  
  type: "Scale"
  bottom: "res_stage_3_78_1"
  top: "res_stage_3_78_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_78_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_78_1_top"
  top: "res_stage_3_78_1_top"
}
layer {
  name: "res_stage_3_78_2"
  type: "Convolution"
  bottom: "res_stage_3_78_1_top"
  top: "res_stage_3_78_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_78_2"
  type: "BatchNorm"
  bottom: "res_stage_3_78_2"
  top: "res_stage_3_78_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_78_2"  
  type: "Scale"
  bottom: "res_stage_3_78_2"
  top: "res_stage_3_78_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_78_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_78_2_top"
  top: "res_stage_3_78_2_top"
}
layer {
  name: "res_stage_3_78_3"
  type: "Convolution"
  bottom: "res_stage_3_78_2_top"
  top: "res_stage_3_78_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_78_3"
  type: "BatchNorm"
  bottom: "res_stage_3_78_3"
  top: "res_stage_3_78_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_78_3"  
  type: "Scale"
  bottom: "res_stage_3_78_3"
  top: "res_stage_3_78_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_78"
  type: "Eltwise"
  bottom: "res_3_77"
  bottom: "res_stage_3_78_3_top"
  top: "res_3_78"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_78_relu"
  type: "ReLU"
  bottom: "res_3_78"
  top: "res_3_78"
}
layer {
  name: "res_stage_3_79_1"
  type: "Convolution"
  bottom: "res_3_78"
  top: "res_stage_3_79_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_79_1"
  type: "BatchNorm"
  bottom: "res_stage_3_79_1"
  top: "res_stage_3_79_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_79_1"  
  type: "Scale"
  bottom: "res_stage_3_79_1"
  top: "res_stage_3_79_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_79_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_79_1_top"
  top: "res_stage_3_79_1_top"
}
layer {
  name: "res_stage_3_79_2"
  type: "Convolution"
  bottom: "res_stage_3_79_1_top"
  top: "res_stage_3_79_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_79_2"
  type: "BatchNorm"
  bottom: "res_stage_3_79_2"
  top: "res_stage_3_79_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_79_2"  
  type: "Scale"
  bottom: "res_stage_3_79_2"
  top: "res_stage_3_79_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_79_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_79_2_top"
  top: "res_stage_3_79_2_top"
}
layer {
  name: "res_stage_3_79_3"
  type: "Convolution"
  bottom: "res_stage_3_79_2_top"
  top: "res_stage_3_79_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_79_3"
  type: "BatchNorm"
  bottom: "res_stage_3_79_3"
  top: "res_stage_3_79_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_79_3"  
  type: "Scale"
  bottom: "res_stage_3_79_3"
  top: "res_stage_3_79_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_79"
  type: "Eltwise"
  bottom: "res_3_78"
  bottom: "res_stage_3_79_3_top"
  top: "res_3_79"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_79_relu"
  type: "ReLU"
  bottom: "res_3_79"
  top: "res_3_79"
}
layer {
  name: "res_stage_3_80_1"
  type: "Convolution"
  bottom: "res_3_79"
  top: "res_stage_3_80_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_80_1"
  type: "BatchNorm"
  bottom: "res_stage_3_80_1"
  top: "res_stage_3_80_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_80_1"  
  type: "Scale"
  bottom: "res_stage_3_80_1"
  top: "res_stage_3_80_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_80_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_80_1_top"
  top: "res_stage_3_80_1_top"
}
layer {
  name: "res_stage_3_80_2"
  type: "Convolution"
  bottom: "res_stage_3_80_1_top"
  top: "res_stage_3_80_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_80_2"
  type: "BatchNorm"
  bottom: "res_stage_3_80_2"
  top: "res_stage_3_80_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_80_2"  
  type: "Scale"
  bottom: "res_stage_3_80_2"
  top: "res_stage_3_80_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_80_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_80_2_top"
  top: "res_stage_3_80_2_top"
}
layer {
  name: "res_stage_3_80_3"
  type: "Convolution"
  bottom: "res_stage_3_80_2_top"
  top: "res_stage_3_80_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_80_3"
  type: "BatchNorm"
  bottom: "res_stage_3_80_3"
  top: "res_stage_3_80_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_80_3"  
  type: "Scale"
  bottom: "res_stage_3_80_3"
  top: "res_stage_3_80_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_80"
  type: "Eltwise"
  bottom: "res_3_79"
  bottom: "res_stage_3_80_3_top"
  top: "res_3_80"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_80_relu"
  type: "ReLU"
  bottom: "res_3_80"
  top: "res_3_80"
}
layer {
  name: "res_stage_3_81_1"
  type: "Convolution"
  bottom: "res_3_80"
  top: "res_stage_3_81_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_81_1"
  type: "BatchNorm"
  bottom: "res_stage_3_81_1"
  top: "res_stage_3_81_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_81_1"  
  type: "Scale"
  bottom: "res_stage_3_81_1"
  top: "res_stage_3_81_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_81_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_81_1_top"
  top: "res_stage_3_81_1_top"
}
layer {
  name: "res_stage_3_81_2"
  type: "Convolution"
  bottom: "res_stage_3_81_1_top"
  top: "res_stage_3_81_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_81_2"
  type: "BatchNorm"
  bottom: "res_stage_3_81_2"
  top: "res_stage_3_81_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_81_2"  
  type: "Scale"
  bottom: "res_stage_3_81_2"
  top: "res_stage_3_81_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_81_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_81_2_top"
  top: "res_stage_3_81_2_top"
}
layer {
  name: "res_stage_3_81_3"
  type: "Convolution"
  bottom: "res_stage_3_81_2_top"
  top: "res_stage_3_81_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_81_3"
  type: "BatchNorm"
  bottom: "res_stage_3_81_3"
  top: "res_stage_3_81_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_81_3"  
  type: "Scale"
  bottom: "res_stage_3_81_3"
  top: "res_stage_3_81_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_81"
  type: "Eltwise"
  bottom: "res_3_80"
  bottom: "res_stage_3_81_3_top"
  top: "res_3_81"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_81_relu"
  type: "ReLU"
  bottom: "res_3_81"
  top: "res_3_81"
}
layer {
  name: "res_stage_3_82_1"
  type: "Convolution"
  bottom: "res_3_81"
  top: "res_stage_3_82_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_82_1"
  type: "BatchNorm"
  bottom: "res_stage_3_82_1"
  top: "res_stage_3_82_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_82_1"  
  type: "Scale"
  bottom: "res_stage_3_82_1"
  top: "res_stage_3_82_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_82_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_82_1_top"
  top: "res_stage_3_82_1_top"
}
layer {
  name: "res_stage_3_82_2"
  type: "Convolution"
  bottom: "res_stage_3_82_1_top"
  top: "res_stage_3_82_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_82_2"
  type: "BatchNorm"
  bottom: "res_stage_3_82_2"
  top: "res_stage_3_82_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_82_2"  
  type: "Scale"
  bottom: "res_stage_3_82_2"
  top: "res_stage_3_82_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_82_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_82_2_top"
  top: "res_stage_3_82_2_top"
}
layer {
  name: "res_stage_3_82_3"
  type: "Convolution"
  bottom: "res_stage_3_82_2_top"
  top: "res_stage_3_82_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_82_3"
  type: "BatchNorm"
  bottom: "res_stage_3_82_3"
  top: "res_stage_3_82_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_82_3"  
  type: "Scale"
  bottom: "res_stage_3_82_3"
  top: "res_stage_3_82_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_82"
  type: "Eltwise"
  bottom: "res_3_81"
  bottom: "res_stage_3_82_3_top"
  top: "res_3_82"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_82_relu"
  type: "ReLU"
  bottom: "res_3_82"
  top: "res_3_82"
}
layer {
  name: "res_stage_3_83_1"
  type: "Convolution"
  bottom: "res_3_82"
  top: "res_stage_3_83_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_83_1"
  type: "BatchNorm"
  bottom: "res_stage_3_83_1"
  top: "res_stage_3_83_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_83_1"  
  type: "Scale"
  bottom: "res_stage_3_83_1"
  top: "res_stage_3_83_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_83_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_83_1_top"
  top: "res_stage_3_83_1_top"
}
layer {
  name: "res_stage_3_83_2"
  type: "Convolution"
  bottom: "res_stage_3_83_1_top"
  top: "res_stage_3_83_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_83_2"
  type: "BatchNorm"
  bottom: "res_stage_3_83_2"
  top: "res_stage_3_83_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_83_2"  
  type: "Scale"
  bottom: "res_stage_3_83_2"
  top: "res_stage_3_83_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_83_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_83_2_top"
  top: "res_stage_3_83_2_top"
}
layer {
  name: "res_stage_3_83_3"
  type: "Convolution"
  bottom: "res_stage_3_83_2_top"
  top: "res_stage_3_83_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_83_3"
  type: "BatchNorm"
  bottom: "res_stage_3_83_3"
  top: "res_stage_3_83_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_83_3"  
  type: "Scale"
  bottom: "res_stage_3_83_3"
  top: "res_stage_3_83_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_83"
  type: "Eltwise"
  bottom: "res_3_82"
  bottom: "res_stage_3_83_3_top"
  top: "res_3_83"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_83_relu"
  type: "ReLU"
  bottom: "res_3_83"
  top: "res_3_83"
}
layer {
  name: "res_stage_3_84_1"
  type: "Convolution"
  bottom: "res_3_83"
  top: "res_stage_3_84_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_84_1"
  type: "BatchNorm"
  bottom: "res_stage_3_84_1"
  top: "res_stage_3_84_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_84_1"  
  type: "Scale"
  bottom: "res_stage_3_84_1"
  top: "res_stage_3_84_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_84_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_84_1_top"
  top: "res_stage_3_84_1_top"
}
layer {
  name: "res_stage_3_84_2"
  type: "Convolution"
  bottom: "res_stage_3_84_1_top"
  top: "res_stage_3_84_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_84_2"
  type: "BatchNorm"
  bottom: "res_stage_3_84_2"
  top: "res_stage_3_84_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_84_2"  
  type: "Scale"
  bottom: "res_stage_3_84_2"
  top: "res_stage_3_84_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_84_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_84_2_top"
  top: "res_stage_3_84_2_top"
}
layer {
  name: "res_stage_3_84_3"
  type: "Convolution"
  bottom: "res_stage_3_84_2_top"
  top: "res_stage_3_84_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_84_3"
  type: "BatchNorm"
  bottom: "res_stage_3_84_3"
  top: "res_stage_3_84_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_84_3"  
  type: "Scale"
  bottom: "res_stage_3_84_3"
  top: "res_stage_3_84_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_84"
  type: "Eltwise"
  bottom: "res_3_83"
  bottom: "res_stage_3_84_3_top"
  top: "res_3_84"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_84_relu"
  type: "ReLU"
  bottom: "res_3_84"
  top: "res_3_84"
}
layer {
  name: "res_stage_3_85_1"
  type: "Convolution"
  bottom: "res_3_84"
  top: "res_stage_3_85_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_85_1"
  type: "BatchNorm"
  bottom: "res_stage_3_85_1"
  top: "res_stage_3_85_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_85_1"  
  type: "Scale"
  bottom: "res_stage_3_85_1"
  top: "res_stage_3_85_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_85_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_85_1_top"
  top: "res_stage_3_85_1_top"
}
layer {
  name: "res_stage_3_85_2"
  type: "Convolution"
  bottom: "res_stage_3_85_1_top"
  top: "res_stage_3_85_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_85_2"
  type: "BatchNorm"
  bottom: "res_stage_3_85_2"
  top: "res_stage_3_85_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_85_2"  
  type: "Scale"
  bottom: "res_stage_3_85_2"
  top: "res_stage_3_85_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_85_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_85_2_top"
  top: "res_stage_3_85_2_top"
}
layer {
  name: "res_stage_3_85_3"
  type: "Convolution"
  bottom: "res_stage_3_85_2_top"
  top: "res_stage_3_85_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_85_3"
  type: "BatchNorm"
  bottom: "res_stage_3_85_3"
  top: "res_stage_3_85_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_85_3"  
  type: "Scale"
  bottom: "res_stage_3_85_3"
  top: "res_stage_3_85_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_85"
  type: "Eltwise"
  bottom: "res_3_84"
  bottom: "res_stage_3_85_3_top"
  top: "res_3_85"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_85_relu"
  type: "ReLU"
  bottom: "res_3_85"
  top: "res_3_85"
}
layer {
  name: "res_stage_3_86_1"
  type: "Convolution"
  bottom: "res_3_85"
  top: "res_stage_3_86_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_86_1"
  type: "BatchNorm"
  bottom: "res_stage_3_86_1"
  top: "res_stage_3_86_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_86_1"  
  type: "Scale"
  bottom: "res_stage_3_86_1"
  top: "res_stage_3_86_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_86_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_86_1_top"
  top: "res_stage_3_86_1_top"
}
layer {
  name: "res_stage_3_86_2"
  type: "Convolution"
  bottom: "res_stage_3_86_1_top"
  top: "res_stage_3_86_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_86_2"
  type: "BatchNorm"
  bottom: "res_stage_3_86_2"
  top: "res_stage_3_86_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_86_2"  
  type: "Scale"
  bottom: "res_stage_3_86_2"
  top: "res_stage_3_86_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_86_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_86_2_top"
  top: "res_stage_3_86_2_top"
}
layer {
  name: "res_stage_3_86_3"
  type: "Convolution"
  bottom: "res_stage_3_86_2_top"
  top: "res_stage_3_86_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_86_3"
  type: "BatchNorm"
  bottom: "res_stage_3_86_3"
  top: "res_stage_3_86_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_86_3"  
  type: "Scale"
  bottom: "res_stage_3_86_3"
  top: "res_stage_3_86_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_86"
  type: "Eltwise"
  bottom: "res_3_85"
  bottom: "res_stage_3_86_3_top"
  top: "res_3_86"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_86_relu"
  type: "ReLU"
  bottom: "res_3_86"
  top: "res_3_86"
}
layer {
  name: "res_stage_3_87_1"
  type: "Convolution"
  bottom: "res_3_86"
  top: "res_stage_3_87_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_87_1"
  type: "BatchNorm"
  bottom: "res_stage_3_87_1"
  top: "res_stage_3_87_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_87_1"  
  type: "Scale"
  bottom: "res_stage_3_87_1"
  top: "res_stage_3_87_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_87_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_87_1_top"
  top: "res_stage_3_87_1_top"
}
layer {
  name: "res_stage_3_87_2"
  type: "Convolution"
  bottom: "res_stage_3_87_1_top"
  top: "res_stage_3_87_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_87_2"
  type: "BatchNorm"
  bottom: "res_stage_3_87_2"
  top: "res_stage_3_87_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_87_2"  
  type: "Scale"
  bottom: "res_stage_3_87_2"
  top: "res_stage_3_87_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_87_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_87_2_top"
  top: "res_stage_3_87_2_top"
}
layer {
  name: "res_stage_3_87_3"
  type: "Convolution"
  bottom: "res_stage_3_87_2_top"
  top: "res_stage_3_87_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_87_3"
  type: "BatchNorm"
  bottom: "res_stage_3_87_3"
  top: "res_stage_3_87_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_87_3"  
  type: "Scale"
  bottom: "res_stage_3_87_3"
  top: "res_stage_3_87_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_87"
  type: "Eltwise"
  bottom: "res_3_86"
  bottom: "res_stage_3_87_3_top"
  top: "res_3_87"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_87_relu"
  type: "ReLU"
  bottom: "res_3_87"
  top: "res_3_87"
}
layer {
  name: "res_stage_3_88_1"
  type: "Convolution"
  bottom: "res_3_87"
  top: "res_stage_3_88_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_88_1"
  type: "BatchNorm"
  bottom: "res_stage_3_88_1"
  top: "res_stage_3_88_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_88_1"  
  type: "Scale"
  bottom: "res_stage_3_88_1"
  top: "res_stage_3_88_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_88_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_88_1_top"
  top: "res_stage_3_88_1_top"
}
layer {
  name: "res_stage_3_88_2"
  type: "Convolution"
  bottom: "res_stage_3_88_1_top"
  top: "res_stage_3_88_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_88_2"
  type: "BatchNorm"
  bottom: "res_stage_3_88_2"
  top: "res_stage_3_88_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_88_2"  
  type: "Scale"
  bottom: "res_stage_3_88_2"
  top: "res_stage_3_88_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_88_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_88_2_top"
  top: "res_stage_3_88_2_top"
}
layer {
  name: "res_stage_3_88_3"
  type: "Convolution"
  bottom: "res_stage_3_88_2_top"
  top: "res_stage_3_88_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_88_3"
  type: "BatchNorm"
  bottom: "res_stage_3_88_3"
  top: "res_stage_3_88_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_88_3"  
  type: "Scale"
  bottom: "res_stage_3_88_3"
  top: "res_stage_3_88_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_88"
  type: "Eltwise"
  bottom: "res_3_87"
  bottom: "res_stage_3_88_3_top"
  top: "res_3_88"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_88_relu"
  type: "ReLU"
  bottom: "res_3_88"
  top: "res_3_88"
}
layer {
  name: "res_stage_3_89_1"
  type: "Convolution"
  bottom: "res_3_88"
  top: "res_stage_3_89_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_89_1"
  type: "BatchNorm"
  bottom: "res_stage_3_89_1"
  top: "res_stage_3_89_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_89_1"  
  type: "Scale"
  bottom: "res_stage_3_89_1"
  top: "res_stage_3_89_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_89_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_89_1_top"
  top: "res_stage_3_89_1_top"
}
layer {
  name: "res_stage_3_89_2"
  type: "Convolution"
  bottom: "res_stage_3_89_1_top"
  top: "res_stage_3_89_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_89_2"
  type: "BatchNorm"
  bottom: "res_stage_3_89_2"
  top: "res_stage_3_89_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_89_2"  
  type: "Scale"
  bottom: "res_stage_3_89_2"
  top: "res_stage_3_89_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_89_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_89_2_top"
  top: "res_stage_3_89_2_top"
}
layer {
  name: "res_stage_3_89_3"
  type: "Convolution"
  bottom: "res_stage_3_89_2_top"
  top: "res_stage_3_89_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_89_3"
  type: "BatchNorm"
  bottom: "res_stage_3_89_3"
  top: "res_stage_3_89_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_89_3"  
  type: "Scale"
  bottom: "res_stage_3_89_3"
  top: "res_stage_3_89_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_89"
  type: "Eltwise"
  bottom: "res_3_88"
  bottom: "res_stage_3_89_3_top"
  top: "res_3_89"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_89_relu"
  type: "ReLU"
  bottom: "res_3_89"
  top: "res_3_89"
}
layer {
  name: "res_stage_3_90_1"
  type: "Convolution"
  bottom: "res_3_89"
  top: "res_stage_3_90_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_90_1"
  type: "BatchNorm"
  bottom: "res_stage_3_90_1"
  top: "res_stage_3_90_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_90_1"  
  type: "Scale"
  bottom: "res_stage_3_90_1"
  top: "res_stage_3_90_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_90_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_90_1_top"
  top: "res_stage_3_90_1_top"
}
layer {
  name: "res_stage_3_90_2"
  type: "Convolution"
  bottom: "res_stage_3_90_1_top"
  top: "res_stage_3_90_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_90_2"
  type: "BatchNorm"
  bottom: "res_stage_3_90_2"
  top: "res_stage_3_90_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_90_2"  
  type: "Scale"
  bottom: "res_stage_3_90_2"
  top: "res_stage_3_90_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_90_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_90_2_top"
  top: "res_stage_3_90_2_top"
}
layer {
  name: "res_stage_3_90_3"
  type: "Convolution"
  bottom: "res_stage_3_90_2_top"
  top: "res_stage_3_90_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_90_3"
  type: "BatchNorm"
  bottom: "res_stage_3_90_3"
  top: "res_stage_3_90_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_90_3"  
  type: "Scale"
  bottom: "res_stage_3_90_3"
  top: "res_stage_3_90_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_90"
  type: "Eltwise"
  bottom: "res_3_89"
  bottom: "res_stage_3_90_3_top"
  top: "res_3_90"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_90_relu"
  type: "ReLU"
  bottom: "res_3_90"
  top: "res_3_90"
}
layer {
  name: "res_stage_3_91_1"
  type: "Convolution"
  bottom: "res_3_90"
  top: "res_stage_3_91_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_91_1"
  type: "BatchNorm"
  bottom: "res_stage_3_91_1"
  top: "res_stage_3_91_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_91_1"  
  type: "Scale"
  bottom: "res_stage_3_91_1"
  top: "res_stage_3_91_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_91_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_91_1_top"
  top: "res_stage_3_91_1_top"
}
layer {
  name: "res_stage_3_91_2"
  type: "Convolution"
  bottom: "res_stage_3_91_1_top"
  top: "res_stage_3_91_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_91_2"
  type: "BatchNorm"
  bottom: "res_stage_3_91_2"
  top: "res_stage_3_91_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_91_2"  
  type: "Scale"
  bottom: "res_stage_3_91_2"
  top: "res_stage_3_91_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_91_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_91_2_top"
  top: "res_stage_3_91_2_top"
}
layer {
  name: "res_stage_3_91_3"
  type: "Convolution"
  bottom: "res_stage_3_91_2_top"
  top: "res_stage_3_91_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_91_3"
  type: "BatchNorm"
  bottom: "res_stage_3_91_3"
  top: "res_stage_3_91_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_91_3"  
  type: "Scale"
  bottom: "res_stage_3_91_3"
  top: "res_stage_3_91_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_91"
  type: "Eltwise"
  bottom: "res_3_90"
  bottom: "res_stage_3_91_3_top"
  top: "res_3_91"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_91_relu"
  type: "ReLU"
  bottom: "res_3_91"
  top: "res_3_91"
}
layer {
  name: "res_stage_3_92_1"
  type: "Convolution"
  bottom: "res_3_91"
  top: "res_stage_3_92_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_92_1"
  type: "BatchNorm"
  bottom: "res_stage_3_92_1"
  top: "res_stage_3_92_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_92_1"  
  type: "Scale"
  bottom: "res_stage_3_92_1"
  top: "res_stage_3_92_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_92_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_92_1_top"
  top: "res_stage_3_92_1_top"
}
layer {
  name: "res_stage_3_92_2"
  type: "Convolution"
  bottom: "res_stage_3_92_1_top"
  top: "res_stage_3_92_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_92_2"
  type: "BatchNorm"
  bottom: "res_stage_3_92_2"
  top: "res_stage_3_92_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_92_2"  
  type: "Scale"
  bottom: "res_stage_3_92_2"
  top: "res_stage_3_92_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_92_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_92_2_top"
  top: "res_stage_3_92_2_top"
}
layer {
  name: "res_stage_3_92_3"
  type: "Convolution"
  bottom: "res_stage_3_92_2_top"
  top: "res_stage_3_92_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_92_3"
  type: "BatchNorm"
  bottom: "res_stage_3_92_3"
  top: "res_stage_3_92_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_92_3"  
  type: "Scale"
  bottom: "res_stage_3_92_3"
  top: "res_stage_3_92_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_92"
  type: "Eltwise"
  bottom: "res_3_91"
  bottom: "res_stage_3_92_3_top"
  top: "res_3_92"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_92_relu"
  type: "ReLU"
  bottom: "res_3_92"
  top: "res_3_92"
}
layer {
  name: "res_stage_3_93_1"
  type: "Convolution"
  bottom: "res_3_92"
  top: "res_stage_3_93_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_93_1"
  type: "BatchNorm"
  bottom: "res_stage_3_93_1"
  top: "res_stage_3_93_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_93_1"  
  type: "Scale"
  bottom: "res_stage_3_93_1"
  top: "res_stage_3_93_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_93_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_93_1_top"
  top: "res_stage_3_93_1_top"
}
layer {
  name: "res_stage_3_93_2"
  type: "Convolution"
  bottom: "res_stage_3_93_1_top"
  top: "res_stage_3_93_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_93_2"
  type: "BatchNorm"
  bottom: "res_stage_3_93_2"
  top: "res_stage_3_93_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_93_2"  
  type: "Scale"
  bottom: "res_stage_3_93_2"
  top: "res_stage_3_93_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_93_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_93_2_top"
  top: "res_stage_3_93_2_top"
}
layer {
  name: "res_stage_3_93_3"
  type: "Convolution"
  bottom: "res_stage_3_93_2_top"
  top: "res_stage_3_93_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_93_3"
  type: "BatchNorm"
  bottom: "res_stage_3_93_3"
  top: "res_stage_3_93_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_93_3"  
  type: "Scale"
  bottom: "res_stage_3_93_3"
  top: "res_stage_3_93_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_93"
  type: "Eltwise"
  bottom: "res_3_92"
  bottom: "res_stage_3_93_3_top"
  top: "res_3_93"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_93_relu"
  type: "ReLU"
  bottom: "res_3_93"
  top: "res_3_93"
}
layer {
  name: "res_stage_3_94_1"
  type: "Convolution"
  bottom: "res_3_93"
  top: "res_stage_3_94_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_94_1"
  type: "BatchNorm"
  bottom: "res_stage_3_94_1"
  top: "res_stage_3_94_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_94_1"  
  type: "Scale"
  bottom: "res_stage_3_94_1"
  top: "res_stage_3_94_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_94_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_94_1_top"
  top: "res_stage_3_94_1_top"
}
layer {
  name: "res_stage_3_94_2"
  type: "Convolution"
  bottom: "res_stage_3_94_1_top"
  top: "res_stage_3_94_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_94_2"
  type: "BatchNorm"
  bottom: "res_stage_3_94_2"
  top: "res_stage_3_94_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_94_2"  
  type: "Scale"
  bottom: "res_stage_3_94_2"
  top: "res_stage_3_94_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_94_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_94_2_top"
  top: "res_stage_3_94_2_top"
}
layer {
  name: "res_stage_3_94_3"
  type: "Convolution"
  bottom: "res_stage_3_94_2_top"
  top: "res_stage_3_94_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_94_3"
  type: "BatchNorm"
  bottom: "res_stage_3_94_3"
  top: "res_stage_3_94_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_94_3"  
  type: "Scale"
  bottom: "res_stage_3_94_3"
  top: "res_stage_3_94_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_94"
  type: "Eltwise"
  bottom: "res_3_93"
  bottom: "res_stage_3_94_3_top"
  top: "res_3_94"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_94_relu"
  type: "ReLU"
  bottom: "res_3_94"
  top: "res_3_94"
}
layer {
  name: "res_stage_3_95_1"
  type: "Convolution"
  bottom: "res_3_94"
  top: "res_stage_3_95_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_95_1"
  type: "BatchNorm"
  bottom: "res_stage_3_95_1"
  top: "res_stage_3_95_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_95_1"  
  type: "Scale"
  bottom: "res_stage_3_95_1"
  top: "res_stage_3_95_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_95_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_95_1_top"
  top: "res_stage_3_95_1_top"
}
layer {
  name: "res_stage_3_95_2"
  type: "Convolution"
  bottom: "res_stage_3_95_1_top"
  top: "res_stage_3_95_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_95_2"
  type: "BatchNorm"
  bottom: "res_stage_3_95_2"
  top: "res_stage_3_95_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_95_2"  
  type: "Scale"
  bottom: "res_stage_3_95_2"
  top: "res_stage_3_95_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_95_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_95_2_top"
  top: "res_stage_3_95_2_top"
}
layer {
  name: "res_stage_3_95_3"
  type: "Convolution"
  bottom: "res_stage_3_95_2_top"
  top: "res_stage_3_95_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_95_3"
  type: "BatchNorm"
  bottom: "res_stage_3_95_3"
  top: "res_stage_3_95_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_95_3"  
  type: "Scale"
  bottom: "res_stage_3_95_3"
  top: "res_stage_3_95_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_95"
  type: "Eltwise"
  bottom: "res_3_94"
  bottom: "res_stage_3_95_3_top"
  top: "res_3_95"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_95_relu"
  type: "ReLU"
  bottom: "res_3_95"
  top: "res_3_95"
}
layer {
  name: "res_stage_3_96_1"
  type: "Convolution"
  bottom: "res_3_95"
  top: "res_stage_3_96_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_96_1"
  type: "BatchNorm"
  bottom: "res_stage_3_96_1"
  top: "res_stage_3_96_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_96_1"  
  type: "Scale"
  bottom: "res_stage_3_96_1"
  top: "res_stage_3_96_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_96_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_96_1_top"
  top: "res_stage_3_96_1_top"
}
layer {
  name: "res_stage_3_96_2"
  type: "Convolution"
  bottom: "res_stage_3_96_1_top"
  top: "res_stage_3_96_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_96_2"
  type: "BatchNorm"
  bottom: "res_stage_3_96_2"
  top: "res_stage_3_96_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_96_2"  
  type: "Scale"
  bottom: "res_stage_3_96_2"
  top: "res_stage_3_96_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_96_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_96_2_top"
  top: "res_stage_3_96_2_top"
}
layer {
  name: "res_stage_3_96_3"
  type: "Convolution"
  bottom: "res_stage_3_96_2_top"
  top: "res_stage_3_96_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_96_3"
  type: "BatchNorm"
  bottom: "res_stage_3_96_3"
  top: "res_stage_3_96_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_96_3"  
  type: "Scale"
  bottom: "res_stage_3_96_3"
  top: "res_stage_3_96_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_96"
  type: "Eltwise"
  bottom: "res_3_95"
  bottom: "res_stage_3_96_3_top"
  top: "res_3_96"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_96_relu"
  type: "ReLU"
  bottom: "res_3_96"
  top: "res_3_96"
}
layer {
  name: "res_stage_3_97_1"
  type: "Convolution"
  bottom: "res_3_96"
  top: "res_stage_3_97_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_97_1"
  type: "BatchNorm"
  bottom: "res_stage_3_97_1"
  top: "res_stage_3_97_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_97_1"  
  type: "Scale"
  bottom: "res_stage_3_97_1"
  top: "res_stage_3_97_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_97_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_97_1_top"
  top: "res_stage_3_97_1_top"
}
layer {
  name: "res_stage_3_97_2"
  type: "Convolution"
  bottom: "res_stage_3_97_1_top"
  top: "res_stage_3_97_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_97_2"
  type: "BatchNorm"
  bottom: "res_stage_3_97_2"
  top: "res_stage_3_97_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_97_2"  
  type: "Scale"
  bottom: "res_stage_3_97_2"
  top: "res_stage_3_97_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_97_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_97_2_top"
  top: "res_stage_3_97_2_top"
}
layer {
  name: "res_stage_3_97_3"
  type: "Convolution"
  bottom: "res_stage_3_97_2_top"
  top: "res_stage_3_97_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_97_3"
  type: "BatchNorm"
  bottom: "res_stage_3_97_3"
  top: "res_stage_3_97_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_97_3"  
  type: "Scale"
  bottom: "res_stage_3_97_3"
  top: "res_stage_3_97_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_97"
  type: "Eltwise"
  bottom: "res_3_96"
  bottom: "res_stage_3_97_3_top"
  top: "res_3_97"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_97_relu"
  type: "ReLU"
  bottom: "res_3_97"
  top: "res_3_97"
}
layer {
  name: "res_stage_3_98_1"
  type: "Convolution"
  bottom: "res_3_97"
  top: "res_stage_3_98_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_98_1"
  type: "BatchNorm"
  bottom: "res_stage_3_98_1"
  top: "res_stage_3_98_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_98_1"  
  type: "Scale"
  bottom: "res_stage_3_98_1"
  top: "res_stage_3_98_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_98_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_98_1_top"
  top: "res_stage_3_98_1_top"
}
layer {
  name: "res_stage_3_98_2"
  type: "Convolution"
  bottom: "res_stage_3_98_1_top"
  top: "res_stage_3_98_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_98_2"
  type: "BatchNorm"
  bottom: "res_stage_3_98_2"
  top: "res_stage_3_98_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_98_2"  
  type: "Scale"
  bottom: "res_stage_3_98_2"
  top: "res_stage_3_98_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_98_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_98_2_top"
  top: "res_stage_3_98_2_top"
}
layer {
  name: "res_stage_3_98_3"
  type: "Convolution"
  bottom: "res_stage_3_98_2_top"
  top: "res_stage_3_98_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_98_3"
  type: "BatchNorm"
  bottom: "res_stage_3_98_3"
  top: "res_stage_3_98_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_98_3"  
  type: "Scale"
  bottom: "res_stage_3_98_3"
  top: "res_stage_3_98_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_98"
  type: "Eltwise"
  bottom: "res_3_97"
  bottom: "res_stage_3_98_3_top"
  top: "res_3_98"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_98_relu"
  type: "ReLU"
  bottom: "res_3_98"
  top: "res_3_98"
}
layer {
  name: "res_stage_3_99_1"
  type: "Convolution"
  bottom: "res_3_98"
  top: "res_stage_3_99_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_99_1"
  type: "BatchNorm"
  bottom: "res_stage_3_99_1"
  top: "res_stage_3_99_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_99_1"  
  type: "Scale"
  bottom: "res_stage_3_99_1"
  top: "res_stage_3_99_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_99_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_99_1_top"
  top: "res_stage_3_99_1_top"
}
layer {
  name: "res_stage_3_99_2"
  type: "Convolution"
  bottom: "res_stage_3_99_1_top"
  top: "res_stage_3_99_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_99_2"
  type: "BatchNorm"
  bottom: "res_stage_3_99_2"
  top: "res_stage_3_99_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_99_2"  
  type: "Scale"
  bottom: "res_stage_3_99_2"
  top: "res_stage_3_99_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_99_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_99_2_top"
  top: "res_stage_3_99_2_top"
}
layer {
  name: "res_stage_3_99_3"
  type: "Convolution"
  bottom: "res_stage_3_99_2_top"
  top: "res_stage_3_99_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_99_3"
  type: "BatchNorm"
  bottom: "res_stage_3_99_3"
  top: "res_stage_3_99_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_99_3"  
  type: "Scale"
  bottom: "res_stage_3_99_3"
  top: "res_stage_3_99_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_99"
  type: "Eltwise"
  bottom: "res_3_98"
  bottom: "res_stage_3_99_3_top"
  top: "res_3_99"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_99_relu"
  type: "ReLU"
  bottom: "res_3_99"
  top: "res_3_99"
}
layer {
  name: "res_stage_3_100_1"
  type: "Convolution"
  bottom: "res_3_99"
  top: "res_stage_3_100_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_100_1"
  type: "BatchNorm"
  bottom: "res_stage_3_100_1"
  top: "res_stage_3_100_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_100_1"  
  type: "Scale"
  bottom: "res_stage_3_100_1"
  top: "res_stage_3_100_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_100_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_100_1_top"
  top: "res_stage_3_100_1_top"
}
layer {
  name: "res_stage_3_100_2"
  type: "Convolution"
  bottom: "res_stage_3_100_1_top"
  top: "res_stage_3_100_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_100_2"
  type: "BatchNorm"
  bottom: "res_stage_3_100_2"
  top: "res_stage_3_100_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_100_2"  
  type: "Scale"
  bottom: "res_stage_3_100_2"
  top: "res_stage_3_100_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_100_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_100_2_top"
  top: "res_stage_3_100_2_top"
}
layer {
  name: "res_stage_3_100_3"
  type: "Convolution"
  bottom: "res_stage_3_100_2_top"
  top: "res_stage_3_100_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_100_3"
  type: "BatchNorm"
  bottom: "res_stage_3_100_3"
  top: "res_stage_3_100_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_100_3"  
  type: "Scale"
  bottom: "res_stage_3_100_3"
  top: "res_stage_3_100_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_100"
  type: "Eltwise"
  bottom: "res_3_99"
  bottom: "res_stage_3_100_3_top"
  top: "res_3_100"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_100_relu"
  type: "ReLU"
  bottom: "res_3_100"
  top: "res_3_100"
}
layer {
  name: "res_stage_3_101_1"
  type: "Convolution"
  bottom: "res_3_100"
  top: "res_stage_3_101_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_101_1"
  type: "BatchNorm"
  bottom: "res_stage_3_101_1"
  top: "res_stage_3_101_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_101_1"  
  type: "Scale"
  bottom: "res_stage_3_101_1"
  top: "res_stage_3_101_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_101_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_101_1_top"
  top: "res_stage_3_101_1_top"
}
layer {
  name: "res_stage_3_101_2"
  type: "Convolution"
  bottom: "res_stage_3_101_1_top"
  top: "res_stage_3_101_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_101_2"
  type: "BatchNorm"
  bottom: "res_stage_3_101_2"
  top: "res_stage_3_101_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_101_2"  
  type: "Scale"
  bottom: "res_stage_3_101_2"
  top: "res_stage_3_101_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_101_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_101_2_top"
  top: "res_stage_3_101_2_top"
}
layer {
  name: "res_stage_3_101_3"
  type: "Convolution"
  bottom: "res_stage_3_101_2_top"
  top: "res_stage_3_101_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_101_3"
  type: "BatchNorm"
  bottom: "res_stage_3_101_3"
  top: "res_stage_3_101_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_101_3"  
  type: "Scale"
  bottom: "res_stage_3_101_3"
  top: "res_stage_3_101_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_101"
  type: "Eltwise"
  bottom: "res_3_100"
  bottom: "res_stage_3_101_3_top"
  top: "res_3_101"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_101_relu"
  type: "ReLU"
  bottom: "res_3_101"
  top: "res_3_101"
}
layer {
  name: "res_stage_3_102_1"
  type: "Convolution"
  bottom: "res_3_101"
  top: "res_stage_3_102_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_102_1"
  type: "BatchNorm"
  bottom: "res_stage_3_102_1"
  top: "res_stage_3_102_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_102_1"  
  type: "Scale"
  bottom: "res_stage_3_102_1"
  top: "res_stage_3_102_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_102_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_102_1_top"
  top: "res_stage_3_102_1_top"
}
layer {
  name: "res_stage_3_102_2"
  type: "Convolution"
  bottom: "res_stage_3_102_1_top"
  top: "res_stage_3_102_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_102_2"
  type: "BatchNorm"
  bottom: "res_stage_3_102_2"
  top: "res_stage_3_102_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_102_2"  
  type: "Scale"
  bottom: "res_stage_3_102_2"
  top: "res_stage_3_102_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_102_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_102_2_top"
  top: "res_stage_3_102_2_top"
}
layer {
  name: "res_stage_3_102_3"
  type: "Convolution"
  bottom: "res_stage_3_102_2_top"
  top: "res_stage_3_102_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_102_3"
  type: "BatchNorm"
  bottom: "res_stage_3_102_3"
  top: "res_stage_3_102_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_102_3"  
  type: "Scale"
  bottom: "res_stage_3_102_3"
  top: "res_stage_3_102_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_102"
  type: "Eltwise"
  bottom: "res_3_101"
  bottom: "res_stage_3_102_3_top"
  top: "res_3_102"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_102_relu"
  type: "ReLU"
  bottom: "res_3_102"
  top: "res_3_102"
}
layer {
  name: "res_stage_3_103_1"
  type: "Convolution"
  bottom: "res_3_102"
  top: "res_stage_3_103_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_103_1"
  type: "BatchNorm"
  bottom: "res_stage_3_103_1"
  top: "res_stage_3_103_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_103_1"  
  type: "Scale"
  bottom: "res_stage_3_103_1"
  top: "res_stage_3_103_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_103_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_103_1_top"
  top: "res_stage_3_103_1_top"
}
layer {
  name: "res_stage_3_103_2"
  type: "Convolution"
  bottom: "res_stage_3_103_1_top"
  top: "res_stage_3_103_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_103_2"
  type: "BatchNorm"
  bottom: "res_stage_3_103_2"
  top: "res_stage_3_103_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_103_2"  
  type: "Scale"
  bottom: "res_stage_3_103_2"
  top: "res_stage_3_103_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_103_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_103_2_top"
  top: "res_stage_3_103_2_top"
}
layer {
  name: "res_stage_3_103_3"
  type: "Convolution"
  bottom: "res_stage_3_103_2_top"
  top: "res_stage_3_103_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_103_3"
  type: "BatchNorm"
  bottom: "res_stage_3_103_3"
  top: "res_stage_3_103_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_103_3"  
  type: "Scale"
  bottom: "res_stage_3_103_3"
  top: "res_stage_3_103_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_103"
  type: "Eltwise"
  bottom: "res_3_102"
  bottom: "res_stage_3_103_3_top"
  top: "res_3_103"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_103_relu"
  type: "ReLU"
  bottom: "res_3_103"
  top: "res_3_103"
}
layer {
  name: "res_stage_3_104_1"
  type: "Convolution"
  bottom: "res_3_103"
  top: "res_stage_3_104_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_104_1"
  type: "BatchNorm"
  bottom: "res_stage_3_104_1"
  top: "res_stage_3_104_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_104_1"  
  type: "Scale"
  bottom: "res_stage_3_104_1"
  top: "res_stage_3_104_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_104_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_104_1_top"
  top: "res_stage_3_104_1_top"
}
layer {
  name: "res_stage_3_104_2"
  type: "Convolution"
  bottom: "res_stage_3_104_1_top"
  top: "res_stage_3_104_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_104_2"
  type: "BatchNorm"
  bottom: "res_stage_3_104_2"
  top: "res_stage_3_104_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_104_2"  
  type: "Scale"
  bottom: "res_stage_3_104_2"
  top: "res_stage_3_104_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_104_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_104_2_top"
  top: "res_stage_3_104_2_top"
}
layer {
  name: "res_stage_3_104_3"
  type: "Convolution"
  bottom: "res_stage_3_104_2_top"
  top: "res_stage_3_104_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_104_3"
  type: "BatchNorm"
  bottom: "res_stage_3_104_3"
  top: "res_stage_3_104_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_104_3"  
  type: "Scale"
  bottom: "res_stage_3_104_3"
  top: "res_stage_3_104_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_104"
  type: "Eltwise"
  bottom: "res_3_103"
  bottom: "res_stage_3_104_3_top"
  top: "res_3_104"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_104_relu"
  type: "ReLU"
  bottom: "res_3_104"
  top: "res_3_104"
}
layer {
  name: "res_stage_3_105_1"
  type: "Convolution"
  bottom: "res_3_104"
  top: "res_stage_3_105_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_105_1"
  type: "BatchNorm"
  bottom: "res_stage_3_105_1"
  top: "res_stage_3_105_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_105_1"  
  type: "Scale"
  bottom: "res_stage_3_105_1"
  top: "res_stage_3_105_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_105_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_105_1_top"
  top: "res_stage_3_105_1_top"
}
layer {
  name: "res_stage_3_105_2"
  type: "Convolution"
  bottom: "res_stage_3_105_1_top"
  top: "res_stage_3_105_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_105_2"
  type: "BatchNorm"
  bottom: "res_stage_3_105_2"
  top: "res_stage_3_105_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_105_2"  
  type: "Scale"
  bottom: "res_stage_3_105_2"
  top: "res_stage_3_105_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_105_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_105_2_top"
  top: "res_stage_3_105_2_top"
}
layer {
  name: "res_stage_3_105_3"
  type: "Convolution"
  bottom: "res_stage_3_105_2_top"
  top: "res_stage_3_105_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_105_3"
  type: "BatchNorm"
  bottom: "res_stage_3_105_3"
  top: "res_stage_3_105_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_105_3"  
  type: "Scale"
  bottom: "res_stage_3_105_3"
  top: "res_stage_3_105_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_105"
  type: "Eltwise"
  bottom: "res_3_104"
  bottom: "res_stage_3_105_3_top"
  top: "res_3_105"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_105_relu"
  type: "ReLU"
  bottom: "res_3_105"
  top: "res_3_105"
}
layer {
  name: "res_stage_3_106_1"
  type: "Convolution"
  bottom: "res_3_105"
  top: "res_stage_3_106_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_106_1"
  type: "BatchNorm"
  bottom: "res_stage_3_106_1"
  top: "res_stage_3_106_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_106_1"  
  type: "Scale"
  bottom: "res_stage_3_106_1"
  top: "res_stage_3_106_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_106_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_106_1_top"
  top: "res_stage_3_106_1_top"
}
layer {
  name: "res_stage_3_106_2"
  type: "Convolution"
  bottom: "res_stage_3_106_1_top"
  top: "res_stage_3_106_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_106_2"
  type: "BatchNorm"
  bottom: "res_stage_3_106_2"
  top: "res_stage_3_106_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_106_2"  
  type: "Scale"
  bottom: "res_stage_3_106_2"
  top: "res_stage_3_106_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_106_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_106_2_top"
  top: "res_stage_3_106_2_top"
}
layer {
  name: "res_stage_3_106_3"
  type: "Convolution"
  bottom: "res_stage_3_106_2_top"
  top: "res_stage_3_106_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_106_3"
  type: "BatchNorm"
  bottom: "res_stage_3_106_3"
  top: "res_stage_3_106_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_106_3"  
  type: "Scale"
  bottom: "res_stage_3_106_3"
  top: "res_stage_3_106_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_106"
  type: "Eltwise"
  bottom: "res_3_105"
  bottom: "res_stage_3_106_3_top"
  top: "res_3_106"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_106_relu"
  type: "ReLU"
  bottom: "res_3_106"
  top: "res_3_106"
}
layer {
  name: "res_stage_3_107_1"
  type: "Convolution"
  bottom: "res_3_106"
  top: "res_stage_3_107_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_107_1"
  type: "BatchNorm"
  bottom: "res_stage_3_107_1"
  top: "res_stage_3_107_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_107_1"  
  type: "Scale"
  bottom: "res_stage_3_107_1"
  top: "res_stage_3_107_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_107_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_107_1_top"
  top: "res_stage_3_107_1_top"
}
layer {
  name: "res_stage_3_107_2"
  type: "Convolution"
  bottom: "res_stage_3_107_1_top"
  top: "res_stage_3_107_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_107_2"
  type: "BatchNorm"
  bottom: "res_stage_3_107_2"
  top: "res_stage_3_107_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_107_2"  
  type: "Scale"
  bottom: "res_stage_3_107_2"
  top: "res_stage_3_107_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_107_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_107_2_top"
  top: "res_stage_3_107_2_top"
}
layer {
  name: "res_stage_3_107_3"
  type: "Convolution"
  bottom: "res_stage_3_107_2_top"
  top: "res_stage_3_107_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_107_3"
  type: "BatchNorm"
  bottom: "res_stage_3_107_3"
  top: "res_stage_3_107_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_107_3"  
  type: "Scale"
  bottom: "res_stage_3_107_3"
  top: "res_stage_3_107_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_107"
  type: "Eltwise"
  bottom: "res_3_106"
  bottom: "res_stage_3_107_3_top"
  top: "res_3_107"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_107_relu"
  type: "ReLU"
  bottom: "res_3_107"
  top: "res_3_107"
}
layer {
  name: "res_stage_3_108_1"
  type: "Convolution"
  bottom: "res_3_107"
  top: "res_stage_3_108_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_108_1"
  type: "BatchNorm"
  bottom: "res_stage_3_108_1"
  top: "res_stage_3_108_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_108_1"  
  type: "Scale"
  bottom: "res_stage_3_108_1"
  top: "res_stage_3_108_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_108_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_108_1_top"
  top: "res_stage_3_108_1_top"
}
layer {
  name: "res_stage_3_108_2"
  type: "Convolution"
  bottom: "res_stage_3_108_1_top"
  top: "res_stage_3_108_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_108_2"
  type: "BatchNorm"
  bottom: "res_stage_3_108_2"
  top: "res_stage_3_108_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_108_2"  
  type: "Scale"
  bottom: "res_stage_3_108_2"
  top: "res_stage_3_108_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_108_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_108_2_top"
  top: "res_stage_3_108_2_top"
}
layer {
  name: "res_stage_3_108_3"
  type: "Convolution"
  bottom: "res_stage_3_108_2_top"
  top: "res_stage_3_108_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_108_3"
  type: "BatchNorm"
  bottom: "res_stage_3_108_3"
  top: "res_stage_3_108_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_108_3"  
  type: "Scale"
  bottom: "res_stage_3_108_3"
  top: "res_stage_3_108_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_108"
  type: "Eltwise"
  bottom: "res_3_107"
  bottom: "res_stage_3_108_3_top"
  top: "res_3_108"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_108_relu"
  type: "ReLU"
  bottom: "res_3_108"
  top: "res_3_108"
}
layer {
  name: "res_stage_3_109_1"
  type: "Convolution"
  bottom: "res_3_108"
  top: "res_stage_3_109_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_109_1"
  type: "BatchNorm"
  bottom: "res_stage_3_109_1"
  top: "res_stage_3_109_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_109_1"  
  type: "Scale"
  bottom: "res_stage_3_109_1"
  top: "res_stage_3_109_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_109_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_109_1_top"
  top: "res_stage_3_109_1_top"
}
layer {
  name: "res_stage_3_109_2"
  type: "Convolution"
  bottom: "res_stage_3_109_1_top"
  top: "res_stage_3_109_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_109_2"
  type: "BatchNorm"
  bottom: "res_stage_3_109_2"
  top: "res_stage_3_109_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_109_2"  
  type: "Scale"
  bottom: "res_stage_3_109_2"
  top: "res_stage_3_109_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_109_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_109_2_top"
  top: "res_stage_3_109_2_top"
}
layer {
  name: "res_stage_3_109_3"
  type: "Convolution"
  bottom: "res_stage_3_109_2_top"
  top: "res_stage_3_109_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_109_3"
  type: "BatchNorm"
  bottom: "res_stage_3_109_3"
  top: "res_stage_3_109_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_109_3"  
  type: "Scale"
  bottom: "res_stage_3_109_3"
  top: "res_stage_3_109_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_109"
  type: "Eltwise"
  bottom: "res_3_108"
  bottom: "res_stage_3_109_3_top"
  top: "res_3_109"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_109_relu"
  type: "ReLU"
  bottom: "res_3_109"
  top: "res_3_109"
}
layer {
  name: "res_stage_3_110_1"
  type: "Convolution"
  bottom: "res_3_109"
  top: "res_stage_3_110_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_110_1"
  type: "BatchNorm"
  bottom: "res_stage_3_110_1"
  top: "res_stage_3_110_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_110_1"  
  type: "Scale"
  bottom: "res_stage_3_110_1"
  top: "res_stage_3_110_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_110_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_110_1_top"
  top: "res_stage_3_110_1_top"
}
layer {
  name: "res_stage_3_110_2"
  type: "Convolution"
  bottom: "res_stage_3_110_1_top"
  top: "res_stage_3_110_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_110_2"
  type: "BatchNorm"
  bottom: "res_stage_3_110_2"
  top: "res_stage_3_110_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_110_2"  
  type: "Scale"
  bottom: "res_stage_3_110_2"
  top: "res_stage_3_110_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_110_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_110_2_top"
  top: "res_stage_3_110_2_top"
}
layer {
  name: "res_stage_3_110_3"
  type: "Convolution"
  bottom: "res_stage_3_110_2_top"
  top: "res_stage_3_110_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_110_3"
  type: "BatchNorm"
  bottom: "res_stage_3_110_3"
  top: "res_stage_3_110_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_110_3"  
  type: "Scale"
  bottom: "res_stage_3_110_3"
  top: "res_stage_3_110_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_110"
  type: "Eltwise"
  bottom: "res_3_109"
  bottom: "res_stage_3_110_3_top"
  top: "res_3_110"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_110_relu"
  type: "ReLU"
  bottom: "res_3_110"
  top: "res_3_110"
}
layer {
  name: "res_stage_3_111_1"
  type: "Convolution"
  bottom: "res_3_110"
  top: "res_stage_3_111_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_111_1"
  type: "BatchNorm"
  bottom: "res_stage_3_111_1"
  top: "res_stage_3_111_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_111_1"  
  type: "Scale"
  bottom: "res_stage_3_111_1"
  top: "res_stage_3_111_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_111_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_111_1_top"
  top: "res_stage_3_111_1_top"
}
layer {
  name: "res_stage_3_111_2"
  type: "Convolution"
  bottom: "res_stage_3_111_1_top"
  top: "res_stage_3_111_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_111_2"
  type: "BatchNorm"
  bottom: "res_stage_3_111_2"
  top: "res_stage_3_111_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_111_2"  
  type: "Scale"
  bottom: "res_stage_3_111_2"
  top: "res_stage_3_111_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_111_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_111_2_top"
  top: "res_stage_3_111_2_top"
}
layer {
  name: "res_stage_3_111_3"
  type: "Convolution"
  bottom: "res_stage_3_111_2_top"
  top: "res_stage_3_111_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_111_3"
  type: "BatchNorm"
  bottom: "res_stage_3_111_3"
  top: "res_stage_3_111_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_111_3"  
  type: "Scale"
  bottom: "res_stage_3_111_3"
  top: "res_stage_3_111_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_111"
  type: "Eltwise"
  bottom: "res_3_110"
  bottom: "res_stage_3_111_3_top"
  top: "res_3_111"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_111_relu"
  type: "ReLU"
  bottom: "res_3_111"
  top: "res_3_111"
}
layer {
  name: "res_stage_3_112_1"
  type: "Convolution"
  bottom: "res_3_111"
  top: "res_stage_3_112_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_112_1"
  type: "BatchNorm"
  bottom: "res_stage_3_112_1"
  top: "res_stage_3_112_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_112_1"  
  type: "Scale"
  bottom: "res_stage_3_112_1"
  top: "res_stage_3_112_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_112_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_112_1_top"
  top: "res_stage_3_112_1_top"
}
layer {
  name: "res_stage_3_112_2"
  type: "Convolution"
  bottom: "res_stage_3_112_1_top"
  top: "res_stage_3_112_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_112_2"
  type: "BatchNorm"
  bottom: "res_stage_3_112_2"
  top: "res_stage_3_112_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_112_2"  
  type: "Scale"
  bottom: "res_stage_3_112_2"
  top: "res_stage_3_112_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_112_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_112_2_top"
  top: "res_stage_3_112_2_top"
}
layer {
  name: "res_stage_3_112_3"
  type: "Convolution"
  bottom: "res_stage_3_112_2_top"
  top: "res_stage_3_112_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_112_3"
  type: "BatchNorm"
  bottom: "res_stage_3_112_3"
  top: "res_stage_3_112_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_112_3"  
  type: "Scale"
  bottom: "res_stage_3_112_3"
  top: "res_stage_3_112_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_112"
  type: "Eltwise"
  bottom: "res_3_111"
  bottom: "res_stage_3_112_3_top"
  top: "res_3_112"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_112_relu"
  type: "ReLU"
  bottom: "res_3_112"
  top: "res_3_112"
}
layer {
  name: "res_stage_3_113_1"
  type: "Convolution"
  bottom: "res_3_112"
  top: "res_stage_3_113_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_113_1"
  type: "BatchNorm"
  bottom: "res_stage_3_113_1"
  top: "res_stage_3_113_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_113_1"  
  type: "Scale"
  bottom: "res_stage_3_113_1"
  top: "res_stage_3_113_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_113_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_113_1_top"
  top: "res_stage_3_113_1_top"
}
layer {
  name: "res_stage_3_113_2"
  type: "Convolution"
  bottom: "res_stage_3_113_1_top"
  top: "res_stage_3_113_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_113_2"
  type: "BatchNorm"
  bottom: "res_stage_3_113_2"
  top: "res_stage_3_113_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_113_2"  
  type: "Scale"
  bottom: "res_stage_3_113_2"
  top: "res_stage_3_113_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_113_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_113_2_top"
  top: "res_stage_3_113_2_top"
}
layer {
  name: "res_stage_3_113_3"
  type: "Convolution"
  bottom: "res_stage_3_113_2_top"
  top: "res_stage_3_113_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_113_3"
  type: "BatchNorm"
  bottom: "res_stage_3_113_3"
  top: "res_stage_3_113_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_113_3"  
  type: "Scale"
  bottom: "res_stage_3_113_3"
  top: "res_stage_3_113_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_113"
  type: "Eltwise"
  bottom: "res_3_112"
  bottom: "res_stage_3_113_3_top"
  top: "res_3_113"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_113_relu"
  type: "ReLU"
  bottom: "res_3_113"
  top: "res_3_113"
}
layer {
  name: "res_stage_3_114_1"
  type: "Convolution"
  bottom: "res_3_113"
  top: "res_stage_3_114_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_114_1"
  type: "BatchNorm"
  bottom: "res_stage_3_114_1"
  top: "res_stage_3_114_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_114_1"  
  type: "Scale"
  bottom: "res_stage_3_114_1"
  top: "res_stage_3_114_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_114_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_114_1_top"
  top: "res_stage_3_114_1_top"
}
layer {
  name: "res_stage_3_114_2"
  type: "Convolution"
  bottom: "res_stage_3_114_1_top"
  top: "res_stage_3_114_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_114_2"
  type: "BatchNorm"
  bottom: "res_stage_3_114_2"
  top: "res_stage_3_114_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_114_2"  
  type: "Scale"
  bottom: "res_stage_3_114_2"
  top: "res_stage_3_114_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_114_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_114_2_top"
  top: "res_stage_3_114_2_top"
}
layer {
  name: "res_stage_3_114_3"
  type: "Convolution"
  bottom: "res_stage_3_114_2_top"
  top: "res_stage_3_114_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_114_3"
  type: "BatchNorm"
  bottom: "res_stage_3_114_3"
  top: "res_stage_3_114_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_114_3"  
  type: "Scale"
  bottom: "res_stage_3_114_3"
  top: "res_stage_3_114_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_114"
  type: "Eltwise"
  bottom: "res_3_113"
  bottom: "res_stage_3_114_3_top"
  top: "res_3_114"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_114_relu"
  type: "ReLU"
  bottom: "res_3_114"
  top: "res_3_114"
}
layer {
  name: "res_stage_3_115_1"
  type: "Convolution"
  bottom: "res_3_114"
  top: "res_stage_3_115_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_115_1"
  type: "BatchNorm"
  bottom: "res_stage_3_115_1"
  top: "res_stage_3_115_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_115_1"  
  type: "Scale"
  bottom: "res_stage_3_115_1"
  top: "res_stage_3_115_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_115_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_115_1_top"
  top: "res_stage_3_115_1_top"
}
layer {
  name: "res_stage_3_115_2"
  type: "Convolution"
  bottom: "res_stage_3_115_1_top"
  top: "res_stage_3_115_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_115_2"
  type: "BatchNorm"
  bottom: "res_stage_3_115_2"
  top: "res_stage_3_115_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_115_2"  
  type: "Scale"
  bottom: "res_stage_3_115_2"
  top: "res_stage_3_115_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_115_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_115_2_top"
  top: "res_stage_3_115_2_top"
}
layer {
  name: "res_stage_3_115_3"
  type: "Convolution"
  bottom: "res_stage_3_115_2_top"
  top: "res_stage_3_115_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_115_3"
  type: "BatchNorm"
  bottom: "res_stage_3_115_3"
  top: "res_stage_3_115_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_115_3"  
  type: "Scale"
  bottom: "res_stage_3_115_3"
  top: "res_stage_3_115_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_115"
  type: "Eltwise"
  bottom: "res_3_114"
  bottom: "res_stage_3_115_3_top"
  top: "res_3_115"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_115_relu"
  type: "ReLU"
  bottom: "res_3_115"
  top: "res_3_115"
}
layer {
  name: "res_stage_3_116_1"
  type: "Convolution"
  bottom: "res_3_115"
  top: "res_stage_3_116_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_116_1"
  type: "BatchNorm"
  bottom: "res_stage_3_116_1"
  top: "res_stage_3_116_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_116_1"  
  type: "Scale"
  bottom: "res_stage_3_116_1"
  top: "res_stage_3_116_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_116_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_116_1_top"
  top: "res_stage_3_116_1_top"
}
layer {
  name: "res_stage_3_116_2"
  type: "Convolution"
  bottom: "res_stage_3_116_1_top"
  top: "res_stage_3_116_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_116_2"
  type: "BatchNorm"
  bottom: "res_stage_3_116_2"
  top: "res_stage_3_116_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_116_2"  
  type: "Scale"
  bottom: "res_stage_3_116_2"
  top: "res_stage_3_116_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_116_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_116_2_top"
  top: "res_stage_3_116_2_top"
}
layer {
  name: "res_stage_3_116_3"
  type: "Convolution"
  bottom: "res_stage_3_116_2_top"
  top: "res_stage_3_116_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_116_3"
  type: "BatchNorm"
  bottom: "res_stage_3_116_3"
  top: "res_stage_3_116_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_116_3"  
  type: "Scale"
  bottom: "res_stage_3_116_3"
  top: "res_stage_3_116_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_116"
  type: "Eltwise"
  bottom: "res_3_115"
  bottom: "res_stage_3_116_3_top"
  top: "res_3_116"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_116_relu"
  type: "ReLU"
  bottom: "res_3_116"
  top: "res_3_116"
}
layer {
  name: "res_stage_3_117_1"
  type: "Convolution"
  bottom: "res_3_116"
  top: "res_stage_3_117_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_117_1"
  type: "BatchNorm"
  bottom: "res_stage_3_117_1"
  top: "res_stage_3_117_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_117_1"  
  type: "Scale"
  bottom: "res_stage_3_117_1"
  top: "res_stage_3_117_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_117_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_117_1_top"
  top: "res_stage_3_117_1_top"
}
layer {
  name: "res_stage_3_117_2"
  type: "Convolution"
  bottom: "res_stage_3_117_1_top"
  top: "res_stage_3_117_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_117_2"
  type: "BatchNorm"
  bottom: "res_stage_3_117_2"
  top: "res_stage_3_117_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_117_2"  
  type: "Scale"
  bottom: "res_stage_3_117_2"
  top: "res_stage_3_117_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_117_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_117_2_top"
  top: "res_stage_3_117_2_top"
}
layer {
  name: "res_stage_3_117_3"
  type: "Convolution"
  bottom: "res_stage_3_117_2_top"
  top: "res_stage_3_117_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_117_3"
  type: "BatchNorm"
  bottom: "res_stage_3_117_3"
  top: "res_stage_3_117_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_117_3"  
  type: "Scale"
  bottom: "res_stage_3_117_3"
  top: "res_stage_3_117_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_117"
  type: "Eltwise"
  bottom: "res_3_116"
  bottom: "res_stage_3_117_3_top"
  top: "res_3_117"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_117_relu"
  type: "ReLU"
  bottom: "res_3_117"
  top: "res_3_117"
}
layer {
  name: "res_stage_3_118_1"
  type: "Convolution"
  bottom: "res_3_117"
  top: "res_stage_3_118_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_118_1"
  type: "BatchNorm"
  bottom: "res_stage_3_118_1"
  top: "res_stage_3_118_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_118_1"  
  type: "Scale"
  bottom: "res_stage_3_118_1"
  top: "res_stage_3_118_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_118_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_118_1_top"
  top: "res_stage_3_118_1_top"
}
layer {
  name: "res_stage_3_118_2"
  type: "Convolution"
  bottom: "res_stage_3_118_1_top"
  top: "res_stage_3_118_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_118_2"
  type: "BatchNorm"
  bottom: "res_stage_3_118_2"
  top: "res_stage_3_118_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_118_2"  
  type: "Scale"
  bottom: "res_stage_3_118_2"
  top: "res_stage_3_118_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_118_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_118_2_top"
  top: "res_stage_3_118_2_top"
}
layer {
  name: "res_stage_3_118_3"
  type: "Convolution"
  bottom: "res_stage_3_118_2_top"
  top: "res_stage_3_118_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_118_3"
  type: "BatchNorm"
  bottom: "res_stage_3_118_3"
  top: "res_stage_3_118_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_118_3"  
  type: "Scale"
  bottom: "res_stage_3_118_3"
  top: "res_stage_3_118_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_118"
  type: "Eltwise"
  bottom: "res_3_117"
  bottom: "res_stage_3_118_3_top"
  top: "res_3_118"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_118_relu"
  type: "ReLU"
  bottom: "res_3_118"
  top: "res_3_118"
}
layer {
  name: "res_stage_3_119_1"
  type: "Convolution"
  bottom: "res_3_118"
  top: "res_stage_3_119_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_119_1"
  type: "BatchNorm"
  bottom: "res_stage_3_119_1"
  top: "res_stage_3_119_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_119_1"  
  type: "Scale"
  bottom: "res_stage_3_119_1"
  top: "res_stage_3_119_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_119_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_119_1_top"
  top: "res_stage_3_119_1_top"
}
layer {
  name: "res_stage_3_119_2"
  type: "Convolution"
  bottom: "res_stage_3_119_1_top"
  top: "res_stage_3_119_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_119_2"
  type: "BatchNorm"
  bottom: "res_stage_3_119_2"
  top: "res_stage_3_119_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_119_2"  
  type: "Scale"
  bottom: "res_stage_3_119_2"
  top: "res_stage_3_119_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_119_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_119_2_top"
  top: "res_stage_3_119_2_top"
}
layer {
  name: "res_stage_3_119_3"
  type: "Convolution"
  bottom: "res_stage_3_119_2_top"
  top: "res_stage_3_119_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_119_3"
  type: "BatchNorm"
  bottom: "res_stage_3_119_3"
  top: "res_stage_3_119_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_119_3"  
  type: "Scale"
  bottom: "res_stage_3_119_3"
  top: "res_stage_3_119_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_119"
  type: "Eltwise"
  bottom: "res_3_118"
  bottom: "res_stage_3_119_3_top"
  top: "res_3_119"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_119_relu"
  type: "ReLU"
  bottom: "res_3_119"
  top: "res_3_119"
}
layer {
  name: "res_stage_3_120_1"
  type: "Convolution"
  bottom: "res_3_119"
  top: "res_stage_3_120_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_120_1"
  type: "BatchNorm"
  bottom: "res_stage_3_120_1"
  top: "res_stage_3_120_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_120_1"  
  type: "Scale"
  bottom: "res_stage_3_120_1"
  top: "res_stage_3_120_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_120_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_120_1_top"
  top: "res_stage_3_120_1_top"
}
layer {
  name: "res_stage_3_120_2"
  type: "Convolution"
  bottom: "res_stage_3_120_1_top"
  top: "res_stage_3_120_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_120_2"
  type: "BatchNorm"
  bottom: "res_stage_3_120_2"
  top: "res_stage_3_120_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_120_2"  
  type: "Scale"
  bottom: "res_stage_3_120_2"
  top: "res_stage_3_120_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_120_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_120_2_top"
  top: "res_stage_3_120_2_top"
}
layer {
  name: "res_stage_3_120_3"
  type: "Convolution"
  bottom: "res_stage_3_120_2_top"
  top: "res_stage_3_120_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_120_3"
  type: "BatchNorm"
  bottom: "res_stage_3_120_3"
  top: "res_stage_3_120_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_120_3"  
  type: "Scale"
  bottom: "res_stage_3_120_3"
  top: "res_stage_3_120_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_120"
  type: "Eltwise"
  bottom: "res_3_119"
  bottom: "res_stage_3_120_3_top"
  top: "res_3_120"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_120_relu"
  type: "ReLU"
  bottom: "res_3_120"
  top: "res_3_120"
}
layer {
  name: "res_stage_3_121_1"
  type: "Convolution"
  bottom: "res_3_120"
  top: "res_stage_3_121_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_121_1"
  type: "BatchNorm"
  bottom: "res_stage_3_121_1"
  top: "res_stage_3_121_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_121_1"  
  type: "Scale"
  bottom: "res_stage_3_121_1"
  top: "res_stage_3_121_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_121_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_121_1_top"
  top: "res_stage_3_121_1_top"
}
layer {
  name: "res_stage_3_121_2"
  type: "Convolution"
  bottom: "res_stage_3_121_1_top"
  top: "res_stage_3_121_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_121_2"
  type: "BatchNorm"
  bottom: "res_stage_3_121_2"
  top: "res_stage_3_121_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_121_2"  
  type: "Scale"
  bottom: "res_stage_3_121_2"
  top: "res_stage_3_121_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_121_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_121_2_top"
  top: "res_stage_3_121_2_top"
}
layer {
  name: "res_stage_3_121_3"
  type: "Convolution"
  bottom: "res_stage_3_121_2_top"
  top: "res_stage_3_121_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_121_3"
  type: "BatchNorm"
  bottom: "res_stage_3_121_3"
  top: "res_stage_3_121_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_121_3"  
  type: "Scale"
  bottom: "res_stage_3_121_3"
  top: "res_stage_3_121_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_121"
  type: "Eltwise"
  bottom: "res_3_120"
  bottom: "res_stage_3_121_3_top"
  top: "res_3_121"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_121_relu"
  type: "ReLU"
  bottom: "res_3_121"
  top: "res_3_121"
}
layer {
  name: "res_stage_3_122_1"
  type: "Convolution"
  bottom: "res_3_121"
  top: "res_stage_3_122_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_122_1"
  type: "BatchNorm"
  bottom: "res_stage_3_122_1"
  top: "res_stage_3_122_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_122_1"  
  type: "Scale"
  bottom: "res_stage_3_122_1"
  top: "res_stage_3_122_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_122_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_122_1_top"
  top: "res_stage_3_122_1_top"
}
layer {
  name: "res_stage_3_122_2"
  type: "Convolution"
  bottom: "res_stage_3_122_1_top"
  top: "res_stage_3_122_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_122_2"
  type: "BatchNorm"
  bottom: "res_stage_3_122_2"
  top: "res_stage_3_122_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_122_2"  
  type: "Scale"
  bottom: "res_stage_3_122_2"
  top: "res_stage_3_122_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_122_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_122_2_top"
  top: "res_stage_3_122_2_top"
}
layer {
  name: "res_stage_3_122_3"
  type: "Convolution"
  bottom: "res_stage_3_122_2_top"
  top: "res_stage_3_122_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_122_3"
  type: "BatchNorm"
  bottom: "res_stage_3_122_3"
  top: "res_stage_3_122_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_122_3"  
  type: "Scale"
  bottom: "res_stage_3_122_3"
  top: "res_stage_3_122_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_122"
  type: "Eltwise"
  bottom: "res_3_121"
  bottom: "res_stage_3_122_3_top"
  top: "res_3_122"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_122_relu"
  type: "ReLU"
  bottom: "res_3_122"
  top: "res_3_122"
}
layer {
  name: "res_stage_3_123_1"
  type: "Convolution"
  bottom: "res_3_122"
  top: "res_stage_3_123_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_123_1"
  type: "BatchNorm"
  bottom: "res_stage_3_123_1"
  top: "res_stage_3_123_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_123_1"  
  type: "Scale"
  bottom: "res_stage_3_123_1"
  top: "res_stage_3_123_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_123_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_123_1_top"
  top: "res_stage_3_123_1_top"
}
layer {
  name: "res_stage_3_123_2"
  type: "Convolution"
  bottom: "res_stage_3_123_1_top"
  top: "res_stage_3_123_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_123_2"
  type: "BatchNorm"
  bottom: "res_stage_3_123_2"
  top: "res_stage_3_123_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_123_2"  
  type: "Scale"
  bottom: "res_stage_3_123_2"
  top: "res_stage_3_123_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_123_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_123_2_top"
  top: "res_stage_3_123_2_top"
}
layer {
  name: "res_stage_3_123_3"
  type: "Convolution"
  bottom: "res_stage_3_123_2_top"
  top: "res_stage_3_123_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_123_3"
  type: "BatchNorm"
  bottom: "res_stage_3_123_3"
  top: "res_stage_3_123_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_123_3"  
  type: "Scale"
  bottom: "res_stage_3_123_3"
  top: "res_stage_3_123_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_123"
  type: "Eltwise"
  bottom: "res_3_122"
  bottom: "res_stage_3_123_3_top"
  top: "res_3_123"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_123_relu"
  type: "ReLU"
  bottom: "res_3_123"
  top: "res_3_123"
}
layer {
  name: "res_stage_3_124_1"
  type: "Convolution"
  bottom: "res_3_123"
  top: "res_stage_3_124_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_124_1"
  type: "BatchNorm"
  bottom: "res_stage_3_124_1"
  top: "res_stage_3_124_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_124_1"  
  type: "Scale"
  bottom: "res_stage_3_124_1"
  top: "res_stage_3_124_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_124_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_124_1_top"
  top: "res_stage_3_124_1_top"
}
layer {
  name: "res_stage_3_124_2"
  type: "Convolution"
  bottom: "res_stage_3_124_1_top"
  top: "res_stage_3_124_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_124_2"
  type: "BatchNorm"
  bottom: "res_stage_3_124_2"
  top: "res_stage_3_124_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_124_2"  
  type: "Scale"
  bottom: "res_stage_3_124_2"
  top: "res_stage_3_124_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_124_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_124_2_top"
  top: "res_stage_3_124_2_top"
}
layer {
  name: "res_stage_3_124_3"
  type: "Convolution"
  bottom: "res_stage_3_124_2_top"
  top: "res_stage_3_124_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_124_3"
  type: "BatchNorm"
  bottom: "res_stage_3_124_3"
  top: "res_stage_3_124_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_124_3"  
  type: "Scale"
  bottom: "res_stage_3_124_3"
  top: "res_stage_3_124_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_124"
  type: "Eltwise"
  bottom: "res_3_123"
  bottom: "res_stage_3_124_3_top"
  top: "res_3_124"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_124_relu"
  type: "ReLU"
  bottom: "res_3_124"
  top: "res_3_124"
}
layer {
  name: "res_stage_3_125_1"
  type: "Convolution"
  bottom: "res_3_124"
  top: "res_stage_3_125_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_125_1"
  type: "BatchNorm"
  bottom: "res_stage_3_125_1"
  top: "res_stage_3_125_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_125_1"  
  type: "Scale"
  bottom: "res_stage_3_125_1"
  top: "res_stage_3_125_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_125_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_125_1_top"
  top: "res_stage_3_125_1_top"
}
layer {
  name: "res_stage_3_125_2"
  type: "Convolution"
  bottom: "res_stage_3_125_1_top"
  top: "res_stage_3_125_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_125_2"
  type: "BatchNorm"
  bottom: "res_stage_3_125_2"
  top: "res_stage_3_125_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_125_2"  
  type: "Scale"
  bottom: "res_stage_3_125_2"
  top: "res_stage_3_125_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_125_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_125_2_top"
  top: "res_stage_3_125_2_top"
}
layer {
  name: "res_stage_3_125_3"
  type: "Convolution"
  bottom: "res_stage_3_125_2_top"
  top: "res_stage_3_125_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_125_3"
  type: "BatchNorm"
  bottom: "res_stage_3_125_3"
  top: "res_stage_3_125_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_125_3"  
  type: "Scale"
  bottom: "res_stage_3_125_3"
  top: "res_stage_3_125_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_125"
  type: "Eltwise"
  bottom: "res_3_124"
  bottom: "res_stage_3_125_3_top"
  top: "res_3_125"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_125_relu"
  type: "ReLU"
  bottom: "res_3_125"
  top: "res_3_125"
}
layer {
  name: "res_stage_3_126_1"
  type: "Convolution"
  bottom: "res_3_125"
  top: "res_stage_3_126_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_126_1"
  type: "BatchNorm"
  bottom: "res_stage_3_126_1"
  top: "res_stage_3_126_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_126_1"  
  type: "Scale"
  bottom: "res_stage_3_126_1"
  top: "res_stage_3_126_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_126_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_126_1_top"
  top: "res_stage_3_126_1_top"
}
layer {
  name: "res_stage_3_126_2"
  type: "Convolution"
  bottom: "res_stage_3_126_1_top"
  top: "res_stage_3_126_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_126_2"
  type: "BatchNorm"
  bottom: "res_stage_3_126_2"
  top: "res_stage_3_126_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_126_2"  
  type: "Scale"
  bottom: "res_stage_3_126_2"
  top: "res_stage_3_126_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_126_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_126_2_top"
  top: "res_stage_3_126_2_top"
}
layer {
  name: "res_stage_3_126_3"
  type: "Convolution"
  bottom: "res_stage_3_126_2_top"
  top: "res_stage_3_126_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_126_3"
  type: "BatchNorm"
  bottom: "res_stage_3_126_3"
  top: "res_stage_3_126_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_126_3"  
  type: "Scale"
  bottom: "res_stage_3_126_3"
  top: "res_stage_3_126_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_126"
  type: "Eltwise"
  bottom: "res_3_125"
  bottom: "res_stage_3_126_3_top"
  top: "res_3_126"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_126_relu"
  type: "ReLU"
  bottom: "res_3_126"
  top: "res_3_126"
}
layer {
  name: "res_stage_3_127_1"
  type: "Convolution"
  bottom: "res_3_126"
  top: "res_stage_3_127_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_127_1"
  type: "BatchNorm"
  bottom: "res_stage_3_127_1"
  top: "res_stage_3_127_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_127_1"  
  type: "Scale"
  bottom: "res_stage_3_127_1"
  top: "res_stage_3_127_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_127_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_127_1_top"
  top: "res_stage_3_127_1_top"
}
layer {
  name: "res_stage_3_127_2"
  type: "Convolution"
  bottom: "res_stage_3_127_1_top"
  top: "res_stage_3_127_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_127_2"
  type: "BatchNorm"
  bottom: "res_stage_3_127_2"
  top: "res_stage_3_127_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_127_2"  
  type: "Scale"
  bottom: "res_stage_3_127_2"
  top: "res_stage_3_127_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_127_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_127_2_top"
  top: "res_stage_3_127_2_top"
}
layer {
  name: "res_stage_3_127_3"
  type: "Convolution"
  bottom: "res_stage_3_127_2_top"
  top: "res_stage_3_127_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_127_3"
  type: "BatchNorm"
  bottom: "res_stage_3_127_3"
  top: "res_stage_3_127_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_127_3"  
  type: "Scale"
  bottom: "res_stage_3_127_3"
  top: "res_stage_3_127_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_127"
  type: "Eltwise"
  bottom: "res_3_126"
  bottom: "res_stage_3_127_3_top"
  top: "res_3_127"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_127_relu"
  type: "ReLU"
  bottom: "res_3_127"
  top: "res_3_127"
}
layer {
  name: "res_stage_3_128_1"
  type: "Convolution"
  bottom: "res_3_127"
  top: "res_stage_3_128_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_128_1"
  type: "BatchNorm"
  bottom: "res_stage_3_128_1"
  top: "res_stage_3_128_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_128_1"  
  type: "Scale"
  bottom: "res_stage_3_128_1"
  top: "res_stage_3_128_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_128_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_128_1_top"
  top: "res_stage_3_128_1_top"
}
layer {
  name: "res_stage_3_128_2"
  type: "Convolution"
  bottom: "res_stage_3_128_1_top"
  top: "res_stage_3_128_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_128_2"
  type: "BatchNorm"
  bottom: "res_stage_3_128_2"
  top: "res_stage_3_128_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_128_2"  
  type: "Scale"
  bottom: "res_stage_3_128_2"
  top: "res_stage_3_128_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_128_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_128_2_top"
  top: "res_stage_3_128_2_top"
}
layer {
  name: "res_stage_3_128_3"
  type: "Convolution"
  bottom: "res_stage_3_128_2_top"
  top: "res_stage_3_128_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_128_3"
  type: "BatchNorm"
  bottom: "res_stage_3_128_3"
  top: "res_stage_3_128_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_128_3"  
  type: "Scale"
  bottom: "res_stage_3_128_3"
  top: "res_stage_3_128_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_128"
  type: "Eltwise"
  bottom: "res_3_127"
  bottom: "res_stage_3_128_3_top"
  top: "res_3_128"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_128_relu"
  type: "ReLU"
  bottom: "res_3_128"
  top: "res_3_128"
}
layer {
  name: "res_stage_3_129_1"
  type: "Convolution"
  bottom: "res_3_128"
  top: "res_stage_3_129_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_129_1"
  type: "BatchNorm"
  bottom: "res_stage_3_129_1"
  top: "res_stage_3_129_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_129_1"  
  type: "Scale"
  bottom: "res_stage_3_129_1"
  top: "res_stage_3_129_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_129_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_129_1_top"
  top: "res_stage_3_129_1_top"
}
layer {
  name: "res_stage_3_129_2"
  type: "Convolution"
  bottom: "res_stage_3_129_1_top"
  top: "res_stage_3_129_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_129_2"
  type: "BatchNorm"
  bottom: "res_stage_3_129_2"
  top: "res_stage_3_129_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_129_2"  
  type: "Scale"
  bottom: "res_stage_3_129_2"
  top: "res_stage_3_129_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_129_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_129_2_top"
  top: "res_stage_3_129_2_top"
}
layer {
  name: "res_stage_3_129_3"
  type: "Convolution"
  bottom: "res_stage_3_129_2_top"
  top: "res_stage_3_129_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_129_3"
  type: "BatchNorm"
  bottom: "res_stage_3_129_3"
  top: "res_stage_3_129_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_129_3"  
  type: "Scale"
  bottom: "res_stage_3_129_3"
  top: "res_stage_3_129_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_129"
  type: "Eltwise"
  bottom: "res_3_128"
  bottom: "res_stage_3_129_3_top"
  top: "res_3_129"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_129_relu"
  type: "ReLU"
  bottom: "res_3_129"
  top: "res_3_129"
}
layer {
  name: "res_stage_3_130_1"
  type: "Convolution"
  bottom: "res_3_129"
  top: "res_stage_3_130_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_130_1"
  type: "BatchNorm"
  bottom: "res_stage_3_130_1"
  top: "res_stage_3_130_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_130_1"  
  type: "Scale"
  bottom: "res_stage_3_130_1"
  top: "res_stage_3_130_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_130_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_130_1_top"
  top: "res_stage_3_130_1_top"
}
layer {
  name: "res_stage_3_130_2"
  type: "Convolution"
  bottom: "res_stage_3_130_1_top"
  top: "res_stage_3_130_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_130_2"
  type: "BatchNorm"
  bottom: "res_stage_3_130_2"
  top: "res_stage_3_130_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_130_2"  
  type: "Scale"
  bottom: "res_stage_3_130_2"
  top: "res_stage_3_130_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_130_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_130_2_top"
  top: "res_stage_3_130_2_top"
}
layer {
  name: "res_stage_3_130_3"
  type: "Convolution"
  bottom: "res_stage_3_130_2_top"
  top: "res_stage_3_130_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_130_3"
  type: "BatchNorm"
  bottom: "res_stage_3_130_3"
  top: "res_stage_3_130_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_130_3"  
  type: "Scale"
  bottom: "res_stage_3_130_3"
  top: "res_stage_3_130_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_130"
  type: "Eltwise"
  bottom: "res_3_129"
  bottom: "res_stage_3_130_3_top"
  top: "res_3_130"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_130_relu"
  type: "ReLU"
  bottom: "res_3_130"
  top: "res_3_130"
}
layer {
  name: "res_stage_3_131_1"
  type: "Convolution"
  bottom: "res_3_130"
  top: "res_stage_3_131_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_131_1"
  type: "BatchNorm"
  bottom: "res_stage_3_131_1"
  top: "res_stage_3_131_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_131_1"  
  type: "Scale"
  bottom: "res_stage_3_131_1"
  top: "res_stage_3_131_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_131_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_131_1_top"
  top: "res_stage_3_131_1_top"
}
layer {
  name: "res_stage_3_131_2"
  type: "Convolution"
  bottom: "res_stage_3_131_1_top"
  top: "res_stage_3_131_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_131_2"
  type: "BatchNorm"
  bottom: "res_stage_3_131_2"
  top: "res_stage_3_131_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_131_2"  
  type: "Scale"
  bottom: "res_stage_3_131_2"
  top: "res_stage_3_131_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_131_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_131_2_top"
  top: "res_stage_3_131_2_top"
}
layer {
  name: "res_stage_3_131_3"
  type: "Convolution"
  bottom: "res_stage_3_131_2_top"
  top: "res_stage_3_131_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_131_3"
  type: "BatchNorm"
  bottom: "res_stage_3_131_3"
  top: "res_stage_3_131_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_131_3"  
  type: "Scale"
  bottom: "res_stage_3_131_3"
  top: "res_stage_3_131_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_131"
  type: "Eltwise"
  bottom: "res_3_130"
  bottom: "res_stage_3_131_3_top"
  top: "res_3_131"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_131_relu"
  type: "ReLU"
  bottom: "res_3_131"
  top: "res_3_131"
}
layer {
  name: "res_stage_3_132_1"
  type: "Convolution"
  bottom: "res_3_131"
  top: "res_stage_3_132_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_132_1"
  type: "BatchNorm"
  bottom: "res_stage_3_132_1"
  top: "res_stage_3_132_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_132_1"  
  type: "Scale"
  bottom: "res_stage_3_132_1"
  top: "res_stage_3_132_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_132_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_132_1_top"
  top: "res_stage_3_132_1_top"
}
layer {
  name: "res_stage_3_132_2"
  type: "Convolution"
  bottom: "res_stage_3_132_1_top"
  top: "res_stage_3_132_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_132_2"
  type: "BatchNorm"
  bottom: "res_stage_3_132_2"
  top: "res_stage_3_132_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_132_2"  
  type: "Scale"
  bottom: "res_stage_3_132_2"
  top: "res_stage_3_132_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_132_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_132_2_top"
  top: "res_stage_3_132_2_top"
}
layer {
  name: "res_stage_3_132_3"
  type: "Convolution"
  bottom: "res_stage_3_132_2_top"
  top: "res_stage_3_132_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_132_3"
  type: "BatchNorm"
  bottom: "res_stage_3_132_3"
  top: "res_stage_3_132_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_132_3"  
  type: "Scale"
  bottom: "res_stage_3_132_3"
  top: "res_stage_3_132_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_132"
  type: "Eltwise"
  bottom: "res_3_131"
  bottom: "res_stage_3_132_3_top"
  top: "res_3_132"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_132_relu"
  type: "ReLU"
  bottom: "res_3_132"
  top: "res_3_132"
}
layer {
  name: "res_stage_3_133_1"
  type: "Convolution"
  bottom: "res_3_132"
  top: "res_stage_3_133_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_133_1"
  type: "BatchNorm"
  bottom: "res_stage_3_133_1"
  top: "res_stage_3_133_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_133_1"  
  type: "Scale"
  bottom: "res_stage_3_133_1"
  top: "res_stage_3_133_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_133_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_133_1_top"
  top: "res_stage_3_133_1_top"
}
layer {
  name: "res_stage_3_133_2"
  type: "Convolution"
  bottom: "res_stage_3_133_1_top"
  top: "res_stage_3_133_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_133_2"
  type: "BatchNorm"
  bottom: "res_stage_3_133_2"
  top: "res_stage_3_133_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_133_2"  
  type: "Scale"
  bottom: "res_stage_3_133_2"
  top: "res_stage_3_133_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_133_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_133_2_top"
  top: "res_stage_3_133_2_top"
}
layer {
  name: "res_stage_3_133_3"
  type: "Convolution"
  bottom: "res_stage_3_133_2_top"
  top: "res_stage_3_133_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_133_3"
  type: "BatchNorm"
  bottom: "res_stage_3_133_3"
  top: "res_stage_3_133_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_133_3"  
  type: "Scale"
  bottom: "res_stage_3_133_3"
  top: "res_stage_3_133_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_133"
  type: "Eltwise"
  bottom: "res_3_132"
  bottom: "res_stage_3_133_3_top"
  top: "res_3_133"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_133_relu"
  type: "ReLU"
  bottom: "res_3_133"
  top: "res_3_133"
}
layer {
  name: "res_stage_3_134_1"
  type: "Convolution"
  bottom: "res_3_133"
  top: "res_stage_3_134_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_134_1"
  type: "BatchNorm"
  bottom: "res_stage_3_134_1"
  top: "res_stage_3_134_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_134_1"  
  type: "Scale"
  bottom: "res_stage_3_134_1"
  top: "res_stage_3_134_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_134_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_134_1_top"
  top: "res_stage_3_134_1_top"
}
layer {
  name: "res_stage_3_134_2"
  type: "Convolution"
  bottom: "res_stage_3_134_1_top"
  top: "res_stage_3_134_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_134_2"
  type: "BatchNorm"
  bottom: "res_stage_3_134_2"
  top: "res_stage_3_134_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_134_2"  
  type: "Scale"
  bottom: "res_stage_3_134_2"
  top: "res_stage_3_134_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_134_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_134_2_top"
  top: "res_stage_3_134_2_top"
}
layer {
  name: "res_stage_3_134_3"
  type: "Convolution"
  bottom: "res_stage_3_134_2_top"
  top: "res_stage_3_134_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_134_3"
  type: "BatchNorm"
  bottom: "res_stage_3_134_3"
  top: "res_stage_3_134_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_134_3"  
  type: "Scale"
  bottom: "res_stage_3_134_3"
  top: "res_stage_3_134_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_134"
  type: "Eltwise"
  bottom: "res_3_133"
  bottom: "res_stage_3_134_3_top"
  top: "res_3_134"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_134_relu"
  type: "ReLU"
  bottom: "res_3_134"
  top: "res_3_134"
}
layer {
  name: "res_stage_3_135_1"
  type: "Convolution"
  bottom: "res_3_134"
  top: "res_stage_3_135_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_135_1"
  type: "BatchNorm"
  bottom: "res_stage_3_135_1"
  top: "res_stage_3_135_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_135_1"  
  type: "Scale"
  bottom: "res_stage_3_135_1"
  top: "res_stage_3_135_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_135_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_135_1_top"
  top: "res_stage_3_135_1_top"
}
layer {
  name: "res_stage_3_135_2"
  type: "Convolution"
  bottom: "res_stage_3_135_1_top"
  top: "res_stage_3_135_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_135_2"
  type: "BatchNorm"
  bottom: "res_stage_3_135_2"
  top: "res_stage_3_135_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_135_2"  
  type: "Scale"
  bottom: "res_stage_3_135_2"
  top: "res_stage_3_135_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_135_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_135_2_top"
  top: "res_stage_3_135_2_top"
}
layer {
  name: "res_stage_3_135_3"
  type: "Convolution"
  bottom: "res_stage_3_135_2_top"
  top: "res_stage_3_135_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_135_3"
  type: "BatchNorm"
  bottom: "res_stage_3_135_3"
  top: "res_stage_3_135_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_135_3"  
  type: "Scale"
  bottom: "res_stage_3_135_3"
  top: "res_stage_3_135_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_135"
  type: "Eltwise"
  bottom: "res_3_134"
  bottom: "res_stage_3_135_3_top"
  top: "res_3_135"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_135_relu"
  type: "ReLU"
  bottom: "res_3_135"
  top: "res_3_135"
}
layer {
  name: "res_stage_3_136_1"
  type: "Convolution"
  bottom: "res_3_135"
  top: "res_stage_3_136_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_136_1"
  type: "BatchNorm"
  bottom: "res_stage_3_136_1"
  top: "res_stage_3_136_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_136_1"  
  type: "Scale"
  bottom: "res_stage_3_136_1"
  top: "res_stage_3_136_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_136_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_136_1_top"
  top: "res_stage_3_136_1_top"
}
layer {
  name: "res_stage_3_136_2"
  type: "Convolution"
  bottom: "res_stage_3_136_1_top"
  top: "res_stage_3_136_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_136_2"
  type: "BatchNorm"
  bottom: "res_stage_3_136_2"
  top: "res_stage_3_136_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_136_2"  
  type: "Scale"
  bottom: "res_stage_3_136_2"
  top: "res_stage_3_136_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_136_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_136_2_top"
  top: "res_stage_3_136_2_top"
}
layer {
  name: "res_stage_3_136_3"
  type: "Convolution"
  bottom: "res_stage_3_136_2_top"
  top: "res_stage_3_136_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_136_3"
  type: "BatchNorm"
  bottom: "res_stage_3_136_3"
  top: "res_stage_3_136_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_136_3"  
  type: "Scale"
  bottom: "res_stage_3_136_3"
  top: "res_stage_3_136_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_136"
  type: "Eltwise"
  bottom: "res_3_135"
  bottom: "res_stage_3_136_3_top"
  top: "res_3_136"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_136_relu"
  type: "ReLU"
  bottom: "res_3_136"
  top: "res_3_136"
}
layer {
  name: "res_stage_3_137_1"
  type: "Convolution"
  bottom: "res_3_136"
  top: "res_stage_3_137_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_137_1"
  type: "BatchNorm"
  bottom: "res_stage_3_137_1"
  top: "res_stage_3_137_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_137_1"  
  type: "Scale"
  bottom: "res_stage_3_137_1"
  top: "res_stage_3_137_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_137_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_137_1_top"
  top: "res_stage_3_137_1_top"
}
layer {
  name: "res_stage_3_137_2"
  type: "Convolution"
  bottom: "res_stage_3_137_1_top"
  top: "res_stage_3_137_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_137_2"
  type: "BatchNorm"
  bottom: "res_stage_3_137_2"
  top: "res_stage_3_137_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_137_2"  
  type: "Scale"
  bottom: "res_stage_3_137_2"
  top: "res_stage_3_137_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_137_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_137_2_top"
  top: "res_stage_3_137_2_top"
}
layer {
  name: "res_stage_3_137_3"
  type: "Convolution"
  bottom: "res_stage_3_137_2_top"
  top: "res_stage_3_137_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_137_3"
  type: "BatchNorm"
  bottom: "res_stage_3_137_3"
  top: "res_stage_3_137_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_137_3"  
  type: "Scale"
  bottom: "res_stage_3_137_3"
  top: "res_stage_3_137_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_137"
  type: "Eltwise"
  bottom: "res_3_136"
  bottom: "res_stage_3_137_3_top"
  top: "res_3_137"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_137_relu"
  type: "ReLU"
  bottom: "res_3_137"
  top: "res_3_137"
}
layer {
  name: "res_stage_3_138_1"
  type: "Convolution"
  bottom: "res_3_137"
  top: "res_stage_3_138_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_138_1"
  type: "BatchNorm"
  bottom: "res_stage_3_138_1"
  top: "res_stage_3_138_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_138_1"  
  type: "Scale"
  bottom: "res_stage_3_138_1"
  top: "res_stage_3_138_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_138_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_138_1_top"
  top: "res_stage_3_138_1_top"
}
layer {
  name: "res_stage_3_138_2"
  type: "Convolution"
  bottom: "res_stage_3_138_1_top"
  top: "res_stage_3_138_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_138_2"
  type: "BatchNorm"
  bottom: "res_stage_3_138_2"
  top: "res_stage_3_138_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_138_2"  
  type: "Scale"
  bottom: "res_stage_3_138_2"
  top: "res_stage_3_138_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_138_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_138_2_top"
  top: "res_stage_3_138_2_top"
}
layer {
  name: "res_stage_3_138_3"
  type: "Convolution"
  bottom: "res_stage_3_138_2_top"
  top: "res_stage_3_138_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_138_3"
  type: "BatchNorm"
  bottom: "res_stage_3_138_3"
  top: "res_stage_3_138_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_138_3"  
  type: "Scale"
  bottom: "res_stage_3_138_3"
  top: "res_stage_3_138_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_138"
  type: "Eltwise"
  bottom: "res_3_137"
  bottom: "res_stage_3_138_3_top"
  top: "res_3_138"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_138_relu"
  type: "ReLU"
  bottom: "res_3_138"
  top: "res_3_138"
}
layer {
  name: "res_stage_3_139_1"
  type: "Convolution"
  bottom: "res_3_138"
  top: "res_stage_3_139_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_139_1"
  type: "BatchNorm"
  bottom: "res_stage_3_139_1"
  top: "res_stage_3_139_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_139_1"  
  type: "Scale"
  bottom: "res_stage_3_139_1"
  top: "res_stage_3_139_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_139_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_139_1_top"
  top: "res_stage_3_139_1_top"
}
layer {
  name: "res_stage_3_139_2"
  type: "Convolution"
  bottom: "res_stage_3_139_1_top"
  top: "res_stage_3_139_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_139_2"
  type: "BatchNorm"
  bottom: "res_stage_3_139_2"
  top: "res_stage_3_139_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_139_2"  
  type: "Scale"
  bottom: "res_stage_3_139_2"
  top: "res_stage_3_139_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_139_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_139_2_top"
  top: "res_stage_3_139_2_top"
}
layer {
  name: "res_stage_3_139_3"
  type: "Convolution"
  bottom: "res_stage_3_139_2_top"
  top: "res_stage_3_139_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_139_3"
  type: "BatchNorm"
  bottom: "res_stage_3_139_3"
  top: "res_stage_3_139_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_139_3"  
  type: "Scale"
  bottom: "res_stage_3_139_3"
  top: "res_stage_3_139_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_139"
  type: "Eltwise"
  bottom: "res_3_138"
  bottom: "res_stage_3_139_3_top"
  top: "res_3_139"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_139_relu"
  type: "ReLU"
  bottom: "res_3_139"
  top: "res_3_139"
}
layer {
  name: "res_stage_3_140_1"
  type: "Convolution"
  bottom: "res_3_139"
  top: "res_stage_3_140_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_140_1"
  type: "BatchNorm"
  bottom: "res_stage_3_140_1"
  top: "res_stage_3_140_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_140_1"  
  type: "Scale"
  bottom: "res_stage_3_140_1"
  top: "res_stage_3_140_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_140_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_140_1_top"
  top: "res_stage_3_140_1_top"
}
layer {
  name: "res_stage_3_140_2"
  type: "Convolution"
  bottom: "res_stage_3_140_1_top"
  top: "res_stage_3_140_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_140_2"
  type: "BatchNorm"
  bottom: "res_stage_3_140_2"
  top: "res_stage_3_140_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_140_2"  
  type: "Scale"
  bottom: "res_stage_3_140_2"
  top: "res_stage_3_140_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_140_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_140_2_top"
  top: "res_stage_3_140_2_top"
}
layer {
  name: "res_stage_3_140_3"
  type: "Convolution"
  bottom: "res_stage_3_140_2_top"
  top: "res_stage_3_140_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_140_3"
  type: "BatchNorm"
  bottom: "res_stage_3_140_3"
  top: "res_stage_3_140_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_140_3"  
  type: "Scale"
  bottom: "res_stage_3_140_3"
  top: "res_stage_3_140_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_140"
  type: "Eltwise"
  bottom: "res_3_139"
  bottom: "res_stage_3_140_3_top"
  top: "res_3_140"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_140_relu"
  type: "ReLU"
  bottom: "res_3_140"
  top: "res_3_140"
}
layer {
  name: "res_stage_3_141_1"
  type: "Convolution"
  bottom: "res_3_140"
  top: "res_stage_3_141_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_141_1"
  type: "BatchNorm"
  bottom: "res_stage_3_141_1"
  top: "res_stage_3_141_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_141_1"  
  type: "Scale"
  bottom: "res_stage_3_141_1"
  top: "res_stage_3_141_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_141_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_141_1_top"
  top: "res_stage_3_141_1_top"
}
layer {
  name: "res_stage_3_141_2"
  type: "Convolution"
  bottom: "res_stage_3_141_1_top"
  top: "res_stage_3_141_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_141_2"
  type: "BatchNorm"
  bottom: "res_stage_3_141_2"
  top: "res_stage_3_141_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_141_2"  
  type: "Scale"
  bottom: "res_stage_3_141_2"
  top: "res_stage_3_141_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_141_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_141_2_top"
  top: "res_stage_3_141_2_top"
}
layer {
  name: "res_stage_3_141_3"
  type: "Convolution"
  bottom: "res_stage_3_141_2_top"
  top: "res_stage_3_141_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_141_3"
  type: "BatchNorm"
  bottom: "res_stage_3_141_3"
  top: "res_stage_3_141_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_141_3"  
  type: "Scale"
  bottom: "res_stage_3_141_3"
  top: "res_stage_3_141_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_141"
  type: "Eltwise"
  bottom: "res_3_140"
  bottom: "res_stage_3_141_3_top"
  top: "res_3_141"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_141_relu"
  type: "ReLU"
  bottom: "res_3_141"
  top: "res_3_141"
}
layer {
  name: "res_stage_3_142_1"
  type: "Convolution"
  bottom: "res_3_141"
  top: "res_stage_3_142_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_142_1"
  type: "BatchNorm"
  bottom: "res_stage_3_142_1"
  top: "res_stage_3_142_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_142_1"  
  type: "Scale"
  bottom: "res_stage_3_142_1"
  top: "res_stage_3_142_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_142_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_142_1_top"
  top: "res_stage_3_142_1_top"
}
layer {
  name: "res_stage_3_142_2"
  type: "Convolution"
  bottom: "res_stage_3_142_1_top"
  top: "res_stage_3_142_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_142_2"
  type: "BatchNorm"
  bottom: "res_stage_3_142_2"
  top: "res_stage_3_142_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_142_2"  
  type: "Scale"
  bottom: "res_stage_3_142_2"
  top: "res_stage_3_142_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_142_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_142_2_top"
  top: "res_stage_3_142_2_top"
}
layer {
  name: "res_stage_3_142_3"
  type: "Convolution"
  bottom: "res_stage_3_142_2_top"
  top: "res_stage_3_142_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_142_3"
  type: "BatchNorm"
  bottom: "res_stage_3_142_3"
  top: "res_stage_3_142_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_142_3"  
  type: "Scale"
  bottom: "res_stage_3_142_3"
  top: "res_stage_3_142_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_142"
  type: "Eltwise"
  bottom: "res_3_141"
  bottom: "res_stage_3_142_3_top"
  top: "res_3_142"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_142_relu"
  type: "ReLU"
  bottom: "res_3_142"
  top: "res_3_142"
}
layer {
  name: "res_stage_3_143_1"
  type: "Convolution"
  bottom: "res_3_142"
  top: "res_stage_3_143_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_143_1"
  type: "BatchNorm"
  bottom: "res_stage_3_143_1"
  top: "res_stage_3_143_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_143_1"  
  type: "Scale"
  bottom: "res_stage_3_143_1"
  top: "res_stage_3_143_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_143_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_143_1_top"
  top: "res_stage_3_143_1_top"
}
layer {
  name: "res_stage_3_143_2"
  type: "Convolution"
  bottom: "res_stage_3_143_1_top"
  top: "res_stage_3_143_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_143_2"
  type: "BatchNorm"
  bottom: "res_stage_3_143_2"
  top: "res_stage_3_143_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_143_2"  
  type: "Scale"
  bottom: "res_stage_3_143_2"
  top: "res_stage_3_143_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_143_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_143_2_top"
  top: "res_stage_3_143_2_top"
}
layer {
  name: "res_stage_3_143_3"
  type: "Convolution"
  bottom: "res_stage_3_143_2_top"
  top: "res_stage_3_143_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_143_3"
  type: "BatchNorm"
  bottom: "res_stage_3_143_3"
  top: "res_stage_3_143_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_143_3"  
  type: "Scale"
  bottom: "res_stage_3_143_3"
  top: "res_stage_3_143_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_143"
  type: "Eltwise"
  bottom: "res_3_142"
  bottom: "res_stage_3_143_3_top"
  top: "res_3_143"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_143_relu"
  type: "ReLU"
  bottom: "res_3_143"
  top: "res_3_143"
}
layer {
  name: "res_stage_3_144_1"
  type: "Convolution"
  bottom: "res_3_143"
  top: "res_stage_3_144_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_144_1"
  type: "BatchNorm"
  bottom: "res_stage_3_144_1"
  top: "res_stage_3_144_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_144_1"  
  type: "Scale"
  bottom: "res_stage_3_144_1"
  top: "res_stage_3_144_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_144_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_144_1_top"
  top: "res_stage_3_144_1_top"
}
layer {
  name: "res_stage_3_144_2"
  type: "Convolution"
  bottom: "res_stage_3_144_1_top"
  top: "res_stage_3_144_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_144_2"
  type: "BatchNorm"
  bottom: "res_stage_3_144_2"
  top: "res_stage_3_144_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_144_2"  
  type: "Scale"
  bottom: "res_stage_3_144_2"
  top: "res_stage_3_144_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_144_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_144_2_top"
  top: "res_stage_3_144_2_top"
}
layer {
  name: "res_stage_3_144_3"
  type: "Convolution"
  bottom: "res_stage_3_144_2_top"
  top: "res_stage_3_144_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_144_3"
  type: "BatchNorm"
  bottom: "res_stage_3_144_3"
  top: "res_stage_3_144_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_144_3"  
  type: "Scale"
  bottom: "res_stage_3_144_3"
  top: "res_stage_3_144_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_144"
  type: "Eltwise"
  bottom: "res_3_143"
  bottom: "res_stage_3_144_3_top"
  top: "res_3_144"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_144_relu"
  type: "ReLU"
  bottom: "res_3_144"
  top: "res_3_144"
}
layer {
  name: "res_stage_3_145_1"
  type: "Convolution"
  bottom: "res_3_144"
  top: "res_stage_3_145_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_145_1"
  type: "BatchNorm"
  bottom: "res_stage_3_145_1"
  top: "res_stage_3_145_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_145_1"  
  type: "Scale"
  bottom: "res_stage_3_145_1"
  top: "res_stage_3_145_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_145_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_145_1_top"
  top: "res_stage_3_145_1_top"
}
layer {
  name: "res_stage_3_145_2"
  type: "Convolution"
  bottom: "res_stage_3_145_1_top"
  top: "res_stage_3_145_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_145_2"
  type: "BatchNorm"
  bottom: "res_stage_3_145_2"
  top: "res_stage_3_145_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_145_2"  
  type: "Scale"
  bottom: "res_stage_3_145_2"
  top: "res_stage_3_145_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_145_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_145_2_top"
  top: "res_stage_3_145_2_top"
}
layer {
  name: "res_stage_3_145_3"
  type: "Convolution"
  bottom: "res_stage_3_145_2_top"
  top: "res_stage_3_145_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_145_3"
  type: "BatchNorm"
  bottom: "res_stage_3_145_3"
  top: "res_stage_3_145_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_145_3"  
  type: "Scale"
  bottom: "res_stage_3_145_3"
  top: "res_stage_3_145_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_145"
  type: "Eltwise"
  bottom: "res_3_144"
  bottom: "res_stage_3_145_3_top"
  top: "res_3_145"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_145_relu"
  type: "ReLU"
  bottom: "res_3_145"
  top: "res_3_145"
}
layer {
  name: "res_stage_3_146_1"
  type: "Convolution"
  bottom: "res_3_145"
  top: "res_stage_3_146_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_146_1"
  type: "BatchNorm"
  bottom: "res_stage_3_146_1"
  top: "res_stage_3_146_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_146_1"  
  type: "Scale"
  bottom: "res_stage_3_146_1"
  top: "res_stage_3_146_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_146_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_146_1_top"
  top: "res_stage_3_146_1_top"
}
layer {
  name: "res_stage_3_146_2"
  type: "Convolution"
  bottom: "res_stage_3_146_1_top"
  top: "res_stage_3_146_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_146_2"
  type: "BatchNorm"
  bottom: "res_stage_3_146_2"
  top: "res_stage_3_146_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_146_2"  
  type: "Scale"
  bottom: "res_stage_3_146_2"
  top: "res_stage_3_146_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_146_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_146_2_top"
  top: "res_stage_3_146_2_top"
}
layer {
  name: "res_stage_3_146_3"
  type: "Convolution"
  bottom: "res_stage_3_146_2_top"
  top: "res_stage_3_146_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_146_3"
  type: "BatchNorm"
  bottom: "res_stage_3_146_3"
  top: "res_stage_3_146_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_146_3"  
  type: "Scale"
  bottom: "res_stage_3_146_3"
  top: "res_stage_3_146_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_146"
  type: "Eltwise"
  bottom: "res_3_145"
  bottom: "res_stage_3_146_3_top"
  top: "res_3_146"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_146_relu"
  type: "ReLU"
  bottom: "res_3_146"
  top: "res_3_146"
}
layer {
  name: "res_stage_3_147_1"
  type: "Convolution"
  bottom: "res_3_146"
  top: "res_stage_3_147_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_147_1"
  type: "BatchNorm"
  bottom: "res_stage_3_147_1"
  top: "res_stage_3_147_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_147_1"  
  type: "Scale"
  bottom: "res_stage_3_147_1"
  top: "res_stage_3_147_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_147_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_147_1_top"
  top: "res_stage_3_147_1_top"
}
layer {
  name: "res_stage_3_147_2"
  type: "Convolution"
  bottom: "res_stage_3_147_1_top"
  top: "res_stage_3_147_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_147_2"
  type: "BatchNorm"
  bottom: "res_stage_3_147_2"
  top: "res_stage_3_147_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_147_2"  
  type: "Scale"
  bottom: "res_stage_3_147_2"
  top: "res_stage_3_147_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_147_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_147_2_top"
  top: "res_stage_3_147_2_top"
}
layer {
  name: "res_stage_3_147_3"
  type: "Convolution"
  bottom: "res_stage_3_147_2_top"
  top: "res_stage_3_147_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_147_3"
  type: "BatchNorm"
  bottom: "res_stage_3_147_3"
  top: "res_stage_3_147_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_147_3"  
  type: "Scale"
  bottom: "res_stage_3_147_3"
  top: "res_stage_3_147_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_147"
  type: "Eltwise"
  bottom: "res_3_146"
  bottom: "res_stage_3_147_3_top"
  top: "res_3_147"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_147_relu"
  type: "ReLU"
  bottom: "res_3_147"
  top: "res_3_147"
}
layer {
  name: "res_stage_3_148_1"
  type: "Convolution"
  bottom: "res_3_147"
  top: "res_stage_3_148_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_148_1"
  type: "BatchNorm"
  bottom: "res_stage_3_148_1"
  top: "res_stage_3_148_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_148_1"  
  type: "Scale"
  bottom: "res_stage_3_148_1"
  top: "res_stage_3_148_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_148_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_148_1_top"
  top: "res_stage_3_148_1_top"
}
layer {
  name: "res_stage_3_148_2"
  type: "Convolution"
  bottom: "res_stage_3_148_1_top"
  top: "res_stage_3_148_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_148_2"
  type: "BatchNorm"
  bottom: "res_stage_3_148_2"
  top: "res_stage_3_148_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_148_2"  
  type: "Scale"
  bottom: "res_stage_3_148_2"
  top: "res_stage_3_148_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_148_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_148_2_top"
  top: "res_stage_3_148_2_top"
}
layer {
  name: "res_stage_3_148_3"
  type: "Convolution"
  bottom: "res_stage_3_148_2_top"
  top: "res_stage_3_148_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_148_3"
  type: "BatchNorm"
  bottom: "res_stage_3_148_3"
  top: "res_stage_3_148_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_148_3"  
  type: "Scale"
  bottom: "res_stage_3_148_3"
  top: "res_stage_3_148_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_148"
  type: "Eltwise"
  bottom: "res_3_147"
  bottom: "res_stage_3_148_3_top"
  top: "res_3_148"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_148_relu"
  type: "ReLU"
  bottom: "res_3_148"
  top: "res_3_148"
}
layer {
  name: "res_stage_3_149_1"
  type: "Convolution"
  bottom: "res_3_148"
  top: "res_stage_3_149_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_149_1"
  type: "BatchNorm"
  bottom: "res_stage_3_149_1"
  top: "res_stage_3_149_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_149_1"  
  type: "Scale"
  bottom: "res_stage_3_149_1"
  top: "res_stage_3_149_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_149_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_149_1_top"
  top: "res_stage_3_149_1_top"
}
layer {
  name: "res_stage_3_149_2"
  type: "Convolution"
  bottom: "res_stage_3_149_1_top"
  top: "res_stage_3_149_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_149_2"
  type: "BatchNorm"
  bottom: "res_stage_3_149_2"
  top: "res_stage_3_149_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_149_2"  
  type: "Scale"
  bottom: "res_stage_3_149_2"
  top: "res_stage_3_149_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_149_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_149_2_top"
  top: "res_stage_3_149_2_top"
}
layer {
  name: "res_stage_3_149_3"
  type: "Convolution"
  bottom: "res_stage_3_149_2_top"
  top: "res_stage_3_149_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_149_3"
  type: "BatchNorm"
  bottom: "res_stage_3_149_3"
  top: "res_stage_3_149_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_149_3"  
  type: "Scale"
  bottom: "res_stage_3_149_3"
  top: "res_stage_3_149_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_149"
  type: "Eltwise"
  bottom: "res_3_148"
  bottom: "res_stage_3_149_3_top"
  top: "res_3_149"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_149_relu"
  type: "ReLU"
  bottom: "res_3_149"
  top: "res_3_149"
}
layer {
  name: "res_stage_3_150_1"
  type: "Convolution"
  bottom: "res_3_149"
  top: "res_stage_3_150_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_150_1"
  type: "BatchNorm"
  bottom: "res_stage_3_150_1"
  top: "res_stage_3_150_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_150_1"  
  type: "Scale"
  bottom: "res_stage_3_150_1"
  top: "res_stage_3_150_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_150_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_150_1_top"
  top: "res_stage_3_150_1_top"
}
layer {
  name: "res_stage_3_150_2"
  type: "Convolution"
  bottom: "res_stage_3_150_1_top"
  top: "res_stage_3_150_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_150_2"
  type: "BatchNorm"
  bottom: "res_stage_3_150_2"
  top: "res_stage_3_150_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_150_2"  
  type: "Scale"
  bottom: "res_stage_3_150_2"
  top: "res_stage_3_150_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_150_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_150_2_top"
  top: "res_stage_3_150_2_top"
}
layer {
  name: "res_stage_3_150_3"
  type: "Convolution"
  bottom: "res_stage_3_150_2_top"
  top: "res_stage_3_150_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_150_3"
  type: "BatchNorm"
  bottom: "res_stage_3_150_3"
  top: "res_stage_3_150_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_150_3"  
  type: "Scale"
  bottom: "res_stage_3_150_3"
  top: "res_stage_3_150_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_150"
  type: "Eltwise"
  bottom: "res_3_149"
  bottom: "res_stage_3_150_3_top"
  top: "res_3_150"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_150_relu"
  type: "ReLU"
  bottom: "res_3_150"
  top: "res_3_150"
}
layer {
  name: "res_stage_3_151_1"
  type: "Convolution"
  bottom: "res_3_150"
  top: "res_stage_3_151_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_151_1"
  type: "BatchNorm"
  bottom: "res_stage_3_151_1"
  top: "res_stage_3_151_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_151_1"  
  type: "Scale"
  bottom: "res_stage_3_151_1"
  top: "res_stage_3_151_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_151_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_151_1_top"
  top: "res_stage_3_151_1_top"
}
layer {
  name: "res_stage_3_151_2"
  type: "Convolution"
  bottom: "res_stage_3_151_1_top"
  top: "res_stage_3_151_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_151_2"
  type: "BatchNorm"
  bottom: "res_stage_3_151_2"
  top: "res_stage_3_151_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_151_2"  
  type: "Scale"
  bottom: "res_stage_3_151_2"
  top: "res_stage_3_151_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_151_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_151_2_top"
  top: "res_stage_3_151_2_top"
}
layer {
  name: "res_stage_3_151_3"
  type: "Convolution"
  bottom: "res_stage_3_151_2_top"
  top: "res_stage_3_151_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_151_3"
  type: "BatchNorm"
  bottom: "res_stage_3_151_3"
  top: "res_stage_3_151_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_151_3"  
  type: "Scale"
  bottom: "res_stage_3_151_3"
  top: "res_stage_3_151_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_151"
  type: "Eltwise"
  bottom: "res_3_150"
  bottom: "res_stage_3_151_3_top"
  top: "res_3_151"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_151_relu"
  type: "ReLU"
  bottom: "res_3_151"
  top: "res_3_151"
}
layer {
  name: "res_stage_3_152_1"
  type: "Convolution"
  bottom: "res_3_151"
  top: "res_stage_3_152_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_152_1"
  type: "BatchNorm"
  bottom: "res_stage_3_152_1"
  top: "res_stage_3_152_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_152_1"  
  type: "Scale"
  bottom: "res_stage_3_152_1"
  top: "res_stage_3_152_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_152_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_152_1_top"
  top: "res_stage_3_152_1_top"
}
layer {
  name: "res_stage_3_152_2"
  type: "Convolution"
  bottom: "res_stage_3_152_1_top"
  top: "res_stage_3_152_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_152_2"
  type: "BatchNorm"
  bottom: "res_stage_3_152_2"
  top: "res_stage_3_152_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_152_2"  
  type: "Scale"
  bottom: "res_stage_3_152_2"
  top: "res_stage_3_152_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_152_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_152_2_top"
  top: "res_stage_3_152_2_top"
}
layer {
  name: "res_stage_3_152_3"
  type: "Convolution"
  bottom: "res_stage_3_152_2_top"
  top: "res_stage_3_152_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_152_3"
  type: "BatchNorm"
  bottom: "res_stage_3_152_3"
  top: "res_stage_3_152_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_152_3"  
  type: "Scale"
  bottom: "res_stage_3_152_3"
  top: "res_stage_3_152_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_152"
  type: "Eltwise"
  bottom: "res_3_151"
  bottom: "res_stage_3_152_3_top"
  top: "res_3_152"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_152_relu"
  type: "ReLU"
  bottom: "res_3_152"
  top: "res_3_152"
}
layer {
  name: "res_stage_3_153_1"
  type: "Convolution"
  bottom: "res_3_152"
  top: "res_stage_3_153_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_153_1"
  type: "BatchNorm"
  bottom: "res_stage_3_153_1"
  top: "res_stage_3_153_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_153_1"  
  type: "Scale"
  bottom: "res_stage_3_153_1"
  top: "res_stage_3_153_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_153_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_153_1_top"
  top: "res_stage_3_153_1_top"
}
layer {
  name: "res_stage_3_153_2"
  type: "Convolution"
  bottom: "res_stage_3_153_1_top"
  top: "res_stage_3_153_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_153_2"
  type: "BatchNorm"
  bottom: "res_stage_3_153_2"
  top: "res_stage_3_153_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_153_2"  
  type: "Scale"
  bottom: "res_stage_3_153_2"
  top: "res_stage_3_153_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_153_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_153_2_top"
  top: "res_stage_3_153_2_top"
}
layer {
  name: "res_stage_3_153_3"
  type: "Convolution"
  bottom: "res_stage_3_153_2_top"
  top: "res_stage_3_153_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_153_3"
  type: "BatchNorm"
  bottom: "res_stage_3_153_3"
  top: "res_stage_3_153_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_153_3"  
  type: "Scale"
  bottom: "res_stage_3_153_3"
  top: "res_stage_3_153_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_153"
  type: "Eltwise"
  bottom: "res_3_152"
  bottom: "res_stage_3_153_3_top"
  top: "res_3_153"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_153_relu"
  type: "ReLU"
  bottom: "res_3_153"
  top: "res_3_153"
}
layer {
  name: "res_stage_3_154_1"
  type: "Convolution"
  bottom: "res_3_153"
  top: "res_stage_3_154_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_154_1"
  type: "BatchNorm"
  bottom: "res_stage_3_154_1"
  top: "res_stage_3_154_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_154_1"  
  type: "Scale"
  bottom: "res_stage_3_154_1"
  top: "res_stage_3_154_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_154_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_154_1_top"
  top: "res_stage_3_154_1_top"
}
layer {
  name: "res_stage_3_154_2"
  type: "Convolution"
  bottom: "res_stage_3_154_1_top"
  top: "res_stage_3_154_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_154_2"
  type: "BatchNorm"
  bottom: "res_stage_3_154_2"
  top: "res_stage_3_154_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_154_2"  
  type: "Scale"
  bottom: "res_stage_3_154_2"
  top: "res_stage_3_154_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_154_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_154_2_top"
  top: "res_stage_3_154_2_top"
}
layer {
  name: "res_stage_3_154_3"
  type: "Convolution"
  bottom: "res_stage_3_154_2_top"
  top: "res_stage_3_154_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_154_3"
  type: "BatchNorm"
  bottom: "res_stage_3_154_3"
  top: "res_stage_3_154_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_154_3"  
  type: "Scale"
  bottom: "res_stage_3_154_3"
  top: "res_stage_3_154_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_154"
  type: "Eltwise"
  bottom: "res_3_153"
  bottom: "res_stage_3_154_3_top"
  top: "res_3_154"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_154_relu"
  type: "ReLU"
  bottom: "res_3_154"
  top: "res_3_154"
}
layer {
  name: "res_stage_3_155_1"
  type: "Convolution"
  bottom: "res_3_154"
  top: "res_stage_3_155_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_155_1"
  type: "BatchNorm"
  bottom: "res_stage_3_155_1"
  top: "res_stage_3_155_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_155_1"  
  type: "Scale"
  bottom: "res_stage_3_155_1"
  top: "res_stage_3_155_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_155_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_155_1_top"
  top: "res_stage_3_155_1_top"
}
layer {
  name: "res_stage_3_155_2"
  type: "Convolution"
  bottom: "res_stage_3_155_1_top"
  top: "res_stage_3_155_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_155_2"
  type: "BatchNorm"
  bottom: "res_stage_3_155_2"
  top: "res_stage_3_155_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_155_2"  
  type: "Scale"
  bottom: "res_stage_3_155_2"
  top: "res_stage_3_155_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_155_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_155_2_top"
  top: "res_stage_3_155_2_top"
}
layer {
  name: "res_stage_3_155_3"
  type: "Convolution"
  bottom: "res_stage_3_155_2_top"
  top: "res_stage_3_155_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_155_3"
  type: "BatchNorm"
  bottom: "res_stage_3_155_3"
  top: "res_stage_3_155_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_155_3"  
  type: "Scale"
  bottom: "res_stage_3_155_3"
  top: "res_stage_3_155_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_155"
  type: "Eltwise"
  bottom: "res_3_154"
  bottom: "res_stage_3_155_3_top"
  top: "res_3_155"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_155_relu"
  type: "ReLU"
  bottom: "res_3_155"
  top: "res_3_155"
}
layer {
  name: "res_stage_3_156_1"
  type: "Convolution"
  bottom: "res_3_155"
  top: "res_stage_3_156_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_156_1"
  type: "BatchNorm"
  bottom: "res_stage_3_156_1"
  top: "res_stage_3_156_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_156_1"  
  type: "Scale"
  bottom: "res_stage_3_156_1"
  top: "res_stage_3_156_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_156_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_156_1_top"
  top: "res_stage_3_156_1_top"
}
layer {
  name: "res_stage_3_156_2"
  type: "Convolution"
  bottom: "res_stage_3_156_1_top"
  top: "res_stage_3_156_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_156_2"
  type: "BatchNorm"
  bottom: "res_stage_3_156_2"
  top: "res_stage_3_156_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_156_2"  
  type: "Scale"
  bottom: "res_stage_3_156_2"
  top: "res_stage_3_156_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_156_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_156_2_top"
  top: "res_stage_3_156_2_top"
}
layer {
  name: "res_stage_3_156_3"
  type: "Convolution"
  bottom: "res_stage_3_156_2_top"
  top: "res_stage_3_156_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_156_3"
  type: "BatchNorm"
  bottom: "res_stage_3_156_3"
  top: "res_stage_3_156_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_156_3"  
  type: "Scale"
  bottom: "res_stage_3_156_3"
  top: "res_stage_3_156_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_156"
  type: "Eltwise"
  bottom: "res_3_155"
  bottom: "res_stage_3_156_3_top"
  top: "res_3_156"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_156_relu"
  type: "ReLU"
  bottom: "res_3_156"
  top: "res_3_156"
}
layer {
  name: "res_stage_3_157_1"
  type: "Convolution"
  bottom: "res_3_156"
  top: "res_stage_3_157_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_157_1"
  type: "BatchNorm"
  bottom: "res_stage_3_157_1"
  top: "res_stage_3_157_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_157_1"  
  type: "Scale"
  bottom: "res_stage_3_157_1"
  top: "res_stage_3_157_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_157_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_157_1_top"
  top: "res_stage_3_157_1_top"
}
layer {
  name: "res_stage_3_157_2"
  type: "Convolution"
  bottom: "res_stage_3_157_1_top"
  top: "res_stage_3_157_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_157_2"
  type: "BatchNorm"
  bottom: "res_stage_3_157_2"
  top: "res_stage_3_157_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_157_2"  
  type: "Scale"
  bottom: "res_stage_3_157_2"
  top: "res_stage_3_157_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_157_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_157_2_top"
  top: "res_stage_3_157_2_top"
}
layer {
  name: "res_stage_3_157_3"
  type: "Convolution"
  bottom: "res_stage_3_157_2_top"
  top: "res_stage_3_157_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_157_3"
  type: "BatchNorm"
  bottom: "res_stage_3_157_3"
  top: "res_stage_3_157_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_157_3"  
  type: "Scale"
  bottom: "res_stage_3_157_3"
  top: "res_stage_3_157_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_157"
  type: "Eltwise"
  bottom: "res_3_156"
  bottom: "res_stage_3_157_3_top"
  top: "res_3_157"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_157_relu"
  type: "ReLU"
  bottom: "res_3_157"
  top: "res_3_157"
}
layer {
  name: "res_stage_3_158_1"
  type: "Convolution"
  bottom: "res_3_157"
  top: "res_stage_3_158_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_158_1"
  type: "BatchNorm"
  bottom: "res_stage_3_158_1"
  top: "res_stage_3_158_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_158_1"  
  type: "Scale"
  bottom: "res_stage_3_158_1"
  top: "res_stage_3_158_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_158_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_158_1_top"
  top: "res_stage_3_158_1_top"
}
layer {
  name: "res_stage_3_158_2"
  type: "Convolution"
  bottom: "res_stage_3_158_1_top"
  top: "res_stage_3_158_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_158_2"
  type: "BatchNorm"
  bottom: "res_stage_3_158_2"
  top: "res_stage_3_158_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_158_2"  
  type: "Scale"
  bottom: "res_stage_3_158_2"
  top: "res_stage_3_158_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_158_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_158_2_top"
  top: "res_stage_3_158_2_top"
}
layer {
  name: "res_stage_3_158_3"
  type: "Convolution"
  bottom: "res_stage_3_158_2_top"
  top: "res_stage_3_158_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_158_3"
  type: "BatchNorm"
  bottom: "res_stage_3_158_3"
  top: "res_stage_3_158_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_158_3"  
  type: "Scale"
  bottom: "res_stage_3_158_3"
  top: "res_stage_3_158_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_158"
  type: "Eltwise"
  bottom: "res_3_157"
  bottom: "res_stage_3_158_3_top"
  top: "res_3_158"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_158_relu"
  type: "ReLU"
  bottom: "res_3_158"
  top: "res_3_158"
}
layer {
  name: "res_stage_3_159_1"
  type: "Convolution"
  bottom: "res_3_158"
  top: "res_stage_3_159_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_159_1"
  type: "BatchNorm"
  bottom: "res_stage_3_159_1"
  top: "res_stage_3_159_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_159_1"  
  type: "Scale"
  bottom: "res_stage_3_159_1"
  top: "res_stage_3_159_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_159_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_159_1_top"
  top: "res_stage_3_159_1_top"
}
layer {
  name: "res_stage_3_159_2"
  type: "Convolution"
  bottom: "res_stage_3_159_1_top"
  top: "res_stage_3_159_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_159_2"
  type: "BatchNorm"
  bottom: "res_stage_3_159_2"
  top: "res_stage_3_159_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_159_2"  
  type: "Scale"
  bottom: "res_stage_3_159_2"
  top: "res_stage_3_159_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_159_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_159_2_top"
  top: "res_stage_3_159_2_top"
}
layer {
  name: "res_stage_3_159_3"
  type: "Convolution"
  bottom: "res_stage_3_159_2_top"
  top: "res_stage_3_159_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_159_3"
  type: "BatchNorm"
  bottom: "res_stage_3_159_3"
  top: "res_stage_3_159_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_159_3"  
  type: "Scale"
  bottom: "res_stage_3_159_3"
  top: "res_stage_3_159_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_159"
  type: "Eltwise"
  bottom: "res_3_158"
  bottom: "res_stage_3_159_3_top"
  top: "res_3_159"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_159_relu"
  type: "ReLU"
  bottom: "res_3_159"
  top: "res_3_159"
}
layer {
  name: "res_stage_3_160_1"
  type: "Convolution"
  bottom: "res_3_159"
  top: "res_stage_3_160_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_160_1"
  type: "BatchNorm"
  bottom: "res_stage_3_160_1"
  top: "res_stage_3_160_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_160_1"  
  type: "Scale"
  bottom: "res_stage_3_160_1"
  top: "res_stage_3_160_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_160_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_160_1_top"
  top: "res_stage_3_160_1_top"
}
layer {
  name: "res_stage_3_160_2"
  type: "Convolution"
  bottom: "res_stage_3_160_1_top"
  top: "res_stage_3_160_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_160_2"
  type: "BatchNorm"
  bottom: "res_stage_3_160_2"
  top: "res_stage_3_160_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_160_2"  
  type: "Scale"
  bottom: "res_stage_3_160_2"
  top: "res_stage_3_160_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_160_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_160_2_top"
  top: "res_stage_3_160_2_top"
}
layer {
  name: "res_stage_3_160_3"
  type: "Convolution"
  bottom: "res_stage_3_160_2_top"
  top: "res_stage_3_160_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_160_3"
  type: "BatchNorm"
  bottom: "res_stage_3_160_3"
  top: "res_stage_3_160_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_160_3"  
  type: "Scale"
  bottom: "res_stage_3_160_3"
  top: "res_stage_3_160_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_160"
  type: "Eltwise"
  bottom: "res_3_159"
  bottom: "res_stage_3_160_3_top"
  top: "res_3_160"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_160_relu"
  type: "ReLU"
  bottom: "res_3_160"
  top: "res_3_160"
}
layer {
  name: "res_stage_3_161_1"
  type: "Convolution"
  bottom: "res_3_160"
  top: "res_stage_3_161_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_161_1"
  type: "BatchNorm"
  bottom: "res_stage_3_161_1"
  top: "res_stage_3_161_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_161_1"  
  type: "Scale"
  bottom: "res_stage_3_161_1"
  top: "res_stage_3_161_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_161_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_161_1_top"
  top: "res_stage_3_161_1_top"
}
layer {
  name: "res_stage_3_161_2"
  type: "Convolution"
  bottom: "res_stage_3_161_1_top"
  top: "res_stage_3_161_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_161_2"
  type: "BatchNorm"
  bottom: "res_stage_3_161_2"
  top: "res_stage_3_161_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_161_2"  
  type: "Scale"
  bottom: "res_stage_3_161_2"
  top: "res_stage_3_161_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_161_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_161_2_top"
  top: "res_stage_3_161_2_top"
}
layer {
  name: "res_stage_3_161_3"
  type: "Convolution"
  bottom: "res_stage_3_161_2_top"
  top: "res_stage_3_161_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_161_3"
  type: "BatchNorm"
  bottom: "res_stage_3_161_3"
  top: "res_stage_3_161_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_161_3"  
  type: "Scale"
  bottom: "res_stage_3_161_3"
  top: "res_stage_3_161_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_161"
  type: "Eltwise"
  bottom: "res_3_160"
  bottom: "res_stage_3_161_3_top"
  top: "res_3_161"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_161_relu"
  type: "ReLU"
  bottom: "res_3_161"
  top: "res_3_161"
}
layer {
  name: "res_stage_3_162_1"
  type: "Convolution"
  bottom: "res_3_161"
  top: "res_stage_3_162_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_162_1"
  type: "BatchNorm"
  bottom: "res_stage_3_162_1"
  top: "res_stage_3_162_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_162_1"  
  type: "Scale"
  bottom: "res_stage_3_162_1"
  top: "res_stage_3_162_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_162_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_162_1_top"
  top: "res_stage_3_162_1_top"
}
layer {
  name: "res_stage_3_162_2"
  type: "Convolution"
  bottom: "res_stage_3_162_1_top"
  top: "res_stage_3_162_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_162_2"
  type: "BatchNorm"
  bottom: "res_stage_3_162_2"
  top: "res_stage_3_162_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_162_2"  
  type: "Scale"
  bottom: "res_stage_3_162_2"
  top: "res_stage_3_162_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_162_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_162_2_top"
  top: "res_stage_3_162_2_top"
}
layer {
  name: "res_stage_3_162_3"
  type: "Convolution"
  bottom: "res_stage_3_162_2_top"
  top: "res_stage_3_162_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_162_3"
  type: "BatchNorm"
  bottom: "res_stage_3_162_3"
  top: "res_stage_3_162_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_162_3"  
  type: "Scale"
  bottom: "res_stage_3_162_3"
  top: "res_stage_3_162_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_162"
  type: "Eltwise"
  bottom: "res_3_161"
  bottom: "res_stage_3_162_3_top"
  top: "res_3_162"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_162_relu"
  type: "ReLU"
  bottom: "res_3_162"
  top: "res_3_162"
}
layer {
  name: "res_stage_3_163_1"
  type: "Convolution"
  bottom: "res_3_162"
  top: "res_stage_3_163_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_163_1"
  type: "BatchNorm"
  bottom: "res_stage_3_163_1"
  top: "res_stage_3_163_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_163_1"  
  type: "Scale"
  bottom: "res_stage_3_163_1"
  top: "res_stage_3_163_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_163_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_163_1_top"
  top: "res_stage_3_163_1_top"
}
layer {
  name: "res_stage_3_163_2"
  type: "Convolution"
  bottom: "res_stage_3_163_1_top"
  top: "res_stage_3_163_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_163_2"
  type: "BatchNorm"
  bottom: "res_stage_3_163_2"
  top: "res_stage_3_163_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_163_2"  
  type: "Scale"
  bottom: "res_stage_3_163_2"
  top: "res_stage_3_163_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_163_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_163_2_top"
  top: "res_stage_3_163_2_top"
}
layer {
  name: "res_stage_3_163_3"
  type: "Convolution"
  bottom: "res_stage_3_163_2_top"
  top: "res_stage_3_163_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_163_3"
  type: "BatchNorm"
  bottom: "res_stage_3_163_3"
  top: "res_stage_3_163_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_163_3"  
  type: "Scale"
  bottom: "res_stage_3_163_3"
  top: "res_stage_3_163_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_163"
  type: "Eltwise"
  bottom: "res_3_162"
  bottom: "res_stage_3_163_3_top"
  top: "res_3_163"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_163_relu"
  type: "ReLU"
  bottom: "res_3_163"
  top: "res_3_163"
}
layer {
  name: "res_stage_3_164_1"
  type: "Convolution"
  bottom: "res_3_163"
  top: "res_stage_3_164_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_164_1"
  type: "BatchNorm"
  bottom: "res_stage_3_164_1"
  top: "res_stage_3_164_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_164_1"  
  type: "Scale"
  bottom: "res_stage_3_164_1"
  top: "res_stage_3_164_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_164_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_164_1_top"
  top: "res_stage_3_164_1_top"
}
layer {
  name: "res_stage_3_164_2"
  type: "Convolution"
  bottom: "res_stage_3_164_1_top"
  top: "res_stage_3_164_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_164_2"
  type: "BatchNorm"
  bottom: "res_stage_3_164_2"
  top: "res_stage_3_164_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_164_2"  
  type: "Scale"
  bottom: "res_stage_3_164_2"
  top: "res_stage_3_164_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_164_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_164_2_top"
  top: "res_stage_3_164_2_top"
}
layer {
  name: "res_stage_3_164_3"
  type: "Convolution"
  bottom: "res_stage_3_164_2_top"
  top: "res_stage_3_164_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_164_3"
  type: "BatchNorm"
  bottom: "res_stage_3_164_3"
  top: "res_stage_3_164_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_164_3"  
  type: "Scale"
  bottom: "res_stage_3_164_3"
  top: "res_stage_3_164_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_164"
  type: "Eltwise"
  bottom: "res_3_163"
  bottom: "res_stage_3_164_3_top"
  top: "res_3_164"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_164_relu"
  type: "ReLU"
  bottom: "res_3_164"
  top: "res_3_164"
}
layer {
  name: "res_stage_3_165_1"
  type: "Convolution"
  bottom: "res_3_164"
  top: "res_stage_3_165_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_165_1"
  type: "BatchNorm"
  bottom: "res_stage_3_165_1"
  top: "res_stage_3_165_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_165_1"  
  type: "Scale"
  bottom: "res_stage_3_165_1"
  top: "res_stage_3_165_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_165_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_165_1_top"
  top: "res_stage_3_165_1_top"
}
layer {
  name: "res_stage_3_165_2"
  type: "Convolution"
  bottom: "res_stage_3_165_1_top"
  top: "res_stage_3_165_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_165_2"
  type: "BatchNorm"
  bottom: "res_stage_3_165_2"
  top: "res_stage_3_165_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_165_2"  
  type: "Scale"
  bottom: "res_stage_3_165_2"
  top: "res_stage_3_165_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_165_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_165_2_top"
  top: "res_stage_3_165_2_top"
}
layer {
  name: "res_stage_3_165_3"
  type: "Convolution"
  bottom: "res_stage_3_165_2_top"
  top: "res_stage_3_165_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_165_3"
  type: "BatchNorm"
  bottom: "res_stage_3_165_3"
  top: "res_stage_3_165_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_165_3"  
  type: "Scale"
  bottom: "res_stage_3_165_3"
  top: "res_stage_3_165_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_165"
  type: "Eltwise"
  bottom: "res_3_164"
  bottom: "res_stage_3_165_3_top"
  top: "res_3_165"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_165_relu"
  type: "ReLU"
  bottom: "res_3_165"
  top: "res_3_165"
}
layer {
  name: "res_stage_3_166_1"
  type: "Convolution"
  bottom: "res_3_165"
  top: "res_stage_3_166_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_166_1"
  type: "BatchNorm"
  bottom: "res_stage_3_166_1"
  top: "res_stage_3_166_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_166_1"  
  type: "Scale"
  bottom: "res_stage_3_166_1"
  top: "res_stage_3_166_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_166_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_166_1_top"
  top: "res_stage_3_166_1_top"
}
layer {
  name: "res_stage_3_166_2"
  type: "Convolution"
  bottom: "res_stage_3_166_1_top"
  top: "res_stage_3_166_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_166_2"
  type: "BatchNorm"
  bottom: "res_stage_3_166_2"
  top: "res_stage_3_166_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_166_2"  
  type: "Scale"
  bottom: "res_stage_3_166_2"
  top: "res_stage_3_166_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_166_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_166_2_top"
  top: "res_stage_3_166_2_top"
}
layer {
  name: "res_stage_3_166_3"
  type: "Convolution"
  bottom: "res_stage_3_166_2_top"
  top: "res_stage_3_166_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_166_3"
  type: "BatchNorm"
  bottom: "res_stage_3_166_3"
  top: "res_stage_3_166_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_166_3"  
  type: "Scale"
  bottom: "res_stage_3_166_3"
  top: "res_stage_3_166_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_166"
  type: "Eltwise"
  bottom: "res_3_165"
  bottom: "res_stage_3_166_3_top"
  top: "res_3_166"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_166_relu"
  type: "ReLU"
  bottom: "res_3_166"
  top: "res_3_166"
}
layer {
  name: "res_stage_3_167_1"
  type: "Convolution"
  bottom: "res_3_166"
  top: "res_stage_3_167_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_167_1"
  type: "BatchNorm"
  bottom: "res_stage_3_167_1"
  top: "res_stage_3_167_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_167_1"  
  type: "Scale"
  bottom: "res_stage_3_167_1"
  top: "res_stage_3_167_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_167_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_167_1_top"
  top: "res_stage_3_167_1_top"
}
layer {
  name: "res_stage_3_167_2"
  type: "Convolution"
  bottom: "res_stage_3_167_1_top"
  top: "res_stage_3_167_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_167_2"
  type: "BatchNorm"
  bottom: "res_stage_3_167_2"
  top: "res_stage_3_167_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_167_2"  
  type: "Scale"
  bottom: "res_stage_3_167_2"
  top: "res_stage_3_167_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_167_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_167_2_top"
  top: "res_stage_3_167_2_top"
}
layer {
  name: "res_stage_3_167_3"
  type: "Convolution"
  bottom: "res_stage_3_167_2_top"
  top: "res_stage_3_167_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_167_3"
  type: "BatchNorm"
  bottom: "res_stage_3_167_3"
  top: "res_stage_3_167_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_167_3"  
  type: "Scale"
  bottom: "res_stage_3_167_3"
  top: "res_stage_3_167_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_167"
  type: "Eltwise"
  bottom: "res_3_166"
  bottom: "res_stage_3_167_3_top"
  top: "res_3_167"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_167_relu"
  type: "ReLU"
  bottom: "res_3_167"
  top: "res_3_167"
}
layer {
  name: "res_stage_3_168_1"
  type: "Convolution"
  bottom: "res_3_167"
  top: "res_stage_3_168_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_168_1"
  type: "BatchNorm"
  bottom: "res_stage_3_168_1"
  top: "res_stage_3_168_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_168_1"  
  type: "Scale"
  bottom: "res_stage_3_168_1"
  top: "res_stage_3_168_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_168_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_168_1_top"
  top: "res_stage_3_168_1_top"
}
layer {
  name: "res_stage_3_168_2"
  type: "Convolution"
  bottom: "res_stage_3_168_1_top"
  top: "res_stage_3_168_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_168_2"
  type: "BatchNorm"
  bottom: "res_stage_3_168_2"
  top: "res_stage_3_168_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_168_2"  
  type: "Scale"
  bottom: "res_stage_3_168_2"
  top: "res_stage_3_168_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_168_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_168_2_top"
  top: "res_stage_3_168_2_top"
}
layer {
  name: "res_stage_3_168_3"
  type: "Convolution"
  bottom: "res_stage_3_168_2_top"
  top: "res_stage_3_168_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_168_3"
  type: "BatchNorm"
  bottom: "res_stage_3_168_3"
  top: "res_stage_3_168_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_168_3"  
  type: "Scale"
  bottom: "res_stage_3_168_3"
  top: "res_stage_3_168_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_168"
  type: "Eltwise"
  bottom: "res_3_167"
  bottom: "res_stage_3_168_3_top"
  top: "res_3_168"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_168_relu"
  type: "ReLU"
  bottom: "res_3_168"
  top: "res_3_168"
}
layer {
  name: "res_stage_3_169_1"
  type: "Convolution"
  bottom: "res_3_168"
  top: "res_stage_3_169_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_169_1"
  type: "BatchNorm"
  bottom: "res_stage_3_169_1"
  top: "res_stage_3_169_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_169_1"  
  type: "Scale"
  bottom: "res_stage_3_169_1"
  top: "res_stage_3_169_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_169_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_169_1_top"
  top: "res_stage_3_169_1_top"
}
layer {
  name: "res_stage_3_169_2"
  type: "Convolution"
  bottom: "res_stage_3_169_1_top"
  top: "res_stage_3_169_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_169_2"
  type: "BatchNorm"
  bottom: "res_stage_3_169_2"
  top: "res_stage_3_169_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_169_2"  
  type: "Scale"
  bottom: "res_stage_3_169_2"
  top: "res_stage_3_169_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_169_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_169_2_top"
  top: "res_stage_3_169_2_top"
}
layer {
  name: "res_stage_3_169_3"
  type: "Convolution"
  bottom: "res_stage_3_169_2_top"
  top: "res_stage_3_169_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_169_3"
  type: "BatchNorm"
  bottom: "res_stage_3_169_3"
  top: "res_stage_3_169_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_169_3"  
  type: "Scale"
  bottom: "res_stage_3_169_3"
  top: "res_stage_3_169_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_169"
  type: "Eltwise"
  bottom: "res_3_168"
  bottom: "res_stage_3_169_3_top"
  top: "res_3_169"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_169_relu"
  type: "ReLU"
  bottom: "res_3_169"
  top: "res_3_169"
}
layer {
  name: "res_stage_3_170_1"
  type: "Convolution"
  bottom: "res_3_169"
  top: "res_stage_3_170_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_170_1"
  type: "BatchNorm"
  bottom: "res_stage_3_170_1"
  top: "res_stage_3_170_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_170_1"  
  type: "Scale"
  bottom: "res_stage_3_170_1"
  top: "res_stage_3_170_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_170_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_170_1_top"
  top: "res_stage_3_170_1_top"
}
layer {
  name: "res_stage_3_170_2"
  type: "Convolution"
  bottom: "res_stage_3_170_1_top"
  top: "res_stage_3_170_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_170_2"
  type: "BatchNorm"
  bottom: "res_stage_3_170_2"
  top: "res_stage_3_170_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_170_2"  
  type: "Scale"
  bottom: "res_stage_3_170_2"
  top: "res_stage_3_170_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_170_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_170_2_top"
  top: "res_stage_3_170_2_top"
}
layer {
  name: "res_stage_3_170_3"
  type: "Convolution"
  bottom: "res_stage_3_170_2_top"
  top: "res_stage_3_170_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_170_3"
  type: "BatchNorm"
  bottom: "res_stage_3_170_3"
  top: "res_stage_3_170_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_170_3"  
  type: "Scale"
  bottom: "res_stage_3_170_3"
  top: "res_stage_3_170_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_170"
  type: "Eltwise"
  bottom: "res_3_169"
  bottom: "res_stage_3_170_3_top"
  top: "res_3_170"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_170_relu"
  type: "ReLU"
  bottom: "res_3_170"
  top: "res_3_170"
}
layer {
  name: "res_stage_3_171_1"
  type: "Convolution"
  bottom: "res_3_170"
  top: "res_stage_3_171_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_171_1"
  type: "BatchNorm"
  bottom: "res_stage_3_171_1"
  top: "res_stage_3_171_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_171_1"  
  type: "Scale"
  bottom: "res_stage_3_171_1"
  top: "res_stage_3_171_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_171_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_171_1_top"
  top: "res_stage_3_171_1_top"
}
layer {
  name: "res_stage_3_171_2"
  type: "Convolution"
  bottom: "res_stage_3_171_1_top"
  top: "res_stage_3_171_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_171_2"
  type: "BatchNorm"
  bottom: "res_stage_3_171_2"
  top: "res_stage_3_171_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_171_2"  
  type: "Scale"
  bottom: "res_stage_3_171_2"
  top: "res_stage_3_171_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_171_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_171_2_top"
  top: "res_stage_3_171_2_top"
}
layer {
  name: "res_stage_3_171_3"
  type: "Convolution"
  bottom: "res_stage_3_171_2_top"
  top: "res_stage_3_171_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_171_3"
  type: "BatchNorm"
  bottom: "res_stage_3_171_3"
  top: "res_stage_3_171_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_171_3"  
  type: "Scale"
  bottom: "res_stage_3_171_3"
  top: "res_stage_3_171_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_171"
  type: "Eltwise"
  bottom: "res_3_170"
  bottom: "res_stage_3_171_3_top"
  top: "res_3_171"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_171_relu"
  type: "ReLU"
  bottom: "res_3_171"
  top: "res_3_171"
}
layer {
  name: "res_stage_3_172_1"
  type: "Convolution"
  bottom: "res_3_171"
  top: "res_stage_3_172_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_172_1"
  type: "BatchNorm"
  bottom: "res_stage_3_172_1"
  top: "res_stage_3_172_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_172_1"  
  type: "Scale"
  bottom: "res_stage_3_172_1"
  top: "res_stage_3_172_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_172_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_172_1_top"
  top: "res_stage_3_172_1_top"
}
layer {
  name: "res_stage_3_172_2"
  type: "Convolution"
  bottom: "res_stage_3_172_1_top"
  top: "res_stage_3_172_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_172_2"
  type: "BatchNorm"
  bottom: "res_stage_3_172_2"
  top: "res_stage_3_172_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_172_2"  
  type: "Scale"
  bottom: "res_stage_3_172_2"
  top: "res_stage_3_172_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_172_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_172_2_top"
  top: "res_stage_3_172_2_top"
}
layer {
  name: "res_stage_3_172_3"
  type: "Convolution"
  bottom: "res_stage_3_172_2_top"
  top: "res_stage_3_172_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_172_3"
  type: "BatchNorm"
  bottom: "res_stage_3_172_3"
  top: "res_stage_3_172_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_172_3"  
  type: "Scale"
  bottom: "res_stage_3_172_3"
  top: "res_stage_3_172_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_172"
  type: "Eltwise"
  bottom: "res_3_171"
  bottom: "res_stage_3_172_3_top"
  top: "res_3_172"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_172_relu"
  type: "ReLU"
  bottom: "res_3_172"
  top: "res_3_172"
}
layer {
  name: "res_stage_3_173_1"
  type: "Convolution"
  bottom: "res_3_172"
  top: "res_stage_3_173_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_173_1"
  type: "BatchNorm"
  bottom: "res_stage_3_173_1"
  top: "res_stage_3_173_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_173_1"  
  type: "Scale"
  bottom: "res_stage_3_173_1"
  top: "res_stage_3_173_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_173_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_173_1_top"
  top: "res_stage_3_173_1_top"
}
layer {
  name: "res_stage_3_173_2"
  type: "Convolution"
  bottom: "res_stage_3_173_1_top"
  top: "res_stage_3_173_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_173_2"
  type: "BatchNorm"
  bottom: "res_stage_3_173_2"
  top: "res_stage_3_173_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_173_2"  
  type: "Scale"
  bottom: "res_stage_3_173_2"
  top: "res_stage_3_173_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_173_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_173_2_top"
  top: "res_stage_3_173_2_top"
}
layer {
  name: "res_stage_3_173_3"
  type: "Convolution"
  bottom: "res_stage_3_173_2_top"
  top: "res_stage_3_173_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_173_3"
  type: "BatchNorm"
  bottom: "res_stage_3_173_3"
  top: "res_stage_3_173_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_173_3"  
  type: "Scale"
  bottom: "res_stage_3_173_3"
  top: "res_stage_3_173_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_173"
  type: "Eltwise"
  bottom: "res_3_172"
  bottom: "res_stage_3_173_3_top"
  top: "res_3_173"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_173_relu"
  type: "ReLU"
  bottom: "res_3_173"
  top: "res_3_173"
}
layer {
  name: "res_stage_3_174_1"
  type: "Convolution"
  bottom: "res_3_173"
  top: "res_stage_3_174_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_174_1"
  type: "BatchNorm"
  bottom: "res_stage_3_174_1"
  top: "res_stage_3_174_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_174_1"  
  type: "Scale"
  bottom: "res_stage_3_174_1"
  top: "res_stage_3_174_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_174_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_174_1_top"
  top: "res_stage_3_174_1_top"
}
layer {
  name: "res_stage_3_174_2"
  type: "Convolution"
  bottom: "res_stage_3_174_1_top"
  top: "res_stage_3_174_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_174_2"
  type: "BatchNorm"
  bottom: "res_stage_3_174_2"
  top: "res_stage_3_174_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_174_2"  
  type: "Scale"
  bottom: "res_stage_3_174_2"
  top: "res_stage_3_174_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_174_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_174_2_top"
  top: "res_stage_3_174_2_top"
}
layer {
  name: "res_stage_3_174_3"
  type: "Convolution"
  bottom: "res_stage_3_174_2_top"
  top: "res_stage_3_174_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_174_3"
  type: "BatchNorm"
  bottom: "res_stage_3_174_3"
  top: "res_stage_3_174_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_174_3"  
  type: "Scale"
  bottom: "res_stage_3_174_3"
  top: "res_stage_3_174_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_174"
  type: "Eltwise"
  bottom: "res_3_173"
  bottom: "res_stage_3_174_3_top"
  top: "res_3_174"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_174_relu"
  type: "ReLU"
  bottom: "res_3_174"
  top: "res_3_174"
}
layer {
  name: "res_stage_3_175_1"
  type: "Convolution"
  bottom: "res_3_174"
  top: "res_stage_3_175_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_175_1"
  type: "BatchNorm"
  bottom: "res_stage_3_175_1"
  top: "res_stage_3_175_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_175_1"  
  type: "Scale"
  bottom: "res_stage_3_175_1"
  top: "res_stage_3_175_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_175_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_175_1_top"
  top: "res_stage_3_175_1_top"
}
layer {
  name: "res_stage_3_175_2"
  type: "Convolution"
  bottom: "res_stage_3_175_1_top"
  top: "res_stage_3_175_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_175_2"
  type: "BatchNorm"
  bottom: "res_stage_3_175_2"
  top: "res_stage_3_175_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_175_2"  
  type: "Scale"
  bottom: "res_stage_3_175_2"
  top: "res_stage_3_175_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_175_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_175_2_top"
  top: "res_stage_3_175_2_top"
}
layer {
  name: "res_stage_3_175_3"
  type: "Convolution"
  bottom: "res_stage_3_175_2_top"
  top: "res_stage_3_175_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_175_3"
  type: "BatchNorm"
  bottom: "res_stage_3_175_3"
  top: "res_stage_3_175_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_175_3"  
  type: "Scale"
  bottom: "res_stage_3_175_3"
  top: "res_stage_3_175_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_175"
  type: "Eltwise"
  bottom: "res_3_174"
  bottom: "res_stage_3_175_3_top"
  top: "res_3_175"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_175_relu"
  type: "ReLU"
  bottom: "res_3_175"
  top: "res_3_175"
}
layer {
  name: "res_stage_3_176_1"
  type: "Convolution"
  bottom: "res_3_175"
  top: "res_stage_3_176_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_176_1"
  type: "BatchNorm"
  bottom: "res_stage_3_176_1"
  top: "res_stage_3_176_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_176_1"  
  type: "Scale"
  bottom: "res_stage_3_176_1"
  top: "res_stage_3_176_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_176_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_176_1_top"
  top: "res_stage_3_176_1_top"
}
layer {
  name: "res_stage_3_176_2"
  type: "Convolution"
  bottom: "res_stage_3_176_1_top"
  top: "res_stage_3_176_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_176_2"
  type: "BatchNorm"
  bottom: "res_stage_3_176_2"
  top: "res_stage_3_176_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_176_2"  
  type: "Scale"
  bottom: "res_stage_3_176_2"
  top: "res_stage_3_176_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_176_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_176_2_top"
  top: "res_stage_3_176_2_top"
}
layer {
  name: "res_stage_3_176_3"
  type: "Convolution"
  bottom: "res_stage_3_176_2_top"
  top: "res_stage_3_176_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_176_3"
  type: "BatchNorm"
  bottom: "res_stage_3_176_3"
  top: "res_stage_3_176_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_176_3"  
  type: "Scale"
  bottom: "res_stage_3_176_3"
  top: "res_stage_3_176_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_176"
  type: "Eltwise"
  bottom: "res_3_175"
  bottom: "res_stage_3_176_3_top"
  top: "res_3_176"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_176_relu"
  type: "ReLU"
  bottom: "res_3_176"
  top: "res_3_176"
}
layer {
  name: "res_stage_3_177_1"
  type: "Convolution"
  bottom: "res_3_176"
  top: "res_stage_3_177_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_177_1"
  type: "BatchNorm"
  bottom: "res_stage_3_177_1"
  top: "res_stage_3_177_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_177_1"  
  type: "Scale"
  bottom: "res_stage_3_177_1"
  top: "res_stage_3_177_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_177_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_177_1_top"
  top: "res_stage_3_177_1_top"
}
layer {
  name: "res_stage_3_177_2"
  type: "Convolution"
  bottom: "res_stage_3_177_1_top"
  top: "res_stage_3_177_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_177_2"
  type: "BatchNorm"
  bottom: "res_stage_3_177_2"
  top: "res_stage_3_177_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_177_2"  
  type: "Scale"
  bottom: "res_stage_3_177_2"
  top: "res_stage_3_177_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_177_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_177_2_top"
  top: "res_stage_3_177_2_top"
}
layer {
  name: "res_stage_3_177_3"
  type: "Convolution"
  bottom: "res_stage_3_177_2_top"
  top: "res_stage_3_177_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_177_3"
  type: "BatchNorm"
  bottom: "res_stage_3_177_3"
  top: "res_stage_3_177_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_177_3"  
  type: "Scale"
  bottom: "res_stage_3_177_3"
  top: "res_stage_3_177_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_177"
  type: "Eltwise"
  bottom: "res_3_176"
  bottom: "res_stage_3_177_3_top"
  top: "res_3_177"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_177_relu"
  type: "ReLU"
  bottom: "res_3_177"
  top: "res_3_177"
}
layer {
  name: "res_stage_3_178_1"
  type: "Convolution"
  bottom: "res_3_177"
  top: "res_stage_3_178_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_178_1"
  type: "BatchNorm"
  bottom: "res_stage_3_178_1"
  top: "res_stage_3_178_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_178_1"  
  type: "Scale"
  bottom: "res_stage_3_178_1"
  top: "res_stage_3_178_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_178_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_178_1_top"
  top: "res_stage_3_178_1_top"
}
layer {
  name: "res_stage_3_178_2"
  type: "Convolution"
  bottom: "res_stage_3_178_1_top"
  top: "res_stage_3_178_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_178_2"
  type: "BatchNorm"
  bottom: "res_stage_3_178_2"
  top: "res_stage_3_178_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_178_2"  
  type: "Scale"
  bottom: "res_stage_3_178_2"
  top: "res_stage_3_178_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_178_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_178_2_top"
  top: "res_stage_3_178_2_top"
}
layer {
  name: "res_stage_3_178_3"
  type: "Convolution"
  bottom: "res_stage_3_178_2_top"
  top: "res_stage_3_178_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_178_3"
  type: "BatchNorm"
  bottom: "res_stage_3_178_3"
  top: "res_stage_3_178_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_178_3"  
  type: "Scale"
  bottom: "res_stage_3_178_3"
  top: "res_stage_3_178_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_178"
  type: "Eltwise"
  bottom: "res_3_177"
  bottom: "res_stage_3_178_3_top"
  top: "res_3_178"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_178_relu"
  type: "ReLU"
  bottom: "res_3_178"
  top: "res_3_178"
}
layer {
  name: "res_stage_3_179_1"
  type: "Convolution"
  bottom: "res_3_178"
  top: "res_stage_3_179_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_179_1"
  type: "BatchNorm"
  bottom: "res_stage_3_179_1"
  top: "res_stage_3_179_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_179_1"  
  type: "Scale"
  bottom: "res_stage_3_179_1"
  top: "res_stage_3_179_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_179_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_179_1_top"
  top: "res_stage_3_179_1_top"
}
layer {
  name: "res_stage_3_179_2"
  type: "Convolution"
  bottom: "res_stage_3_179_1_top"
  top: "res_stage_3_179_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_179_2"
  type: "BatchNorm"
  bottom: "res_stage_3_179_2"
  top: "res_stage_3_179_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_179_2"  
  type: "Scale"
  bottom: "res_stage_3_179_2"
  top: "res_stage_3_179_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_179_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_179_2_top"
  top: "res_stage_3_179_2_top"
}
layer {
  name: "res_stage_3_179_3"
  type: "Convolution"
  bottom: "res_stage_3_179_2_top"
  top: "res_stage_3_179_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_179_3"
  type: "BatchNorm"
  bottom: "res_stage_3_179_3"
  top: "res_stage_3_179_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_179_3"  
  type: "Scale"
  bottom: "res_stage_3_179_3"
  top: "res_stage_3_179_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_179"
  type: "Eltwise"
  bottom: "res_3_178"
  bottom: "res_stage_3_179_3_top"
  top: "res_3_179"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_179_relu"
  type: "ReLU"
  bottom: "res_3_179"
  top: "res_3_179"
}
layer {
  name: "res_stage_3_180_1"
  type: "Convolution"
  bottom: "res_3_179"
  top: "res_stage_3_180_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_180_1"
  type: "BatchNorm"
  bottom: "res_stage_3_180_1"
  top: "res_stage_3_180_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_180_1"  
  type: "Scale"
  bottom: "res_stage_3_180_1"
  top: "res_stage_3_180_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_180_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_180_1_top"
  top: "res_stage_3_180_1_top"
}
layer {
  name: "res_stage_3_180_2"
  type: "Convolution"
  bottom: "res_stage_3_180_1_top"
  top: "res_stage_3_180_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_180_2"
  type: "BatchNorm"
  bottom: "res_stage_3_180_2"
  top: "res_stage_3_180_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_180_2"  
  type: "Scale"
  bottom: "res_stage_3_180_2"
  top: "res_stage_3_180_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_180_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_180_2_top"
  top: "res_stage_3_180_2_top"
}
layer {
  name: "res_stage_3_180_3"
  type: "Convolution"
  bottom: "res_stage_3_180_2_top"
  top: "res_stage_3_180_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_180_3"
  type: "BatchNorm"
  bottom: "res_stage_3_180_3"
  top: "res_stage_3_180_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_180_3"  
  type: "Scale"
  bottom: "res_stage_3_180_3"
  top: "res_stage_3_180_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_180"
  type: "Eltwise"
  bottom: "res_3_179"
  bottom: "res_stage_3_180_3_top"
  top: "res_3_180"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_180_relu"
  type: "ReLU"
  bottom: "res_3_180"
  top: "res_3_180"
}
layer {
  name: "res_stage_3_181_1"
  type: "Convolution"
  bottom: "res_3_180"
  top: "res_stage_3_181_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_181_1"
  type: "BatchNorm"
  bottom: "res_stage_3_181_1"
  top: "res_stage_3_181_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_181_1"  
  type: "Scale"
  bottom: "res_stage_3_181_1"
  top: "res_stage_3_181_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_181_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_181_1_top"
  top: "res_stage_3_181_1_top"
}
layer {
  name: "res_stage_3_181_2"
  type: "Convolution"
  bottom: "res_stage_3_181_1_top"
  top: "res_stage_3_181_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_181_2"
  type: "BatchNorm"
  bottom: "res_stage_3_181_2"
  top: "res_stage_3_181_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_181_2"  
  type: "Scale"
  bottom: "res_stage_3_181_2"
  top: "res_stage_3_181_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_181_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_181_2_top"
  top: "res_stage_3_181_2_top"
}
layer {
  name: "res_stage_3_181_3"
  type: "Convolution"
  bottom: "res_stage_3_181_2_top"
  top: "res_stage_3_181_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_181_3"
  type: "BatchNorm"
  bottom: "res_stage_3_181_3"
  top: "res_stage_3_181_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_181_3"  
  type: "Scale"
  bottom: "res_stage_3_181_3"
  top: "res_stage_3_181_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_181"
  type: "Eltwise"
  bottom: "res_3_180"
  bottom: "res_stage_3_181_3_top"
  top: "res_3_181"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_181_relu"
  type: "ReLU"
  bottom: "res_3_181"
  top: "res_3_181"
}
layer {
  name: "res_stage_3_182_1"
  type: "Convolution"
  bottom: "res_3_181"
  top: "res_stage_3_182_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_182_1"
  type: "BatchNorm"
  bottom: "res_stage_3_182_1"
  top: "res_stage_3_182_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_182_1"  
  type: "Scale"
  bottom: "res_stage_3_182_1"
  top: "res_stage_3_182_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_182_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_182_1_top"
  top: "res_stage_3_182_1_top"
}
layer {
  name: "res_stage_3_182_2"
  type: "Convolution"
  bottom: "res_stage_3_182_1_top"
  top: "res_stage_3_182_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_182_2"
  type: "BatchNorm"
  bottom: "res_stage_3_182_2"
  top: "res_stage_3_182_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_182_2"  
  type: "Scale"
  bottom: "res_stage_3_182_2"
  top: "res_stage_3_182_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_182_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_182_2_top"
  top: "res_stage_3_182_2_top"
}
layer {
  name: "res_stage_3_182_3"
  type: "Convolution"
  bottom: "res_stage_3_182_2_top"
  top: "res_stage_3_182_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_182_3"
  type: "BatchNorm"
  bottom: "res_stage_3_182_3"
  top: "res_stage_3_182_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_182_3"  
  type: "Scale"
  bottom: "res_stage_3_182_3"
  top: "res_stage_3_182_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_182"
  type: "Eltwise"
  bottom: "res_3_181"
  bottom: "res_stage_3_182_3_top"
  top: "res_3_182"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_182_relu"
  type: "ReLU"
  bottom: "res_3_182"
  top: "res_3_182"
}
layer {
  name: "res_stage_3_183_1"
  type: "Convolution"
  bottom: "res_3_182"
  top: "res_stage_3_183_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_183_1"
  type: "BatchNorm"
  bottom: "res_stage_3_183_1"
  top: "res_stage_3_183_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_183_1"  
  type: "Scale"
  bottom: "res_stage_3_183_1"
  top: "res_stage_3_183_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_183_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_183_1_top"
  top: "res_stage_3_183_1_top"
}
layer {
  name: "res_stage_3_183_2"
  type: "Convolution"
  bottom: "res_stage_3_183_1_top"
  top: "res_stage_3_183_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_183_2"
  type: "BatchNorm"
  bottom: "res_stage_3_183_2"
  top: "res_stage_3_183_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_183_2"  
  type: "Scale"
  bottom: "res_stage_3_183_2"
  top: "res_stage_3_183_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_183_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_183_2_top"
  top: "res_stage_3_183_2_top"
}
layer {
  name: "res_stage_3_183_3"
  type: "Convolution"
  bottom: "res_stage_3_183_2_top"
  top: "res_stage_3_183_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_183_3"
  type: "BatchNorm"
  bottom: "res_stage_3_183_3"
  top: "res_stage_3_183_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_183_3"  
  type: "Scale"
  bottom: "res_stage_3_183_3"
  top: "res_stage_3_183_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_183"
  type: "Eltwise"
  bottom: "res_3_182"
  bottom: "res_stage_3_183_3_top"
  top: "res_3_183"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_183_relu"
  type: "ReLU"
  bottom: "res_3_183"
  top: "res_3_183"
}
layer {
  name: "res_stage_3_184_1"
  type: "Convolution"
  bottom: "res_3_183"
  top: "res_stage_3_184_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_184_1"
  type: "BatchNorm"
  bottom: "res_stage_3_184_1"
  top: "res_stage_3_184_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_184_1"  
  type: "Scale"
  bottom: "res_stage_3_184_1"
  top: "res_stage_3_184_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_184_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_184_1_top"
  top: "res_stage_3_184_1_top"
}
layer {
  name: "res_stage_3_184_2"
  type: "Convolution"
  bottom: "res_stage_3_184_1_top"
  top: "res_stage_3_184_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_184_2"
  type: "BatchNorm"
  bottom: "res_stage_3_184_2"
  top: "res_stage_3_184_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_184_2"  
  type: "Scale"
  bottom: "res_stage_3_184_2"
  top: "res_stage_3_184_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_184_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_184_2_top"
  top: "res_stage_3_184_2_top"
}
layer {
  name: "res_stage_3_184_3"
  type: "Convolution"
  bottom: "res_stage_3_184_2_top"
  top: "res_stage_3_184_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_184_3"
  type: "BatchNorm"
  bottom: "res_stage_3_184_3"
  top: "res_stage_3_184_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_184_3"  
  type: "Scale"
  bottom: "res_stage_3_184_3"
  top: "res_stage_3_184_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_184"
  type: "Eltwise"
  bottom: "res_3_183"
  bottom: "res_stage_3_184_3_top"
  top: "res_3_184"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_184_relu"
  type: "ReLU"
  bottom: "res_3_184"
  top: "res_3_184"
}
layer {
  name: "res_stage_3_185_1"
  type: "Convolution"
  bottom: "res_3_184"
  top: "res_stage_3_185_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_185_1"
  type: "BatchNorm"
  bottom: "res_stage_3_185_1"
  top: "res_stage_3_185_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_185_1"  
  type: "Scale"
  bottom: "res_stage_3_185_1"
  top: "res_stage_3_185_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_185_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_185_1_top"
  top: "res_stage_3_185_1_top"
}
layer {
  name: "res_stage_3_185_2"
  type: "Convolution"
  bottom: "res_stage_3_185_1_top"
  top: "res_stage_3_185_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_185_2"
  type: "BatchNorm"
  bottom: "res_stage_3_185_2"
  top: "res_stage_3_185_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_185_2"  
  type: "Scale"
  bottom: "res_stage_3_185_2"
  top: "res_stage_3_185_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_185_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_185_2_top"
  top: "res_stage_3_185_2_top"
}
layer {
  name: "res_stage_3_185_3"
  type: "Convolution"
  bottom: "res_stage_3_185_2_top"
  top: "res_stage_3_185_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_185_3"
  type: "BatchNorm"
  bottom: "res_stage_3_185_3"
  top: "res_stage_3_185_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_185_3"  
  type: "Scale"
  bottom: "res_stage_3_185_3"
  top: "res_stage_3_185_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_185"
  type: "Eltwise"
  bottom: "res_3_184"
  bottom: "res_stage_3_185_3_top"
  top: "res_3_185"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_185_relu"
  type: "ReLU"
  bottom: "res_3_185"
  top: "res_3_185"
}
layer {
  name: "res_stage_3_186_1"
  type: "Convolution"
  bottom: "res_3_185"
  top: "res_stage_3_186_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_186_1"
  type: "BatchNorm"
  bottom: "res_stage_3_186_1"
  top: "res_stage_3_186_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_186_1"  
  type: "Scale"
  bottom: "res_stage_3_186_1"
  top: "res_stage_3_186_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_186_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_186_1_top"
  top: "res_stage_3_186_1_top"
}
layer {
  name: "res_stage_3_186_2"
  type: "Convolution"
  bottom: "res_stage_3_186_1_top"
  top: "res_stage_3_186_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_186_2"
  type: "BatchNorm"
  bottom: "res_stage_3_186_2"
  top: "res_stage_3_186_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_186_2"  
  type: "Scale"
  bottom: "res_stage_3_186_2"
  top: "res_stage_3_186_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_186_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_186_2_top"
  top: "res_stage_3_186_2_top"
}
layer {
  name: "res_stage_3_186_3"
  type: "Convolution"
  bottom: "res_stage_3_186_2_top"
  top: "res_stage_3_186_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_186_3"
  type: "BatchNorm"
  bottom: "res_stage_3_186_3"
  top: "res_stage_3_186_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_186_3"  
  type: "Scale"
  bottom: "res_stage_3_186_3"
  top: "res_stage_3_186_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_186"
  type: "Eltwise"
  bottom: "res_3_185"
  bottom: "res_stage_3_186_3_top"
  top: "res_3_186"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_186_relu"
  type: "ReLU"
  bottom: "res_3_186"
  top: "res_3_186"
}
layer {
  name: "res_stage_3_187_1"
  type: "Convolution"
  bottom: "res_3_186"
  top: "res_stage_3_187_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_187_1"
  type: "BatchNorm"
  bottom: "res_stage_3_187_1"
  top: "res_stage_3_187_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_187_1"  
  type: "Scale"
  bottom: "res_stage_3_187_1"
  top: "res_stage_3_187_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_187_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_187_1_top"
  top: "res_stage_3_187_1_top"
}
layer {
  name: "res_stage_3_187_2"
  type: "Convolution"
  bottom: "res_stage_3_187_1_top"
  top: "res_stage_3_187_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_187_2"
  type: "BatchNorm"
  bottom: "res_stage_3_187_2"
  top: "res_stage_3_187_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_187_2"  
  type: "Scale"
  bottom: "res_stage_3_187_2"
  top: "res_stage_3_187_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_187_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_187_2_top"
  top: "res_stage_3_187_2_top"
}
layer {
  name: "res_stage_3_187_3"
  type: "Convolution"
  bottom: "res_stage_3_187_2_top"
  top: "res_stage_3_187_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_187_3"
  type: "BatchNorm"
  bottom: "res_stage_3_187_3"
  top: "res_stage_3_187_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_187_3"  
  type: "Scale"
  bottom: "res_stage_3_187_3"
  top: "res_stage_3_187_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_187"
  type: "Eltwise"
  bottom: "res_3_186"
  bottom: "res_stage_3_187_3_top"
  top: "res_3_187"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_187_relu"
  type: "ReLU"
  bottom: "res_3_187"
  top: "res_3_187"
}
layer {
  name: "res_stage_3_188_1"
  type: "Convolution"
  bottom: "res_3_187"
  top: "res_stage_3_188_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_188_1"
  type: "BatchNorm"
  bottom: "res_stage_3_188_1"
  top: "res_stage_3_188_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_188_1"  
  type: "Scale"
  bottom: "res_stage_3_188_1"
  top: "res_stage_3_188_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_188_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_188_1_top"
  top: "res_stage_3_188_1_top"
}
layer {
  name: "res_stage_3_188_2"
  type: "Convolution"
  bottom: "res_stage_3_188_1_top"
  top: "res_stage_3_188_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_188_2"
  type: "BatchNorm"
  bottom: "res_stage_3_188_2"
  top: "res_stage_3_188_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_188_2"  
  type: "Scale"
  bottom: "res_stage_3_188_2"
  top: "res_stage_3_188_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_188_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_188_2_top"
  top: "res_stage_3_188_2_top"
}
layer {
  name: "res_stage_3_188_3"
  type: "Convolution"
  bottom: "res_stage_3_188_2_top"
  top: "res_stage_3_188_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_188_3"
  type: "BatchNorm"
  bottom: "res_stage_3_188_3"
  top: "res_stage_3_188_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_188_3"  
  type: "Scale"
  bottom: "res_stage_3_188_3"
  top: "res_stage_3_188_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_188"
  type: "Eltwise"
  bottom: "res_3_187"
  bottom: "res_stage_3_188_3_top"
  top: "res_3_188"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_188_relu"
  type: "ReLU"
  bottom: "res_3_188"
  top: "res_3_188"
}
layer {
  name: "res_stage_3_189_1"
  type: "Convolution"
  bottom: "res_3_188"
  top: "res_stage_3_189_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_189_1"
  type: "BatchNorm"
  bottom: "res_stage_3_189_1"
  top: "res_stage_3_189_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_189_1"  
  type: "Scale"
  bottom: "res_stage_3_189_1"
  top: "res_stage_3_189_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_189_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_189_1_top"
  top: "res_stage_3_189_1_top"
}
layer {
  name: "res_stage_3_189_2"
  type: "Convolution"
  bottom: "res_stage_3_189_1_top"
  top: "res_stage_3_189_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_189_2"
  type: "BatchNorm"
  bottom: "res_stage_3_189_2"
  top: "res_stage_3_189_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_189_2"  
  type: "Scale"
  bottom: "res_stage_3_189_2"
  top: "res_stage_3_189_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_189_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_189_2_top"
  top: "res_stage_3_189_2_top"
}
layer {
  name: "res_stage_3_189_3"
  type: "Convolution"
  bottom: "res_stage_3_189_2_top"
  top: "res_stage_3_189_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_189_3"
  type: "BatchNorm"
  bottom: "res_stage_3_189_3"
  top: "res_stage_3_189_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_189_3"  
  type: "Scale"
  bottom: "res_stage_3_189_3"
  top: "res_stage_3_189_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_189"
  type: "Eltwise"
  bottom: "res_3_188"
  bottom: "res_stage_3_189_3_top"
  top: "res_3_189"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_189_relu"
  type: "ReLU"
  bottom: "res_3_189"
  top: "res_3_189"
}
layer {
  name: "res_stage_3_190_1"
  type: "Convolution"
  bottom: "res_3_189"
  top: "res_stage_3_190_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_190_1"
  type: "BatchNorm"
  bottom: "res_stage_3_190_1"
  top: "res_stage_3_190_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_190_1"  
  type: "Scale"
  bottom: "res_stage_3_190_1"
  top: "res_stage_3_190_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_190_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_190_1_top"
  top: "res_stage_3_190_1_top"
}
layer {
  name: "res_stage_3_190_2"
  type: "Convolution"
  bottom: "res_stage_3_190_1_top"
  top: "res_stage_3_190_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_190_2"
  type: "BatchNorm"
  bottom: "res_stage_3_190_2"
  top: "res_stage_3_190_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_190_2"  
  type: "Scale"
  bottom: "res_stage_3_190_2"
  top: "res_stage_3_190_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_190_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_190_2_top"
  top: "res_stage_3_190_2_top"
}
layer {
  name: "res_stage_3_190_3"
  type: "Convolution"
  bottom: "res_stage_3_190_2_top"
  top: "res_stage_3_190_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_190_3"
  type: "BatchNorm"
  bottom: "res_stage_3_190_3"
  top: "res_stage_3_190_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_190_3"  
  type: "Scale"
  bottom: "res_stage_3_190_3"
  top: "res_stage_3_190_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_190"
  type: "Eltwise"
  bottom: "res_3_189"
  bottom: "res_stage_3_190_3_top"
  top: "res_3_190"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_190_relu"
  type: "ReLU"
  bottom: "res_3_190"
  top: "res_3_190"
}
layer {
  name: "res_stage_3_191_1"
  type: "Convolution"
  bottom: "res_3_190"
  top: "res_stage_3_191_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_191_1"
  type: "BatchNorm"
  bottom: "res_stage_3_191_1"
  top: "res_stage_3_191_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_191_1"  
  type: "Scale"
  bottom: "res_stage_3_191_1"
  top: "res_stage_3_191_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_191_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_191_1_top"
  top: "res_stage_3_191_1_top"
}
layer {
  name: "res_stage_3_191_2"
  type: "Convolution"
  bottom: "res_stage_3_191_1_top"
  top: "res_stage_3_191_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_191_2"
  type: "BatchNorm"
  bottom: "res_stage_3_191_2"
  top: "res_stage_3_191_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_191_2"  
  type: "Scale"
  bottom: "res_stage_3_191_2"
  top: "res_stage_3_191_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_191_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_191_2_top"
  top: "res_stage_3_191_2_top"
}
layer {
  name: "res_stage_3_191_3"
  type: "Convolution"
  bottom: "res_stage_3_191_2_top"
  top: "res_stage_3_191_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_191_3"
  type: "BatchNorm"
  bottom: "res_stage_3_191_3"
  top: "res_stage_3_191_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_191_3"  
  type: "Scale"
  bottom: "res_stage_3_191_3"
  top: "res_stage_3_191_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_191"
  type: "Eltwise"
  bottom: "res_3_190"
  bottom: "res_stage_3_191_3_top"
  top: "res_3_191"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_191_relu"
  type: "ReLU"
  bottom: "res_3_191"
  top: "res_3_191"
}
layer {
  name: "res_stage_3_192_1"
  type: "Convolution"
  bottom: "res_3_191"
  top: "res_stage_3_192_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_192_1"
  type: "BatchNorm"
  bottom: "res_stage_3_192_1"
  top: "res_stage_3_192_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_192_1"  
  type: "Scale"
  bottom: "res_stage_3_192_1"
  top: "res_stage_3_192_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_192_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_192_1_top"
  top: "res_stage_3_192_1_top"
}
layer {
  name: "res_stage_3_192_2"
  type: "Convolution"
  bottom: "res_stage_3_192_1_top"
  top: "res_stage_3_192_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_192_2"
  type: "BatchNorm"
  bottom: "res_stage_3_192_2"
  top: "res_stage_3_192_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_192_2"  
  type: "Scale"
  bottom: "res_stage_3_192_2"
  top: "res_stage_3_192_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_192_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_192_2_top"
  top: "res_stage_3_192_2_top"
}
layer {
  name: "res_stage_3_192_3"
  type: "Convolution"
  bottom: "res_stage_3_192_2_top"
  top: "res_stage_3_192_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_192_3"
  type: "BatchNorm"
  bottom: "res_stage_3_192_3"
  top: "res_stage_3_192_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_192_3"  
  type: "Scale"
  bottom: "res_stage_3_192_3"
  top: "res_stage_3_192_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_192"
  type: "Eltwise"
  bottom: "res_3_191"
  bottom: "res_stage_3_192_3_top"
  top: "res_3_192"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_192_relu"
  type: "ReLU"
  bottom: "res_3_192"
  top: "res_3_192"
}
layer {
  name: "res_stage_3_193_1"
  type: "Convolution"
  bottom: "res_3_192"
  top: "res_stage_3_193_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_193_1"
  type: "BatchNorm"
  bottom: "res_stage_3_193_1"
  top: "res_stage_3_193_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_193_1"  
  type: "Scale"
  bottom: "res_stage_3_193_1"
  top: "res_stage_3_193_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_193_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_193_1_top"
  top: "res_stage_3_193_1_top"
}
layer {
  name: "res_stage_3_193_2"
  type: "Convolution"
  bottom: "res_stage_3_193_1_top"
  top: "res_stage_3_193_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_193_2"
  type: "BatchNorm"
  bottom: "res_stage_3_193_2"
  top: "res_stage_3_193_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_193_2"  
  type: "Scale"
  bottom: "res_stage_3_193_2"
  top: "res_stage_3_193_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_193_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_193_2_top"
  top: "res_stage_3_193_2_top"
}
layer {
  name: "res_stage_3_193_3"
  type: "Convolution"
  bottom: "res_stage_3_193_2_top"
  top: "res_stage_3_193_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_193_3"
  type: "BatchNorm"
  bottom: "res_stage_3_193_3"
  top: "res_stage_3_193_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_193_3"  
  type: "Scale"
  bottom: "res_stage_3_193_3"
  top: "res_stage_3_193_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_193"
  type: "Eltwise"
  bottom: "res_3_192"
  bottom: "res_stage_3_193_3_top"
  top: "res_3_193"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_193_relu"
  type: "ReLU"
  bottom: "res_3_193"
  top: "res_3_193"
}
layer {
  name: "res_stage_3_194_1"
  type: "Convolution"
  bottom: "res_3_193"
  top: "res_stage_3_194_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_194_1"
  type: "BatchNorm"
  bottom: "res_stage_3_194_1"
  top: "res_stage_3_194_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_194_1"  
  type: "Scale"
  bottom: "res_stage_3_194_1"
  top: "res_stage_3_194_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_194_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_194_1_top"
  top: "res_stage_3_194_1_top"
}
layer {
  name: "res_stage_3_194_2"
  type: "Convolution"
  bottom: "res_stage_3_194_1_top"
  top: "res_stage_3_194_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_194_2"
  type: "BatchNorm"
  bottom: "res_stage_3_194_2"
  top: "res_stage_3_194_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_194_2"  
  type: "Scale"
  bottom: "res_stage_3_194_2"
  top: "res_stage_3_194_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_194_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_194_2_top"
  top: "res_stage_3_194_2_top"
}
layer {
  name: "res_stage_3_194_3"
  type: "Convolution"
  bottom: "res_stage_3_194_2_top"
  top: "res_stage_3_194_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_194_3"
  type: "BatchNorm"
  bottom: "res_stage_3_194_3"
  top: "res_stage_3_194_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_194_3"  
  type: "Scale"
  bottom: "res_stage_3_194_3"
  top: "res_stage_3_194_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_194"
  type: "Eltwise"
  bottom: "res_3_193"
  bottom: "res_stage_3_194_3_top"
  top: "res_3_194"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_194_relu"
  type: "ReLU"
  bottom: "res_3_194"
  top: "res_3_194"
}
layer {
  name: "res_stage_3_195_1"
  type: "Convolution"
  bottom: "res_3_194"
  top: "res_stage_3_195_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_195_1"
  type: "BatchNorm"
  bottom: "res_stage_3_195_1"
  top: "res_stage_3_195_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_195_1"  
  type: "Scale"
  bottom: "res_stage_3_195_1"
  top: "res_stage_3_195_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_195_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_195_1_top"
  top: "res_stage_3_195_1_top"
}
layer {
  name: "res_stage_3_195_2"
  type: "Convolution"
  bottom: "res_stage_3_195_1_top"
  top: "res_stage_3_195_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_195_2"
  type: "BatchNorm"
  bottom: "res_stage_3_195_2"
  top: "res_stage_3_195_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_195_2"  
  type: "Scale"
  bottom: "res_stage_3_195_2"
  top: "res_stage_3_195_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_195_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_195_2_top"
  top: "res_stage_3_195_2_top"
}
layer {
  name: "res_stage_3_195_3"
  type: "Convolution"
  bottom: "res_stage_3_195_2_top"
  top: "res_stage_3_195_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_195_3"
  type: "BatchNorm"
  bottom: "res_stage_3_195_3"
  top: "res_stage_3_195_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_195_3"  
  type: "Scale"
  bottom: "res_stage_3_195_3"
  top: "res_stage_3_195_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_195"
  type: "Eltwise"
  bottom: "res_3_194"
  bottom: "res_stage_3_195_3_top"
  top: "res_3_195"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_195_relu"
  type: "ReLU"
  bottom: "res_3_195"
  top: "res_3_195"
}
layer {
  name: "res_stage_3_196_1"
  type: "Convolution"
  bottom: "res_3_195"
  top: "res_stage_3_196_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_196_1"
  type: "BatchNorm"
  bottom: "res_stage_3_196_1"
  top: "res_stage_3_196_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_196_1"  
  type: "Scale"
  bottom: "res_stage_3_196_1"
  top: "res_stage_3_196_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_196_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_196_1_top"
  top: "res_stage_3_196_1_top"
}
layer {
  name: "res_stage_3_196_2"
  type: "Convolution"
  bottom: "res_stage_3_196_1_top"
  top: "res_stage_3_196_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_196_2"
  type: "BatchNorm"
  bottom: "res_stage_3_196_2"
  top: "res_stage_3_196_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_196_2"  
  type: "Scale"
  bottom: "res_stage_3_196_2"
  top: "res_stage_3_196_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_196_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_196_2_top"
  top: "res_stage_3_196_2_top"
}
layer {
  name: "res_stage_3_196_3"
  type: "Convolution"
  bottom: "res_stage_3_196_2_top"
  top: "res_stage_3_196_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_196_3"
  type: "BatchNorm"
  bottom: "res_stage_3_196_3"
  top: "res_stage_3_196_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_196_3"  
  type: "Scale"
  bottom: "res_stage_3_196_3"
  top: "res_stage_3_196_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_196"
  type: "Eltwise"
  bottom: "res_3_195"
  bottom: "res_stage_3_196_3_top"
  top: "res_3_196"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_196_relu"
  type: "ReLU"
  bottom: "res_3_196"
  top: "res_3_196"
}
layer {
  name: "res_stage_3_197_1"
  type: "Convolution"
  bottom: "res_3_196"
  top: "res_stage_3_197_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_197_1"
  type: "BatchNorm"
  bottom: "res_stage_3_197_1"
  top: "res_stage_3_197_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_197_1"  
  type: "Scale"
  bottom: "res_stage_3_197_1"
  top: "res_stage_3_197_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_197_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_197_1_top"
  top: "res_stage_3_197_1_top"
}
layer {
  name: "res_stage_3_197_2"
  type: "Convolution"
  bottom: "res_stage_3_197_1_top"
  top: "res_stage_3_197_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_197_2"
  type: "BatchNorm"
  bottom: "res_stage_3_197_2"
  top: "res_stage_3_197_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_197_2"  
  type: "Scale"
  bottom: "res_stage_3_197_2"
  top: "res_stage_3_197_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_197_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_197_2_top"
  top: "res_stage_3_197_2_top"
}
layer {
  name: "res_stage_3_197_3"
  type: "Convolution"
  bottom: "res_stage_3_197_2_top"
  top: "res_stage_3_197_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_197_3"
  type: "BatchNorm"
  bottom: "res_stage_3_197_3"
  top: "res_stage_3_197_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_197_3"  
  type: "Scale"
  bottom: "res_stage_3_197_3"
  top: "res_stage_3_197_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_197"
  type: "Eltwise"
  bottom: "res_3_196"
  bottom: "res_stage_3_197_3_top"
  top: "res_3_197"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_197_relu"
  type: "ReLU"
  bottom: "res_3_197"
  top: "res_3_197"
}
layer {
  name: "res_stage_3_198_1"
  type: "Convolution"
  bottom: "res_3_197"
  top: "res_stage_3_198_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_198_1"
  type: "BatchNorm"
  bottom: "res_stage_3_198_1"
  top: "res_stage_3_198_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_198_1"  
  type: "Scale"
  bottom: "res_stage_3_198_1"
  top: "res_stage_3_198_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_198_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_198_1_top"
  top: "res_stage_3_198_1_top"
}
layer {
  name: "res_stage_3_198_2"
  type: "Convolution"
  bottom: "res_stage_3_198_1_top"
  top: "res_stage_3_198_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_198_2"
  type: "BatchNorm"
  bottom: "res_stage_3_198_2"
  top: "res_stage_3_198_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_198_2"  
  type: "Scale"
  bottom: "res_stage_3_198_2"
  top: "res_stage_3_198_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_198_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_198_2_top"
  top: "res_stage_3_198_2_top"
}
layer {
  name: "res_stage_3_198_3"
  type: "Convolution"
  bottom: "res_stage_3_198_2_top"
  top: "res_stage_3_198_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_198_3"
  type: "BatchNorm"
  bottom: "res_stage_3_198_3"
  top: "res_stage_3_198_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_198_3"  
  type: "Scale"
  bottom: "res_stage_3_198_3"
  top: "res_stage_3_198_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_198"
  type: "Eltwise"
  bottom: "res_3_197"
  bottom: "res_stage_3_198_3_top"
  top: "res_3_198"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_198_relu"
  type: "ReLU"
  bottom: "res_3_198"
  top: "res_3_198"
}
layer {
  name: "res_stage_3_199_1"
  type: "Convolution"
  bottom: "res_3_198"
  top: "res_stage_3_199_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_199_1"
  type: "BatchNorm"
  bottom: "res_stage_3_199_1"
  top: "res_stage_3_199_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_199_1"  
  type: "Scale"
  bottom: "res_stage_3_199_1"
  top: "res_stage_3_199_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_199_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_199_1_top"
  top: "res_stage_3_199_1_top"
}
layer {
  name: "res_stage_3_199_2"
  type: "Convolution"
  bottom: "res_stage_3_199_1_top"
  top: "res_stage_3_199_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_199_2"
  type: "BatchNorm"
  bottom: "res_stage_3_199_2"
  top: "res_stage_3_199_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_199_2"  
  type: "Scale"
  bottom: "res_stage_3_199_2"
  top: "res_stage_3_199_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_199_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_199_2_top"
  top: "res_stage_3_199_2_top"
}
layer {
  name: "res_stage_3_199_3"
  type: "Convolution"
  bottom: "res_stage_3_199_2_top"
  top: "res_stage_3_199_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_199_3"
  type: "BatchNorm"
  bottom: "res_stage_3_199_3"
  top: "res_stage_3_199_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_199_3"  
  type: "Scale"
  bottom: "res_stage_3_199_3"
  top: "res_stage_3_199_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_199"
  type: "Eltwise"
  bottom: "res_3_198"
  bottom: "res_stage_3_199_3_top"
  top: "res_3_199"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_199_relu"
  type: "ReLU"
  bottom: "res_3_199"
  top: "res_3_199"
}
layer {
  name: "res_stage_3_200_1"
  type: "Convolution"
  bottom: "res_3_199"
  top: "res_stage_3_200_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_200_1"
  type: "BatchNorm"
  bottom: "res_stage_3_200_1"
  top: "res_stage_3_200_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_200_1"  
  type: "Scale"
  bottom: "res_stage_3_200_1"
  top: "res_stage_3_200_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_200_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_200_1_top"
  top: "res_stage_3_200_1_top"
}
layer {
  name: "res_stage_3_200_2"
  type: "Convolution"
  bottom: "res_stage_3_200_1_top"
  top: "res_stage_3_200_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_200_2"
  type: "BatchNorm"
  bottom: "res_stage_3_200_2"
  top: "res_stage_3_200_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_200_2"  
  type: "Scale"
  bottom: "res_stage_3_200_2"
  top: "res_stage_3_200_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_200_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_200_2_top"
  top: "res_stage_3_200_2_top"
}
layer {
  name: "res_stage_3_200_3"
  type: "Convolution"
  bottom: "res_stage_3_200_2_top"
  top: "res_stage_3_200_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_200_3"
  type: "BatchNorm"
  bottom: "res_stage_3_200_3"
  top: "res_stage_3_200_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_200_3"  
  type: "Scale"
  bottom: "res_stage_3_200_3"
  top: "res_stage_3_200_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_200"
  type: "Eltwise"
  bottom: "res_3_199"
  bottom: "res_stage_3_200_3_top"
  top: "res_3_200"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_200_relu"
  type: "ReLU"
  bottom: "res_3_200"
  top: "res_3_200"
}
layer {
  name: "res_stage_3_201_1"
  type: "Convolution"
  bottom: "res_3_200"
  top: "res_stage_3_201_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_201_1"
  type: "BatchNorm"
  bottom: "res_stage_3_201_1"
  top: "res_stage_3_201_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_201_1"  
  type: "Scale"
  bottom: "res_stage_3_201_1"
  top: "res_stage_3_201_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_201_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_201_1_top"
  top: "res_stage_3_201_1_top"
}
layer {
  name: "res_stage_3_201_2"
  type: "Convolution"
  bottom: "res_stage_3_201_1_top"
  top: "res_stage_3_201_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_201_2"
  type: "BatchNorm"
  bottom: "res_stage_3_201_2"
  top: "res_stage_3_201_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_201_2"  
  type: "Scale"
  bottom: "res_stage_3_201_2"
  top: "res_stage_3_201_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_201_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_201_2_top"
  top: "res_stage_3_201_2_top"
}
layer {
  name: "res_stage_3_201_3"
  type: "Convolution"
  bottom: "res_stage_3_201_2_top"
  top: "res_stage_3_201_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_201_3"
  type: "BatchNorm"
  bottom: "res_stage_3_201_3"
  top: "res_stage_3_201_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_201_3"  
  type: "Scale"
  bottom: "res_stage_3_201_3"
  top: "res_stage_3_201_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_201"
  type: "Eltwise"
  bottom: "res_3_200"
  bottom: "res_stage_3_201_3_top"
  top: "res_3_201"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_201_relu"
  type: "ReLU"
  bottom: "res_3_201"
  top: "res_3_201"
}
layer {
  name: "res_stage_3_202_1"
  type: "Convolution"
  bottom: "res_3_201"
  top: "res_stage_3_202_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_202_1"
  type: "BatchNorm"
  bottom: "res_stage_3_202_1"
  top: "res_stage_3_202_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_202_1"  
  type: "Scale"
  bottom: "res_stage_3_202_1"
  top: "res_stage_3_202_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_202_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_202_1_top"
  top: "res_stage_3_202_1_top"
}
layer {
  name: "res_stage_3_202_2"
  type: "Convolution"
  bottom: "res_stage_3_202_1_top"
  top: "res_stage_3_202_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_202_2"
  type: "BatchNorm"
  bottom: "res_stage_3_202_2"
  top: "res_stage_3_202_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_202_2"  
  type: "Scale"
  bottom: "res_stage_3_202_2"
  top: "res_stage_3_202_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_202_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_202_2_top"
  top: "res_stage_3_202_2_top"
}
layer {
  name: "res_stage_3_202_3"
  type: "Convolution"
  bottom: "res_stage_3_202_2_top"
  top: "res_stage_3_202_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_202_3"
  type: "BatchNorm"
  bottom: "res_stage_3_202_3"
  top: "res_stage_3_202_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_202_3"  
  type: "Scale"
  bottom: "res_stage_3_202_3"
  top: "res_stage_3_202_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_202"
  type: "Eltwise"
  bottom: "res_3_201"
  bottom: "res_stage_3_202_3_top"
  top: "res_3_202"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_202_relu"
  type: "ReLU"
  bottom: "res_3_202"
  top: "res_3_202"
}
layer {
  name: "res_stage_3_203_1"
  type: "Convolution"
  bottom: "res_3_202"
  top: "res_stage_3_203_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_203_1"
  type: "BatchNorm"
  bottom: "res_stage_3_203_1"
  top: "res_stage_3_203_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_203_1"  
  type: "Scale"
  bottom: "res_stage_3_203_1"
  top: "res_stage_3_203_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_203_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_203_1_top"
  top: "res_stage_3_203_1_top"
}
layer {
  name: "res_stage_3_203_2"
  type: "Convolution"
  bottom: "res_stage_3_203_1_top"
  top: "res_stage_3_203_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_203_2"
  type: "BatchNorm"
  bottom: "res_stage_3_203_2"
  top: "res_stage_3_203_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_203_2"  
  type: "Scale"
  bottom: "res_stage_3_203_2"
  top: "res_stage_3_203_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_203_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_203_2_top"
  top: "res_stage_3_203_2_top"
}
layer {
  name: "res_stage_3_203_3"
  type: "Convolution"
  bottom: "res_stage_3_203_2_top"
  top: "res_stage_3_203_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_203_3"
  type: "BatchNorm"
  bottom: "res_stage_3_203_3"
  top: "res_stage_3_203_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_203_3"  
  type: "Scale"
  bottom: "res_stage_3_203_3"
  top: "res_stage_3_203_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_203"
  type: "Eltwise"
  bottom: "res_3_202"
  bottom: "res_stage_3_203_3_top"
  top: "res_3_203"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_203_relu"
  type: "ReLU"
  bottom: "res_3_203"
  top: "res_3_203"
}
layer {
  name: "res_stage_3_204_1"
  type: "Convolution"
  bottom: "res_3_203"
  top: "res_stage_3_204_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_204_1"
  type: "BatchNorm"
  bottom: "res_stage_3_204_1"
  top: "res_stage_3_204_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_204_1"  
  type: "Scale"
  bottom: "res_stage_3_204_1"
  top: "res_stage_3_204_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_204_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_204_1_top"
  top: "res_stage_3_204_1_top"
}
layer {
  name: "res_stage_3_204_2"
  type: "Convolution"
  bottom: "res_stage_3_204_1_top"
  top: "res_stage_3_204_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_204_2"
  type: "BatchNorm"
  bottom: "res_stage_3_204_2"
  top: "res_stage_3_204_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_204_2"  
  type: "Scale"
  bottom: "res_stage_3_204_2"
  top: "res_stage_3_204_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_204_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_204_2_top"
  top: "res_stage_3_204_2_top"
}
layer {
  name: "res_stage_3_204_3"
  type: "Convolution"
  bottom: "res_stage_3_204_2_top"
  top: "res_stage_3_204_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_204_3"
  type: "BatchNorm"
  bottom: "res_stage_3_204_3"
  top: "res_stage_3_204_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_204_3"  
  type: "Scale"
  bottom: "res_stage_3_204_3"
  top: "res_stage_3_204_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_204"
  type: "Eltwise"
  bottom: "res_3_203"
  bottom: "res_stage_3_204_3_top"
  top: "res_3_204"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_204_relu"
  type: "ReLU"
  bottom: "res_3_204"
  top: "res_3_204"
}
layer {
  name: "res_stage_3_205_1"
  type: "Convolution"
  bottom: "res_3_204"
  top: "res_stage_3_205_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_205_1"
  type: "BatchNorm"
  bottom: "res_stage_3_205_1"
  top: "res_stage_3_205_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_205_1"  
  type: "Scale"
  bottom: "res_stage_3_205_1"
  top: "res_stage_3_205_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_205_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_205_1_top"
  top: "res_stage_3_205_1_top"
}
layer {
  name: "res_stage_3_205_2"
  type: "Convolution"
  bottom: "res_stage_3_205_1_top"
  top: "res_stage_3_205_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_205_2"
  type: "BatchNorm"
  bottom: "res_stage_3_205_2"
  top: "res_stage_3_205_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_205_2"  
  type: "Scale"
  bottom: "res_stage_3_205_2"
  top: "res_stage_3_205_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_205_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_205_2_top"
  top: "res_stage_3_205_2_top"
}
layer {
  name: "res_stage_3_205_3"
  type: "Convolution"
  bottom: "res_stage_3_205_2_top"
  top: "res_stage_3_205_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_205_3"
  type: "BatchNorm"
  bottom: "res_stage_3_205_3"
  top: "res_stage_3_205_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_205_3"  
  type: "Scale"
  bottom: "res_stage_3_205_3"
  top: "res_stage_3_205_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_205"
  type: "Eltwise"
  bottom: "res_3_204"
  bottom: "res_stage_3_205_3_top"
  top: "res_3_205"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_205_relu"
  type: "ReLU"
  bottom: "res_3_205"
  top: "res_3_205"
}
layer {
  name: "res_stage_3_206_1"
  type: "Convolution"
  bottom: "res_3_205"
  top: "res_stage_3_206_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_206_1"
  type: "BatchNorm"
  bottom: "res_stage_3_206_1"
  top: "res_stage_3_206_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_206_1"  
  type: "Scale"
  bottom: "res_stage_3_206_1"
  top: "res_stage_3_206_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_206_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_206_1_top"
  top: "res_stage_3_206_1_top"
}
layer {
  name: "res_stage_3_206_2"
  type: "Convolution"
  bottom: "res_stage_3_206_1_top"
  top: "res_stage_3_206_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_206_2"
  type: "BatchNorm"
  bottom: "res_stage_3_206_2"
  top: "res_stage_3_206_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_206_2"  
  type: "Scale"
  bottom: "res_stage_3_206_2"
  top: "res_stage_3_206_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_206_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_206_2_top"
  top: "res_stage_3_206_2_top"
}
layer {
  name: "res_stage_3_206_3"
  type: "Convolution"
  bottom: "res_stage_3_206_2_top"
  top: "res_stage_3_206_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_206_3"
  type: "BatchNorm"
  bottom: "res_stage_3_206_3"
  top: "res_stage_3_206_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_206_3"  
  type: "Scale"
  bottom: "res_stage_3_206_3"
  top: "res_stage_3_206_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_206"
  type: "Eltwise"
  bottom: "res_3_205"
  bottom: "res_stage_3_206_3_top"
  top: "res_3_206"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_206_relu"
  type: "ReLU"
  bottom: "res_3_206"
  top: "res_3_206"
}
layer {
  name: "res_stage_3_207_1"
  type: "Convolution"
  bottom: "res_3_206"
  top: "res_stage_3_207_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_207_1"
  type: "BatchNorm"
  bottom: "res_stage_3_207_1"
  top: "res_stage_3_207_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_207_1"  
  type: "Scale"
  bottom: "res_stage_3_207_1"
  top: "res_stage_3_207_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_207_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_207_1_top"
  top: "res_stage_3_207_1_top"
}
layer {
  name: "res_stage_3_207_2"
  type: "Convolution"
  bottom: "res_stage_3_207_1_top"
  top: "res_stage_3_207_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_207_2"
  type: "BatchNorm"
  bottom: "res_stage_3_207_2"
  top: "res_stage_3_207_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_207_2"  
  type: "Scale"
  bottom: "res_stage_3_207_2"
  top: "res_stage_3_207_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_207_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_207_2_top"
  top: "res_stage_3_207_2_top"
}
layer {
  name: "res_stage_3_207_3"
  type: "Convolution"
  bottom: "res_stage_3_207_2_top"
  top: "res_stage_3_207_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_207_3"
  type: "BatchNorm"
  bottom: "res_stage_3_207_3"
  top: "res_stage_3_207_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_207_3"  
  type: "Scale"
  bottom: "res_stage_3_207_3"
  top: "res_stage_3_207_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_207"
  type: "Eltwise"
  bottom: "res_3_206"
  bottom: "res_stage_3_207_3_top"
  top: "res_3_207"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_207_relu"
  type: "ReLU"
  bottom: "res_3_207"
  top: "res_3_207"
}
layer {
  name: "res_stage_3_208_1"
  type: "Convolution"
  bottom: "res_3_207"
  top: "res_stage_3_208_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_208_1"
  type: "BatchNorm"
  bottom: "res_stage_3_208_1"
  top: "res_stage_3_208_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_208_1"  
  type: "Scale"
  bottom: "res_stage_3_208_1"
  top: "res_stage_3_208_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_208_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_208_1_top"
  top: "res_stage_3_208_1_top"
}
layer {
  name: "res_stage_3_208_2"
  type: "Convolution"
  bottom: "res_stage_3_208_1_top"
  top: "res_stage_3_208_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_208_2"
  type: "BatchNorm"
  bottom: "res_stage_3_208_2"
  top: "res_stage_3_208_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_208_2"  
  type: "Scale"
  bottom: "res_stage_3_208_2"
  top: "res_stage_3_208_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_208_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_208_2_top"
  top: "res_stage_3_208_2_top"
}
layer {
  name: "res_stage_3_208_3"
  type: "Convolution"
  bottom: "res_stage_3_208_2_top"
  top: "res_stage_3_208_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_208_3"
  type: "BatchNorm"
  bottom: "res_stage_3_208_3"
  top: "res_stage_3_208_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_208_3"  
  type: "Scale"
  bottom: "res_stage_3_208_3"
  top: "res_stage_3_208_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_208"
  type: "Eltwise"
  bottom: "res_3_207"
  bottom: "res_stage_3_208_3_top"
  top: "res_3_208"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_208_relu"
  type: "ReLU"
  bottom: "res_3_208"
  top: "res_3_208"
}
layer {
  name: "res_stage_3_209_1"
  type: "Convolution"
  bottom: "res_3_208"
  top: "res_stage_3_209_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_209_1"
  type: "BatchNorm"
  bottom: "res_stage_3_209_1"
  top: "res_stage_3_209_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_209_1"  
  type: "Scale"
  bottom: "res_stage_3_209_1"
  top: "res_stage_3_209_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_209_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_209_1_top"
  top: "res_stage_3_209_1_top"
}
layer {
  name: "res_stage_3_209_2"
  type: "Convolution"
  bottom: "res_stage_3_209_1_top"
  top: "res_stage_3_209_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_209_2"
  type: "BatchNorm"
  bottom: "res_stage_3_209_2"
  top: "res_stage_3_209_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_209_2"  
  type: "Scale"
  bottom: "res_stage_3_209_2"
  top: "res_stage_3_209_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_209_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_209_2_top"
  top: "res_stage_3_209_2_top"
}
layer {
  name: "res_stage_3_209_3"
  type: "Convolution"
  bottom: "res_stage_3_209_2_top"
  top: "res_stage_3_209_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_209_3"
  type: "BatchNorm"
  bottom: "res_stage_3_209_3"
  top: "res_stage_3_209_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_209_3"  
  type: "Scale"
  bottom: "res_stage_3_209_3"
  top: "res_stage_3_209_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_209"
  type: "Eltwise"
  bottom: "res_3_208"
  bottom: "res_stage_3_209_3_top"
  top: "res_3_209"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_209_relu"
  type: "ReLU"
  bottom: "res_3_209"
  top: "res_3_209"
}
layer {
  name: "res_stage_3_210_1"
  type: "Convolution"
  bottom: "res_3_209"
  top: "res_stage_3_210_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_210_1"
  type: "BatchNorm"
  bottom: "res_stage_3_210_1"
  top: "res_stage_3_210_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_210_1"  
  type: "Scale"
  bottom: "res_stage_3_210_1"
  top: "res_stage_3_210_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_210_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_210_1_top"
  top: "res_stage_3_210_1_top"
}
layer {
  name: "res_stage_3_210_2"
  type: "Convolution"
  bottom: "res_stage_3_210_1_top"
  top: "res_stage_3_210_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_210_2"
  type: "BatchNorm"
  bottom: "res_stage_3_210_2"
  top: "res_stage_3_210_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_210_2"  
  type: "Scale"
  bottom: "res_stage_3_210_2"
  top: "res_stage_3_210_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_210_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_210_2_top"
  top: "res_stage_3_210_2_top"
}
layer {
  name: "res_stage_3_210_3"
  type: "Convolution"
  bottom: "res_stage_3_210_2_top"
  top: "res_stage_3_210_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_210_3"
  type: "BatchNorm"
  bottom: "res_stage_3_210_3"
  top: "res_stage_3_210_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_210_3"  
  type: "Scale"
  bottom: "res_stage_3_210_3"
  top: "res_stage_3_210_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_210"
  type: "Eltwise"
  bottom: "res_3_209"
  bottom: "res_stage_3_210_3_top"
  top: "res_3_210"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_210_relu"
  type: "ReLU"
  bottom: "res_3_210"
  top: "res_3_210"
}
layer {
  name: "res_stage_3_211_1"
  type: "Convolution"
  bottom: "res_3_210"
  top: "res_stage_3_211_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_211_1"
  type: "BatchNorm"
  bottom: "res_stage_3_211_1"
  top: "res_stage_3_211_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_211_1"  
  type: "Scale"
  bottom: "res_stage_3_211_1"
  top: "res_stage_3_211_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_211_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_211_1_top"
  top: "res_stage_3_211_1_top"
}
layer {
  name: "res_stage_3_211_2"
  type: "Convolution"
  bottom: "res_stage_3_211_1_top"
  top: "res_stage_3_211_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_211_2"
  type: "BatchNorm"
  bottom: "res_stage_3_211_2"
  top: "res_stage_3_211_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_211_2"  
  type: "Scale"
  bottom: "res_stage_3_211_2"
  top: "res_stage_3_211_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_211_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_211_2_top"
  top: "res_stage_3_211_2_top"
}
layer {
  name: "res_stage_3_211_3"
  type: "Convolution"
  bottom: "res_stage_3_211_2_top"
  top: "res_stage_3_211_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_211_3"
  type: "BatchNorm"
  bottom: "res_stage_3_211_3"
  top: "res_stage_3_211_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_211_3"  
  type: "Scale"
  bottom: "res_stage_3_211_3"
  top: "res_stage_3_211_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_211"
  type: "Eltwise"
  bottom: "res_3_210"
  bottom: "res_stage_3_211_3_top"
  top: "res_3_211"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_211_relu"
  type: "ReLU"
  bottom: "res_3_211"
  top: "res_3_211"
}
layer {
  name: "res_stage_3_212_1"
  type: "Convolution"
  bottom: "res_3_211"
  top: "res_stage_3_212_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_212_1"
  type: "BatchNorm"
  bottom: "res_stage_3_212_1"
  top: "res_stage_3_212_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_212_1"  
  type: "Scale"
  bottom: "res_stage_3_212_1"
  top: "res_stage_3_212_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_212_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_212_1_top"
  top: "res_stage_3_212_1_top"
}
layer {
  name: "res_stage_3_212_2"
  type: "Convolution"
  bottom: "res_stage_3_212_1_top"
  top: "res_stage_3_212_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_212_2"
  type: "BatchNorm"
  bottom: "res_stage_3_212_2"
  top: "res_stage_3_212_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_212_2"  
  type: "Scale"
  bottom: "res_stage_3_212_2"
  top: "res_stage_3_212_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_212_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_212_2_top"
  top: "res_stage_3_212_2_top"
}
layer {
  name: "res_stage_3_212_3"
  type: "Convolution"
  bottom: "res_stage_3_212_2_top"
  top: "res_stage_3_212_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_212_3"
  type: "BatchNorm"
  bottom: "res_stage_3_212_3"
  top: "res_stage_3_212_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_212_3"  
  type: "Scale"
  bottom: "res_stage_3_212_3"
  top: "res_stage_3_212_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_212"
  type: "Eltwise"
  bottom: "res_3_211"
  bottom: "res_stage_3_212_3_top"
  top: "res_3_212"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_212_relu"
  type: "ReLU"
  bottom: "res_3_212"
  top: "res_3_212"
}
layer {
  name: "res_stage_3_213_1"
  type: "Convolution"
  bottom: "res_3_212"
  top: "res_stage_3_213_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_213_1"
  type: "BatchNorm"
  bottom: "res_stage_3_213_1"
  top: "res_stage_3_213_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_213_1"  
  type: "Scale"
  bottom: "res_stage_3_213_1"
  top: "res_stage_3_213_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_213_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_213_1_top"
  top: "res_stage_3_213_1_top"
}
layer {
  name: "res_stage_3_213_2"
  type: "Convolution"
  bottom: "res_stage_3_213_1_top"
  top: "res_stage_3_213_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_213_2"
  type: "BatchNorm"
  bottom: "res_stage_3_213_2"
  top: "res_stage_3_213_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_213_2"  
  type: "Scale"
  bottom: "res_stage_3_213_2"
  top: "res_stage_3_213_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_213_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_213_2_top"
  top: "res_stage_3_213_2_top"
}
layer {
  name: "res_stage_3_213_3"
  type: "Convolution"
  bottom: "res_stage_3_213_2_top"
  top: "res_stage_3_213_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_213_3"
  type: "BatchNorm"
  bottom: "res_stage_3_213_3"
  top: "res_stage_3_213_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_213_3"  
  type: "Scale"
  bottom: "res_stage_3_213_3"
  top: "res_stage_3_213_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_213"
  type: "Eltwise"
  bottom: "res_3_212"
  bottom: "res_stage_3_213_3_top"
  top: "res_3_213"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_213_relu"
  type: "ReLU"
  bottom: "res_3_213"
  top: "res_3_213"
}
layer {
  name: "res_stage_3_214_1"
  type: "Convolution"
  bottom: "res_3_213"
  top: "res_stage_3_214_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_214_1"
  type: "BatchNorm"
  bottom: "res_stage_3_214_1"
  top: "res_stage_3_214_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_214_1"  
  type: "Scale"
  bottom: "res_stage_3_214_1"
  top: "res_stage_3_214_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_214_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_214_1_top"
  top: "res_stage_3_214_1_top"
}
layer {
  name: "res_stage_3_214_2"
  type: "Convolution"
  bottom: "res_stage_3_214_1_top"
  top: "res_stage_3_214_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_214_2"
  type: "BatchNorm"
  bottom: "res_stage_3_214_2"
  top: "res_stage_3_214_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_214_2"  
  type: "Scale"
  bottom: "res_stage_3_214_2"
  top: "res_stage_3_214_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_214_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_214_2_top"
  top: "res_stage_3_214_2_top"
}
layer {
  name: "res_stage_3_214_3"
  type: "Convolution"
  bottom: "res_stage_3_214_2_top"
  top: "res_stage_3_214_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_214_3"
  type: "BatchNorm"
  bottom: "res_stage_3_214_3"
  top: "res_stage_3_214_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_214_3"  
  type: "Scale"
  bottom: "res_stage_3_214_3"
  top: "res_stage_3_214_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_214"
  type: "Eltwise"
  bottom: "res_3_213"
  bottom: "res_stage_3_214_3_top"
  top: "res_3_214"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_214_relu"
  type: "ReLU"
  bottom: "res_3_214"
  top: "res_3_214"
}
layer {
  name: "res_stage_3_215_1"
  type: "Convolution"
  bottom: "res_3_214"
  top: "res_stage_3_215_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_215_1"
  type: "BatchNorm"
  bottom: "res_stage_3_215_1"
  top: "res_stage_3_215_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_215_1"  
  type: "Scale"
  bottom: "res_stage_3_215_1"
  top: "res_stage_3_215_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_215_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_215_1_top"
  top: "res_stage_3_215_1_top"
}
layer {
  name: "res_stage_3_215_2"
  type: "Convolution"
  bottom: "res_stage_3_215_1_top"
  top: "res_stage_3_215_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_215_2"
  type: "BatchNorm"
  bottom: "res_stage_3_215_2"
  top: "res_stage_3_215_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_215_2"  
  type: "Scale"
  bottom: "res_stage_3_215_2"
  top: "res_stage_3_215_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_215_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_215_2_top"
  top: "res_stage_3_215_2_top"
}
layer {
  name: "res_stage_3_215_3"
  type: "Convolution"
  bottom: "res_stage_3_215_2_top"
  top: "res_stage_3_215_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_215_3"
  type: "BatchNorm"
  bottom: "res_stage_3_215_3"
  top: "res_stage_3_215_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_215_3"  
  type: "Scale"
  bottom: "res_stage_3_215_3"
  top: "res_stage_3_215_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_215"
  type: "Eltwise"
  bottom: "res_3_214"
  bottom: "res_stage_3_215_3_top"
  top: "res_3_215"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_215_relu"
  type: "ReLU"
  bottom: "res_3_215"
  top: "res_3_215"
}
layer {
  name: "res_stage_3_216_1"
  type: "Convolution"
  bottom: "res_3_215"
  top: "res_stage_3_216_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_216_1"
  type: "BatchNorm"
  bottom: "res_stage_3_216_1"
  top: "res_stage_3_216_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_216_1"  
  type: "Scale"
  bottom: "res_stage_3_216_1"
  top: "res_stage_3_216_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_216_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_216_1_top"
  top: "res_stage_3_216_1_top"
}
layer {
  name: "res_stage_3_216_2"
  type: "Convolution"
  bottom: "res_stage_3_216_1_top"
  top: "res_stage_3_216_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_216_2"
  type: "BatchNorm"
  bottom: "res_stage_3_216_2"
  top: "res_stage_3_216_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_216_2"  
  type: "Scale"
  bottom: "res_stage_3_216_2"
  top: "res_stage_3_216_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_216_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_216_2_top"
  top: "res_stage_3_216_2_top"
}
layer {
  name: "res_stage_3_216_3"
  type: "Convolution"
  bottom: "res_stage_3_216_2_top"
  top: "res_stage_3_216_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_216_3"
  type: "BatchNorm"
  bottom: "res_stage_3_216_3"
  top: "res_stage_3_216_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_216_3"  
  type: "Scale"
  bottom: "res_stage_3_216_3"
  top: "res_stage_3_216_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_216"
  type: "Eltwise"
  bottom: "res_3_215"
  bottom: "res_stage_3_216_3_top"
  top: "res_3_216"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_216_relu"
  type: "ReLU"
  bottom: "res_3_216"
  top: "res_3_216"
}
layer {
  name: "res_stage_3_217_1"
  type: "Convolution"
  bottom: "res_3_216"
  top: "res_stage_3_217_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_217_1"
  type: "BatchNorm"
  bottom: "res_stage_3_217_1"
  top: "res_stage_3_217_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_217_1"  
  type: "Scale"
  bottom: "res_stage_3_217_1"
  top: "res_stage_3_217_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_217_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_217_1_top"
  top: "res_stage_3_217_1_top"
}
layer {
  name: "res_stage_3_217_2"
  type: "Convolution"
  bottom: "res_stage_3_217_1_top"
  top: "res_stage_3_217_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_217_2"
  type: "BatchNorm"
  bottom: "res_stage_3_217_2"
  top: "res_stage_3_217_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_217_2"  
  type: "Scale"
  bottom: "res_stage_3_217_2"
  top: "res_stage_3_217_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_217_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_217_2_top"
  top: "res_stage_3_217_2_top"
}
layer {
  name: "res_stage_3_217_3"
  type: "Convolution"
  bottom: "res_stage_3_217_2_top"
  top: "res_stage_3_217_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_217_3"
  type: "BatchNorm"
  bottom: "res_stage_3_217_3"
  top: "res_stage_3_217_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_217_3"  
  type: "Scale"
  bottom: "res_stage_3_217_3"
  top: "res_stage_3_217_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_217"
  type: "Eltwise"
  bottom: "res_3_216"
  bottom: "res_stage_3_217_3_top"
  top: "res_3_217"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_217_relu"
  type: "ReLU"
  bottom: "res_3_217"
  top: "res_3_217"
}
layer {
  name: "res_stage_3_218_1"
  type: "Convolution"
  bottom: "res_3_217"
  top: "res_stage_3_218_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_218_1"
  type: "BatchNorm"
  bottom: "res_stage_3_218_1"
  top: "res_stage_3_218_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_218_1"  
  type: "Scale"
  bottom: "res_stage_3_218_1"
  top: "res_stage_3_218_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_218_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_218_1_top"
  top: "res_stage_3_218_1_top"
}
layer {
  name: "res_stage_3_218_2"
  type: "Convolution"
  bottom: "res_stage_3_218_1_top"
  top: "res_stage_3_218_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_218_2"
  type: "BatchNorm"
  bottom: "res_stage_3_218_2"
  top: "res_stage_3_218_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_218_2"  
  type: "Scale"
  bottom: "res_stage_3_218_2"
  top: "res_stage_3_218_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_218_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_218_2_top"
  top: "res_stage_3_218_2_top"
}
layer {
  name: "res_stage_3_218_3"
  type: "Convolution"
  bottom: "res_stage_3_218_2_top"
  top: "res_stage_3_218_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_218_3"
  type: "BatchNorm"
  bottom: "res_stage_3_218_3"
  top: "res_stage_3_218_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_218_3"  
  type: "Scale"
  bottom: "res_stage_3_218_3"
  top: "res_stage_3_218_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_218"
  type: "Eltwise"
  bottom: "res_3_217"
  bottom: "res_stage_3_218_3_top"
  top: "res_3_218"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_218_relu"
  type: "ReLU"
  bottom: "res_3_218"
  top: "res_3_218"
}
layer {
  name: "res_stage_3_219_1"
  type: "Convolution"
  bottom: "res_3_218"
  top: "res_stage_3_219_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_219_1"
  type: "BatchNorm"
  bottom: "res_stage_3_219_1"
  top: "res_stage_3_219_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_219_1"  
  type: "Scale"
  bottom: "res_stage_3_219_1"
  top: "res_stage_3_219_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_219_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_219_1_top"
  top: "res_stage_3_219_1_top"
}
layer {
  name: "res_stage_3_219_2"
  type: "Convolution"
  bottom: "res_stage_3_219_1_top"
  top: "res_stage_3_219_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_219_2"
  type: "BatchNorm"
  bottom: "res_stage_3_219_2"
  top: "res_stage_3_219_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_219_2"  
  type: "Scale"
  bottom: "res_stage_3_219_2"
  top: "res_stage_3_219_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_219_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_219_2_top"
  top: "res_stage_3_219_2_top"
}
layer {
  name: "res_stage_3_219_3"
  type: "Convolution"
  bottom: "res_stage_3_219_2_top"
  top: "res_stage_3_219_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_219_3"
  type: "BatchNorm"
  bottom: "res_stage_3_219_3"
  top: "res_stage_3_219_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_219_3"  
  type: "Scale"
  bottom: "res_stage_3_219_3"
  top: "res_stage_3_219_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_219"
  type: "Eltwise"
  bottom: "res_3_218"
  bottom: "res_stage_3_219_3_top"
  top: "res_3_219"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_219_relu"
  type: "ReLU"
  bottom: "res_3_219"
  top: "res_3_219"
}
layer {
  name: "res_stage_3_220_1"
  type: "Convolution"
  bottom: "res_3_219"
  top: "res_stage_3_220_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_220_1"
  type: "BatchNorm"
  bottom: "res_stage_3_220_1"
  top: "res_stage_3_220_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_220_1"  
  type: "Scale"
  bottom: "res_stage_3_220_1"
  top: "res_stage_3_220_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_220_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_220_1_top"
  top: "res_stage_3_220_1_top"
}
layer {
  name: "res_stage_3_220_2"
  type: "Convolution"
  bottom: "res_stage_3_220_1_top"
  top: "res_stage_3_220_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_220_2"
  type: "BatchNorm"
  bottom: "res_stage_3_220_2"
  top: "res_stage_3_220_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_220_2"  
  type: "Scale"
  bottom: "res_stage_3_220_2"
  top: "res_stage_3_220_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_220_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_220_2_top"
  top: "res_stage_3_220_2_top"
}
layer {
  name: "res_stage_3_220_3"
  type: "Convolution"
  bottom: "res_stage_3_220_2_top"
  top: "res_stage_3_220_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_220_3"
  type: "BatchNorm"
  bottom: "res_stage_3_220_3"
  top: "res_stage_3_220_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_220_3"  
  type: "Scale"
  bottom: "res_stage_3_220_3"
  top: "res_stage_3_220_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_220"
  type: "Eltwise"
  bottom: "res_3_219"
  bottom: "res_stage_3_220_3_top"
  top: "res_3_220"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_220_relu"
  type: "ReLU"
  bottom: "res_3_220"
  top: "res_3_220"
}
layer {
  name: "res_stage_3_221_1"
  type: "Convolution"
  bottom: "res_3_220"
  top: "res_stage_3_221_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_221_1"
  type: "BatchNorm"
  bottom: "res_stage_3_221_1"
  top: "res_stage_3_221_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_221_1"  
  type: "Scale"
  bottom: "res_stage_3_221_1"
  top: "res_stage_3_221_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_221_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_221_1_top"
  top: "res_stage_3_221_1_top"
}
layer {
  name: "res_stage_3_221_2"
  type: "Convolution"
  bottom: "res_stage_3_221_1_top"
  top: "res_stage_3_221_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_221_2"
  type: "BatchNorm"
  bottom: "res_stage_3_221_2"
  top: "res_stage_3_221_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_221_2"  
  type: "Scale"
  bottom: "res_stage_3_221_2"
  top: "res_stage_3_221_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_221_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_221_2_top"
  top: "res_stage_3_221_2_top"
}
layer {
  name: "res_stage_3_221_3"
  type: "Convolution"
  bottom: "res_stage_3_221_2_top"
  top: "res_stage_3_221_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_221_3"
  type: "BatchNorm"
  bottom: "res_stage_3_221_3"
  top: "res_stage_3_221_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_221_3"  
  type: "Scale"
  bottom: "res_stage_3_221_3"
  top: "res_stage_3_221_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_221"
  type: "Eltwise"
  bottom: "res_3_220"
  bottom: "res_stage_3_221_3_top"
  top: "res_3_221"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_221_relu"
  type: "ReLU"
  bottom: "res_3_221"
  top: "res_3_221"
}
layer {
  name: "res_stage_3_222_1"
  type: "Convolution"
  bottom: "res_3_221"
  top: "res_stage_3_222_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_222_1"
  type: "BatchNorm"
  bottom: "res_stage_3_222_1"
  top: "res_stage_3_222_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_222_1"  
  type: "Scale"
  bottom: "res_stage_3_222_1"
  top: "res_stage_3_222_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_222_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_222_1_top"
  top: "res_stage_3_222_1_top"
}
layer {
  name: "res_stage_3_222_2"
  type: "Convolution"
  bottom: "res_stage_3_222_1_top"
  top: "res_stage_3_222_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_222_2"
  type: "BatchNorm"
  bottom: "res_stage_3_222_2"
  top: "res_stage_3_222_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_222_2"  
  type: "Scale"
  bottom: "res_stage_3_222_2"
  top: "res_stage_3_222_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_222_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_222_2_top"
  top: "res_stage_3_222_2_top"
}
layer {
  name: "res_stage_3_222_3"
  type: "Convolution"
  bottom: "res_stage_3_222_2_top"
  top: "res_stage_3_222_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_222_3"
  type: "BatchNorm"
  bottom: "res_stage_3_222_3"
  top: "res_stage_3_222_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_222_3"  
  type: "Scale"
  bottom: "res_stage_3_222_3"
  top: "res_stage_3_222_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_222"
  type: "Eltwise"
  bottom: "res_3_221"
  bottom: "res_stage_3_222_3_top"
  top: "res_3_222"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_222_relu"
  type: "ReLU"
  bottom: "res_3_222"
  top: "res_3_222"
}
layer {
  name: "res_stage_3_223_1"
  type: "Convolution"
  bottom: "res_3_222"
  top: "res_stage_3_223_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_223_1"
  type: "BatchNorm"
  bottom: "res_stage_3_223_1"
  top: "res_stage_3_223_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_223_1"  
  type: "Scale"
  bottom: "res_stage_3_223_1"
  top: "res_stage_3_223_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_223_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_223_1_top"
  top: "res_stage_3_223_1_top"
}
layer {
  name: "res_stage_3_223_2"
  type: "Convolution"
  bottom: "res_stage_3_223_1_top"
  top: "res_stage_3_223_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_223_2"
  type: "BatchNorm"
  bottom: "res_stage_3_223_2"
  top: "res_stage_3_223_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_223_2"  
  type: "Scale"
  bottom: "res_stage_3_223_2"
  top: "res_stage_3_223_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_223_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_223_2_top"
  top: "res_stage_3_223_2_top"
}
layer {
  name: "res_stage_3_223_3"
  type: "Convolution"
  bottom: "res_stage_3_223_2_top"
  top: "res_stage_3_223_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_223_3"
  type: "BatchNorm"
  bottom: "res_stage_3_223_3"
  top: "res_stage_3_223_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_223_3"  
  type: "Scale"
  bottom: "res_stage_3_223_3"
  top: "res_stage_3_223_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_223"
  type: "Eltwise"
  bottom: "res_3_222"
  bottom: "res_stage_3_223_3_top"
  top: "res_3_223"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_223_relu"
  type: "ReLU"
  bottom: "res_3_223"
  top: "res_3_223"
}
layer {
  name: "res_stage_3_224_1"
  type: "Convolution"
  bottom: "res_3_223"
  top: "res_stage_3_224_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_224_1"
  type: "BatchNorm"
  bottom: "res_stage_3_224_1"
  top: "res_stage_3_224_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_224_1"  
  type: "Scale"
  bottom: "res_stage_3_224_1"
  top: "res_stage_3_224_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_224_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_224_1_top"
  top: "res_stage_3_224_1_top"
}
layer {
  name: "res_stage_3_224_2"
  type: "Convolution"
  bottom: "res_stage_3_224_1_top"
  top: "res_stage_3_224_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_224_2"
  type: "BatchNorm"
  bottom: "res_stage_3_224_2"
  top: "res_stage_3_224_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_224_2"  
  type: "Scale"
  bottom: "res_stage_3_224_2"
  top: "res_stage_3_224_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_224_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_224_2_top"
  top: "res_stage_3_224_2_top"
}
layer {
  name: "res_stage_3_224_3"
  type: "Convolution"
  bottom: "res_stage_3_224_2_top"
  top: "res_stage_3_224_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_224_3"
  type: "BatchNorm"
  bottom: "res_stage_3_224_3"
  top: "res_stage_3_224_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_224_3"  
  type: "Scale"
  bottom: "res_stage_3_224_3"
  top: "res_stage_3_224_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_224"
  type: "Eltwise"
  bottom: "res_3_223"
  bottom: "res_stage_3_224_3_top"
  top: "res_3_224"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_224_relu"
  type: "ReLU"
  bottom: "res_3_224"
  top: "res_3_224"
}
layer {
  name: "res_stage_3_225_1"
  type: "Convolution"
  bottom: "res_3_224"
  top: "res_stage_3_225_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_225_1"
  type: "BatchNorm"
  bottom: "res_stage_3_225_1"
  top: "res_stage_3_225_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_225_1"  
  type: "Scale"
  bottom: "res_stage_3_225_1"
  top: "res_stage_3_225_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_225_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_225_1_top"
  top: "res_stage_3_225_1_top"
}
layer {
  name: "res_stage_3_225_2"
  type: "Convolution"
  bottom: "res_stage_3_225_1_top"
  top: "res_stage_3_225_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_225_2"
  type: "BatchNorm"
  bottom: "res_stage_3_225_2"
  top: "res_stage_3_225_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_225_2"  
  type: "Scale"
  bottom: "res_stage_3_225_2"
  top: "res_stage_3_225_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_225_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_225_2_top"
  top: "res_stage_3_225_2_top"
}
layer {
  name: "res_stage_3_225_3"
  type: "Convolution"
  bottom: "res_stage_3_225_2_top"
  top: "res_stage_3_225_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_225_3"
  type: "BatchNorm"
  bottom: "res_stage_3_225_3"
  top: "res_stage_3_225_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_225_3"  
  type: "Scale"
  bottom: "res_stage_3_225_3"
  top: "res_stage_3_225_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_225"
  type: "Eltwise"
  bottom: "res_3_224"
  bottom: "res_stage_3_225_3_top"
  top: "res_3_225"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_225_relu"
  type: "ReLU"
  bottom: "res_3_225"
  top: "res_3_225"
}
layer {
  name: "res_stage_3_226_1"
  type: "Convolution"
  bottom: "res_3_225"
  top: "res_stage_3_226_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_226_1"
  type: "BatchNorm"
  bottom: "res_stage_3_226_1"
  top: "res_stage_3_226_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_226_1"  
  type: "Scale"
  bottom: "res_stage_3_226_1"
  top: "res_stage_3_226_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_226_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_226_1_top"
  top: "res_stage_3_226_1_top"
}
layer {
  name: "res_stage_3_226_2"
  type: "Convolution"
  bottom: "res_stage_3_226_1_top"
  top: "res_stage_3_226_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_226_2"
  type: "BatchNorm"
  bottom: "res_stage_3_226_2"
  top: "res_stage_3_226_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_226_2"  
  type: "Scale"
  bottom: "res_stage_3_226_2"
  top: "res_stage_3_226_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_226_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_226_2_top"
  top: "res_stage_3_226_2_top"
}
layer {
  name: "res_stage_3_226_3"
  type: "Convolution"
  bottom: "res_stage_3_226_2_top"
  top: "res_stage_3_226_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_226_3"
  type: "BatchNorm"
  bottom: "res_stage_3_226_3"
  top: "res_stage_3_226_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_226_3"  
  type: "Scale"
  bottom: "res_stage_3_226_3"
  top: "res_stage_3_226_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_226"
  type: "Eltwise"
  bottom: "res_3_225"
  bottom: "res_stage_3_226_3_top"
  top: "res_3_226"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_226_relu"
  type: "ReLU"
  bottom: "res_3_226"
  top: "res_3_226"
}
layer {
  name: "res_stage_3_227_1"
  type: "Convolution"
  bottom: "res_3_226"
  top: "res_stage_3_227_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_227_1"
  type: "BatchNorm"
  bottom: "res_stage_3_227_1"
  top: "res_stage_3_227_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_227_1"  
  type: "Scale"
  bottom: "res_stage_3_227_1"
  top: "res_stage_3_227_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_227_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_227_1_top"
  top: "res_stage_3_227_1_top"
}
layer {
  name: "res_stage_3_227_2"
  type: "Convolution"
  bottom: "res_stage_3_227_1_top"
  top: "res_stage_3_227_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_227_2"
  type: "BatchNorm"
  bottom: "res_stage_3_227_2"
  top: "res_stage_3_227_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_227_2"  
  type: "Scale"
  bottom: "res_stage_3_227_2"
  top: "res_stage_3_227_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_227_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_227_2_top"
  top: "res_stage_3_227_2_top"
}
layer {
  name: "res_stage_3_227_3"
  type: "Convolution"
  bottom: "res_stage_3_227_2_top"
  top: "res_stage_3_227_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_227_3"
  type: "BatchNorm"
  bottom: "res_stage_3_227_3"
  top: "res_stage_3_227_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_227_3"  
  type: "Scale"
  bottom: "res_stage_3_227_3"
  top: "res_stage_3_227_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_227"
  type: "Eltwise"
  bottom: "res_3_226"
  bottom: "res_stage_3_227_3_top"
  top: "res_3_227"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_227_relu"
  type: "ReLU"
  bottom: "res_3_227"
  top: "res_3_227"
}
layer {
  name: "res_stage_3_228_1"
  type: "Convolution"
  bottom: "res_3_227"
  top: "res_stage_3_228_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_228_1"
  type: "BatchNorm"
  bottom: "res_stage_3_228_1"
  top: "res_stage_3_228_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_228_1"  
  type: "Scale"
  bottom: "res_stage_3_228_1"
  top: "res_stage_3_228_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_228_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_228_1_top"
  top: "res_stage_3_228_1_top"
}
layer {
  name: "res_stage_3_228_2"
  type: "Convolution"
  bottom: "res_stage_3_228_1_top"
  top: "res_stage_3_228_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_228_2"
  type: "BatchNorm"
  bottom: "res_stage_3_228_2"
  top: "res_stage_3_228_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_228_2"  
  type: "Scale"
  bottom: "res_stage_3_228_2"
  top: "res_stage_3_228_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_228_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_228_2_top"
  top: "res_stage_3_228_2_top"
}
layer {
  name: "res_stage_3_228_3"
  type: "Convolution"
  bottom: "res_stage_3_228_2_top"
  top: "res_stage_3_228_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_228_3"
  type: "BatchNorm"
  bottom: "res_stage_3_228_3"
  top: "res_stage_3_228_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_228_3"  
  type: "Scale"
  bottom: "res_stage_3_228_3"
  top: "res_stage_3_228_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_228"
  type: "Eltwise"
  bottom: "res_3_227"
  bottom: "res_stage_3_228_3_top"
  top: "res_3_228"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_228_relu"
  type: "ReLU"
  bottom: "res_3_228"
  top: "res_3_228"
}
layer {
  name: "res_stage_3_229_1"
  type: "Convolution"
  bottom: "res_3_228"
  top: "res_stage_3_229_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_229_1"
  type: "BatchNorm"
  bottom: "res_stage_3_229_1"
  top: "res_stage_3_229_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_229_1"  
  type: "Scale"
  bottom: "res_stage_3_229_1"
  top: "res_stage_3_229_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_229_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_229_1_top"
  top: "res_stage_3_229_1_top"
}
layer {
  name: "res_stage_3_229_2"
  type: "Convolution"
  bottom: "res_stage_3_229_1_top"
  top: "res_stage_3_229_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_229_2"
  type: "BatchNorm"
  bottom: "res_stage_3_229_2"
  top: "res_stage_3_229_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_229_2"  
  type: "Scale"
  bottom: "res_stage_3_229_2"
  top: "res_stage_3_229_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_229_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_229_2_top"
  top: "res_stage_3_229_2_top"
}
layer {
  name: "res_stage_3_229_3"
  type: "Convolution"
  bottom: "res_stage_3_229_2_top"
  top: "res_stage_3_229_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_229_3"
  type: "BatchNorm"
  bottom: "res_stage_3_229_3"
  top: "res_stage_3_229_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_229_3"  
  type: "Scale"
  bottom: "res_stage_3_229_3"
  top: "res_stage_3_229_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_229"
  type: "Eltwise"
  bottom: "res_3_228"
  bottom: "res_stage_3_229_3_top"
  top: "res_3_229"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_229_relu"
  type: "ReLU"
  bottom: "res_3_229"
  top: "res_3_229"
}
layer {
  name: "res_stage_3_230_1"
  type: "Convolution"
  bottom: "res_3_229"
  top: "res_stage_3_230_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_230_1"
  type: "BatchNorm"
  bottom: "res_stage_3_230_1"
  top: "res_stage_3_230_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_230_1"  
  type: "Scale"
  bottom: "res_stage_3_230_1"
  top: "res_stage_3_230_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_230_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_230_1_top"
  top: "res_stage_3_230_1_top"
}
layer {
  name: "res_stage_3_230_2"
  type: "Convolution"
  bottom: "res_stage_3_230_1_top"
  top: "res_stage_3_230_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_230_2"
  type: "BatchNorm"
  bottom: "res_stage_3_230_2"
  top: "res_stage_3_230_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_230_2"  
  type: "Scale"
  bottom: "res_stage_3_230_2"
  top: "res_stage_3_230_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_230_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_230_2_top"
  top: "res_stage_3_230_2_top"
}
layer {
  name: "res_stage_3_230_3"
  type: "Convolution"
  bottom: "res_stage_3_230_2_top"
  top: "res_stage_3_230_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_230_3"
  type: "BatchNorm"
  bottom: "res_stage_3_230_3"
  top: "res_stage_3_230_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_230_3"  
  type: "Scale"
  bottom: "res_stage_3_230_3"
  top: "res_stage_3_230_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_230"
  type: "Eltwise"
  bottom: "res_3_229"
  bottom: "res_stage_3_230_3_top"
  top: "res_3_230"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_230_relu"
  type: "ReLU"
  bottom: "res_3_230"
  top: "res_3_230"
}
layer {
  name: "res_stage_3_231_1"
  type: "Convolution"
  bottom: "res_3_230"
  top: "res_stage_3_231_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_231_1"
  type: "BatchNorm"
  bottom: "res_stage_3_231_1"
  top: "res_stage_3_231_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_231_1"  
  type: "Scale"
  bottom: "res_stage_3_231_1"
  top: "res_stage_3_231_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_231_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_231_1_top"
  top: "res_stage_3_231_1_top"
}
layer {
  name: "res_stage_3_231_2"
  type: "Convolution"
  bottom: "res_stage_3_231_1_top"
  top: "res_stage_3_231_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_231_2"
  type: "BatchNorm"
  bottom: "res_stage_3_231_2"
  top: "res_stage_3_231_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_231_2"  
  type: "Scale"
  bottom: "res_stage_3_231_2"
  top: "res_stage_3_231_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_231_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_231_2_top"
  top: "res_stage_3_231_2_top"
}
layer {
  name: "res_stage_3_231_3"
  type: "Convolution"
  bottom: "res_stage_3_231_2_top"
  top: "res_stage_3_231_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_231_3"
  type: "BatchNorm"
  bottom: "res_stage_3_231_3"
  top: "res_stage_3_231_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_231_3"  
  type: "Scale"
  bottom: "res_stage_3_231_3"
  top: "res_stage_3_231_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_231"
  type: "Eltwise"
  bottom: "res_3_230"
  bottom: "res_stage_3_231_3_top"
  top: "res_3_231"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_231_relu"
  type: "ReLU"
  bottom: "res_3_231"
  top: "res_3_231"
}
layer {
  name: "res_stage_3_232_1"
  type: "Convolution"
  bottom: "res_3_231"
  top: "res_stage_3_232_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_232_1"
  type: "BatchNorm"
  bottom: "res_stage_3_232_1"
  top: "res_stage_3_232_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_232_1"  
  type: "Scale"
  bottom: "res_stage_3_232_1"
  top: "res_stage_3_232_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_232_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_232_1_top"
  top: "res_stage_3_232_1_top"
}
layer {
  name: "res_stage_3_232_2"
  type: "Convolution"
  bottom: "res_stage_3_232_1_top"
  top: "res_stage_3_232_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_232_2"
  type: "BatchNorm"
  bottom: "res_stage_3_232_2"
  top: "res_stage_3_232_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_232_2"  
  type: "Scale"
  bottom: "res_stage_3_232_2"
  top: "res_stage_3_232_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_232_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_232_2_top"
  top: "res_stage_3_232_2_top"
}
layer {
  name: "res_stage_3_232_3"
  type: "Convolution"
  bottom: "res_stage_3_232_2_top"
  top: "res_stage_3_232_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_232_3"
  type: "BatchNorm"
  bottom: "res_stage_3_232_3"
  top: "res_stage_3_232_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_232_3"  
  type: "Scale"
  bottom: "res_stage_3_232_3"
  top: "res_stage_3_232_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_232"
  type: "Eltwise"
  bottom: "res_3_231"
  bottom: "res_stage_3_232_3_top"
  top: "res_3_232"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_232_relu"
  type: "ReLU"
  bottom: "res_3_232"
  top: "res_3_232"
}
layer {
  name: "res_stage_3_233_1"
  type: "Convolution"
  bottom: "res_3_232"
  top: "res_stage_3_233_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_233_1"
  type: "BatchNorm"
  bottom: "res_stage_3_233_1"
  top: "res_stage_3_233_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_233_1"  
  type: "Scale"
  bottom: "res_stage_3_233_1"
  top: "res_stage_3_233_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_233_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_233_1_top"
  top: "res_stage_3_233_1_top"
}
layer {
  name: "res_stage_3_233_2"
  type: "Convolution"
  bottom: "res_stage_3_233_1_top"
  top: "res_stage_3_233_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_233_2"
  type: "BatchNorm"
  bottom: "res_stage_3_233_2"
  top: "res_stage_3_233_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_233_2"  
  type: "Scale"
  bottom: "res_stage_3_233_2"
  top: "res_stage_3_233_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_233_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_233_2_top"
  top: "res_stage_3_233_2_top"
}
layer {
  name: "res_stage_3_233_3"
  type: "Convolution"
  bottom: "res_stage_3_233_2_top"
  top: "res_stage_3_233_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_233_3"
  type: "BatchNorm"
  bottom: "res_stage_3_233_3"
  top: "res_stage_3_233_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_233_3"  
  type: "Scale"
  bottom: "res_stage_3_233_3"
  top: "res_stage_3_233_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_233"
  type: "Eltwise"
  bottom: "res_3_232"
  bottom: "res_stage_3_233_3_top"
  top: "res_3_233"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_233_relu"
  type: "ReLU"
  bottom: "res_3_233"
  top: "res_3_233"
}
layer {
  name: "res_stage_3_234_1"
  type: "Convolution"
  bottom: "res_3_233"
  top: "res_stage_3_234_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_234_1"
  type: "BatchNorm"
  bottom: "res_stage_3_234_1"
  top: "res_stage_3_234_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_234_1"  
  type: "Scale"
  bottom: "res_stage_3_234_1"
  top: "res_stage_3_234_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_234_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_234_1_top"
  top: "res_stage_3_234_1_top"
}
layer {
  name: "res_stage_3_234_2"
  type: "Convolution"
  bottom: "res_stage_3_234_1_top"
  top: "res_stage_3_234_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_234_2"
  type: "BatchNorm"
  bottom: "res_stage_3_234_2"
  top: "res_stage_3_234_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_234_2"  
  type: "Scale"
  bottom: "res_stage_3_234_2"
  top: "res_stage_3_234_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_234_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_234_2_top"
  top: "res_stage_3_234_2_top"
}
layer {
  name: "res_stage_3_234_3"
  type: "Convolution"
  bottom: "res_stage_3_234_2_top"
  top: "res_stage_3_234_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_234_3"
  type: "BatchNorm"
  bottom: "res_stage_3_234_3"
  top: "res_stage_3_234_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_234_3"  
  type: "Scale"
  bottom: "res_stage_3_234_3"
  top: "res_stage_3_234_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_234"
  type: "Eltwise"
  bottom: "res_3_233"
  bottom: "res_stage_3_234_3_top"
  top: "res_3_234"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_234_relu"
  type: "ReLU"
  bottom: "res_3_234"
  top: "res_3_234"
}
layer {
  name: "res_stage_3_235_1"
  type: "Convolution"
  bottom: "res_3_234"
  top: "res_stage_3_235_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_235_1"
  type: "BatchNorm"
  bottom: "res_stage_3_235_1"
  top: "res_stage_3_235_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_235_1"  
  type: "Scale"
  bottom: "res_stage_3_235_1"
  top: "res_stage_3_235_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_235_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_235_1_top"
  top: "res_stage_3_235_1_top"
}
layer {
  name: "res_stage_3_235_2"
  type: "Convolution"
  bottom: "res_stage_3_235_1_top"
  top: "res_stage_3_235_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_235_2"
  type: "BatchNorm"
  bottom: "res_stage_3_235_2"
  top: "res_stage_3_235_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_235_2"  
  type: "Scale"
  bottom: "res_stage_3_235_2"
  top: "res_stage_3_235_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_235_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_235_2_top"
  top: "res_stage_3_235_2_top"
}
layer {
  name: "res_stage_3_235_3"
  type: "Convolution"
  bottom: "res_stage_3_235_2_top"
  top: "res_stage_3_235_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_235_3"
  type: "BatchNorm"
  bottom: "res_stage_3_235_3"
  top: "res_stage_3_235_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_235_3"  
  type: "Scale"
  bottom: "res_stage_3_235_3"
  top: "res_stage_3_235_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_235"
  type: "Eltwise"
  bottom: "res_3_234"
  bottom: "res_stage_3_235_3_top"
  top: "res_3_235"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_235_relu"
  type: "ReLU"
  bottom: "res_3_235"
  top: "res_3_235"
}
layer {
  name: "res_stage_3_236_1"
  type: "Convolution"
  bottom: "res_3_235"
  top: "res_stage_3_236_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_236_1"
  type: "BatchNorm"
  bottom: "res_stage_3_236_1"
  top: "res_stage_3_236_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_236_1"  
  type: "Scale"
  bottom: "res_stage_3_236_1"
  top: "res_stage_3_236_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_236_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_236_1_top"
  top: "res_stage_3_236_1_top"
}
layer {
  name: "res_stage_3_236_2"
  type: "Convolution"
  bottom: "res_stage_3_236_1_top"
  top: "res_stage_3_236_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_236_2"
  type: "BatchNorm"
  bottom: "res_stage_3_236_2"
  top: "res_stage_3_236_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_236_2"  
  type: "Scale"
  bottom: "res_stage_3_236_2"
  top: "res_stage_3_236_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_236_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_236_2_top"
  top: "res_stage_3_236_2_top"
}
layer {
  name: "res_stage_3_236_3"
  type: "Convolution"
  bottom: "res_stage_3_236_2_top"
  top: "res_stage_3_236_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_236_3"
  type: "BatchNorm"
  bottom: "res_stage_3_236_3"
  top: "res_stage_3_236_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_236_3"  
  type: "Scale"
  bottom: "res_stage_3_236_3"
  top: "res_stage_3_236_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_236"
  type: "Eltwise"
  bottom: "res_3_235"
  bottom: "res_stage_3_236_3_top"
  top: "res_3_236"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_236_relu"
  type: "ReLU"
  bottom: "res_3_236"
  top: "res_3_236"
}
layer {
  name: "res_stage_3_237_1"
  type: "Convolution"
  bottom: "res_3_236"
  top: "res_stage_3_237_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_237_1"
  type: "BatchNorm"
  bottom: "res_stage_3_237_1"
  top: "res_stage_3_237_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_237_1"  
  type: "Scale"
  bottom: "res_stage_3_237_1"
  top: "res_stage_3_237_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_237_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_237_1_top"
  top: "res_stage_3_237_1_top"
}
layer {
  name: "res_stage_3_237_2"
  type: "Convolution"
  bottom: "res_stage_3_237_1_top"
  top: "res_stage_3_237_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_237_2"
  type: "BatchNorm"
  bottom: "res_stage_3_237_2"
  top: "res_stage_3_237_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_237_2"  
  type: "Scale"
  bottom: "res_stage_3_237_2"
  top: "res_stage_3_237_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_237_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_237_2_top"
  top: "res_stage_3_237_2_top"
}
layer {
  name: "res_stage_3_237_3"
  type: "Convolution"
  bottom: "res_stage_3_237_2_top"
  top: "res_stage_3_237_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_237_3"
  type: "BatchNorm"
  bottom: "res_stage_3_237_3"
  top: "res_stage_3_237_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_237_3"  
  type: "Scale"
  bottom: "res_stage_3_237_3"
  top: "res_stage_3_237_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_237"
  type: "Eltwise"
  bottom: "res_3_236"
  bottom: "res_stage_3_237_3_top"
  top: "res_3_237"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_237_relu"
  type: "ReLU"
  bottom: "res_3_237"
  top: "res_3_237"
}
layer {
  name: "res_stage_3_238_1"
  type: "Convolution"
  bottom: "res_3_237"
  top: "res_stage_3_238_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_238_1"
  type: "BatchNorm"
  bottom: "res_stage_3_238_1"
  top: "res_stage_3_238_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_238_1"  
  type: "Scale"
  bottom: "res_stage_3_238_1"
  top: "res_stage_3_238_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_238_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_238_1_top"
  top: "res_stage_3_238_1_top"
}
layer {
  name: "res_stage_3_238_2"
  type: "Convolution"
  bottom: "res_stage_3_238_1_top"
  top: "res_stage_3_238_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_238_2"
  type: "BatchNorm"
  bottom: "res_stage_3_238_2"
  top: "res_stage_3_238_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_238_2"  
  type: "Scale"
  bottom: "res_stage_3_238_2"
  top: "res_stage_3_238_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_238_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_238_2_top"
  top: "res_stage_3_238_2_top"
}
layer {
  name: "res_stage_3_238_3"
  type: "Convolution"
  bottom: "res_stage_3_238_2_top"
  top: "res_stage_3_238_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_238_3"
  type: "BatchNorm"
  bottom: "res_stage_3_238_3"
  top: "res_stage_3_238_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_238_3"  
  type: "Scale"
  bottom: "res_stage_3_238_3"
  top: "res_stage_3_238_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_238"
  type: "Eltwise"
  bottom: "res_3_237"
  bottom: "res_stage_3_238_3_top"
  top: "res_3_238"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_238_relu"
  type: "ReLU"
  bottom: "res_3_238"
  top: "res_3_238"
}
layer {
  name: "res_stage_3_239_1"
  type: "Convolution"
  bottom: "res_3_238"
  top: "res_stage_3_239_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_239_1"
  type: "BatchNorm"
  bottom: "res_stage_3_239_1"
  top: "res_stage_3_239_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_239_1"  
  type: "Scale"
  bottom: "res_stage_3_239_1"
  top: "res_stage_3_239_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_239_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_239_1_top"
  top: "res_stage_3_239_1_top"
}
layer {
  name: "res_stage_3_239_2"
  type: "Convolution"
  bottom: "res_stage_3_239_1_top"
  top: "res_stage_3_239_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_239_2"
  type: "BatchNorm"
  bottom: "res_stage_3_239_2"
  top: "res_stage_3_239_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_239_2"  
  type: "Scale"
  bottom: "res_stage_3_239_2"
  top: "res_stage_3_239_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_239_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_239_2_top"
  top: "res_stage_3_239_2_top"
}
layer {
  name: "res_stage_3_239_3"
  type: "Convolution"
  bottom: "res_stage_3_239_2_top"
  top: "res_stage_3_239_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_239_3"
  type: "BatchNorm"
  bottom: "res_stage_3_239_3"
  top: "res_stage_3_239_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_239_3"  
  type: "Scale"
  bottom: "res_stage_3_239_3"
  top: "res_stage_3_239_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_239"
  type: "Eltwise"
  bottom: "res_3_238"
  bottom: "res_stage_3_239_3_top"
  top: "res_3_239"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_239_relu"
  type: "ReLU"
  bottom: "res_3_239"
  top: "res_3_239"
}
layer {
  name: "res_stage_3_240_1"
  type: "Convolution"
  bottom: "res_3_239"
  top: "res_stage_3_240_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_240_1"
  type: "BatchNorm"
  bottom: "res_stage_3_240_1"
  top: "res_stage_3_240_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_240_1"  
  type: "Scale"
  bottom: "res_stage_3_240_1"
  top: "res_stage_3_240_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_240_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_240_1_top"
  top: "res_stage_3_240_1_top"
}
layer {
  name: "res_stage_3_240_2"
  type: "Convolution"
  bottom: "res_stage_3_240_1_top"
  top: "res_stage_3_240_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_240_2"
  type: "BatchNorm"
  bottom: "res_stage_3_240_2"
  top: "res_stage_3_240_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_240_2"  
  type: "Scale"
  bottom: "res_stage_3_240_2"
  top: "res_stage_3_240_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_240_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_240_2_top"
  top: "res_stage_3_240_2_top"
}
layer {
  name: "res_stage_3_240_3"
  type: "Convolution"
  bottom: "res_stage_3_240_2_top"
  top: "res_stage_3_240_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_240_3"
  type: "BatchNorm"
  bottom: "res_stage_3_240_3"
  top: "res_stage_3_240_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_240_3"  
  type: "Scale"
  bottom: "res_stage_3_240_3"
  top: "res_stage_3_240_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_240"
  type: "Eltwise"
  bottom: "res_3_239"
  bottom: "res_stage_3_240_3_top"
  top: "res_3_240"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_240_relu"
  type: "ReLU"
  bottom: "res_3_240"
  top: "res_3_240"
}
layer {
  name: "res_stage_3_241_1"
  type: "Convolution"
  bottom: "res_3_240"
  top: "res_stage_3_241_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_241_1"
  type: "BatchNorm"
  bottom: "res_stage_3_241_1"
  top: "res_stage_3_241_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_241_1"  
  type: "Scale"
  bottom: "res_stage_3_241_1"
  top: "res_stage_3_241_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_241_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_241_1_top"
  top: "res_stage_3_241_1_top"
}
layer {
  name: "res_stage_3_241_2"
  type: "Convolution"
  bottom: "res_stage_3_241_1_top"
  top: "res_stage_3_241_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_241_2"
  type: "BatchNorm"
  bottom: "res_stage_3_241_2"
  top: "res_stage_3_241_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_241_2"  
  type: "Scale"
  bottom: "res_stage_3_241_2"
  top: "res_stage_3_241_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_241_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_241_2_top"
  top: "res_stage_3_241_2_top"
}
layer {
  name: "res_stage_3_241_3"
  type: "Convolution"
  bottom: "res_stage_3_241_2_top"
  top: "res_stage_3_241_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_241_3"
  type: "BatchNorm"
  bottom: "res_stage_3_241_3"
  top: "res_stage_3_241_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_241_3"  
  type: "Scale"
  bottom: "res_stage_3_241_3"
  top: "res_stage_3_241_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_241"
  type: "Eltwise"
  bottom: "res_3_240"
  bottom: "res_stage_3_241_3_top"
  top: "res_3_241"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_241_relu"
  type: "ReLU"
  bottom: "res_3_241"
  top: "res_3_241"
}
layer {
  name: "res_stage_3_242_1"
  type: "Convolution"
  bottom: "res_3_241"
  top: "res_stage_3_242_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_242_1"
  type: "BatchNorm"
  bottom: "res_stage_3_242_1"
  top: "res_stage_3_242_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_242_1"  
  type: "Scale"
  bottom: "res_stage_3_242_1"
  top: "res_stage_3_242_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_242_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_242_1_top"
  top: "res_stage_3_242_1_top"
}
layer {
  name: "res_stage_3_242_2"
  type: "Convolution"
  bottom: "res_stage_3_242_1_top"
  top: "res_stage_3_242_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_242_2"
  type: "BatchNorm"
  bottom: "res_stage_3_242_2"
  top: "res_stage_3_242_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_242_2"  
  type: "Scale"
  bottom: "res_stage_3_242_2"
  top: "res_stage_3_242_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_242_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_242_2_top"
  top: "res_stage_3_242_2_top"
}
layer {
  name: "res_stage_3_242_3"
  type: "Convolution"
  bottom: "res_stage_3_242_2_top"
  top: "res_stage_3_242_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_242_3"
  type: "BatchNorm"
  bottom: "res_stage_3_242_3"
  top: "res_stage_3_242_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_242_3"  
  type: "Scale"
  bottom: "res_stage_3_242_3"
  top: "res_stage_3_242_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_242"
  type: "Eltwise"
  bottom: "res_3_241"
  bottom: "res_stage_3_242_3_top"
  top: "res_3_242"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_242_relu"
  type: "ReLU"
  bottom: "res_3_242"
  top: "res_3_242"
}
layer {
  name: "res_stage_3_243_1"
  type: "Convolution"
  bottom: "res_3_242"
  top: "res_stage_3_243_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_243_1"
  type: "BatchNorm"
  bottom: "res_stage_3_243_1"
  top: "res_stage_3_243_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_243_1"  
  type: "Scale"
  bottom: "res_stage_3_243_1"
  top: "res_stage_3_243_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_243_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_243_1_top"
  top: "res_stage_3_243_1_top"
}
layer {
  name: "res_stage_3_243_2"
  type: "Convolution"
  bottom: "res_stage_3_243_1_top"
  top: "res_stage_3_243_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_243_2"
  type: "BatchNorm"
  bottom: "res_stage_3_243_2"
  top: "res_stage_3_243_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_243_2"  
  type: "Scale"
  bottom: "res_stage_3_243_2"
  top: "res_stage_3_243_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_243_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_243_2_top"
  top: "res_stage_3_243_2_top"
}
layer {
  name: "res_stage_3_243_3"
  type: "Convolution"
  bottom: "res_stage_3_243_2_top"
  top: "res_stage_3_243_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_243_3"
  type: "BatchNorm"
  bottom: "res_stage_3_243_3"
  top: "res_stage_3_243_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_243_3"  
  type: "Scale"
  bottom: "res_stage_3_243_3"
  top: "res_stage_3_243_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_243"
  type: "Eltwise"
  bottom: "res_3_242"
  bottom: "res_stage_3_243_3_top"
  top: "res_3_243"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_243_relu"
  type: "ReLU"
  bottom: "res_3_243"
  top: "res_3_243"
}
layer {
  name: "res_stage_3_244_1"
  type: "Convolution"
  bottom: "res_3_243"
  top: "res_stage_3_244_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_244_1"
  type: "BatchNorm"
  bottom: "res_stage_3_244_1"
  top: "res_stage_3_244_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_244_1"  
  type: "Scale"
  bottom: "res_stage_3_244_1"
  top: "res_stage_3_244_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_244_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_244_1_top"
  top: "res_stage_3_244_1_top"
}
layer {
  name: "res_stage_3_244_2"
  type: "Convolution"
  bottom: "res_stage_3_244_1_top"
  top: "res_stage_3_244_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_244_2"
  type: "BatchNorm"
  bottom: "res_stage_3_244_2"
  top: "res_stage_3_244_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_244_2"  
  type: "Scale"
  bottom: "res_stage_3_244_2"
  top: "res_stage_3_244_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_244_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_244_2_top"
  top: "res_stage_3_244_2_top"
}
layer {
  name: "res_stage_3_244_3"
  type: "Convolution"
  bottom: "res_stage_3_244_2_top"
  top: "res_stage_3_244_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_244_3"
  type: "BatchNorm"
  bottom: "res_stage_3_244_3"
  top: "res_stage_3_244_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_244_3"  
  type: "Scale"
  bottom: "res_stage_3_244_3"
  top: "res_stage_3_244_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_244"
  type: "Eltwise"
  bottom: "res_3_243"
  bottom: "res_stage_3_244_3_top"
  top: "res_3_244"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_244_relu"
  type: "ReLU"
  bottom: "res_3_244"
  top: "res_3_244"
}
layer {
  name: "res_stage_3_245_1"
  type: "Convolution"
  bottom: "res_3_244"
  top: "res_stage_3_245_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_245_1"
  type: "BatchNorm"
  bottom: "res_stage_3_245_1"
  top: "res_stage_3_245_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_245_1"  
  type: "Scale"
  bottom: "res_stage_3_245_1"
  top: "res_stage_3_245_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_245_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_245_1_top"
  top: "res_stage_3_245_1_top"
}
layer {
  name: "res_stage_3_245_2"
  type: "Convolution"
  bottom: "res_stage_3_245_1_top"
  top: "res_stage_3_245_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_245_2"
  type: "BatchNorm"
  bottom: "res_stage_3_245_2"
  top: "res_stage_3_245_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_245_2"  
  type: "Scale"
  bottom: "res_stage_3_245_2"
  top: "res_stage_3_245_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_245_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_245_2_top"
  top: "res_stage_3_245_2_top"
}
layer {
  name: "res_stage_3_245_3"
  type: "Convolution"
  bottom: "res_stage_3_245_2_top"
  top: "res_stage_3_245_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_245_3"
  type: "BatchNorm"
  bottom: "res_stage_3_245_3"
  top: "res_stage_3_245_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_245_3"  
  type: "Scale"
  bottom: "res_stage_3_245_3"
  top: "res_stage_3_245_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_245"
  type: "Eltwise"
  bottom: "res_3_244"
  bottom: "res_stage_3_245_3_top"
  top: "res_3_245"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_245_relu"
  type: "ReLU"
  bottom: "res_3_245"
  top: "res_3_245"
}
layer {
  name: "res_stage_3_246_1"
  type: "Convolution"
  bottom: "res_3_245"
  top: "res_stage_3_246_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_246_1"
  type: "BatchNorm"
  bottom: "res_stage_3_246_1"
  top: "res_stage_3_246_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_246_1"  
  type: "Scale"
  bottom: "res_stage_3_246_1"
  top: "res_stage_3_246_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_246_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_246_1_top"
  top: "res_stage_3_246_1_top"
}
layer {
  name: "res_stage_3_246_2"
  type: "Convolution"
  bottom: "res_stage_3_246_1_top"
  top: "res_stage_3_246_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_246_2"
  type: "BatchNorm"
  bottom: "res_stage_3_246_2"
  top: "res_stage_3_246_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_246_2"  
  type: "Scale"
  bottom: "res_stage_3_246_2"
  top: "res_stage_3_246_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_246_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_246_2_top"
  top: "res_stage_3_246_2_top"
}
layer {
  name: "res_stage_3_246_3"
  type: "Convolution"
  bottom: "res_stage_3_246_2_top"
  top: "res_stage_3_246_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_246_3"
  type: "BatchNorm"
  bottom: "res_stage_3_246_3"
  top: "res_stage_3_246_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_246_3"  
  type: "Scale"
  bottom: "res_stage_3_246_3"
  top: "res_stage_3_246_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_246"
  type: "Eltwise"
  bottom: "res_3_245"
  bottom: "res_stage_3_246_3_top"
  top: "res_3_246"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_246_relu"
  type: "ReLU"
  bottom: "res_3_246"
  top: "res_3_246"
}
layer {
  name: "res_stage_3_247_1"
  type: "Convolution"
  bottom: "res_3_246"
  top: "res_stage_3_247_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_247_1"
  type: "BatchNorm"
  bottom: "res_stage_3_247_1"
  top: "res_stage_3_247_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_247_1"  
  type: "Scale"
  bottom: "res_stage_3_247_1"
  top: "res_stage_3_247_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_247_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_247_1_top"
  top: "res_stage_3_247_1_top"
}
layer {
  name: "res_stage_3_247_2"
  type: "Convolution"
  bottom: "res_stage_3_247_1_top"
  top: "res_stage_3_247_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_247_2"
  type: "BatchNorm"
  bottom: "res_stage_3_247_2"
  top: "res_stage_3_247_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_247_2"  
  type: "Scale"
  bottom: "res_stage_3_247_2"
  top: "res_stage_3_247_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_247_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_247_2_top"
  top: "res_stage_3_247_2_top"
}
layer {
  name: "res_stage_3_247_3"
  type: "Convolution"
  bottom: "res_stage_3_247_2_top"
  top: "res_stage_3_247_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_247_3"
  type: "BatchNorm"
  bottom: "res_stage_3_247_3"
  top: "res_stage_3_247_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_247_3"  
  type: "Scale"
  bottom: "res_stage_3_247_3"
  top: "res_stage_3_247_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_247"
  type: "Eltwise"
  bottom: "res_3_246"
  bottom: "res_stage_3_247_3_top"
  top: "res_3_247"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_247_relu"
  type: "ReLU"
  bottom: "res_3_247"
  top: "res_3_247"
}
layer {
  name: "res_stage_3_248_1"
  type: "Convolution"
  bottom: "res_3_247"
  top: "res_stage_3_248_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_248_1"
  type: "BatchNorm"
  bottom: "res_stage_3_248_1"
  top: "res_stage_3_248_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_248_1"  
  type: "Scale"
  bottom: "res_stage_3_248_1"
  top: "res_stage_3_248_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_248_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_248_1_top"
  top: "res_stage_3_248_1_top"
}
layer {
  name: "res_stage_3_248_2"
  type: "Convolution"
  bottom: "res_stage_3_248_1_top"
  top: "res_stage_3_248_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_248_2"
  type: "BatchNorm"
  bottom: "res_stage_3_248_2"
  top: "res_stage_3_248_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_248_2"  
  type: "Scale"
  bottom: "res_stage_3_248_2"
  top: "res_stage_3_248_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_248_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_248_2_top"
  top: "res_stage_3_248_2_top"
}
layer {
  name: "res_stage_3_248_3"
  type: "Convolution"
  bottom: "res_stage_3_248_2_top"
  top: "res_stage_3_248_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_248_3"
  type: "BatchNorm"
  bottom: "res_stage_3_248_3"
  top: "res_stage_3_248_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_248_3"  
  type: "Scale"
  bottom: "res_stage_3_248_3"
  top: "res_stage_3_248_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_248"
  type: "Eltwise"
  bottom: "res_3_247"
  bottom: "res_stage_3_248_3_top"
  top: "res_3_248"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_248_relu"
  type: "ReLU"
  bottom: "res_3_248"
  top: "res_3_248"
}
layer {
  name: "res_stage_3_249_1"
  type: "Convolution"
  bottom: "res_3_248"
  top: "res_stage_3_249_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_249_1"
  type: "BatchNorm"
  bottom: "res_stage_3_249_1"
  top: "res_stage_3_249_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_249_1"  
  type: "Scale"
  bottom: "res_stage_3_249_1"
  top: "res_stage_3_249_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_249_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_249_1_top"
  top: "res_stage_3_249_1_top"
}
layer {
  name: "res_stage_3_249_2"
  type: "Convolution"
  bottom: "res_stage_3_249_1_top"
  top: "res_stage_3_249_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_249_2"
  type: "BatchNorm"
  bottom: "res_stage_3_249_2"
  top: "res_stage_3_249_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_249_2"  
  type: "Scale"
  bottom: "res_stage_3_249_2"
  top: "res_stage_3_249_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_249_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_249_2_top"
  top: "res_stage_3_249_2_top"
}
layer {
  name: "res_stage_3_249_3"
  type: "Convolution"
  bottom: "res_stage_3_249_2_top"
  top: "res_stage_3_249_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_249_3"
  type: "BatchNorm"
  bottom: "res_stage_3_249_3"
  top: "res_stage_3_249_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_249_3"  
  type: "Scale"
  bottom: "res_stage_3_249_3"
  top: "res_stage_3_249_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_249"
  type: "Eltwise"
  bottom: "res_3_248"
  bottom: "res_stage_3_249_3_top"
  top: "res_3_249"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_249_relu"
  type: "ReLU"
  bottom: "res_3_249"
  top: "res_3_249"
}
layer {
  name: "res_stage_3_250_1"
  type: "Convolution"
  bottom: "res_3_249"
  top: "res_stage_3_250_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_250_1"
  type: "BatchNorm"
  bottom: "res_stage_3_250_1"
  top: "res_stage_3_250_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_250_1"  
  type: "Scale"
  bottom: "res_stage_3_250_1"
  top: "res_stage_3_250_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_250_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_250_1_top"
  top: "res_stage_3_250_1_top"
}
layer {
  name: "res_stage_3_250_2"
  type: "Convolution"
  bottom: "res_stage_3_250_1_top"
  top: "res_stage_3_250_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_250_2"
  type: "BatchNorm"
  bottom: "res_stage_3_250_2"
  top: "res_stage_3_250_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_250_2"  
  type: "Scale"
  bottom: "res_stage_3_250_2"
  top: "res_stage_3_250_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_250_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_250_2_top"
  top: "res_stage_3_250_2_top"
}
layer {
  name: "res_stage_3_250_3"
  type: "Convolution"
  bottom: "res_stage_3_250_2_top"
  top: "res_stage_3_250_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_250_3"
  type: "BatchNorm"
  bottom: "res_stage_3_250_3"
  top: "res_stage_3_250_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_250_3"  
  type: "Scale"
  bottom: "res_stage_3_250_3"
  top: "res_stage_3_250_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_250"
  type: "Eltwise"
  bottom: "res_3_249"
  bottom: "res_stage_3_250_3_top"
  top: "res_3_250"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_250_relu"
  type: "ReLU"
  bottom: "res_3_250"
  top: "res_3_250"
}
layer {
  name: "res_stage_3_251_1"
  type: "Convolution"
  bottom: "res_3_250"
  top: "res_stage_3_251_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_251_1"
  type: "BatchNorm"
  bottom: "res_stage_3_251_1"
  top: "res_stage_3_251_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_251_1"  
  type: "Scale"
  bottom: "res_stage_3_251_1"
  top: "res_stage_3_251_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_251_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_251_1_top"
  top: "res_stage_3_251_1_top"
}
layer {
  name: "res_stage_3_251_2"
  type: "Convolution"
  bottom: "res_stage_3_251_1_top"
  top: "res_stage_3_251_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_251_2"
  type: "BatchNorm"
  bottom: "res_stage_3_251_2"
  top: "res_stage_3_251_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_251_2"  
  type: "Scale"
  bottom: "res_stage_3_251_2"
  top: "res_stage_3_251_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_251_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_251_2_top"
  top: "res_stage_3_251_2_top"
}
layer {
  name: "res_stage_3_251_3"
  type: "Convolution"
  bottom: "res_stage_3_251_2_top"
  top: "res_stage_3_251_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_251_3"
  type: "BatchNorm"
  bottom: "res_stage_3_251_3"
  top: "res_stage_3_251_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_251_3"  
  type: "Scale"
  bottom: "res_stage_3_251_3"
  top: "res_stage_3_251_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_251"
  type: "Eltwise"
  bottom: "res_3_250"
  bottom: "res_stage_3_251_3_top"
  top: "res_3_251"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_251_relu"
  type: "ReLU"
  bottom: "res_3_251"
  top: "res_3_251"
}
layer {
  name: "res_stage_3_252_1"
  type: "Convolution"
  bottom: "res_3_251"
  top: "res_stage_3_252_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_252_1"
  type: "BatchNorm"
  bottom: "res_stage_3_252_1"
  top: "res_stage_3_252_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_252_1"  
  type: "Scale"
  bottom: "res_stage_3_252_1"
  top: "res_stage_3_252_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_252_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_252_1_top"
  top: "res_stage_3_252_1_top"
}
layer {
  name: "res_stage_3_252_2"
  type: "Convolution"
  bottom: "res_stage_3_252_1_top"
  top: "res_stage_3_252_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_252_2"
  type: "BatchNorm"
  bottom: "res_stage_3_252_2"
  top: "res_stage_3_252_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_252_2"  
  type: "Scale"
  bottom: "res_stage_3_252_2"
  top: "res_stage_3_252_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_252_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_252_2_top"
  top: "res_stage_3_252_2_top"
}
layer {
  name: "res_stage_3_252_3"
  type: "Convolution"
  bottom: "res_stage_3_252_2_top"
  top: "res_stage_3_252_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_252_3"
  type: "BatchNorm"
  bottom: "res_stage_3_252_3"
  top: "res_stage_3_252_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_252_3"  
  type: "Scale"
  bottom: "res_stage_3_252_3"
  top: "res_stage_3_252_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_252"
  type: "Eltwise"
  bottom: "res_3_251"
  bottom: "res_stage_3_252_3_top"
  top: "res_3_252"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_252_relu"
  type: "ReLU"
  bottom: "res_3_252"
  top: "res_3_252"
}
layer {
  name: "res_stage_3_253_1"
  type: "Convolution"
  bottom: "res_3_252"
  top: "res_stage_3_253_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_253_1"
  type: "BatchNorm"
  bottom: "res_stage_3_253_1"
  top: "res_stage_3_253_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_253_1"  
  type: "Scale"
  bottom: "res_stage_3_253_1"
  top: "res_stage_3_253_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_253_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_253_1_top"
  top: "res_stage_3_253_1_top"
}
layer {
  name: "res_stage_3_253_2"
  type: "Convolution"
  bottom: "res_stage_3_253_1_top"
  top: "res_stage_3_253_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_253_2"
  type: "BatchNorm"
  bottom: "res_stage_3_253_2"
  top: "res_stage_3_253_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_253_2"  
  type: "Scale"
  bottom: "res_stage_3_253_2"
  top: "res_stage_3_253_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_253_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_253_2_top"
  top: "res_stage_3_253_2_top"
}
layer {
  name: "res_stage_3_253_3"
  type: "Convolution"
  bottom: "res_stage_3_253_2_top"
  top: "res_stage_3_253_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_253_3"
  type: "BatchNorm"
  bottom: "res_stage_3_253_3"
  top: "res_stage_3_253_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_253_3"  
  type: "Scale"
  bottom: "res_stage_3_253_3"
  top: "res_stage_3_253_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_253"
  type: "Eltwise"
  bottom: "res_3_252"
  bottom: "res_stage_3_253_3_top"
  top: "res_3_253"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_253_relu"
  type: "ReLU"
  bottom: "res_3_253"
  top: "res_3_253"
}
layer {
  name: "res_stage_3_254_1"
  type: "Convolution"
  bottom: "res_3_253"
  top: "res_stage_3_254_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_254_1"
  type: "BatchNorm"
  bottom: "res_stage_3_254_1"
  top: "res_stage_3_254_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_254_1"  
  type: "Scale"
  bottom: "res_stage_3_254_1"
  top: "res_stage_3_254_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_254_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_254_1_top"
  top: "res_stage_3_254_1_top"
}
layer {
  name: "res_stage_3_254_2"
  type: "Convolution"
  bottom: "res_stage_3_254_1_top"
  top: "res_stage_3_254_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_254_2"
  type: "BatchNorm"
  bottom: "res_stage_3_254_2"
  top: "res_stage_3_254_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_254_2"  
  type: "Scale"
  bottom: "res_stage_3_254_2"
  top: "res_stage_3_254_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_254_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_254_2_top"
  top: "res_stage_3_254_2_top"
}
layer {
  name: "res_stage_3_254_3"
  type: "Convolution"
  bottom: "res_stage_3_254_2_top"
  top: "res_stage_3_254_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_254_3"
  type: "BatchNorm"
  bottom: "res_stage_3_254_3"
  top: "res_stage_3_254_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_254_3"  
  type: "Scale"
  bottom: "res_stage_3_254_3"
  top: "res_stage_3_254_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_254"
  type: "Eltwise"
  bottom: "res_3_253"
  bottom: "res_stage_3_254_3_top"
  top: "res_3_254"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_254_relu"
  type: "ReLU"
  bottom: "res_3_254"
  top: "res_3_254"
}
layer {
  name: "res_stage_3_255_1"
  type: "Convolution"
  bottom: "res_3_254"
  top: "res_stage_3_255_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_255_1"
  type: "BatchNorm"
  bottom: "res_stage_3_255_1"
  top: "res_stage_3_255_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_255_1"  
  type: "Scale"
  bottom: "res_stage_3_255_1"
  top: "res_stage_3_255_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_255_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_255_1_top"
  top: "res_stage_3_255_1_top"
}
layer {
  name: "res_stage_3_255_2"
  type: "Convolution"
  bottom: "res_stage_3_255_1_top"
  top: "res_stage_3_255_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_255_2"
  type: "BatchNorm"
  bottom: "res_stage_3_255_2"
  top: "res_stage_3_255_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_255_2"  
  type: "Scale"
  bottom: "res_stage_3_255_2"
  top: "res_stage_3_255_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_255_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_255_2_top"
  top: "res_stage_3_255_2_top"
}
layer {
  name: "res_stage_3_255_3"
  type: "Convolution"
  bottom: "res_stage_3_255_2_top"
  top: "res_stage_3_255_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_255_3"
  type: "BatchNorm"
  bottom: "res_stage_3_255_3"
  top: "res_stage_3_255_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_255_3"  
  type: "Scale"
  bottom: "res_stage_3_255_3"
  top: "res_stage_3_255_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_255"
  type: "Eltwise"
  bottom: "res_3_254"
  bottom: "res_stage_3_255_3_top"
  top: "res_3_255"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_255_relu"
  type: "ReLU"
  bottom: "res_3_255"
  top: "res_3_255"
}
layer {
  name: "res_stage_3_256_1"
  type: "Convolution"
  bottom: "res_3_255"
  top: "res_stage_3_256_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_256_1"
  type: "BatchNorm"
  bottom: "res_stage_3_256_1"
  top: "res_stage_3_256_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_256_1"  
  type: "Scale"
  bottom: "res_stage_3_256_1"
  top: "res_stage_3_256_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_256_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_256_1_top"
  top: "res_stage_3_256_1_top"
}
layer {
  name: "res_stage_3_256_2"
  type: "Convolution"
  bottom: "res_stage_3_256_1_top"
  top: "res_stage_3_256_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_256_2"
  type: "BatchNorm"
  bottom: "res_stage_3_256_2"
  top: "res_stage_3_256_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_256_2"  
  type: "Scale"
  bottom: "res_stage_3_256_2"
  top: "res_stage_3_256_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_256_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_256_2_top"
  top: "res_stage_3_256_2_top"
}
layer {
  name: "res_stage_3_256_3"
  type: "Convolution"
  bottom: "res_stage_3_256_2_top"
  top: "res_stage_3_256_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_256_3"
  type: "BatchNorm"
  bottom: "res_stage_3_256_3"
  top: "res_stage_3_256_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_256_3"  
  type: "Scale"
  bottom: "res_stage_3_256_3"
  top: "res_stage_3_256_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_256"
  type: "Eltwise"
  bottom: "res_3_255"
  bottom: "res_stage_3_256_3_top"
  top: "res_3_256"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_256_relu"
  type: "ReLU"
  bottom: "res_3_256"
  top: "res_3_256"
}
layer {
  name: "res_stage_3_257_1"
  type: "Convolution"
  bottom: "res_3_256"
  top: "res_stage_3_257_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_257_1"
  type: "BatchNorm"
  bottom: "res_stage_3_257_1"
  top: "res_stage_3_257_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_257_1"  
  type: "Scale"
  bottom: "res_stage_3_257_1"
  top: "res_stage_3_257_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_257_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_257_1_top"
  top: "res_stage_3_257_1_top"
}
layer {
  name: "res_stage_3_257_2"
  type: "Convolution"
  bottom: "res_stage_3_257_1_top"
  top: "res_stage_3_257_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_257_2"
  type: "BatchNorm"
  bottom: "res_stage_3_257_2"
  top: "res_stage_3_257_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_257_2"  
  type: "Scale"
  bottom: "res_stage_3_257_2"
  top: "res_stage_3_257_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_257_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_257_2_top"
  top: "res_stage_3_257_2_top"
}
layer {
  name: "res_stage_3_257_3"
  type: "Convolution"
  bottom: "res_stage_3_257_2_top"
  top: "res_stage_3_257_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_257_3"
  type: "BatchNorm"
  bottom: "res_stage_3_257_3"
  top: "res_stage_3_257_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_257_3"  
  type: "Scale"
  bottom: "res_stage_3_257_3"
  top: "res_stage_3_257_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_257"
  type: "Eltwise"
  bottom: "res_3_256"
  bottom: "res_stage_3_257_3_top"
  top: "res_3_257"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_257_relu"
  type: "ReLU"
  bottom: "res_3_257"
  top: "res_3_257"
}
layer {
  name: "res_stage_3_258_1"
  type: "Convolution"
  bottom: "res_3_257"
  top: "res_stage_3_258_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_258_1"
  type: "BatchNorm"
  bottom: "res_stage_3_258_1"
  top: "res_stage_3_258_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_258_1"  
  type: "Scale"
  bottom: "res_stage_3_258_1"
  top: "res_stage_3_258_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_258_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_258_1_top"
  top: "res_stage_3_258_1_top"
}
layer {
  name: "res_stage_3_258_2"
  type: "Convolution"
  bottom: "res_stage_3_258_1_top"
  top: "res_stage_3_258_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_258_2"
  type: "BatchNorm"
  bottom: "res_stage_3_258_2"
  top: "res_stage_3_258_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_258_2"  
  type: "Scale"
  bottom: "res_stage_3_258_2"
  top: "res_stage_3_258_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_258_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_258_2_top"
  top: "res_stage_3_258_2_top"
}
layer {
  name: "res_stage_3_258_3"
  type: "Convolution"
  bottom: "res_stage_3_258_2_top"
  top: "res_stage_3_258_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_258_3"
  type: "BatchNorm"
  bottom: "res_stage_3_258_3"
  top: "res_stage_3_258_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_258_3"  
  type: "Scale"
  bottom: "res_stage_3_258_3"
  top: "res_stage_3_258_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_258"
  type: "Eltwise"
  bottom: "res_3_257"
  bottom: "res_stage_3_258_3_top"
  top: "res_3_258"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_258_relu"
  type: "ReLU"
  bottom: "res_3_258"
  top: "res_3_258"
}
layer {
  name: "res_stage_3_259_1"
  type: "Convolution"
  bottom: "res_3_258"
  top: "res_stage_3_259_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_259_1"
  type: "BatchNorm"
  bottom: "res_stage_3_259_1"
  top: "res_stage_3_259_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_259_1"  
  type: "Scale"
  bottom: "res_stage_3_259_1"
  top: "res_stage_3_259_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_259_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_259_1_top"
  top: "res_stage_3_259_1_top"
}
layer {
  name: "res_stage_3_259_2"
  type: "Convolution"
  bottom: "res_stage_3_259_1_top"
  top: "res_stage_3_259_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_259_2"
  type: "BatchNorm"
  bottom: "res_stage_3_259_2"
  top: "res_stage_3_259_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_259_2"  
  type: "Scale"
  bottom: "res_stage_3_259_2"
  top: "res_stage_3_259_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_259_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_259_2_top"
  top: "res_stage_3_259_2_top"
}
layer {
  name: "res_stage_3_259_3"
  type: "Convolution"
  bottom: "res_stage_3_259_2_top"
  top: "res_stage_3_259_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_259_3"
  type: "BatchNorm"
  bottom: "res_stage_3_259_3"
  top: "res_stage_3_259_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_259_3"  
  type: "Scale"
  bottom: "res_stage_3_259_3"
  top: "res_stage_3_259_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_259"
  type: "Eltwise"
  bottom: "res_3_258"
  bottom: "res_stage_3_259_3_top"
  top: "res_3_259"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_259_relu"
  type: "ReLU"
  bottom: "res_3_259"
  top: "res_3_259"
}
layer {
  name: "res_stage_3_260_1"
  type: "Convolution"
  bottom: "res_3_259"
  top: "res_stage_3_260_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_260_1"
  type: "BatchNorm"
  bottom: "res_stage_3_260_1"
  top: "res_stage_3_260_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_260_1"  
  type: "Scale"
  bottom: "res_stage_3_260_1"
  top: "res_stage_3_260_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_260_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_260_1_top"
  top: "res_stage_3_260_1_top"
}
layer {
  name: "res_stage_3_260_2"
  type: "Convolution"
  bottom: "res_stage_3_260_1_top"
  top: "res_stage_3_260_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_260_2"
  type: "BatchNorm"
  bottom: "res_stage_3_260_2"
  top: "res_stage_3_260_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_260_2"  
  type: "Scale"
  bottom: "res_stage_3_260_2"
  top: "res_stage_3_260_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_260_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_260_2_top"
  top: "res_stage_3_260_2_top"
}
layer {
  name: "res_stage_3_260_3"
  type: "Convolution"
  bottom: "res_stage_3_260_2_top"
  top: "res_stage_3_260_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_260_3"
  type: "BatchNorm"
  bottom: "res_stage_3_260_3"
  top: "res_stage_3_260_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_260_3"  
  type: "Scale"
  bottom: "res_stage_3_260_3"
  top: "res_stage_3_260_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_260"
  type: "Eltwise"
  bottom: "res_3_259"
  bottom: "res_stage_3_260_3_top"
  top: "res_3_260"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_260_relu"
  type: "ReLU"
  bottom: "res_3_260"
  top: "res_3_260"
}
layer {
  name: "res_stage_3_261_1"
  type: "Convolution"
  bottom: "res_3_260"
  top: "res_stage_3_261_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_261_1"
  type: "BatchNorm"
  bottom: "res_stage_3_261_1"
  top: "res_stage_3_261_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_261_1"  
  type: "Scale"
  bottom: "res_stage_3_261_1"
  top: "res_stage_3_261_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_261_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_261_1_top"
  top: "res_stage_3_261_1_top"
}
layer {
  name: "res_stage_3_261_2"
  type: "Convolution"
  bottom: "res_stage_3_261_1_top"
  top: "res_stage_3_261_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_261_2"
  type: "BatchNorm"
  bottom: "res_stage_3_261_2"
  top: "res_stage_3_261_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_261_2"  
  type: "Scale"
  bottom: "res_stage_3_261_2"
  top: "res_stage_3_261_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_261_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_261_2_top"
  top: "res_stage_3_261_2_top"
}
layer {
  name: "res_stage_3_261_3"
  type: "Convolution"
  bottom: "res_stage_3_261_2_top"
  top: "res_stage_3_261_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_261_3"
  type: "BatchNorm"
  bottom: "res_stage_3_261_3"
  top: "res_stage_3_261_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_261_3"  
  type: "Scale"
  bottom: "res_stage_3_261_3"
  top: "res_stage_3_261_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_261"
  type: "Eltwise"
  bottom: "res_3_260"
  bottom: "res_stage_3_261_3_top"
  top: "res_3_261"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_261_relu"
  type: "ReLU"
  bottom: "res_3_261"
  top: "res_3_261"
}
layer {
  name: "res_stage_3_262_1"
  type: "Convolution"
  bottom: "res_3_261"
  top: "res_stage_3_262_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_262_1"
  type: "BatchNorm"
  bottom: "res_stage_3_262_1"
  top: "res_stage_3_262_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_262_1"  
  type: "Scale"
  bottom: "res_stage_3_262_1"
  top: "res_stage_3_262_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_262_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_262_1_top"
  top: "res_stage_3_262_1_top"
}
layer {
  name: "res_stage_3_262_2"
  type: "Convolution"
  bottom: "res_stage_3_262_1_top"
  top: "res_stage_3_262_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_262_2"
  type: "BatchNorm"
  bottom: "res_stage_3_262_2"
  top: "res_stage_3_262_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_262_2"  
  type: "Scale"
  bottom: "res_stage_3_262_2"
  top: "res_stage_3_262_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_262_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_262_2_top"
  top: "res_stage_3_262_2_top"
}
layer {
  name: "res_stage_3_262_3"
  type: "Convolution"
  bottom: "res_stage_3_262_2_top"
  top: "res_stage_3_262_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_262_3"
  type: "BatchNorm"
  bottom: "res_stage_3_262_3"
  top: "res_stage_3_262_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_262_3"  
  type: "Scale"
  bottom: "res_stage_3_262_3"
  top: "res_stage_3_262_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_262"
  type: "Eltwise"
  bottom: "res_3_261"
  bottom: "res_stage_3_262_3_top"
  top: "res_3_262"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_262_relu"
  type: "ReLU"
  bottom: "res_3_262"
  top: "res_3_262"
}
layer {
  name: "res_stage_3_263_1"
  type: "Convolution"
  bottom: "res_3_262"
  top: "res_stage_3_263_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_263_1"
  type: "BatchNorm"
  bottom: "res_stage_3_263_1"
  top: "res_stage_3_263_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_263_1"  
  type: "Scale"
  bottom: "res_stage_3_263_1"
  top: "res_stage_3_263_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_263_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_263_1_top"
  top: "res_stage_3_263_1_top"
}
layer {
  name: "res_stage_3_263_2"
  type: "Convolution"
  bottom: "res_stage_3_263_1_top"
  top: "res_stage_3_263_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_263_2"
  type: "BatchNorm"
  bottom: "res_stage_3_263_2"
  top: "res_stage_3_263_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_263_2"  
  type: "Scale"
  bottom: "res_stage_3_263_2"
  top: "res_stage_3_263_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_263_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_263_2_top"
  top: "res_stage_3_263_2_top"
}
layer {
  name: "res_stage_3_263_3"
  type: "Convolution"
  bottom: "res_stage_3_263_2_top"
  top: "res_stage_3_263_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_263_3"
  type: "BatchNorm"
  bottom: "res_stage_3_263_3"
  top: "res_stage_3_263_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_263_3"  
  type: "Scale"
  bottom: "res_stage_3_263_3"
  top: "res_stage_3_263_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_263"
  type: "Eltwise"
  bottom: "res_3_262"
  bottom: "res_stage_3_263_3_top"
  top: "res_3_263"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_263_relu"
  type: "ReLU"
  bottom: "res_3_263"
  top: "res_3_263"
}
layer {
  name: "res_stage_3_264_1"
  type: "Convolution"
  bottom: "res_3_263"
  top: "res_stage_3_264_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_264_1"
  type: "BatchNorm"
  bottom: "res_stage_3_264_1"
  top: "res_stage_3_264_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_264_1"  
  type: "Scale"
  bottom: "res_stage_3_264_1"
  top: "res_stage_3_264_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_264_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_264_1_top"
  top: "res_stage_3_264_1_top"
}
layer {
  name: "res_stage_3_264_2"
  type: "Convolution"
  bottom: "res_stage_3_264_1_top"
  top: "res_stage_3_264_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_264_2"
  type: "BatchNorm"
  bottom: "res_stage_3_264_2"
  top: "res_stage_3_264_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_264_2"  
  type: "Scale"
  bottom: "res_stage_3_264_2"
  top: "res_stage_3_264_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_264_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_264_2_top"
  top: "res_stage_3_264_2_top"
}
layer {
  name: "res_stage_3_264_3"
  type: "Convolution"
  bottom: "res_stage_3_264_2_top"
  top: "res_stage_3_264_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_264_3"
  type: "BatchNorm"
  bottom: "res_stage_3_264_3"
  top: "res_stage_3_264_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_264_3"  
  type: "Scale"
  bottom: "res_stage_3_264_3"
  top: "res_stage_3_264_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_264"
  type: "Eltwise"
  bottom: "res_3_263"
  bottom: "res_stage_3_264_3_top"
  top: "res_3_264"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_264_relu"
  type: "ReLU"
  bottom: "res_3_264"
  top: "res_3_264"
}
layer {
  name: "res_stage_3_265_1"
  type: "Convolution"
  bottom: "res_3_264"
  top: "res_stage_3_265_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_265_1"
  type: "BatchNorm"
  bottom: "res_stage_3_265_1"
  top: "res_stage_3_265_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_265_1"  
  type: "Scale"
  bottom: "res_stage_3_265_1"
  top: "res_stage_3_265_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_265_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_265_1_top"
  top: "res_stage_3_265_1_top"
}
layer {
  name: "res_stage_3_265_2"
  type: "Convolution"
  bottom: "res_stage_3_265_1_top"
  top: "res_stage_3_265_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_265_2"
  type: "BatchNorm"
  bottom: "res_stage_3_265_2"
  top: "res_stage_3_265_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_265_2"  
  type: "Scale"
  bottom: "res_stage_3_265_2"
  top: "res_stage_3_265_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_265_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_265_2_top"
  top: "res_stage_3_265_2_top"
}
layer {
  name: "res_stage_3_265_3"
  type: "Convolution"
  bottom: "res_stage_3_265_2_top"
  top: "res_stage_3_265_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_265_3"
  type: "BatchNorm"
  bottom: "res_stage_3_265_3"
  top: "res_stage_3_265_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_265_3"  
  type: "Scale"
  bottom: "res_stage_3_265_3"
  top: "res_stage_3_265_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_265"
  type: "Eltwise"
  bottom: "res_3_264"
  bottom: "res_stage_3_265_3_top"
  top: "res_3_265"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_265_relu"
  type: "ReLU"
  bottom: "res_3_265"
  top: "res_3_265"
}
layer {
  name: "res_stage_3_266_1"
  type: "Convolution"
  bottom: "res_3_265"
  top: "res_stage_3_266_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_266_1"
  type: "BatchNorm"
  bottom: "res_stage_3_266_1"
  top: "res_stage_3_266_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_266_1"  
  type: "Scale"
  bottom: "res_stage_3_266_1"
  top: "res_stage_3_266_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_266_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_266_1_top"
  top: "res_stage_3_266_1_top"
}
layer {
  name: "res_stage_3_266_2"
  type: "Convolution"
  bottom: "res_stage_3_266_1_top"
  top: "res_stage_3_266_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_266_2"
  type: "BatchNorm"
  bottom: "res_stage_3_266_2"
  top: "res_stage_3_266_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_266_2"  
  type: "Scale"
  bottom: "res_stage_3_266_2"
  top: "res_stage_3_266_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_266_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_266_2_top"
  top: "res_stage_3_266_2_top"
}
layer {
  name: "res_stage_3_266_3"
  type: "Convolution"
  bottom: "res_stage_3_266_2_top"
  top: "res_stage_3_266_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_266_3"
  type: "BatchNorm"
  bottom: "res_stage_3_266_3"
  top: "res_stage_3_266_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_266_3"  
  type: "Scale"
  bottom: "res_stage_3_266_3"
  top: "res_stage_3_266_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_266"
  type: "Eltwise"
  bottom: "res_3_265"
  bottom: "res_stage_3_266_3_top"
  top: "res_3_266"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_266_relu"
  type: "ReLU"
  bottom: "res_3_266"
  top: "res_3_266"
}
layer {
  name: "res_stage_3_267_1"
  type: "Convolution"
  bottom: "res_3_266"
  top: "res_stage_3_267_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_267_1"
  type: "BatchNorm"
  bottom: "res_stage_3_267_1"
  top: "res_stage_3_267_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_267_1"  
  type: "Scale"
  bottom: "res_stage_3_267_1"
  top: "res_stage_3_267_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_267_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_267_1_top"
  top: "res_stage_3_267_1_top"
}
layer {
  name: "res_stage_3_267_2"
  type: "Convolution"
  bottom: "res_stage_3_267_1_top"
  top: "res_stage_3_267_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_267_2"
  type: "BatchNorm"
  bottom: "res_stage_3_267_2"
  top: "res_stage_3_267_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_267_2"  
  type: "Scale"
  bottom: "res_stage_3_267_2"
  top: "res_stage_3_267_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_267_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_267_2_top"
  top: "res_stage_3_267_2_top"
}
layer {
  name: "res_stage_3_267_3"
  type: "Convolution"
  bottom: "res_stage_3_267_2_top"
  top: "res_stage_3_267_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_267_3"
  type: "BatchNorm"
  bottom: "res_stage_3_267_3"
  top: "res_stage_3_267_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_267_3"  
  type: "Scale"
  bottom: "res_stage_3_267_3"
  top: "res_stage_3_267_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_267"
  type: "Eltwise"
  bottom: "res_3_266"
  bottom: "res_stage_3_267_3_top"
  top: "res_3_267"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_267_relu"
  type: "ReLU"
  bottom: "res_3_267"
  top: "res_3_267"
}
layer {
  name: "res_stage_3_268_1"
  type: "Convolution"
  bottom: "res_3_267"
  top: "res_stage_3_268_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_268_1"
  type: "BatchNorm"
  bottom: "res_stage_3_268_1"
  top: "res_stage_3_268_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_268_1"  
  type: "Scale"
  bottom: "res_stage_3_268_1"
  top: "res_stage_3_268_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_268_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_268_1_top"
  top: "res_stage_3_268_1_top"
}
layer {
  name: "res_stage_3_268_2"
  type: "Convolution"
  bottom: "res_stage_3_268_1_top"
  top: "res_stage_3_268_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_268_2"
  type: "BatchNorm"
  bottom: "res_stage_3_268_2"
  top: "res_stage_3_268_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_268_2"  
  type: "Scale"
  bottom: "res_stage_3_268_2"
  top: "res_stage_3_268_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_268_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_268_2_top"
  top: "res_stage_3_268_2_top"
}
layer {
  name: "res_stage_3_268_3"
  type: "Convolution"
  bottom: "res_stage_3_268_2_top"
  top: "res_stage_3_268_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_268_3"
  type: "BatchNorm"
  bottom: "res_stage_3_268_3"
  top: "res_stage_3_268_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_268_3"  
  type: "Scale"
  bottom: "res_stage_3_268_3"
  top: "res_stage_3_268_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_268"
  type: "Eltwise"
  bottom: "res_3_267"
  bottom: "res_stage_3_268_3_top"
  top: "res_3_268"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_268_relu"
  type: "ReLU"
  bottom: "res_3_268"
  top: "res_3_268"
}
layer {
  name: "res_stage_3_269_1"
  type: "Convolution"
  bottom: "res_3_268"
  top: "res_stage_3_269_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_269_1"
  type: "BatchNorm"
  bottom: "res_stage_3_269_1"
  top: "res_stage_3_269_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_269_1"  
  type: "Scale"
  bottom: "res_stage_3_269_1"
  top: "res_stage_3_269_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_269_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_269_1_top"
  top: "res_stage_3_269_1_top"
}
layer {
  name: "res_stage_3_269_2"
  type: "Convolution"
  bottom: "res_stage_3_269_1_top"
  top: "res_stage_3_269_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_269_2"
  type: "BatchNorm"
  bottom: "res_stage_3_269_2"
  top: "res_stage_3_269_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_269_2"  
  type: "Scale"
  bottom: "res_stage_3_269_2"
  top: "res_stage_3_269_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_269_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_269_2_top"
  top: "res_stage_3_269_2_top"
}
layer {
  name: "res_stage_3_269_3"
  type: "Convolution"
  bottom: "res_stage_3_269_2_top"
  top: "res_stage_3_269_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_269_3"
  type: "BatchNorm"
  bottom: "res_stage_3_269_3"
  top: "res_stage_3_269_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_269_3"  
  type: "Scale"
  bottom: "res_stage_3_269_3"
  top: "res_stage_3_269_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_269"
  type: "Eltwise"
  bottom: "res_3_268"
  bottom: "res_stage_3_269_3_top"
  top: "res_3_269"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_269_relu"
  type: "ReLU"
  bottom: "res_3_269"
  top: "res_3_269"
}
layer {
  name: "res_stage_3_270_1"
  type: "Convolution"
  bottom: "res_3_269"
  top: "res_stage_3_270_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_270_1"
  type: "BatchNorm"
  bottom: "res_stage_3_270_1"
  top: "res_stage_3_270_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_270_1"  
  type: "Scale"
  bottom: "res_stage_3_270_1"
  top: "res_stage_3_270_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_270_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_270_1_top"
  top: "res_stage_3_270_1_top"
}
layer {
  name: "res_stage_3_270_2"
  type: "Convolution"
  bottom: "res_stage_3_270_1_top"
  top: "res_stage_3_270_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_270_2"
  type: "BatchNorm"
  bottom: "res_stage_3_270_2"
  top: "res_stage_3_270_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_270_2"  
  type: "Scale"
  bottom: "res_stage_3_270_2"
  top: "res_stage_3_270_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_270_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_270_2_top"
  top: "res_stage_3_270_2_top"
}
layer {
  name: "res_stage_3_270_3"
  type: "Convolution"
  bottom: "res_stage_3_270_2_top"
  top: "res_stage_3_270_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_270_3"
  type: "BatchNorm"
  bottom: "res_stage_3_270_3"
  top: "res_stage_3_270_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_270_3"  
  type: "Scale"
  bottom: "res_stage_3_270_3"
  top: "res_stage_3_270_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_270"
  type: "Eltwise"
  bottom: "res_3_269"
  bottom: "res_stage_3_270_3_top"
  top: "res_3_270"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_270_relu"
  type: "ReLU"
  bottom: "res_3_270"
  top: "res_3_270"
}
layer {
  name: "res_4_branch1"
  type: "Convolution"
  bottom: "res_3_270"
  top: "res_4_branch1"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_4_branch1"
  type: "BatchNorm"
  bottom: "res_4_branch1"
  top: "res_4_branch1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_4_branch1"  
  type: "Scale"
  bottom: "res_4_branch1"
  top: "res_4_branch1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_1_1"
  type: "Convolution"
  bottom: "res_3_270"
  top: "res_stage_4_1_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_1_1"
  type: "BatchNorm"
  bottom: "res_stage_4_1_1"
  top: "res_stage_4_1_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_1_1"  
  type: "Scale"
  bottom: "res_stage_4_1_1"
  top: "res_stage_4_1_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_1_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_1_1_top"
  top: "res_stage_4_1_1_top"
}
layer {
  name: "res_stage_4_1_2"
  type: "Convolution"
  bottom: "res_stage_4_1_1_top"
  top: "res_stage_4_1_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_1_2"
  type: "BatchNorm"
  bottom: "res_stage_4_1_2"
  top: "res_stage_4_1_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_1_2"  
  type: "Scale"
  bottom: "res_stage_4_1_2"
  top: "res_stage_4_1_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_1_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_1_2_top"
  top: "res_stage_4_1_2_top"
}
layer {
  name: "res_stage_4_1_3"
  type: "Convolution"
  bottom: "res_stage_4_1_2_top"
  top: "res_stage_4_1_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_1_3"
  type: "BatchNorm"
  bottom: "res_stage_4_1_3"
  top: "res_stage_4_1_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_1_3"  
  type: "Scale"
  bottom: "res_stage_4_1_3"
  top: "res_stage_4_1_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_1"
  type: "Eltwise"
  bottom: "res_4_branch1_top"
  bottom: "res_stage_4_1_3_top"
  top: "res_4_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_1_relu"
  type: "ReLU"
  bottom: "res_4_1"
  top: "res_4_1"
}
layer {
  name: "res_stage_4_2_1"
  type: "Convolution"
  bottom: "res_4_1"
  top: "res_stage_4_2_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_2_1"
  type: "BatchNorm"
  bottom: "res_stage_4_2_1"
  top: "res_stage_4_2_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_2_1"  
  type: "Scale"
  bottom: "res_stage_4_2_1"
  top: "res_stage_4_2_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_2_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_2_1_top"
  top: "res_stage_4_2_1_top"
}
layer {
  name: "res_stage_4_2_2"
  type: "Convolution"
  bottom: "res_stage_4_2_1_top"
  top: "res_stage_4_2_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_2_2"
  type: "BatchNorm"
  bottom: "res_stage_4_2_2"
  top: "res_stage_4_2_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_2_2"  
  type: "Scale"
  bottom: "res_stage_4_2_2"
  top: "res_stage_4_2_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_2_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_2_2_top"
  top: "res_stage_4_2_2_top"
}
layer {
  name: "res_stage_4_2_3"
  type: "Convolution"
  bottom: "res_stage_4_2_2_top"
  top: "res_stage_4_2_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_2_3"
  type: "BatchNorm"
  bottom: "res_stage_4_2_3"
  top: "res_stage_4_2_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_2_3"  
  type: "Scale"
  bottom: "res_stage_4_2_3"
  top: "res_stage_4_2_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_2"
  type: "Eltwise"
  bottom: "res_4_1"
  bottom: "res_stage_4_2_3_top"
  top: "res_4_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_2_relu"
  type: "ReLU"
  bottom: "res_4_2"
  top: "res_4_2"
}
layer {
  name: "res_stage_4_3_1"
  type: "Convolution"
  bottom: "res_4_2"
  top: "res_stage_4_3_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_3_1"
  type: "BatchNorm"
  bottom: "res_stage_4_3_1"
  top: "res_stage_4_3_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_3_1"  
  type: "Scale"
  bottom: "res_stage_4_3_1"
  top: "res_stage_4_3_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_3_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_3_1_top"
  top: "res_stage_4_3_1_top"
}
layer {
  name: "res_stage_4_3_2"
  type: "Convolution"
  bottom: "res_stage_4_3_1_top"
  top: "res_stage_4_3_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_3_2"
  type: "BatchNorm"
  bottom: "res_stage_4_3_2"
  top: "res_stage_4_3_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_3_2"  
  type: "Scale"
  bottom: "res_stage_4_3_2"
  top: "res_stage_4_3_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_3_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_3_2_top"
  top: "res_stage_4_3_2_top"
}
layer {
  name: "res_stage_4_3_3"
  type: "Convolution"
  bottom: "res_stage_4_3_2_top"
  top: "res_stage_4_3_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_3_3"
  type: "BatchNorm"
  bottom: "res_stage_4_3_3"
  top: "res_stage_4_3_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_3_3"  
  type: "Scale"
  bottom: "res_stage_4_3_3"
  top: "res_stage_4_3_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_3"
  type: "Eltwise"
  bottom: "res_4_2"
  bottom: "res_stage_4_3_3_top"
  top: "res_4_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_3_relu"
  type: "ReLU"
  bottom: "res_4_3"
  top: "res_4_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res_4_3"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
     num_output: 1000
     weight_filler {
       type: "msra"
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
}

layer {
  name: "acc/top-1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "acc/top-1"
  include {
    phase: TEST
  }
}

layer {
  name: "acc/top-5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "acc/top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
