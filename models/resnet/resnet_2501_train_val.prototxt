name: "ResNet-2501"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "data/ilsvrc12_train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "data/ilsvrc12_val_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_conv1"  
  type: "Scale"
  bottom: "conv1"
  top: "conv1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1_top"
  top: "conv1_top"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_top"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res_1_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res_1_branch1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_1_branch1"
  type: "BatchNorm"
  bottom: "res_1_branch1"
  top: "res_1_branch1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_1_branch1"  
  type: "Scale"
  bottom: "res_1_branch1"
  top: "res_1_branch1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_1_1"
  type: "Convolution"
  bottom: "pool1"
  top: "res_stage_1_1_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_1_1"
  type: "BatchNorm"
  bottom: "res_stage_1_1_1"
  top: "res_stage_1_1_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_1_1"  
  type: "Scale"
  bottom: "res_stage_1_1_1"
  top: "res_stage_1_1_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_1_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_1_1_top"
  top: "res_stage_1_1_1_top"
}
layer {
  name: "res_stage_1_1_2"
  type: "Convolution"
  bottom: "res_stage_1_1_1_top"
  top: "res_stage_1_1_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_1_2"
  type: "BatchNorm"
  bottom: "res_stage_1_1_2"
  top: "res_stage_1_1_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_1_2"  
  type: "Scale"
  bottom: "res_stage_1_1_2"
  top: "res_stage_1_1_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_1_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_1_2_top"
  top: "res_stage_1_1_2_top"
}
layer {
  name: "res_stage_1_1_3"
  type: "Convolution"
  bottom: "res_stage_1_1_2_top"
  top: "res_stage_1_1_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_1_3"
  type: "BatchNorm"
  bottom: "res_stage_1_1_3"
  top: "res_stage_1_1_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_1_3"  
  type: "Scale"
  bottom: "res_stage_1_1_3"
  top: "res_stage_1_1_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_1"
  type: "Eltwise"
  bottom: "res_1_branch1_top"
  bottom: "res_stage_1_1_3_top"
  top: "res_1_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_1_relu"
  type: "ReLU"
  bottom: "res_1_1"
  top: "res_1_1"
}
layer {
  name: "res_stage_1_2_1"
  type: "Convolution"
  bottom: "res_1_1"
  top: "res_stage_1_2_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_2_1"
  type: "BatchNorm"
  bottom: "res_stage_1_2_1"
  top: "res_stage_1_2_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_2_1"  
  type: "Scale"
  bottom: "res_stage_1_2_1"
  top: "res_stage_1_2_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_2_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_2_1_top"
  top: "res_stage_1_2_1_top"
}
layer {
  name: "res_stage_1_2_2"
  type: "Convolution"
  bottom: "res_stage_1_2_1_top"
  top: "res_stage_1_2_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_2_2"
  type: "BatchNorm"
  bottom: "res_stage_1_2_2"
  top: "res_stage_1_2_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_2_2"  
  type: "Scale"
  bottom: "res_stage_1_2_2"
  top: "res_stage_1_2_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_2_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_2_2_top"
  top: "res_stage_1_2_2_top"
}
layer {
  name: "res_stage_1_2_3"
  type: "Convolution"
  bottom: "res_stage_1_2_2_top"
  top: "res_stage_1_2_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_2_3"
  type: "BatchNorm"
  bottom: "res_stage_1_2_3"
  top: "res_stage_1_2_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_2_3"  
  type: "Scale"
  bottom: "res_stage_1_2_3"
  top: "res_stage_1_2_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_2"
  type: "Eltwise"
  bottom: "res_1_1"
  bottom: "res_stage_1_2_3_top"
  top: "res_1_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_2_relu"
  type: "ReLU"
  bottom: "res_1_2"
  top: "res_1_2"
}
layer {
  name: "res_stage_1_3_1"
  type: "Convolution"
  bottom: "res_1_2"
  top: "res_stage_1_3_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_3_1"
  type: "BatchNorm"
  bottom: "res_stage_1_3_1"
  top: "res_stage_1_3_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_3_1"  
  type: "Scale"
  bottom: "res_stage_1_3_1"
  top: "res_stage_1_3_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_3_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_3_1_top"
  top: "res_stage_1_3_1_top"
}
layer {
  name: "res_stage_1_3_2"
  type: "Convolution"
  bottom: "res_stage_1_3_1_top"
  top: "res_stage_1_3_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_3_2"
  type: "BatchNorm"
  bottom: "res_stage_1_3_2"
  top: "res_stage_1_3_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_3_2"  
  type: "Scale"
  bottom: "res_stage_1_3_2"
  top: "res_stage_1_3_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_3_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_3_2_top"
  top: "res_stage_1_3_2_top"
}
layer {
  name: "res_stage_1_3_3"
  type: "Convolution"
  bottom: "res_stage_1_3_2_top"
  top: "res_stage_1_3_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_3_3"
  type: "BatchNorm"
  bottom: "res_stage_1_3_3"
  top: "res_stage_1_3_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_3_3"  
  type: "Scale"
  bottom: "res_stage_1_3_3"
  top: "res_stage_1_3_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_3"
  type: "Eltwise"
  bottom: "res_1_2"
  bottom: "res_stage_1_3_3_top"
  top: "res_1_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_3_relu"
  type: "ReLU"
  bottom: "res_1_3"
  top: "res_1_3"
}
layer {
  name: "res_stage_1_4_1"
  type: "Convolution"
  bottom: "res_1_3"
  top: "res_stage_1_4_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_4_1"
  type: "BatchNorm"
  bottom: "res_stage_1_4_1"
  top: "res_stage_1_4_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_4_1"  
  type: "Scale"
  bottom: "res_stage_1_4_1"
  top: "res_stage_1_4_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_4_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_4_1_top"
  top: "res_stage_1_4_1_top"
}
layer {
  name: "res_stage_1_4_2"
  type: "Convolution"
  bottom: "res_stage_1_4_1_top"
  top: "res_stage_1_4_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_4_2"
  type: "BatchNorm"
  bottom: "res_stage_1_4_2"
  top: "res_stage_1_4_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_4_2"  
  type: "Scale"
  bottom: "res_stage_1_4_2"
  top: "res_stage_1_4_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_4_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_4_2_top"
  top: "res_stage_1_4_2_top"
}
layer {
  name: "res_stage_1_4_3"
  type: "Convolution"
  bottom: "res_stage_1_4_2_top"
  top: "res_stage_1_4_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_4_3"
  type: "BatchNorm"
  bottom: "res_stage_1_4_3"
  top: "res_stage_1_4_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_4_3"  
  type: "Scale"
  bottom: "res_stage_1_4_3"
  top: "res_stage_1_4_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_4"
  type: "Eltwise"
  bottom: "res_1_3"
  bottom: "res_stage_1_4_3_top"
  top: "res_1_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_4_relu"
  type: "ReLU"
  bottom: "res_1_4"
  top: "res_1_4"
}
layer {
  name: "res_stage_1_5_1"
  type: "Convolution"
  bottom: "res_1_4"
  top: "res_stage_1_5_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_5_1"
  type: "BatchNorm"
  bottom: "res_stage_1_5_1"
  top: "res_stage_1_5_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_5_1"  
  type: "Scale"
  bottom: "res_stage_1_5_1"
  top: "res_stage_1_5_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_5_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_5_1_top"
  top: "res_stage_1_5_1_top"
}
layer {
  name: "res_stage_1_5_2"
  type: "Convolution"
  bottom: "res_stage_1_5_1_top"
  top: "res_stage_1_5_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_5_2"
  type: "BatchNorm"
  bottom: "res_stage_1_5_2"
  top: "res_stage_1_5_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_5_2"  
  type: "Scale"
  bottom: "res_stage_1_5_2"
  top: "res_stage_1_5_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_5_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_5_2_top"
  top: "res_stage_1_5_2_top"
}
layer {
  name: "res_stage_1_5_3"
  type: "Convolution"
  bottom: "res_stage_1_5_2_top"
  top: "res_stage_1_5_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_5_3"
  type: "BatchNorm"
  bottom: "res_stage_1_5_3"
  top: "res_stage_1_5_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_5_3"  
  type: "Scale"
  bottom: "res_stage_1_5_3"
  top: "res_stage_1_5_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_5"
  type: "Eltwise"
  bottom: "res_1_4"
  bottom: "res_stage_1_5_3_top"
  top: "res_1_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_5_relu"
  type: "ReLU"
  bottom: "res_1_5"
  top: "res_1_5"
}
layer {
  name: "res_stage_1_6_1"
  type: "Convolution"
  bottom: "res_1_5"
  top: "res_stage_1_6_1"
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_6_1"
  type: "BatchNorm"
  bottom: "res_stage_1_6_1"
  top: "res_stage_1_6_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_6_1"  
  type: "Scale"
  bottom: "res_stage_1_6_1"
  top: "res_stage_1_6_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_6_1_relu"
  type: "ReLU"
  bottom: "res_stage_1_6_1_top"
  top: "res_stage_1_6_1_top"
}
layer {
  name: "res_stage_1_6_2"
  type: "Convolution"
  bottom: "res_stage_1_6_1_top"
  top: "res_stage_1_6_2"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_6_2"
  type: "BatchNorm"
  bottom: "res_stage_1_6_2"
  top: "res_stage_1_6_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_6_2"  
  type: "Scale"
  bottom: "res_stage_1_6_2"
  top: "res_stage_1_6_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_1_6_2_relu"
  type: "ReLU"
  bottom: "res_stage_1_6_2_top"
  top: "res_stage_1_6_2_top"
}
layer {
  name: "res_stage_1_6_3"
  type: "Convolution"
  bottom: "res_stage_1_6_2_top"
  top: "res_stage_1_6_3"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_1_6_3"
  type: "BatchNorm"
  bottom: "res_stage_1_6_3"
  top: "res_stage_1_6_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_1_6_3"  
  type: "Scale"
  bottom: "res_stage_1_6_3"
  top: "res_stage_1_6_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_1_6"
  type: "Eltwise"
  bottom: "res_1_5"
  bottom: "res_stage_1_6_3_top"
  top: "res_1_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_1_6_relu"
  type: "ReLU"
  bottom: "res_1_6"
  top: "res_1_6"
}
layer {
  name: "res_2_branch1"
  type: "Convolution"
  bottom: "res_1_6"
  top: "res_2_branch1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_2_branch1"
  type: "BatchNorm"
  bottom: "res_2_branch1"
  top: "res_2_branch1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_2_branch1"  
  type: "Scale"
  bottom: "res_2_branch1"
  top: "res_2_branch1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_1_1"
  type: "Convolution"
  bottom: "res_1_6"
  top: "res_stage_2_1_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_1_1"
  type: "BatchNorm"
  bottom: "res_stage_2_1_1"
  top: "res_stage_2_1_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_1_1"  
  type: "Scale"
  bottom: "res_stage_2_1_1"
  top: "res_stage_2_1_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_1_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_1_1_top"
  top: "res_stage_2_1_1_top"
}
layer {
  name: "res_stage_2_1_2"
  type: "Convolution"
  bottom: "res_stage_2_1_1_top"
  top: "res_stage_2_1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_1_2"
  type: "BatchNorm"
  bottom: "res_stage_2_1_2"
  top: "res_stage_2_1_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_1_2"  
  type: "Scale"
  bottom: "res_stage_2_1_2"
  top: "res_stage_2_1_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_1_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_1_2_top"
  top: "res_stage_2_1_2_top"
}
layer {
  name: "res_stage_2_1_3"
  type: "Convolution"
  bottom: "res_stage_2_1_2_top"
  top: "res_stage_2_1_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_1_3"
  type: "BatchNorm"
  bottom: "res_stage_2_1_3"
  top: "res_stage_2_1_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_1_3"  
  type: "Scale"
  bottom: "res_stage_2_1_3"
  top: "res_stage_2_1_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_1"
  type: "Eltwise"
  bottom: "res_2_branch1_top"
  bottom: "res_stage_2_1_3_top"
  top: "res_2_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_1_relu"
  type: "ReLU"
  bottom: "res_2_1"
  top: "res_2_1"
}
layer {
  name: "res_stage_2_2_1"
  type: "Convolution"
  bottom: "res_2_1"
  top: "res_stage_2_2_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_2_1"
  type: "BatchNorm"
  bottom: "res_stage_2_2_1"
  top: "res_stage_2_2_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_2_1"  
  type: "Scale"
  bottom: "res_stage_2_2_1"
  top: "res_stage_2_2_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_2_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_2_1_top"
  top: "res_stage_2_2_1_top"
}
layer {
  name: "res_stage_2_2_2"
  type: "Convolution"
  bottom: "res_stage_2_2_1_top"
  top: "res_stage_2_2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_2_2"
  type: "BatchNorm"
  bottom: "res_stage_2_2_2"
  top: "res_stage_2_2_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_2_2"  
  type: "Scale"
  bottom: "res_stage_2_2_2"
  top: "res_stage_2_2_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_2_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_2_2_top"
  top: "res_stage_2_2_2_top"
}
layer {
  name: "res_stage_2_2_3"
  type: "Convolution"
  bottom: "res_stage_2_2_2_top"
  top: "res_stage_2_2_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_2_3"
  type: "BatchNorm"
  bottom: "res_stage_2_2_3"
  top: "res_stage_2_2_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_2_3"  
  type: "Scale"
  bottom: "res_stage_2_2_3"
  top: "res_stage_2_2_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_2"
  type: "Eltwise"
  bottom: "res_2_1"
  bottom: "res_stage_2_2_3_top"
  top: "res_2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_2_relu"
  type: "ReLU"
  bottom: "res_2_2"
  top: "res_2_2"
}
layer {
  name: "res_stage_2_3_1"
  type: "Convolution"
  bottom: "res_2_2"
  top: "res_stage_2_3_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_3_1"
  type: "BatchNorm"
  bottom: "res_stage_2_3_1"
  top: "res_stage_2_3_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_3_1"  
  type: "Scale"
  bottom: "res_stage_2_3_1"
  top: "res_stage_2_3_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_3_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_3_1_top"
  top: "res_stage_2_3_1_top"
}
layer {
  name: "res_stage_2_3_2"
  type: "Convolution"
  bottom: "res_stage_2_3_1_top"
  top: "res_stage_2_3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_3_2"
  type: "BatchNorm"
  bottom: "res_stage_2_3_2"
  top: "res_stage_2_3_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_3_2"  
  type: "Scale"
  bottom: "res_stage_2_3_2"
  top: "res_stage_2_3_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_3_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_3_2_top"
  top: "res_stage_2_3_2_top"
}
layer {
  name: "res_stage_2_3_3"
  type: "Convolution"
  bottom: "res_stage_2_3_2_top"
  top: "res_stage_2_3_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_3_3"
  type: "BatchNorm"
  bottom: "res_stage_2_3_3"
  top: "res_stage_2_3_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_3_3"  
  type: "Scale"
  bottom: "res_stage_2_3_3"
  top: "res_stage_2_3_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_3"
  type: "Eltwise"
  bottom: "res_2_2"
  bottom: "res_stage_2_3_3_top"
  top: "res_2_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_3_relu"
  type: "ReLU"
  bottom: "res_2_3"
  top: "res_2_3"
}
layer {
  name: "res_stage_2_4_1"
  type: "Convolution"
  bottom: "res_2_3"
  top: "res_stage_2_4_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_4_1"
  type: "BatchNorm"
  bottom: "res_stage_2_4_1"
  top: "res_stage_2_4_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_4_1"  
  type: "Scale"
  bottom: "res_stage_2_4_1"
  top: "res_stage_2_4_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_4_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_4_1_top"
  top: "res_stage_2_4_1_top"
}
layer {
  name: "res_stage_2_4_2"
  type: "Convolution"
  bottom: "res_stage_2_4_1_top"
  top: "res_stage_2_4_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_4_2"
  type: "BatchNorm"
  bottom: "res_stage_2_4_2"
  top: "res_stage_2_4_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_4_2"  
  type: "Scale"
  bottom: "res_stage_2_4_2"
  top: "res_stage_2_4_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_4_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_4_2_top"
  top: "res_stage_2_4_2_top"
}
layer {
  name: "res_stage_2_4_3"
  type: "Convolution"
  bottom: "res_stage_2_4_2_top"
  top: "res_stage_2_4_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_4_3"
  type: "BatchNorm"
  bottom: "res_stage_2_4_3"
  top: "res_stage_2_4_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_4_3"  
  type: "Scale"
  bottom: "res_stage_2_4_3"
  top: "res_stage_2_4_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_4"
  type: "Eltwise"
  bottom: "res_2_3"
  bottom: "res_stage_2_4_3_top"
  top: "res_2_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_4_relu"
  type: "ReLU"
  bottom: "res_2_4"
  top: "res_2_4"
}
layer {
  name: "res_stage_2_5_1"
  type: "Convolution"
  bottom: "res_2_4"
  top: "res_stage_2_5_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_5_1"
  type: "BatchNorm"
  bottom: "res_stage_2_5_1"
  top: "res_stage_2_5_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_5_1"  
  type: "Scale"
  bottom: "res_stage_2_5_1"
  top: "res_stage_2_5_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_5_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_5_1_top"
  top: "res_stage_2_5_1_top"
}
layer {
  name: "res_stage_2_5_2"
  type: "Convolution"
  bottom: "res_stage_2_5_1_top"
  top: "res_stage_2_5_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_5_2"
  type: "BatchNorm"
  bottom: "res_stage_2_5_2"
  top: "res_stage_2_5_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_5_2"  
  type: "Scale"
  bottom: "res_stage_2_5_2"
  top: "res_stage_2_5_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_5_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_5_2_top"
  top: "res_stage_2_5_2_top"
}
layer {
  name: "res_stage_2_5_3"
  type: "Convolution"
  bottom: "res_stage_2_5_2_top"
  top: "res_stage_2_5_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_5_3"
  type: "BatchNorm"
  bottom: "res_stage_2_5_3"
  top: "res_stage_2_5_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_5_3"  
  type: "Scale"
  bottom: "res_stage_2_5_3"
  top: "res_stage_2_5_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_5"
  type: "Eltwise"
  bottom: "res_2_4"
  bottom: "res_stage_2_5_3_top"
  top: "res_2_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_5_relu"
  type: "ReLU"
  bottom: "res_2_5"
  top: "res_2_5"
}
layer {
  name: "res_stage_2_6_1"
  type: "Convolution"
  bottom: "res_2_5"
  top: "res_stage_2_6_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_6_1"
  type: "BatchNorm"
  bottom: "res_stage_2_6_1"
  top: "res_stage_2_6_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_6_1"  
  type: "Scale"
  bottom: "res_stage_2_6_1"
  top: "res_stage_2_6_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_6_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_6_1_top"
  top: "res_stage_2_6_1_top"
}
layer {
  name: "res_stage_2_6_2"
  type: "Convolution"
  bottom: "res_stage_2_6_1_top"
  top: "res_stage_2_6_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_6_2"
  type: "BatchNorm"
  bottom: "res_stage_2_6_2"
  top: "res_stage_2_6_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_6_2"  
  type: "Scale"
  bottom: "res_stage_2_6_2"
  top: "res_stage_2_6_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_6_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_6_2_top"
  top: "res_stage_2_6_2_top"
}
layer {
  name: "res_stage_2_6_3"
  type: "Convolution"
  bottom: "res_stage_2_6_2_top"
  top: "res_stage_2_6_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_6_3"
  type: "BatchNorm"
  bottom: "res_stage_2_6_3"
  top: "res_stage_2_6_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_6_3"  
  type: "Scale"
  bottom: "res_stage_2_6_3"
  top: "res_stage_2_6_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_6"
  type: "Eltwise"
  bottom: "res_2_5"
  bottom: "res_stage_2_6_3_top"
  top: "res_2_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_6_relu"
  type: "ReLU"
  bottom: "res_2_6"
  top: "res_2_6"
}
layer {
  name: "res_stage_2_7_1"
  type: "Convolution"
  bottom: "res_2_6"
  top: "res_stage_2_7_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_7_1"
  type: "BatchNorm"
  bottom: "res_stage_2_7_1"
  top: "res_stage_2_7_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_7_1"  
  type: "Scale"
  bottom: "res_stage_2_7_1"
  top: "res_stage_2_7_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_7_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_7_1_top"
  top: "res_stage_2_7_1_top"
}
layer {
  name: "res_stage_2_7_2"
  type: "Convolution"
  bottom: "res_stage_2_7_1_top"
  top: "res_stage_2_7_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_7_2"
  type: "BatchNorm"
  bottom: "res_stage_2_7_2"
  top: "res_stage_2_7_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_7_2"  
  type: "Scale"
  bottom: "res_stage_2_7_2"
  top: "res_stage_2_7_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_7_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_7_2_top"
  top: "res_stage_2_7_2_top"
}
layer {
  name: "res_stage_2_7_3"
  type: "Convolution"
  bottom: "res_stage_2_7_2_top"
  top: "res_stage_2_7_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_7_3"
  type: "BatchNorm"
  bottom: "res_stage_2_7_3"
  top: "res_stage_2_7_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_7_3"  
  type: "Scale"
  bottom: "res_stage_2_7_3"
  top: "res_stage_2_7_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_7"
  type: "Eltwise"
  bottom: "res_2_6"
  bottom: "res_stage_2_7_3_top"
  top: "res_2_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_7_relu"
  type: "ReLU"
  bottom: "res_2_7"
  top: "res_2_7"
}
layer {
  name: "res_stage_2_8_1"
  type: "Convolution"
  bottom: "res_2_7"
  top: "res_stage_2_8_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_8_1"
  type: "BatchNorm"
  bottom: "res_stage_2_8_1"
  top: "res_stage_2_8_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_8_1"  
  type: "Scale"
  bottom: "res_stage_2_8_1"
  top: "res_stage_2_8_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_8_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_8_1_top"
  top: "res_stage_2_8_1_top"
}
layer {
  name: "res_stage_2_8_2"
  type: "Convolution"
  bottom: "res_stage_2_8_1_top"
  top: "res_stage_2_8_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_8_2"
  type: "BatchNorm"
  bottom: "res_stage_2_8_2"
  top: "res_stage_2_8_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_8_2"  
  type: "Scale"
  bottom: "res_stage_2_8_2"
  top: "res_stage_2_8_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_8_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_8_2_top"
  top: "res_stage_2_8_2_top"
}
layer {
  name: "res_stage_2_8_3"
  type: "Convolution"
  bottom: "res_stage_2_8_2_top"
  top: "res_stage_2_8_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_8_3"
  type: "BatchNorm"
  bottom: "res_stage_2_8_3"
  top: "res_stage_2_8_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_8_3"  
  type: "Scale"
  bottom: "res_stage_2_8_3"
  top: "res_stage_2_8_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_8"
  type: "Eltwise"
  bottom: "res_2_7"
  bottom: "res_stage_2_8_3_top"
  top: "res_2_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_8_relu"
  type: "ReLU"
  bottom: "res_2_8"
  top: "res_2_8"
}
layer {
  name: "res_stage_2_9_1"
  type: "Convolution"
  bottom: "res_2_8"
  top: "res_stage_2_9_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_9_1"
  type: "BatchNorm"
  bottom: "res_stage_2_9_1"
  top: "res_stage_2_9_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_9_1"  
  type: "Scale"
  bottom: "res_stage_2_9_1"
  top: "res_stage_2_9_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_9_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_9_1_top"
  top: "res_stage_2_9_1_top"
}
layer {
  name: "res_stage_2_9_2"
  type: "Convolution"
  bottom: "res_stage_2_9_1_top"
  top: "res_stage_2_9_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_9_2"
  type: "BatchNorm"
  bottom: "res_stage_2_9_2"
  top: "res_stage_2_9_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_9_2"  
  type: "Scale"
  bottom: "res_stage_2_9_2"
  top: "res_stage_2_9_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_9_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_9_2_top"
  top: "res_stage_2_9_2_top"
}
layer {
  name: "res_stage_2_9_3"
  type: "Convolution"
  bottom: "res_stage_2_9_2_top"
  top: "res_stage_2_9_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_9_3"
  type: "BatchNorm"
  bottom: "res_stage_2_9_3"
  top: "res_stage_2_9_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_9_3"  
  type: "Scale"
  bottom: "res_stage_2_9_3"
  top: "res_stage_2_9_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_9"
  type: "Eltwise"
  bottom: "res_2_8"
  bottom: "res_stage_2_9_3_top"
  top: "res_2_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_9_relu"
  type: "ReLU"
  bottom: "res_2_9"
  top: "res_2_9"
}
layer {
  name: "res_stage_2_10_1"
  type: "Convolution"
  bottom: "res_2_9"
  top: "res_stage_2_10_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_10_1"
  type: "BatchNorm"
  bottom: "res_stage_2_10_1"
  top: "res_stage_2_10_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_10_1"  
  type: "Scale"
  bottom: "res_stage_2_10_1"
  top: "res_stage_2_10_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_10_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_10_1_top"
  top: "res_stage_2_10_1_top"
}
layer {
  name: "res_stage_2_10_2"
  type: "Convolution"
  bottom: "res_stage_2_10_1_top"
  top: "res_stage_2_10_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_10_2"
  type: "BatchNorm"
  bottom: "res_stage_2_10_2"
  top: "res_stage_2_10_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_10_2"  
  type: "Scale"
  bottom: "res_stage_2_10_2"
  top: "res_stage_2_10_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_10_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_10_2_top"
  top: "res_stage_2_10_2_top"
}
layer {
  name: "res_stage_2_10_3"
  type: "Convolution"
  bottom: "res_stage_2_10_2_top"
  top: "res_stage_2_10_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_10_3"
  type: "BatchNorm"
  bottom: "res_stage_2_10_3"
  top: "res_stage_2_10_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_10_3"  
  type: "Scale"
  bottom: "res_stage_2_10_3"
  top: "res_stage_2_10_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_10"
  type: "Eltwise"
  bottom: "res_2_9"
  bottom: "res_stage_2_10_3_top"
  top: "res_2_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_10_relu"
  type: "ReLU"
  bottom: "res_2_10"
  top: "res_2_10"
}
layer {
  name: "res_stage_2_11_1"
  type: "Convolution"
  bottom: "res_2_10"
  top: "res_stage_2_11_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_11_1"
  type: "BatchNorm"
  bottom: "res_stage_2_11_1"
  top: "res_stage_2_11_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_11_1"  
  type: "Scale"
  bottom: "res_stage_2_11_1"
  top: "res_stage_2_11_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_11_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_11_1_top"
  top: "res_stage_2_11_1_top"
}
layer {
  name: "res_stage_2_11_2"
  type: "Convolution"
  bottom: "res_stage_2_11_1_top"
  top: "res_stage_2_11_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_11_2"
  type: "BatchNorm"
  bottom: "res_stage_2_11_2"
  top: "res_stage_2_11_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_11_2"  
  type: "Scale"
  bottom: "res_stage_2_11_2"
  top: "res_stage_2_11_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_11_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_11_2_top"
  top: "res_stage_2_11_2_top"
}
layer {
  name: "res_stage_2_11_3"
  type: "Convolution"
  bottom: "res_stage_2_11_2_top"
  top: "res_stage_2_11_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_11_3"
  type: "BatchNorm"
  bottom: "res_stage_2_11_3"
  top: "res_stage_2_11_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_11_3"  
  type: "Scale"
  bottom: "res_stage_2_11_3"
  top: "res_stage_2_11_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_11"
  type: "Eltwise"
  bottom: "res_2_10"
  bottom: "res_stage_2_11_3_top"
  top: "res_2_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_11_relu"
  type: "ReLU"
  bottom: "res_2_11"
  top: "res_2_11"
}
layer {
  name: "res_stage_2_12_1"
  type: "Convolution"
  bottom: "res_2_11"
  top: "res_stage_2_12_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_12_1"
  type: "BatchNorm"
  bottom: "res_stage_2_12_1"
  top: "res_stage_2_12_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_12_1"  
  type: "Scale"
  bottom: "res_stage_2_12_1"
  top: "res_stage_2_12_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_12_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_12_1_top"
  top: "res_stage_2_12_1_top"
}
layer {
  name: "res_stage_2_12_2"
  type: "Convolution"
  bottom: "res_stage_2_12_1_top"
  top: "res_stage_2_12_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_12_2"
  type: "BatchNorm"
  bottom: "res_stage_2_12_2"
  top: "res_stage_2_12_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_12_2"  
  type: "Scale"
  bottom: "res_stage_2_12_2"
  top: "res_stage_2_12_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_12_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_12_2_top"
  top: "res_stage_2_12_2_top"
}
layer {
  name: "res_stage_2_12_3"
  type: "Convolution"
  bottom: "res_stage_2_12_2_top"
  top: "res_stage_2_12_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_12_3"
  type: "BatchNorm"
  bottom: "res_stage_2_12_3"
  top: "res_stage_2_12_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_12_3"  
  type: "Scale"
  bottom: "res_stage_2_12_3"
  top: "res_stage_2_12_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_12"
  type: "Eltwise"
  bottom: "res_2_11"
  bottom: "res_stage_2_12_3_top"
  top: "res_2_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_12_relu"
  type: "ReLU"
  bottom: "res_2_12"
  top: "res_2_12"
}
layer {
  name: "res_stage_2_13_1"
  type: "Convolution"
  bottom: "res_2_12"
  top: "res_stage_2_13_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_13_1"
  type: "BatchNorm"
  bottom: "res_stage_2_13_1"
  top: "res_stage_2_13_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_13_1"  
  type: "Scale"
  bottom: "res_stage_2_13_1"
  top: "res_stage_2_13_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_13_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_13_1_top"
  top: "res_stage_2_13_1_top"
}
layer {
  name: "res_stage_2_13_2"
  type: "Convolution"
  bottom: "res_stage_2_13_1_top"
  top: "res_stage_2_13_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_13_2"
  type: "BatchNorm"
  bottom: "res_stage_2_13_2"
  top: "res_stage_2_13_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_13_2"  
  type: "Scale"
  bottom: "res_stage_2_13_2"
  top: "res_stage_2_13_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_13_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_13_2_top"
  top: "res_stage_2_13_2_top"
}
layer {
  name: "res_stage_2_13_3"
  type: "Convolution"
  bottom: "res_stage_2_13_2_top"
  top: "res_stage_2_13_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_13_3"
  type: "BatchNorm"
  bottom: "res_stage_2_13_3"
  top: "res_stage_2_13_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_13_3"  
  type: "Scale"
  bottom: "res_stage_2_13_3"
  top: "res_stage_2_13_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_13"
  type: "Eltwise"
  bottom: "res_2_12"
  bottom: "res_stage_2_13_3_top"
  top: "res_2_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_13_relu"
  type: "ReLU"
  bottom: "res_2_13"
  top: "res_2_13"
}
layer {
  name: "res_stage_2_14_1"
  type: "Convolution"
  bottom: "res_2_13"
  top: "res_stage_2_14_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_14_1"
  type: "BatchNorm"
  bottom: "res_stage_2_14_1"
  top: "res_stage_2_14_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_14_1"  
  type: "Scale"
  bottom: "res_stage_2_14_1"
  top: "res_stage_2_14_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_14_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_14_1_top"
  top: "res_stage_2_14_1_top"
}
layer {
  name: "res_stage_2_14_2"
  type: "Convolution"
  bottom: "res_stage_2_14_1_top"
  top: "res_stage_2_14_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_14_2"
  type: "BatchNorm"
  bottom: "res_stage_2_14_2"
  top: "res_stage_2_14_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_14_2"  
  type: "Scale"
  bottom: "res_stage_2_14_2"
  top: "res_stage_2_14_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_14_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_14_2_top"
  top: "res_stage_2_14_2_top"
}
layer {
  name: "res_stage_2_14_3"
  type: "Convolution"
  bottom: "res_stage_2_14_2_top"
  top: "res_stage_2_14_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_14_3"
  type: "BatchNorm"
  bottom: "res_stage_2_14_3"
  top: "res_stage_2_14_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_14_3"  
  type: "Scale"
  bottom: "res_stage_2_14_3"
  top: "res_stage_2_14_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_14"
  type: "Eltwise"
  bottom: "res_2_13"
  bottom: "res_stage_2_14_3_top"
  top: "res_2_14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_14_relu"
  type: "ReLU"
  bottom: "res_2_14"
  top: "res_2_14"
}
layer {
  name: "res_stage_2_15_1"
  type: "Convolution"
  bottom: "res_2_14"
  top: "res_stage_2_15_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_15_1"
  type: "BatchNorm"
  bottom: "res_stage_2_15_1"
  top: "res_stage_2_15_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_15_1"  
  type: "Scale"
  bottom: "res_stage_2_15_1"
  top: "res_stage_2_15_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_15_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_15_1_top"
  top: "res_stage_2_15_1_top"
}
layer {
  name: "res_stage_2_15_2"
  type: "Convolution"
  bottom: "res_stage_2_15_1_top"
  top: "res_stage_2_15_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_15_2"
  type: "BatchNorm"
  bottom: "res_stage_2_15_2"
  top: "res_stage_2_15_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_15_2"  
  type: "Scale"
  bottom: "res_stage_2_15_2"
  top: "res_stage_2_15_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_15_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_15_2_top"
  top: "res_stage_2_15_2_top"
}
layer {
  name: "res_stage_2_15_3"
  type: "Convolution"
  bottom: "res_stage_2_15_2_top"
  top: "res_stage_2_15_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_15_3"
  type: "BatchNorm"
  bottom: "res_stage_2_15_3"
  top: "res_stage_2_15_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_15_3"  
  type: "Scale"
  bottom: "res_stage_2_15_3"
  top: "res_stage_2_15_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_15"
  type: "Eltwise"
  bottom: "res_2_14"
  bottom: "res_stage_2_15_3_top"
  top: "res_2_15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_15_relu"
  type: "ReLU"
  bottom: "res_2_15"
  top: "res_2_15"
}
layer {
  name: "res_stage_2_16_1"
  type: "Convolution"
  bottom: "res_2_15"
  top: "res_stage_2_16_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_16_1"
  type: "BatchNorm"
  bottom: "res_stage_2_16_1"
  top: "res_stage_2_16_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_16_1"  
  type: "Scale"
  bottom: "res_stage_2_16_1"
  top: "res_stage_2_16_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_16_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_16_1_top"
  top: "res_stage_2_16_1_top"
}
layer {
  name: "res_stage_2_16_2"
  type: "Convolution"
  bottom: "res_stage_2_16_1_top"
  top: "res_stage_2_16_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_16_2"
  type: "BatchNorm"
  bottom: "res_stage_2_16_2"
  top: "res_stage_2_16_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_16_2"  
  type: "Scale"
  bottom: "res_stage_2_16_2"
  top: "res_stage_2_16_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_16_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_16_2_top"
  top: "res_stage_2_16_2_top"
}
layer {
  name: "res_stage_2_16_3"
  type: "Convolution"
  bottom: "res_stage_2_16_2_top"
  top: "res_stage_2_16_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_16_3"
  type: "BatchNorm"
  bottom: "res_stage_2_16_3"
  top: "res_stage_2_16_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_16_3"  
  type: "Scale"
  bottom: "res_stage_2_16_3"
  top: "res_stage_2_16_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_16"
  type: "Eltwise"
  bottom: "res_2_15"
  bottom: "res_stage_2_16_3_top"
  top: "res_2_16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_16_relu"
  type: "ReLU"
  bottom: "res_2_16"
  top: "res_2_16"
}
layer {
  name: "res_stage_2_17_1"
  type: "Convolution"
  bottom: "res_2_16"
  top: "res_stage_2_17_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_17_1"
  type: "BatchNorm"
  bottom: "res_stage_2_17_1"
  top: "res_stage_2_17_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_17_1"  
  type: "Scale"
  bottom: "res_stage_2_17_1"
  top: "res_stage_2_17_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_17_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_17_1_top"
  top: "res_stage_2_17_1_top"
}
layer {
  name: "res_stage_2_17_2"
  type: "Convolution"
  bottom: "res_stage_2_17_1_top"
  top: "res_stage_2_17_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_17_2"
  type: "BatchNorm"
  bottom: "res_stage_2_17_2"
  top: "res_stage_2_17_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_17_2"  
  type: "Scale"
  bottom: "res_stage_2_17_2"
  top: "res_stage_2_17_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_17_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_17_2_top"
  top: "res_stage_2_17_2_top"
}
layer {
  name: "res_stage_2_17_3"
  type: "Convolution"
  bottom: "res_stage_2_17_2_top"
  top: "res_stage_2_17_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_17_3"
  type: "BatchNorm"
  bottom: "res_stage_2_17_3"
  top: "res_stage_2_17_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_17_3"  
  type: "Scale"
  bottom: "res_stage_2_17_3"
  top: "res_stage_2_17_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_17"
  type: "Eltwise"
  bottom: "res_2_16"
  bottom: "res_stage_2_17_3_top"
  top: "res_2_17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_17_relu"
  type: "ReLU"
  bottom: "res_2_17"
  top: "res_2_17"
}
layer {
  name: "res_stage_2_18_1"
  type: "Convolution"
  bottom: "res_2_17"
  top: "res_stage_2_18_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_18_1"
  type: "BatchNorm"
  bottom: "res_stage_2_18_1"
  top: "res_stage_2_18_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_18_1"  
  type: "Scale"
  bottom: "res_stage_2_18_1"
  top: "res_stage_2_18_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_18_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_18_1_top"
  top: "res_stage_2_18_1_top"
}
layer {
  name: "res_stage_2_18_2"
  type: "Convolution"
  bottom: "res_stage_2_18_1_top"
  top: "res_stage_2_18_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_18_2"
  type: "BatchNorm"
  bottom: "res_stage_2_18_2"
  top: "res_stage_2_18_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_18_2"  
  type: "Scale"
  bottom: "res_stage_2_18_2"
  top: "res_stage_2_18_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_18_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_18_2_top"
  top: "res_stage_2_18_2_top"
}
layer {
  name: "res_stage_2_18_3"
  type: "Convolution"
  bottom: "res_stage_2_18_2_top"
  top: "res_stage_2_18_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_18_3"
  type: "BatchNorm"
  bottom: "res_stage_2_18_3"
  top: "res_stage_2_18_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_18_3"  
  type: "Scale"
  bottom: "res_stage_2_18_3"
  top: "res_stage_2_18_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_18"
  type: "Eltwise"
  bottom: "res_2_17"
  bottom: "res_stage_2_18_3_top"
  top: "res_2_18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_18_relu"
  type: "ReLU"
  bottom: "res_2_18"
  top: "res_2_18"
}
layer {
  name: "res_stage_2_19_1"
  type: "Convolution"
  bottom: "res_2_18"
  top: "res_stage_2_19_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_19_1"
  type: "BatchNorm"
  bottom: "res_stage_2_19_1"
  top: "res_stage_2_19_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_19_1"  
  type: "Scale"
  bottom: "res_stage_2_19_1"
  top: "res_stage_2_19_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_19_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_19_1_top"
  top: "res_stage_2_19_1_top"
}
layer {
  name: "res_stage_2_19_2"
  type: "Convolution"
  bottom: "res_stage_2_19_1_top"
  top: "res_stage_2_19_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_19_2"
  type: "BatchNorm"
  bottom: "res_stage_2_19_2"
  top: "res_stage_2_19_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_19_2"  
  type: "Scale"
  bottom: "res_stage_2_19_2"
  top: "res_stage_2_19_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_19_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_19_2_top"
  top: "res_stage_2_19_2_top"
}
layer {
  name: "res_stage_2_19_3"
  type: "Convolution"
  bottom: "res_stage_2_19_2_top"
  top: "res_stage_2_19_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_19_3"
  type: "BatchNorm"
  bottom: "res_stage_2_19_3"
  top: "res_stage_2_19_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_19_3"  
  type: "Scale"
  bottom: "res_stage_2_19_3"
  top: "res_stage_2_19_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_19"
  type: "Eltwise"
  bottom: "res_2_18"
  bottom: "res_stage_2_19_3_top"
  top: "res_2_19"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_19_relu"
  type: "ReLU"
  bottom: "res_2_19"
  top: "res_2_19"
}
layer {
  name: "res_stage_2_20_1"
  type: "Convolution"
  bottom: "res_2_19"
  top: "res_stage_2_20_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_20_1"
  type: "BatchNorm"
  bottom: "res_stage_2_20_1"
  top: "res_stage_2_20_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_20_1"  
  type: "Scale"
  bottom: "res_stage_2_20_1"
  top: "res_stage_2_20_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_20_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_20_1_top"
  top: "res_stage_2_20_1_top"
}
layer {
  name: "res_stage_2_20_2"
  type: "Convolution"
  bottom: "res_stage_2_20_1_top"
  top: "res_stage_2_20_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_20_2"
  type: "BatchNorm"
  bottom: "res_stage_2_20_2"
  top: "res_stage_2_20_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_20_2"  
  type: "Scale"
  bottom: "res_stage_2_20_2"
  top: "res_stage_2_20_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_20_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_20_2_top"
  top: "res_stage_2_20_2_top"
}
layer {
  name: "res_stage_2_20_3"
  type: "Convolution"
  bottom: "res_stage_2_20_2_top"
  top: "res_stage_2_20_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_20_3"
  type: "BatchNorm"
  bottom: "res_stage_2_20_3"
  top: "res_stage_2_20_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_20_3"  
  type: "Scale"
  bottom: "res_stage_2_20_3"
  top: "res_stage_2_20_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_20"
  type: "Eltwise"
  bottom: "res_2_19"
  bottom: "res_stage_2_20_3_top"
  top: "res_2_20"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_20_relu"
  type: "ReLU"
  bottom: "res_2_20"
  top: "res_2_20"
}
layer {
  name: "res_stage_2_21_1"
  type: "Convolution"
  bottom: "res_2_20"
  top: "res_stage_2_21_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_21_1"
  type: "BatchNorm"
  bottom: "res_stage_2_21_1"
  top: "res_stage_2_21_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_21_1"  
  type: "Scale"
  bottom: "res_stage_2_21_1"
  top: "res_stage_2_21_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_21_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_21_1_top"
  top: "res_stage_2_21_1_top"
}
layer {
  name: "res_stage_2_21_2"
  type: "Convolution"
  bottom: "res_stage_2_21_1_top"
  top: "res_stage_2_21_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_21_2"
  type: "BatchNorm"
  bottom: "res_stage_2_21_2"
  top: "res_stage_2_21_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_21_2"  
  type: "Scale"
  bottom: "res_stage_2_21_2"
  top: "res_stage_2_21_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_21_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_21_2_top"
  top: "res_stage_2_21_2_top"
}
layer {
  name: "res_stage_2_21_3"
  type: "Convolution"
  bottom: "res_stage_2_21_2_top"
  top: "res_stage_2_21_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_21_3"
  type: "BatchNorm"
  bottom: "res_stage_2_21_3"
  top: "res_stage_2_21_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_21_3"  
  type: "Scale"
  bottom: "res_stage_2_21_3"
  top: "res_stage_2_21_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_21"
  type: "Eltwise"
  bottom: "res_2_20"
  bottom: "res_stage_2_21_3_top"
  top: "res_2_21"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_21_relu"
  type: "ReLU"
  bottom: "res_2_21"
  top: "res_2_21"
}
layer {
  name: "res_stage_2_22_1"
  type: "Convolution"
  bottom: "res_2_21"
  top: "res_stage_2_22_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_22_1"
  type: "BatchNorm"
  bottom: "res_stage_2_22_1"
  top: "res_stage_2_22_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_22_1"  
  type: "Scale"
  bottom: "res_stage_2_22_1"
  top: "res_stage_2_22_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_22_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_22_1_top"
  top: "res_stage_2_22_1_top"
}
layer {
  name: "res_stage_2_22_2"
  type: "Convolution"
  bottom: "res_stage_2_22_1_top"
  top: "res_stage_2_22_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_22_2"
  type: "BatchNorm"
  bottom: "res_stage_2_22_2"
  top: "res_stage_2_22_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_22_2"  
  type: "Scale"
  bottom: "res_stage_2_22_2"
  top: "res_stage_2_22_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_22_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_22_2_top"
  top: "res_stage_2_22_2_top"
}
layer {
  name: "res_stage_2_22_3"
  type: "Convolution"
  bottom: "res_stage_2_22_2_top"
  top: "res_stage_2_22_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_22_3"
  type: "BatchNorm"
  bottom: "res_stage_2_22_3"
  top: "res_stage_2_22_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_22_3"  
  type: "Scale"
  bottom: "res_stage_2_22_3"
  top: "res_stage_2_22_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_22"
  type: "Eltwise"
  bottom: "res_2_21"
  bottom: "res_stage_2_22_3_top"
  top: "res_2_22"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_22_relu"
  type: "ReLU"
  bottom: "res_2_22"
  top: "res_2_22"
}
layer {
  name: "res_stage_2_23_1"
  type: "Convolution"
  bottom: "res_2_22"
  top: "res_stage_2_23_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_23_1"
  type: "BatchNorm"
  bottom: "res_stage_2_23_1"
  top: "res_stage_2_23_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_23_1"  
  type: "Scale"
  bottom: "res_stage_2_23_1"
  top: "res_stage_2_23_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_23_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_23_1_top"
  top: "res_stage_2_23_1_top"
}
layer {
  name: "res_stage_2_23_2"
  type: "Convolution"
  bottom: "res_stage_2_23_1_top"
  top: "res_stage_2_23_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_23_2"
  type: "BatchNorm"
  bottom: "res_stage_2_23_2"
  top: "res_stage_2_23_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_23_2"  
  type: "Scale"
  bottom: "res_stage_2_23_2"
  top: "res_stage_2_23_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_23_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_23_2_top"
  top: "res_stage_2_23_2_top"
}
layer {
  name: "res_stage_2_23_3"
  type: "Convolution"
  bottom: "res_stage_2_23_2_top"
  top: "res_stage_2_23_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_23_3"
  type: "BatchNorm"
  bottom: "res_stage_2_23_3"
  top: "res_stage_2_23_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_23_3"  
  type: "Scale"
  bottom: "res_stage_2_23_3"
  top: "res_stage_2_23_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_23"
  type: "Eltwise"
  bottom: "res_2_22"
  bottom: "res_stage_2_23_3_top"
  top: "res_2_23"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_23_relu"
  type: "ReLU"
  bottom: "res_2_23"
  top: "res_2_23"
}
layer {
  name: "res_stage_2_24_1"
  type: "Convolution"
  bottom: "res_2_23"
  top: "res_stage_2_24_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_24_1"
  type: "BatchNorm"
  bottom: "res_stage_2_24_1"
  top: "res_stage_2_24_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_24_1"  
  type: "Scale"
  bottom: "res_stage_2_24_1"
  top: "res_stage_2_24_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_24_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_24_1_top"
  top: "res_stage_2_24_1_top"
}
layer {
  name: "res_stage_2_24_2"
  type: "Convolution"
  bottom: "res_stage_2_24_1_top"
  top: "res_stage_2_24_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_24_2"
  type: "BatchNorm"
  bottom: "res_stage_2_24_2"
  top: "res_stage_2_24_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_24_2"  
  type: "Scale"
  bottom: "res_stage_2_24_2"
  top: "res_stage_2_24_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_24_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_24_2_top"
  top: "res_stage_2_24_2_top"
}
layer {
  name: "res_stage_2_24_3"
  type: "Convolution"
  bottom: "res_stage_2_24_2_top"
  top: "res_stage_2_24_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_24_3"
  type: "BatchNorm"
  bottom: "res_stage_2_24_3"
  top: "res_stage_2_24_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_24_3"  
  type: "Scale"
  bottom: "res_stage_2_24_3"
  top: "res_stage_2_24_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_24"
  type: "Eltwise"
  bottom: "res_2_23"
  bottom: "res_stage_2_24_3_top"
  top: "res_2_24"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_24_relu"
  type: "ReLU"
  bottom: "res_2_24"
  top: "res_2_24"
}
layer {
  name: "res_stage_2_25_1"
  type: "Convolution"
  bottom: "res_2_24"
  top: "res_stage_2_25_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_25_1"
  type: "BatchNorm"
  bottom: "res_stage_2_25_1"
  top: "res_stage_2_25_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_25_1"  
  type: "Scale"
  bottom: "res_stage_2_25_1"
  top: "res_stage_2_25_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_25_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_25_1_top"
  top: "res_stage_2_25_1_top"
}
layer {
  name: "res_stage_2_25_2"
  type: "Convolution"
  bottom: "res_stage_2_25_1_top"
  top: "res_stage_2_25_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_25_2"
  type: "BatchNorm"
  bottom: "res_stage_2_25_2"
  top: "res_stage_2_25_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_25_2"  
  type: "Scale"
  bottom: "res_stage_2_25_2"
  top: "res_stage_2_25_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_25_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_25_2_top"
  top: "res_stage_2_25_2_top"
}
layer {
  name: "res_stage_2_25_3"
  type: "Convolution"
  bottom: "res_stage_2_25_2_top"
  top: "res_stage_2_25_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_25_3"
  type: "BatchNorm"
  bottom: "res_stage_2_25_3"
  top: "res_stage_2_25_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_25_3"  
  type: "Scale"
  bottom: "res_stage_2_25_3"
  top: "res_stage_2_25_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_25"
  type: "Eltwise"
  bottom: "res_2_24"
  bottom: "res_stage_2_25_3_top"
  top: "res_2_25"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_25_relu"
  type: "ReLU"
  bottom: "res_2_25"
  top: "res_2_25"
}
layer {
  name: "res_stage_2_26_1"
  type: "Convolution"
  bottom: "res_2_25"
  top: "res_stage_2_26_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_26_1"
  type: "BatchNorm"
  bottom: "res_stage_2_26_1"
  top: "res_stage_2_26_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_26_1"  
  type: "Scale"
  bottom: "res_stage_2_26_1"
  top: "res_stage_2_26_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_26_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_26_1_top"
  top: "res_stage_2_26_1_top"
}
layer {
  name: "res_stage_2_26_2"
  type: "Convolution"
  bottom: "res_stage_2_26_1_top"
  top: "res_stage_2_26_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_26_2"
  type: "BatchNorm"
  bottom: "res_stage_2_26_2"
  top: "res_stage_2_26_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_26_2"  
  type: "Scale"
  bottom: "res_stage_2_26_2"
  top: "res_stage_2_26_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_26_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_26_2_top"
  top: "res_stage_2_26_2_top"
}
layer {
  name: "res_stage_2_26_3"
  type: "Convolution"
  bottom: "res_stage_2_26_2_top"
  top: "res_stage_2_26_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_26_3"
  type: "BatchNorm"
  bottom: "res_stage_2_26_3"
  top: "res_stage_2_26_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_26_3"  
  type: "Scale"
  bottom: "res_stage_2_26_3"
  top: "res_stage_2_26_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_26"
  type: "Eltwise"
  bottom: "res_2_25"
  bottom: "res_stage_2_26_3_top"
  top: "res_2_26"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_26_relu"
  type: "ReLU"
  bottom: "res_2_26"
  top: "res_2_26"
}
layer {
  name: "res_stage_2_27_1"
  type: "Convolution"
  bottom: "res_2_26"
  top: "res_stage_2_27_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_27_1"
  type: "BatchNorm"
  bottom: "res_stage_2_27_1"
  top: "res_stage_2_27_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_27_1"  
  type: "Scale"
  bottom: "res_stage_2_27_1"
  top: "res_stage_2_27_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_27_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_27_1_top"
  top: "res_stage_2_27_1_top"
}
layer {
  name: "res_stage_2_27_2"
  type: "Convolution"
  bottom: "res_stage_2_27_1_top"
  top: "res_stage_2_27_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_27_2"
  type: "BatchNorm"
  bottom: "res_stage_2_27_2"
  top: "res_stage_2_27_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_27_2"  
  type: "Scale"
  bottom: "res_stage_2_27_2"
  top: "res_stage_2_27_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_27_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_27_2_top"
  top: "res_stage_2_27_2_top"
}
layer {
  name: "res_stage_2_27_3"
  type: "Convolution"
  bottom: "res_stage_2_27_2_top"
  top: "res_stage_2_27_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_27_3"
  type: "BatchNorm"
  bottom: "res_stage_2_27_3"
  top: "res_stage_2_27_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_27_3"  
  type: "Scale"
  bottom: "res_stage_2_27_3"
  top: "res_stage_2_27_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_27"
  type: "Eltwise"
  bottom: "res_2_26"
  bottom: "res_stage_2_27_3_top"
  top: "res_2_27"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_27_relu"
  type: "ReLU"
  bottom: "res_2_27"
  top: "res_2_27"
}
layer {
  name: "res_stage_2_28_1"
  type: "Convolution"
  bottom: "res_2_27"
  top: "res_stage_2_28_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_28_1"
  type: "BatchNorm"
  bottom: "res_stage_2_28_1"
  top: "res_stage_2_28_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_28_1"  
  type: "Scale"
  bottom: "res_stage_2_28_1"
  top: "res_stage_2_28_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_28_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_28_1_top"
  top: "res_stage_2_28_1_top"
}
layer {
  name: "res_stage_2_28_2"
  type: "Convolution"
  bottom: "res_stage_2_28_1_top"
  top: "res_stage_2_28_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_28_2"
  type: "BatchNorm"
  bottom: "res_stage_2_28_2"
  top: "res_stage_2_28_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_28_2"  
  type: "Scale"
  bottom: "res_stage_2_28_2"
  top: "res_stage_2_28_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_28_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_28_2_top"
  top: "res_stage_2_28_2_top"
}
layer {
  name: "res_stage_2_28_3"
  type: "Convolution"
  bottom: "res_stage_2_28_2_top"
  top: "res_stage_2_28_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_28_3"
  type: "BatchNorm"
  bottom: "res_stage_2_28_3"
  top: "res_stage_2_28_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_28_3"  
  type: "Scale"
  bottom: "res_stage_2_28_3"
  top: "res_stage_2_28_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_28"
  type: "Eltwise"
  bottom: "res_2_27"
  bottom: "res_stage_2_28_3_top"
  top: "res_2_28"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_28_relu"
  type: "ReLU"
  bottom: "res_2_28"
  top: "res_2_28"
}
layer {
  name: "res_stage_2_29_1"
  type: "Convolution"
  bottom: "res_2_28"
  top: "res_stage_2_29_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_29_1"
  type: "BatchNorm"
  bottom: "res_stage_2_29_1"
  top: "res_stage_2_29_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_29_1"  
  type: "Scale"
  bottom: "res_stage_2_29_1"
  top: "res_stage_2_29_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_29_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_29_1_top"
  top: "res_stage_2_29_1_top"
}
layer {
  name: "res_stage_2_29_2"
  type: "Convolution"
  bottom: "res_stage_2_29_1_top"
  top: "res_stage_2_29_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_29_2"
  type: "BatchNorm"
  bottom: "res_stage_2_29_2"
  top: "res_stage_2_29_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_29_2"  
  type: "Scale"
  bottom: "res_stage_2_29_2"
  top: "res_stage_2_29_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_29_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_29_2_top"
  top: "res_stage_2_29_2_top"
}
layer {
  name: "res_stage_2_29_3"
  type: "Convolution"
  bottom: "res_stage_2_29_2_top"
  top: "res_stage_2_29_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_29_3"
  type: "BatchNorm"
  bottom: "res_stage_2_29_3"
  top: "res_stage_2_29_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_29_3"  
  type: "Scale"
  bottom: "res_stage_2_29_3"
  top: "res_stage_2_29_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_29"
  type: "Eltwise"
  bottom: "res_2_28"
  bottom: "res_stage_2_29_3_top"
  top: "res_2_29"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_29_relu"
  type: "ReLU"
  bottom: "res_2_29"
  top: "res_2_29"
}
layer {
  name: "res_stage_2_30_1"
  type: "Convolution"
  bottom: "res_2_29"
  top: "res_stage_2_30_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_30_1"
  type: "BatchNorm"
  bottom: "res_stage_2_30_1"
  top: "res_stage_2_30_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_30_1"  
  type: "Scale"
  bottom: "res_stage_2_30_1"
  top: "res_stage_2_30_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_30_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_30_1_top"
  top: "res_stage_2_30_1_top"
}
layer {
  name: "res_stage_2_30_2"
  type: "Convolution"
  bottom: "res_stage_2_30_1_top"
  top: "res_stage_2_30_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_30_2"
  type: "BatchNorm"
  bottom: "res_stage_2_30_2"
  top: "res_stage_2_30_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_30_2"  
  type: "Scale"
  bottom: "res_stage_2_30_2"
  top: "res_stage_2_30_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_30_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_30_2_top"
  top: "res_stage_2_30_2_top"
}
layer {
  name: "res_stage_2_30_3"
  type: "Convolution"
  bottom: "res_stage_2_30_2_top"
  top: "res_stage_2_30_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_30_3"
  type: "BatchNorm"
  bottom: "res_stage_2_30_3"
  top: "res_stage_2_30_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_30_3"  
  type: "Scale"
  bottom: "res_stage_2_30_3"
  top: "res_stage_2_30_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_30"
  type: "Eltwise"
  bottom: "res_2_29"
  bottom: "res_stage_2_30_3_top"
  top: "res_2_30"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_30_relu"
  type: "ReLU"
  bottom: "res_2_30"
  top: "res_2_30"
}
layer {
  name: "res_stage_2_31_1"
  type: "Convolution"
  bottom: "res_2_30"
  top: "res_stage_2_31_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_31_1"
  type: "BatchNorm"
  bottom: "res_stage_2_31_1"
  top: "res_stage_2_31_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_31_1"  
  type: "Scale"
  bottom: "res_stage_2_31_1"
  top: "res_stage_2_31_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_31_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_31_1_top"
  top: "res_stage_2_31_1_top"
}
layer {
  name: "res_stage_2_31_2"
  type: "Convolution"
  bottom: "res_stage_2_31_1_top"
  top: "res_stage_2_31_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_31_2"
  type: "BatchNorm"
  bottom: "res_stage_2_31_2"
  top: "res_stage_2_31_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_31_2"  
  type: "Scale"
  bottom: "res_stage_2_31_2"
  top: "res_stage_2_31_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_31_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_31_2_top"
  top: "res_stage_2_31_2_top"
}
layer {
  name: "res_stage_2_31_3"
  type: "Convolution"
  bottom: "res_stage_2_31_2_top"
  top: "res_stage_2_31_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_31_3"
  type: "BatchNorm"
  bottom: "res_stage_2_31_3"
  top: "res_stage_2_31_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_31_3"  
  type: "Scale"
  bottom: "res_stage_2_31_3"
  top: "res_stage_2_31_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_31"
  type: "Eltwise"
  bottom: "res_2_30"
  bottom: "res_stage_2_31_3_top"
  top: "res_2_31"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_31_relu"
  type: "ReLU"
  bottom: "res_2_31"
  top: "res_2_31"
}
layer {
  name: "res_stage_2_32_1"
  type: "Convolution"
  bottom: "res_2_31"
  top: "res_stage_2_32_1"
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_32_1"
  type: "BatchNorm"
  bottom: "res_stage_2_32_1"
  top: "res_stage_2_32_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_32_1"  
  type: "Scale"
  bottom: "res_stage_2_32_1"
  top: "res_stage_2_32_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_32_1_relu"
  type: "ReLU"
  bottom: "res_stage_2_32_1_top"
  top: "res_stage_2_32_1_top"
}
layer {
  name: "res_stage_2_32_2"
  type: "Convolution"
  bottom: "res_stage_2_32_1_top"
  top: "res_stage_2_32_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_32_2"
  type: "BatchNorm"
  bottom: "res_stage_2_32_2"
  top: "res_stage_2_32_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_32_2"  
  type: "Scale"
  bottom: "res_stage_2_32_2"
  top: "res_stage_2_32_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_2_32_2_relu"
  type: "ReLU"
  bottom: "res_stage_2_32_2_top"
  top: "res_stage_2_32_2_top"
}
layer {
  name: "res_stage_2_32_3"
  type: "Convolution"
  bottom: "res_stage_2_32_2_top"
  top: "res_stage_2_32_3"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_2_32_3"
  type: "BatchNorm"
  bottom: "res_stage_2_32_3"
  top: "res_stage_2_32_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_2_32_3"  
  type: "Scale"
  bottom: "res_stage_2_32_3"
  top: "res_stage_2_32_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_2_32"
  type: "Eltwise"
  bottom: "res_2_31"
  bottom: "res_stage_2_32_3_top"
  top: "res_2_32"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_2_32_relu"
  type: "ReLU"
  bottom: "res_2_32"
  top: "res_2_32"
}
layer {
  name: "res_3_branch1"
  type: "Convolution"
  bottom: "res_2_32"
  top: "res_3_branch1"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_3_branch1"
  type: "BatchNorm"
  bottom: "res_3_branch1"
  top: "res_3_branch1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_3_branch1"  
  type: "Scale"
  bottom: "res_3_branch1"
  top: "res_3_branch1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_1_1"
  type: "Convolution"
  bottom: "res_2_32"
  top: "res_stage_3_1_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_1_1"
  type: "BatchNorm"
  bottom: "res_stage_3_1_1"
  top: "res_stage_3_1_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_1_1"  
  type: "Scale"
  bottom: "res_stage_3_1_1"
  top: "res_stage_3_1_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_1_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_1_1_top"
  top: "res_stage_3_1_1_top"
}
layer {
  name: "res_stage_3_1_2"
  type: "Convolution"
  bottom: "res_stage_3_1_1_top"
  top: "res_stage_3_1_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_1_2"
  type: "BatchNorm"
  bottom: "res_stage_3_1_2"
  top: "res_stage_3_1_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_1_2"  
  type: "Scale"
  bottom: "res_stage_3_1_2"
  top: "res_stage_3_1_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_1_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_1_2_top"
  top: "res_stage_3_1_2_top"
}
layer {
  name: "res_stage_3_1_3"
  type: "Convolution"
  bottom: "res_stage_3_1_2_top"
  top: "res_stage_3_1_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_1_3"
  type: "BatchNorm"
  bottom: "res_stage_3_1_3"
  top: "res_stage_3_1_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_1_3"  
  type: "Scale"
  bottom: "res_stage_3_1_3"
  top: "res_stage_3_1_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_1"
  type: "Eltwise"
  bottom: "res_3_branch1_top"
  bottom: "res_stage_3_1_3_top"
  top: "res_3_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_1_relu"
  type: "ReLU"
  bottom: "res_3_1"
  top: "res_3_1"
}
layer {
  name: "res_stage_3_2_1"
  type: "Convolution"
  bottom: "res_3_1"
  top: "res_stage_3_2_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_2_1"
  type: "BatchNorm"
  bottom: "res_stage_3_2_1"
  top: "res_stage_3_2_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_2_1"  
  type: "Scale"
  bottom: "res_stage_3_2_1"
  top: "res_stage_3_2_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_2_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_2_1_top"
  top: "res_stage_3_2_1_top"
}
layer {
  name: "res_stage_3_2_2"
  type: "Convolution"
  bottom: "res_stage_3_2_1_top"
  top: "res_stage_3_2_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_2_2"
  type: "BatchNorm"
  bottom: "res_stage_3_2_2"
  top: "res_stage_3_2_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_2_2"  
  type: "Scale"
  bottom: "res_stage_3_2_2"
  top: "res_stage_3_2_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_2_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_2_2_top"
  top: "res_stage_3_2_2_top"
}
layer {
  name: "res_stage_3_2_3"
  type: "Convolution"
  bottom: "res_stage_3_2_2_top"
  top: "res_stage_3_2_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_2_3"
  type: "BatchNorm"
  bottom: "res_stage_3_2_3"
  top: "res_stage_3_2_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_2_3"  
  type: "Scale"
  bottom: "res_stage_3_2_3"
  top: "res_stage_3_2_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_2"
  type: "Eltwise"
  bottom: "res_3_1"
  bottom: "res_stage_3_2_3_top"
  top: "res_3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_2_relu"
  type: "ReLU"
  bottom: "res_3_2"
  top: "res_3_2"
}
layer {
  name: "res_stage_3_3_1"
  type: "Convolution"
  bottom: "res_3_2"
  top: "res_stage_3_3_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_3_1"
  type: "BatchNorm"
  bottom: "res_stage_3_3_1"
  top: "res_stage_3_3_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_3_1"  
  type: "Scale"
  bottom: "res_stage_3_3_1"
  top: "res_stage_3_3_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_3_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_3_1_top"
  top: "res_stage_3_3_1_top"
}
layer {
  name: "res_stage_3_3_2"
  type: "Convolution"
  bottom: "res_stage_3_3_1_top"
  top: "res_stage_3_3_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_3_2"
  type: "BatchNorm"
  bottom: "res_stage_3_3_2"
  top: "res_stage_3_3_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_3_2"  
  type: "Scale"
  bottom: "res_stage_3_3_2"
  top: "res_stage_3_3_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_3_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_3_2_top"
  top: "res_stage_3_3_2_top"
}
layer {
  name: "res_stage_3_3_3"
  type: "Convolution"
  bottom: "res_stage_3_3_2_top"
  top: "res_stage_3_3_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_3_3"
  type: "BatchNorm"
  bottom: "res_stage_3_3_3"
  top: "res_stage_3_3_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_3_3"  
  type: "Scale"
  bottom: "res_stage_3_3_3"
  top: "res_stage_3_3_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_3"
  type: "Eltwise"
  bottom: "res_3_2"
  bottom: "res_stage_3_3_3_top"
  top: "res_3_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_3_relu"
  type: "ReLU"
  bottom: "res_3_3"
  top: "res_3_3"
}
layer {
  name: "res_stage_3_4_1"
  type: "Convolution"
  bottom: "res_3_3"
  top: "res_stage_3_4_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_4_1"
  type: "BatchNorm"
  bottom: "res_stage_3_4_1"
  top: "res_stage_3_4_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_4_1"  
  type: "Scale"
  bottom: "res_stage_3_4_1"
  top: "res_stage_3_4_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_4_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_4_1_top"
  top: "res_stage_3_4_1_top"
}
layer {
  name: "res_stage_3_4_2"
  type: "Convolution"
  bottom: "res_stage_3_4_1_top"
  top: "res_stage_3_4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_4_2"
  type: "BatchNorm"
  bottom: "res_stage_3_4_2"
  top: "res_stage_3_4_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_4_2"  
  type: "Scale"
  bottom: "res_stage_3_4_2"
  top: "res_stage_3_4_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_4_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_4_2_top"
  top: "res_stage_3_4_2_top"
}
layer {
  name: "res_stage_3_4_3"
  type: "Convolution"
  bottom: "res_stage_3_4_2_top"
  top: "res_stage_3_4_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_4_3"
  type: "BatchNorm"
  bottom: "res_stage_3_4_3"
  top: "res_stage_3_4_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_4_3"  
  type: "Scale"
  bottom: "res_stage_3_4_3"
  top: "res_stage_3_4_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_4"
  type: "Eltwise"
  bottom: "res_3_3"
  bottom: "res_stage_3_4_3_top"
  top: "res_3_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_4_relu"
  type: "ReLU"
  bottom: "res_3_4"
  top: "res_3_4"
}
layer {
  name: "res_stage_3_5_1"
  type: "Convolution"
  bottom: "res_3_4"
  top: "res_stage_3_5_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_5_1"
  type: "BatchNorm"
  bottom: "res_stage_3_5_1"
  top: "res_stage_3_5_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_5_1"  
  type: "Scale"
  bottom: "res_stage_3_5_1"
  top: "res_stage_3_5_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_5_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_5_1_top"
  top: "res_stage_3_5_1_top"
}
layer {
  name: "res_stage_3_5_2"
  type: "Convolution"
  bottom: "res_stage_3_5_1_top"
  top: "res_stage_3_5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_5_2"
  type: "BatchNorm"
  bottom: "res_stage_3_5_2"
  top: "res_stage_3_5_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_5_2"  
  type: "Scale"
  bottom: "res_stage_3_5_2"
  top: "res_stage_3_5_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_5_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_5_2_top"
  top: "res_stage_3_5_2_top"
}
layer {
  name: "res_stage_3_5_3"
  type: "Convolution"
  bottom: "res_stage_3_5_2_top"
  top: "res_stage_3_5_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_5_3"
  type: "BatchNorm"
  bottom: "res_stage_3_5_3"
  top: "res_stage_3_5_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_5_3"  
  type: "Scale"
  bottom: "res_stage_3_5_3"
  top: "res_stage_3_5_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_5"
  type: "Eltwise"
  bottom: "res_3_4"
  bottom: "res_stage_3_5_3_top"
  top: "res_3_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_5_relu"
  type: "ReLU"
  bottom: "res_3_5"
  top: "res_3_5"
}
layer {
  name: "res_stage_3_6_1"
  type: "Convolution"
  bottom: "res_3_5"
  top: "res_stage_3_6_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_6_1"
  type: "BatchNorm"
  bottom: "res_stage_3_6_1"
  top: "res_stage_3_6_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_6_1"  
  type: "Scale"
  bottom: "res_stage_3_6_1"
  top: "res_stage_3_6_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_6_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_6_1_top"
  top: "res_stage_3_6_1_top"
}
layer {
  name: "res_stage_3_6_2"
  type: "Convolution"
  bottom: "res_stage_3_6_1_top"
  top: "res_stage_3_6_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_6_2"
  type: "BatchNorm"
  bottom: "res_stage_3_6_2"
  top: "res_stage_3_6_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_6_2"  
  type: "Scale"
  bottom: "res_stage_3_6_2"
  top: "res_stage_3_6_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_6_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_6_2_top"
  top: "res_stage_3_6_2_top"
}
layer {
  name: "res_stage_3_6_3"
  type: "Convolution"
  bottom: "res_stage_3_6_2_top"
  top: "res_stage_3_6_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_6_3"
  type: "BatchNorm"
  bottom: "res_stage_3_6_3"
  top: "res_stage_3_6_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_6_3"  
  type: "Scale"
  bottom: "res_stage_3_6_3"
  top: "res_stage_3_6_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_6"
  type: "Eltwise"
  bottom: "res_3_5"
  bottom: "res_stage_3_6_3_top"
  top: "res_3_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_6_relu"
  type: "ReLU"
  bottom: "res_3_6"
  top: "res_3_6"
}
layer {
  name: "res_stage_3_7_1"
  type: "Convolution"
  bottom: "res_3_6"
  top: "res_stage_3_7_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_7_1"
  type: "BatchNorm"
  bottom: "res_stage_3_7_1"
  top: "res_stage_3_7_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_7_1"  
  type: "Scale"
  bottom: "res_stage_3_7_1"
  top: "res_stage_3_7_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_7_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_7_1_top"
  top: "res_stage_3_7_1_top"
}
layer {
  name: "res_stage_3_7_2"
  type: "Convolution"
  bottom: "res_stage_3_7_1_top"
  top: "res_stage_3_7_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_7_2"
  type: "BatchNorm"
  bottom: "res_stage_3_7_2"
  top: "res_stage_3_7_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_7_2"  
  type: "Scale"
  bottom: "res_stage_3_7_2"
  top: "res_stage_3_7_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_7_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_7_2_top"
  top: "res_stage_3_7_2_top"
}
layer {
  name: "res_stage_3_7_3"
  type: "Convolution"
  bottom: "res_stage_3_7_2_top"
  top: "res_stage_3_7_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_7_3"
  type: "BatchNorm"
  bottom: "res_stage_3_7_3"
  top: "res_stage_3_7_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_7_3"  
  type: "Scale"
  bottom: "res_stage_3_7_3"
  top: "res_stage_3_7_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_7"
  type: "Eltwise"
  bottom: "res_3_6"
  bottom: "res_stage_3_7_3_top"
  top: "res_3_7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_7_relu"
  type: "ReLU"
  bottom: "res_3_7"
  top: "res_3_7"
}
layer {
  name: "res_stage_3_8_1"
  type: "Convolution"
  bottom: "res_3_7"
  top: "res_stage_3_8_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_8_1"
  type: "BatchNorm"
  bottom: "res_stage_3_8_1"
  top: "res_stage_3_8_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_8_1"  
  type: "Scale"
  bottom: "res_stage_3_8_1"
  top: "res_stage_3_8_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_8_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_8_1_top"
  top: "res_stage_3_8_1_top"
}
layer {
  name: "res_stage_3_8_2"
  type: "Convolution"
  bottom: "res_stage_3_8_1_top"
  top: "res_stage_3_8_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_8_2"
  type: "BatchNorm"
  bottom: "res_stage_3_8_2"
  top: "res_stage_3_8_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_8_2"  
  type: "Scale"
  bottom: "res_stage_3_8_2"
  top: "res_stage_3_8_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_8_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_8_2_top"
  top: "res_stage_3_8_2_top"
}
layer {
  name: "res_stage_3_8_3"
  type: "Convolution"
  bottom: "res_stage_3_8_2_top"
  top: "res_stage_3_8_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_8_3"
  type: "BatchNorm"
  bottom: "res_stage_3_8_3"
  top: "res_stage_3_8_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_8_3"  
  type: "Scale"
  bottom: "res_stage_3_8_3"
  top: "res_stage_3_8_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_8"
  type: "Eltwise"
  bottom: "res_3_7"
  bottom: "res_stage_3_8_3_top"
  top: "res_3_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_8_relu"
  type: "ReLU"
  bottom: "res_3_8"
  top: "res_3_8"
}
layer {
  name: "res_stage_3_9_1"
  type: "Convolution"
  bottom: "res_3_8"
  top: "res_stage_3_9_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_9_1"
  type: "BatchNorm"
  bottom: "res_stage_3_9_1"
  top: "res_stage_3_9_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_9_1"  
  type: "Scale"
  bottom: "res_stage_3_9_1"
  top: "res_stage_3_9_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_9_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_9_1_top"
  top: "res_stage_3_9_1_top"
}
layer {
  name: "res_stage_3_9_2"
  type: "Convolution"
  bottom: "res_stage_3_9_1_top"
  top: "res_stage_3_9_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_9_2"
  type: "BatchNorm"
  bottom: "res_stage_3_9_2"
  top: "res_stage_3_9_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_9_2"  
  type: "Scale"
  bottom: "res_stage_3_9_2"
  top: "res_stage_3_9_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_9_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_9_2_top"
  top: "res_stage_3_9_2_top"
}
layer {
  name: "res_stage_3_9_3"
  type: "Convolution"
  bottom: "res_stage_3_9_2_top"
  top: "res_stage_3_9_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_9_3"
  type: "BatchNorm"
  bottom: "res_stage_3_9_3"
  top: "res_stage_3_9_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_9_3"  
  type: "Scale"
  bottom: "res_stage_3_9_3"
  top: "res_stage_3_9_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_9"
  type: "Eltwise"
  bottom: "res_3_8"
  bottom: "res_stage_3_9_3_top"
  top: "res_3_9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_9_relu"
  type: "ReLU"
  bottom: "res_3_9"
  top: "res_3_9"
}
layer {
  name: "res_stage_3_10_1"
  type: "Convolution"
  bottom: "res_3_9"
  top: "res_stage_3_10_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_10_1"
  type: "BatchNorm"
  bottom: "res_stage_3_10_1"
  top: "res_stage_3_10_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_10_1"  
  type: "Scale"
  bottom: "res_stage_3_10_1"
  top: "res_stage_3_10_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_10_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_10_1_top"
  top: "res_stage_3_10_1_top"
}
layer {
  name: "res_stage_3_10_2"
  type: "Convolution"
  bottom: "res_stage_3_10_1_top"
  top: "res_stage_3_10_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_10_2"
  type: "BatchNorm"
  bottom: "res_stage_3_10_2"
  top: "res_stage_3_10_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_10_2"  
  type: "Scale"
  bottom: "res_stage_3_10_2"
  top: "res_stage_3_10_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_10_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_10_2_top"
  top: "res_stage_3_10_2_top"
}
layer {
  name: "res_stage_3_10_3"
  type: "Convolution"
  bottom: "res_stage_3_10_2_top"
  top: "res_stage_3_10_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_10_3"
  type: "BatchNorm"
  bottom: "res_stage_3_10_3"
  top: "res_stage_3_10_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_10_3"  
  type: "Scale"
  bottom: "res_stage_3_10_3"
  top: "res_stage_3_10_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_10"
  type: "Eltwise"
  bottom: "res_3_9"
  bottom: "res_stage_3_10_3_top"
  top: "res_3_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_10_relu"
  type: "ReLU"
  bottom: "res_3_10"
  top: "res_3_10"
}
layer {
  name: "res_stage_3_11_1"
  type: "Convolution"
  bottom: "res_3_10"
  top: "res_stage_3_11_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_11_1"
  type: "BatchNorm"
  bottom: "res_stage_3_11_1"
  top: "res_stage_3_11_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_11_1"  
  type: "Scale"
  bottom: "res_stage_3_11_1"
  top: "res_stage_3_11_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_11_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_11_1_top"
  top: "res_stage_3_11_1_top"
}
layer {
  name: "res_stage_3_11_2"
  type: "Convolution"
  bottom: "res_stage_3_11_1_top"
  top: "res_stage_3_11_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_11_2"
  type: "BatchNorm"
  bottom: "res_stage_3_11_2"
  top: "res_stage_3_11_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_11_2"  
  type: "Scale"
  bottom: "res_stage_3_11_2"
  top: "res_stage_3_11_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_11_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_11_2_top"
  top: "res_stage_3_11_2_top"
}
layer {
  name: "res_stage_3_11_3"
  type: "Convolution"
  bottom: "res_stage_3_11_2_top"
  top: "res_stage_3_11_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_11_3"
  type: "BatchNorm"
  bottom: "res_stage_3_11_3"
  top: "res_stage_3_11_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_11_3"  
  type: "Scale"
  bottom: "res_stage_3_11_3"
  top: "res_stage_3_11_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_11"
  type: "Eltwise"
  bottom: "res_3_10"
  bottom: "res_stage_3_11_3_top"
  top: "res_3_11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_11_relu"
  type: "ReLU"
  bottom: "res_3_11"
  top: "res_3_11"
}
layer {
  name: "res_stage_3_12_1"
  type: "Convolution"
  bottom: "res_3_11"
  top: "res_stage_3_12_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_12_1"
  type: "BatchNorm"
  bottom: "res_stage_3_12_1"
  top: "res_stage_3_12_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_12_1"  
  type: "Scale"
  bottom: "res_stage_3_12_1"
  top: "res_stage_3_12_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_12_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_12_1_top"
  top: "res_stage_3_12_1_top"
}
layer {
  name: "res_stage_3_12_2"
  type: "Convolution"
  bottom: "res_stage_3_12_1_top"
  top: "res_stage_3_12_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_12_2"
  type: "BatchNorm"
  bottom: "res_stage_3_12_2"
  top: "res_stage_3_12_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_12_2"  
  type: "Scale"
  bottom: "res_stage_3_12_2"
  top: "res_stage_3_12_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_12_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_12_2_top"
  top: "res_stage_3_12_2_top"
}
layer {
  name: "res_stage_3_12_3"
  type: "Convolution"
  bottom: "res_stage_3_12_2_top"
  top: "res_stage_3_12_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_12_3"
  type: "BatchNorm"
  bottom: "res_stage_3_12_3"
  top: "res_stage_3_12_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_12_3"  
  type: "Scale"
  bottom: "res_stage_3_12_3"
  top: "res_stage_3_12_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_12"
  type: "Eltwise"
  bottom: "res_3_11"
  bottom: "res_stage_3_12_3_top"
  top: "res_3_12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_12_relu"
  type: "ReLU"
  bottom: "res_3_12"
  top: "res_3_12"
}
layer {
  name: "res_stage_3_13_1"
  type: "Convolution"
  bottom: "res_3_12"
  top: "res_stage_3_13_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_13_1"
  type: "BatchNorm"
  bottom: "res_stage_3_13_1"
  top: "res_stage_3_13_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_13_1"  
  type: "Scale"
  bottom: "res_stage_3_13_1"
  top: "res_stage_3_13_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_13_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_13_1_top"
  top: "res_stage_3_13_1_top"
}
layer {
  name: "res_stage_3_13_2"
  type: "Convolution"
  bottom: "res_stage_3_13_1_top"
  top: "res_stage_3_13_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_13_2"
  type: "BatchNorm"
  bottom: "res_stage_3_13_2"
  top: "res_stage_3_13_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_13_2"  
  type: "Scale"
  bottom: "res_stage_3_13_2"
  top: "res_stage_3_13_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_13_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_13_2_top"
  top: "res_stage_3_13_2_top"
}
layer {
  name: "res_stage_3_13_3"
  type: "Convolution"
  bottom: "res_stage_3_13_2_top"
  top: "res_stage_3_13_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_13_3"
  type: "BatchNorm"
  bottom: "res_stage_3_13_3"
  top: "res_stage_3_13_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_13_3"  
  type: "Scale"
  bottom: "res_stage_3_13_3"
  top: "res_stage_3_13_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_13"
  type: "Eltwise"
  bottom: "res_3_12"
  bottom: "res_stage_3_13_3_top"
  top: "res_3_13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_13_relu"
  type: "ReLU"
  bottom: "res_3_13"
  top: "res_3_13"
}
layer {
  name: "res_stage_3_14_1"
  type: "Convolution"
  bottom: "res_3_13"
  top: "res_stage_3_14_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_14_1"
  type: "BatchNorm"
  bottom: "res_stage_3_14_1"
  top: "res_stage_3_14_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_14_1"  
  type: "Scale"
  bottom: "res_stage_3_14_1"
  top: "res_stage_3_14_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_14_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_14_1_top"
  top: "res_stage_3_14_1_top"
}
layer {
  name: "res_stage_3_14_2"
  type: "Convolution"
  bottom: "res_stage_3_14_1_top"
  top: "res_stage_3_14_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_14_2"
  type: "BatchNorm"
  bottom: "res_stage_3_14_2"
  top: "res_stage_3_14_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_14_2"  
  type: "Scale"
  bottom: "res_stage_3_14_2"
  top: "res_stage_3_14_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_14_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_14_2_top"
  top: "res_stage_3_14_2_top"
}
layer {
  name: "res_stage_3_14_3"
  type: "Convolution"
  bottom: "res_stage_3_14_2_top"
  top: "res_stage_3_14_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_14_3"
  type: "BatchNorm"
  bottom: "res_stage_3_14_3"
  top: "res_stage_3_14_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_14_3"  
  type: "Scale"
  bottom: "res_stage_3_14_3"
  top: "res_stage_3_14_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_14"
  type: "Eltwise"
  bottom: "res_3_13"
  bottom: "res_stage_3_14_3_top"
  top: "res_3_14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_14_relu"
  type: "ReLU"
  bottom: "res_3_14"
  top: "res_3_14"
}
layer {
  name: "res_stage_3_15_1"
  type: "Convolution"
  bottom: "res_3_14"
  top: "res_stage_3_15_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_15_1"
  type: "BatchNorm"
  bottom: "res_stage_3_15_1"
  top: "res_stage_3_15_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_15_1"  
  type: "Scale"
  bottom: "res_stage_3_15_1"
  top: "res_stage_3_15_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_15_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_15_1_top"
  top: "res_stage_3_15_1_top"
}
layer {
  name: "res_stage_3_15_2"
  type: "Convolution"
  bottom: "res_stage_3_15_1_top"
  top: "res_stage_3_15_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_15_2"
  type: "BatchNorm"
  bottom: "res_stage_3_15_2"
  top: "res_stage_3_15_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_15_2"  
  type: "Scale"
  bottom: "res_stage_3_15_2"
  top: "res_stage_3_15_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_15_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_15_2_top"
  top: "res_stage_3_15_2_top"
}
layer {
  name: "res_stage_3_15_3"
  type: "Convolution"
  bottom: "res_stage_3_15_2_top"
  top: "res_stage_3_15_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_15_3"
  type: "BatchNorm"
  bottom: "res_stage_3_15_3"
  top: "res_stage_3_15_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_15_3"  
  type: "Scale"
  bottom: "res_stage_3_15_3"
  top: "res_stage_3_15_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_15"
  type: "Eltwise"
  bottom: "res_3_14"
  bottom: "res_stage_3_15_3_top"
  top: "res_3_15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_15_relu"
  type: "ReLU"
  bottom: "res_3_15"
  top: "res_3_15"
}
layer {
  name: "res_stage_3_16_1"
  type: "Convolution"
  bottom: "res_3_15"
  top: "res_stage_3_16_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_16_1"
  type: "BatchNorm"
  bottom: "res_stage_3_16_1"
  top: "res_stage_3_16_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_16_1"  
  type: "Scale"
  bottom: "res_stage_3_16_1"
  top: "res_stage_3_16_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_16_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_16_1_top"
  top: "res_stage_3_16_1_top"
}
layer {
  name: "res_stage_3_16_2"
  type: "Convolution"
  bottom: "res_stage_3_16_1_top"
  top: "res_stage_3_16_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_16_2"
  type: "BatchNorm"
  bottom: "res_stage_3_16_2"
  top: "res_stage_3_16_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_16_2"  
  type: "Scale"
  bottom: "res_stage_3_16_2"
  top: "res_stage_3_16_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_16_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_16_2_top"
  top: "res_stage_3_16_2_top"
}
layer {
  name: "res_stage_3_16_3"
  type: "Convolution"
  bottom: "res_stage_3_16_2_top"
  top: "res_stage_3_16_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_16_3"
  type: "BatchNorm"
  bottom: "res_stage_3_16_3"
  top: "res_stage_3_16_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_16_3"  
  type: "Scale"
  bottom: "res_stage_3_16_3"
  top: "res_stage_3_16_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_16"
  type: "Eltwise"
  bottom: "res_3_15"
  bottom: "res_stage_3_16_3_top"
  top: "res_3_16"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_16_relu"
  type: "ReLU"
  bottom: "res_3_16"
  top: "res_3_16"
}
layer {
  name: "res_stage_3_17_1"
  type: "Convolution"
  bottom: "res_3_16"
  top: "res_stage_3_17_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_17_1"
  type: "BatchNorm"
  bottom: "res_stage_3_17_1"
  top: "res_stage_3_17_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_17_1"  
  type: "Scale"
  bottom: "res_stage_3_17_1"
  top: "res_stage_3_17_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_17_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_17_1_top"
  top: "res_stage_3_17_1_top"
}
layer {
  name: "res_stage_3_17_2"
  type: "Convolution"
  bottom: "res_stage_3_17_1_top"
  top: "res_stage_3_17_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_17_2"
  type: "BatchNorm"
  bottom: "res_stage_3_17_2"
  top: "res_stage_3_17_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_17_2"  
  type: "Scale"
  bottom: "res_stage_3_17_2"
  top: "res_stage_3_17_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_17_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_17_2_top"
  top: "res_stage_3_17_2_top"
}
layer {
  name: "res_stage_3_17_3"
  type: "Convolution"
  bottom: "res_stage_3_17_2_top"
  top: "res_stage_3_17_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_17_3"
  type: "BatchNorm"
  bottom: "res_stage_3_17_3"
  top: "res_stage_3_17_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_17_3"  
  type: "Scale"
  bottom: "res_stage_3_17_3"
  top: "res_stage_3_17_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_17"
  type: "Eltwise"
  bottom: "res_3_16"
  bottom: "res_stage_3_17_3_top"
  top: "res_3_17"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_17_relu"
  type: "ReLU"
  bottom: "res_3_17"
  top: "res_3_17"
}
layer {
  name: "res_stage_3_18_1"
  type: "Convolution"
  bottom: "res_3_17"
  top: "res_stage_3_18_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_18_1"
  type: "BatchNorm"
  bottom: "res_stage_3_18_1"
  top: "res_stage_3_18_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_18_1"  
  type: "Scale"
  bottom: "res_stage_3_18_1"
  top: "res_stage_3_18_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_18_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_18_1_top"
  top: "res_stage_3_18_1_top"
}
layer {
  name: "res_stage_3_18_2"
  type: "Convolution"
  bottom: "res_stage_3_18_1_top"
  top: "res_stage_3_18_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_18_2"
  type: "BatchNorm"
  bottom: "res_stage_3_18_2"
  top: "res_stage_3_18_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_18_2"  
  type: "Scale"
  bottom: "res_stage_3_18_2"
  top: "res_stage_3_18_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_18_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_18_2_top"
  top: "res_stage_3_18_2_top"
}
layer {
  name: "res_stage_3_18_3"
  type: "Convolution"
  bottom: "res_stage_3_18_2_top"
  top: "res_stage_3_18_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_18_3"
  type: "BatchNorm"
  bottom: "res_stage_3_18_3"
  top: "res_stage_3_18_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_18_3"  
  type: "Scale"
  bottom: "res_stage_3_18_3"
  top: "res_stage_3_18_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_18"
  type: "Eltwise"
  bottom: "res_3_17"
  bottom: "res_stage_3_18_3_top"
  top: "res_3_18"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_18_relu"
  type: "ReLU"
  bottom: "res_3_18"
  top: "res_3_18"
}
layer {
  name: "res_stage_3_19_1"
  type: "Convolution"
  bottom: "res_3_18"
  top: "res_stage_3_19_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_19_1"
  type: "BatchNorm"
  bottom: "res_stage_3_19_1"
  top: "res_stage_3_19_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_19_1"  
  type: "Scale"
  bottom: "res_stage_3_19_1"
  top: "res_stage_3_19_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_19_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_19_1_top"
  top: "res_stage_3_19_1_top"
}
layer {
  name: "res_stage_3_19_2"
  type: "Convolution"
  bottom: "res_stage_3_19_1_top"
  top: "res_stage_3_19_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_19_2"
  type: "BatchNorm"
  bottom: "res_stage_3_19_2"
  top: "res_stage_3_19_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_19_2"  
  type: "Scale"
  bottom: "res_stage_3_19_2"
  top: "res_stage_3_19_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_19_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_19_2_top"
  top: "res_stage_3_19_2_top"
}
layer {
  name: "res_stage_3_19_3"
  type: "Convolution"
  bottom: "res_stage_3_19_2_top"
  top: "res_stage_3_19_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_19_3"
  type: "BatchNorm"
  bottom: "res_stage_3_19_3"
  top: "res_stage_3_19_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_19_3"  
  type: "Scale"
  bottom: "res_stage_3_19_3"
  top: "res_stage_3_19_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_19"
  type: "Eltwise"
  bottom: "res_3_18"
  bottom: "res_stage_3_19_3_top"
  top: "res_3_19"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_19_relu"
  type: "ReLU"
  bottom: "res_3_19"
  top: "res_3_19"
}
layer {
  name: "res_stage_3_20_1"
  type: "Convolution"
  bottom: "res_3_19"
  top: "res_stage_3_20_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_20_1"
  type: "BatchNorm"
  bottom: "res_stage_3_20_1"
  top: "res_stage_3_20_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_20_1"  
  type: "Scale"
  bottom: "res_stage_3_20_1"
  top: "res_stage_3_20_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_20_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_20_1_top"
  top: "res_stage_3_20_1_top"
}
layer {
  name: "res_stage_3_20_2"
  type: "Convolution"
  bottom: "res_stage_3_20_1_top"
  top: "res_stage_3_20_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_20_2"
  type: "BatchNorm"
  bottom: "res_stage_3_20_2"
  top: "res_stage_3_20_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_20_2"  
  type: "Scale"
  bottom: "res_stage_3_20_2"
  top: "res_stage_3_20_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_20_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_20_2_top"
  top: "res_stage_3_20_2_top"
}
layer {
  name: "res_stage_3_20_3"
  type: "Convolution"
  bottom: "res_stage_3_20_2_top"
  top: "res_stage_3_20_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_20_3"
  type: "BatchNorm"
  bottom: "res_stage_3_20_3"
  top: "res_stage_3_20_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_20_3"  
  type: "Scale"
  bottom: "res_stage_3_20_3"
  top: "res_stage_3_20_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_20"
  type: "Eltwise"
  bottom: "res_3_19"
  bottom: "res_stage_3_20_3_top"
  top: "res_3_20"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_20_relu"
  type: "ReLU"
  bottom: "res_3_20"
  top: "res_3_20"
}
layer {
  name: "res_stage_3_21_1"
  type: "Convolution"
  bottom: "res_3_20"
  top: "res_stage_3_21_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_21_1"
  type: "BatchNorm"
  bottom: "res_stage_3_21_1"
  top: "res_stage_3_21_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_21_1"  
  type: "Scale"
  bottom: "res_stage_3_21_1"
  top: "res_stage_3_21_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_21_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_21_1_top"
  top: "res_stage_3_21_1_top"
}
layer {
  name: "res_stage_3_21_2"
  type: "Convolution"
  bottom: "res_stage_3_21_1_top"
  top: "res_stage_3_21_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_21_2"
  type: "BatchNorm"
  bottom: "res_stage_3_21_2"
  top: "res_stage_3_21_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_21_2"  
  type: "Scale"
  bottom: "res_stage_3_21_2"
  top: "res_stage_3_21_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_21_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_21_2_top"
  top: "res_stage_3_21_2_top"
}
layer {
  name: "res_stage_3_21_3"
  type: "Convolution"
  bottom: "res_stage_3_21_2_top"
  top: "res_stage_3_21_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_21_3"
  type: "BatchNorm"
  bottom: "res_stage_3_21_3"
  top: "res_stage_3_21_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_21_3"  
  type: "Scale"
  bottom: "res_stage_3_21_3"
  top: "res_stage_3_21_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_21"
  type: "Eltwise"
  bottom: "res_3_20"
  bottom: "res_stage_3_21_3_top"
  top: "res_3_21"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_21_relu"
  type: "ReLU"
  bottom: "res_3_21"
  top: "res_3_21"
}
layer {
  name: "res_stage_3_22_1"
  type: "Convolution"
  bottom: "res_3_21"
  top: "res_stage_3_22_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_22_1"
  type: "BatchNorm"
  bottom: "res_stage_3_22_1"
  top: "res_stage_3_22_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_22_1"  
  type: "Scale"
  bottom: "res_stage_3_22_1"
  top: "res_stage_3_22_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_22_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_22_1_top"
  top: "res_stage_3_22_1_top"
}
layer {
  name: "res_stage_3_22_2"
  type: "Convolution"
  bottom: "res_stage_3_22_1_top"
  top: "res_stage_3_22_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_22_2"
  type: "BatchNorm"
  bottom: "res_stage_3_22_2"
  top: "res_stage_3_22_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_22_2"  
  type: "Scale"
  bottom: "res_stage_3_22_2"
  top: "res_stage_3_22_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_22_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_22_2_top"
  top: "res_stage_3_22_2_top"
}
layer {
  name: "res_stage_3_22_3"
  type: "Convolution"
  bottom: "res_stage_3_22_2_top"
  top: "res_stage_3_22_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_22_3"
  type: "BatchNorm"
  bottom: "res_stage_3_22_3"
  top: "res_stage_3_22_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_22_3"  
  type: "Scale"
  bottom: "res_stage_3_22_3"
  top: "res_stage_3_22_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_22"
  type: "Eltwise"
  bottom: "res_3_21"
  bottom: "res_stage_3_22_3_top"
  top: "res_3_22"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_22_relu"
  type: "ReLU"
  bottom: "res_3_22"
  top: "res_3_22"
}
layer {
  name: "res_stage_3_23_1"
  type: "Convolution"
  bottom: "res_3_22"
  top: "res_stage_3_23_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_23_1"
  type: "BatchNorm"
  bottom: "res_stage_3_23_1"
  top: "res_stage_3_23_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_23_1"  
  type: "Scale"
  bottom: "res_stage_3_23_1"
  top: "res_stage_3_23_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_23_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_23_1_top"
  top: "res_stage_3_23_1_top"
}
layer {
  name: "res_stage_3_23_2"
  type: "Convolution"
  bottom: "res_stage_3_23_1_top"
  top: "res_stage_3_23_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_23_2"
  type: "BatchNorm"
  bottom: "res_stage_3_23_2"
  top: "res_stage_3_23_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_23_2"  
  type: "Scale"
  bottom: "res_stage_3_23_2"
  top: "res_stage_3_23_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_23_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_23_2_top"
  top: "res_stage_3_23_2_top"
}
layer {
  name: "res_stage_3_23_3"
  type: "Convolution"
  bottom: "res_stage_3_23_2_top"
  top: "res_stage_3_23_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_23_3"
  type: "BatchNorm"
  bottom: "res_stage_3_23_3"
  top: "res_stage_3_23_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_23_3"  
  type: "Scale"
  bottom: "res_stage_3_23_3"
  top: "res_stage_3_23_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_23"
  type: "Eltwise"
  bottom: "res_3_22"
  bottom: "res_stage_3_23_3_top"
  top: "res_3_23"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_23_relu"
  type: "ReLU"
  bottom: "res_3_23"
  top: "res_3_23"
}
layer {
  name: "res_stage_3_24_1"
  type: "Convolution"
  bottom: "res_3_23"
  top: "res_stage_3_24_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_24_1"
  type: "BatchNorm"
  bottom: "res_stage_3_24_1"
  top: "res_stage_3_24_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_24_1"  
  type: "Scale"
  bottom: "res_stage_3_24_1"
  top: "res_stage_3_24_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_24_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_24_1_top"
  top: "res_stage_3_24_1_top"
}
layer {
  name: "res_stage_3_24_2"
  type: "Convolution"
  bottom: "res_stage_3_24_1_top"
  top: "res_stage_3_24_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_24_2"
  type: "BatchNorm"
  bottom: "res_stage_3_24_2"
  top: "res_stage_3_24_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_24_2"  
  type: "Scale"
  bottom: "res_stage_3_24_2"
  top: "res_stage_3_24_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_24_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_24_2_top"
  top: "res_stage_3_24_2_top"
}
layer {
  name: "res_stage_3_24_3"
  type: "Convolution"
  bottom: "res_stage_3_24_2_top"
  top: "res_stage_3_24_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_24_3"
  type: "BatchNorm"
  bottom: "res_stage_3_24_3"
  top: "res_stage_3_24_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_24_3"  
  type: "Scale"
  bottom: "res_stage_3_24_3"
  top: "res_stage_3_24_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_24"
  type: "Eltwise"
  bottom: "res_3_23"
  bottom: "res_stage_3_24_3_top"
  top: "res_3_24"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_24_relu"
  type: "ReLU"
  bottom: "res_3_24"
  top: "res_3_24"
}
layer {
  name: "res_stage_3_25_1"
  type: "Convolution"
  bottom: "res_3_24"
  top: "res_stage_3_25_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_25_1"
  type: "BatchNorm"
  bottom: "res_stage_3_25_1"
  top: "res_stage_3_25_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_25_1"  
  type: "Scale"
  bottom: "res_stage_3_25_1"
  top: "res_stage_3_25_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_25_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_25_1_top"
  top: "res_stage_3_25_1_top"
}
layer {
  name: "res_stage_3_25_2"
  type: "Convolution"
  bottom: "res_stage_3_25_1_top"
  top: "res_stage_3_25_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_25_2"
  type: "BatchNorm"
  bottom: "res_stage_3_25_2"
  top: "res_stage_3_25_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_25_2"  
  type: "Scale"
  bottom: "res_stage_3_25_2"
  top: "res_stage_3_25_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_25_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_25_2_top"
  top: "res_stage_3_25_2_top"
}
layer {
  name: "res_stage_3_25_3"
  type: "Convolution"
  bottom: "res_stage_3_25_2_top"
  top: "res_stage_3_25_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_25_3"
  type: "BatchNorm"
  bottom: "res_stage_3_25_3"
  top: "res_stage_3_25_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_25_3"  
  type: "Scale"
  bottom: "res_stage_3_25_3"
  top: "res_stage_3_25_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_25"
  type: "Eltwise"
  bottom: "res_3_24"
  bottom: "res_stage_3_25_3_top"
  top: "res_3_25"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_25_relu"
  type: "ReLU"
  bottom: "res_3_25"
  top: "res_3_25"
}
layer {
  name: "res_stage_3_26_1"
  type: "Convolution"
  bottom: "res_3_25"
  top: "res_stage_3_26_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_26_1"
  type: "BatchNorm"
  bottom: "res_stage_3_26_1"
  top: "res_stage_3_26_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_26_1"  
  type: "Scale"
  bottom: "res_stage_3_26_1"
  top: "res_stage_3_26_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_26_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_26_1_top"
  top: "res_stage_3_26_1_top"
}
layer {
  name: "res_stage_3_26_2"
  type: "Convolution"
  bottom: "res_stage_3_26_1_top"
  top: "res_stage_3_26_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_26_2"
  type: "BatchNorm"
  bottom: "res_stage_3_26_2"
  top: "res_stage_3_26_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_26_2"  
  type: "Scale"
  bottom: "res_stage_3_26_2"
  top: "res_stage_3_26_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_26_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_26_2_top"
  top: "res_stage_3_26_2_top"
}
layer {
  name: "res_stage_3_26_3"
  type: "Convolution"
  bottom: "res_stage_3_26_2_top"
  top: "res_stage_3_26_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_26_3"
  type: "BatchNorm"
  bottom: "res_stage_3_26_3"
  top: "res_stage_3_26_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_26_3"  
  type: "Scale"
  bottom: "res_stage_3_26_3"
  top: "res_stage_3_26_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_26"
  type: "Eltwise"
  bottom: "res_3_25"
  bottom: "res_stage_3_26_3_top"
  top: "res_3_26"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_26_relu"
  type: "ReLU"
  bottom: "res_3_26"
  top: "res_3_26"
}
layer {
  name: "res_stage_3_27_1"
  type: "Convolution"
  bottom: "res_3_26"
  top: "res_stage_3_27_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_27_1"
  type: "BatchNorm"
  bottom: "res_stage_3_27_1"
  top: "res_stage_3_27_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_27_1"  
  type: "Scale"
  bottom: "res_stage_3_27_1"
  top: "res_stage_3_27_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_27_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_27_1_top"
  top: "res_stage_3_27_1_top"
}
layer {
  name: "res_stage_3_27_2"
  type: "Convolution"
  bottom: "res_stage_3_27_1_top"
  top: "res_stage_3_27_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_27_2"
  type: "BatchNorm"
  bottom: "res_stage_3_27_2"
  top: "res_stage_3_27_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_27_2"  
  type: "Scale"
  bottom: "res_stage_3_27_2"
  top: "res_stage_3_27_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_27_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_27_2_top"
  top: "res_stage_3_27_2_top"
}
layer {
  name: "res_stage_3_27_3"
  type: "Convolution"
  bottom: "res_stage_3_27_2_top"
  top: "res_stage_3_27_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_27_3"
  type: "BatchNorm"
  bottom: "res_stage_3_27_3"
  top: "res_stage_3_27_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_27_3"  
  type: "Scale"
  bottom: "res_stage_3_27_3"
  top: "res_stage_3_27_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_27"
  type: "Eltwise"
  bottom: "res_3_26"
  bottom: "res_stage_3_27_3_top"
  top: "res_3_27"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_27_relu"
  type: "ReLU"
  bottom: "res_3_27"
  top: "res_3_27"
}
layer {
  name: "res_stage_3_28_1"
  type: "Convolution"
  bottom: "res_3_27"
  top: "res_stage_3_28_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_28_1"
  type: "BatchNorm"
  bottom: "res_stage_3_28_1"
  top: "res_stage_3_28_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_28_1"  
  type: "Scale"
  bottom: "res_stage_3_28_1"
  top: "res_stage_3_28_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_28_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_28_1_top"
  top: "res_stage_3_28_1_top"
}
layer {
  name: "res_stage_3_28_2"
  type: "Convolution"
  bottom: "res_stage_3_28_1_top"
  top: "res_stage_3_28_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_28_2"
  type: "BatchNorm"
  bottom: "res_stage_3_28_2"
  top: "res_stage_3_28_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_28_2"  
  type: "Scale"
  bottom: "res_stage_3_28_2"
  top: "res_stage_3_28_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_28_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_28_2_top"
  top: "res_stage_3_28_2_top"
}
layer {
  name: "res_stage_3_28_3"
  type: "Convolution"
  bottom: "res_stage_3_28_2_top"
  top: "res_stage_3_28_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_28_3"
  type: "BatchNorm"
  bottom: "res_stage_3_28_3"
  top: "res_stage_3_28_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_28_3"  
  type: "Scale"
  bottom: "res_stage_3_28_3"
  top: "res_stage_3_28_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_28"
  type: "Eltwise"
  bottom: "res_3_27"
  bottom: "res_stage_3_28_3_top"
  top: "res_3_28"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_28_relu"
  type: "ReLU"
  bottom: "res_3_28"
  top: "res_3_28"
}
layer {
  name: "res_stage_3_29_1"
  type: "Convolution"
  bottom: "res_3_28"
  top: "res_stage_3_29_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_29_1"
  type: "BatchNorm"
  bottom: "res_stage_3_29_1"
  top: "res_stage_3_29_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_29_1"  
  type: "Scale"
  bottom: "res_stage_3_29_1"
  top: "res_stage_3_29_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_29_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_29_1_top"
  top: "res_stage_3_29_1_top"
}
layer {
  name: "res_stage_3_29_2"
  type: "Convolution"
  bottom: "res_stage_3_29_1_top"
  top: "res_stage_3_29_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_29_2"
  type: "BatchNorm"
  bottom: "res_stage_3_29_2"
  top: "res_stage_3_29_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_29_2"  
  type: "Scale"
  bottom: "res_stage_3_29_2"
  top: "res_stage_3_29_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_29_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_29_2_top"
  top: "res_stage_3_29_2_top"
}
layer {
  name: "res_stage_3_29_3"
  type: "Convolution"
  bottom: "res_stage_3_29_2_top"
  top: "res_stage_3_29_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_29_3"
  type: "BatchNorm"
  bottom: "res_stage_3_29_3"
  top: "res_stage_3_29_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_29_3"  
  type: "Scale"
  bottom: "res_stage_3_29_3"
  top: "res_stage_3_29_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_29"
  type: "Eltwise"
  bottom: "res_3_28"
  bottom: "res_stage_3_29_3_top"
  top: "res_3_29"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_29_relu"
  type: "ReLU"
  bottom: "res_3_29"
  top: "res_3_29"
}
layer {
  name: "res_stage_3_30_1"
  type: "Convolution"
  bottom: "res_3_29"
  top: "res_stage_3_30_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_30_1"
  type: "BatchNorm"
  bottom: "res_stage_3_30_1"
  top: "res_stage_3_30_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_30_1"  
  type: "Scale"
  bottom: "res_stage_3_30_1"
  top: "res_stage_3_30_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_30_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_30_1_top"
  top: "res_stage_3_30_1_top"
}
layer {
  name: "res_stage_3_30_2"
  type: "Convolution"
  bottom: "res_stage_3_30_1_top"
  top: "res_stage_3_30_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_30_2"
  type: "BatchNorm"
  bottom: "res_stage_3_30_2"
  top: "res_stage_3_30_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_30_2"  
  type: "Scale"
  bottom: "res_stage_3_30_2"
  top: "res_stage_3_30_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_30_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_30_2_top"
  top: "res_stage_3_30_2_top"
}
layer {
  name: "res_stage_3_30_3"
  type: "Convolution"
  bottom: "res_stage_3_30_2_top"
  top: "res_stage_3_30_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_30_3"
  type: "BatchNorm"
  bottom: "res_stage_3_30_3"
  top: "res_stage_3_30_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_30_3"  
  type: "Scale"
  bottom: "res_stage_3_30_3"
  top: "res_stage_3_30_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_30"
  type: "Eltwise"
  bottom: "res_3_29"
  bottom: "res_stage_3_30_3_top"
  top: "res_3_30"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_30_relu"
  type: "ReLU"
  bottom: "res_3_30"
  top: "res_3_30"
}
layer {
  name: "res_stage_3_31_1"
  type: "Convolution"
  bottom: "res_3_30"
  top: "res_stage_3_31_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_31_1"
  type: "BatchNorm"
  bottom: "res_stage_3_31_1"
  top: "res_stage_3_31_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_31_1"  
  type: "Scale"
  bottom: "res_stage_3_31_1"
  top: "res_stage_3_31_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_31_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_31_1_top"
  top: "res_stage_3_31_1_top"
}
layer {
  name: "res_stage_3_31_2"
  type: "Convolution"
  bottom: "res_stage_3_31_1_top"
  top: "res_stage_3_31_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_31_2"
  type: "BatchNorm"
  bottom: "res_stage_3_31_2"
  top: "res_stage_3_31_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_31_2"  
  type: "Scale"
  bottom: "res_stage_3_31_2"
  top: "res_stage_3_31_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_31_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_31_2_top"
  top: "res_stage_3_31_2_top"
}
layer {
  name: "res_stage_3_31_3"
  type: "Convolution"
  bottom: "res_stage_3_31_2_top"
  top: "res_stage_3_31_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_31_3"
  type: "BatchNorm"
  bottom: "res_stage_3_31_3"
  top: "res_stage_3_31_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_31_3"  
  type: "Scale"
  bottom: "res_stage_3_31_3"
  top: "res_stage_3_31_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_31"
  type: "Eltwise"
  bottom: "res_3_30"
  bottom: "res_stage_3_31_3_top"
  top: "res_3_31"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_31_relu"
  type: "ReLU"
  bottom: "res_3_31"
  top: "res_3_31"
}
layer {
  name: "res_stage_3_32_1"
  type: "Convolution"
  bottom: "res_3_31"
  top: "res_stage_3_32_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_32_1"
  type: "BatchNorm"
  bottom: "res_stage_3_32_1"
  top: "res_stage_3_32_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_32_1"  
  type: "Scale"
  bottom: "res_stage_3_32_1"
  top: "res_stage_3_32_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_32_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_32_1_top"
  top: "res_stage_3_32_1_top"
}
layer {
  name: "res_stage_3_32_2"
  type: "Convolution"
  bottom: "res_stage_3_32_1_top"
  top: "res_stage_3_32_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_32_2"
  type: "BatchNorm"
  bottom: "res_stage_3_32_2"
  top: "res_stage_3_32_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_32_2"  
  type: "Scale"
  bottom: "res_stage_3_32_2"
  top: "res_stage_3_32_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_32_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_32_2_top"
  top: "res_stage_3_32_2_top"
}
layer {
  name: "res_stage_3_32_3"
  type: "Convolution"
  bottom: "res_stage_3_32_2_top"
  top: "res_stage_3_32_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_32_3"
  type: "BatchNorm"
  bottom: "res_stage_3_32_3"
  top: "res_stage_3_32_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_32_3"  
  type: "Scale"
  bottom: "res_stage_3_32_3"
  top: "res_stage_3_32_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_32"
  type: "Eltwise"
  bottom: "res_3_31"
  bottom: "res_stage_3_32_3_top"
  top: "res_3_32"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_32_relu"
  type: "ReLU"
  bottom: "res_3_32"
  top: "res_3_32"
}
layer {
  name: "res_stage_3_33_1"
  type: "Convolution"
  bottom: "res_3_32"
  top: "res_stage_3_33_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_33_1"
  type: "BatchNorm"
  bottom: "res_stage_3_33_1"
  top: "res_stage_3_33_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_33_1"  
  type: "Scale"
  bottom: "res_stage_3_33_1"
  top: "res_stage_3_33_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_33_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_33_1_top"
  top: "res_stage_3_33_1_top"
}
layer {
  name: "res_stage_3_33_2"
  type: "Convolution"
  bottom: "res_stage_3_33_1_top"
  top: "res_stage_3_33_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_33_2"
  type: "BatchNorm"
  bottom: "res_stage_3_33_2"
  top: "res_stage_3_33_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_33_2"  
  type: "Scale"
  bottom: "res_stage_3_33_2"
  top: "res_stage_3_33_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_33_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_33_2_top"
  top: "res_stage_3_33_2_top"
}
layer {
  name: "res_stage_3_33_3"
  type: "Convolution"
  bottom: "res_stage_3_33_2_top"
  top: "res_stage_3_33_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_33_3"
  type: "BatchNorm"
  bottom: "res_stage_3_33_3"
  top: "res_stage_3_33_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_33_3"  
  type: "Scale"
  bottom: "res_stage_3_33_3"
  top: "res_stage_3_33_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_33"
  type: "Eltwise"
  bottom: "res_3_32"
  bottom: "res_stage_3_33_3_top"
  top: "res_3_33"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_33_relu"
  type: "ReLU"
  bottom: "res_3_33"
  top: "res_3_33"
}
layer {
  name: "res_stage_3_34_1"
  type: "Convolution"
  bottom: "res_3_33"
  top: "res_stage_3_34_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_34_1"
  type: "BatchNorm"
  bottom: "res_stage_3_34_1"
  top: "res_stage_3_34_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_34_1"  
  type: "Scale"
  bottom: "res_stage_3_34_1"
  top: "res_stage_3_34_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_34_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_34_1_top"
  top: "res_stage_3_34_1_top"
}
layer {
  name: "res_stage_3_34_2"
  type: "Convolution"
  bottom: "res_stage_3_34_1_top"
  top: "res_stage_3_34_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_34_2"
  type: "BatchNorm"
  bottom: "res_stage_3_34_2"
  top: "res_stage_3_34_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_34_2"  
  type: "Scale"
  bottom: "res_stage_3_34_2"
  top: "res_stage_3_34_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_34_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_34_2_top"
  top: "res_stage_3_34_2_top"
}
layer {
  name: "res_stage_3_34_3"
  type: "Convolution"
  bottom: "res_stage_3_34_2_top"
  top: "res_stage_3_34_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_34_3"
  type: "BatchNorm"
  bottom: "res_stage_3_34_3"
  top: "res_stage_3_34_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_34_3"  
  type: "Scale"
  bottom: "res_stage_3_34_3"
  top: "res_stage_3_34_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_34"
  type: "Eltwise"
  bottom: "res_3_33"
  bottom: "res_stage_3_34_3_top"
  top: "res_3_34"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_34_relu"
  type: "ReLU"
  bottom: "res_3_34"
  top: "res_3_34"
}
layer {
  name: "res_stage_3_35_1"
  type: "Convolution"
  bottom: "res_3_34"
  top: "res_stage_3_35_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_35_1"
  type: "BatchNorm"
  bottom: "res_stage_3_35_1"
  top: "res_stage_3_35_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_35_1"  
  type: "Scale"
  bottom: "res_stage_3_35_1"
  top: "res_stage_3_35_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_35_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_35_1_top"
  top: "res_stage_3_35_1_top"
}
layer {
  name: "res_stage_3_35_2"
  type: "Convolution"
  bottom: "res_stage_3_35_1_top"
  top: "res_stage_3_35_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_35_2"
  type: "BatchNorm"
  bottom: "res_stage_3_35_2"
  top: "res_stage_3_35_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_35_2"  
  type: "Scale"
  bottom: "res_stage_3_35_2"
  top: "res_stage_3_35_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_35_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_35_2_top"
  top: "res_stage_3_35_2_top"
}
layer {
  name: "res_stage_3_35_3"
  type: "Convolution"
  bottom: "res_stage_3_35_2_top"
  top: "res_stage_3_35_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_35_3"
  type: "BatchNorm"
  bottom: "res_stage_3_35_3"
  top: "res_stage_3_35_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_35_3"  
  type: "Scale"
  bottom: "res_stage_3_35_3"
  top: "res_stage_3_35_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_35"
  type: "Eltwise"
  bottom: "res_3_34"
  bottom: "res_stage_3_35_3_top"
  top: "res_3_35"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_35_relu"
  type: "ReLU"
  bottom: "res_3_35"
  top: "res_3_35"
}
layer {
  name: "res_stage_3_36_1"
  type: "Convolution"
  bottom: "res_3_35"
  top: "res_stage_3_36_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_36_1"
  type: "BatchNorm"
  bottom: "res_stage_3_36_1"
  top: "res_stage_3_36_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_36_1"  
  type: "Scale"
  bottom: "res_stage_3_36_1"
  top: "res_stage_3_36_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_36_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_36_1_top"
  top: "res_stage_3_36_1_top"
}
layer {
  name: "res_stage_3_36_2"
  type: "Convolution"
  bottom: "res_stage_3_36_1_top"
  top: "res_stage_3_36_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_36_2"
  type: "BatchNorm"
  bottom: "res_stage_3_36_2"
  top: "res_stage_3_36_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_36_2"  
  type: "Scale"
  bottom: "res_stage_3_36_2"
  top: "res_stage_3_36_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_36_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_36_2_top"
  top: "res_stage_3_36_2_top"
}
layer {
  name: "res_stage_3_36_3"
  type: "Convolution"
  bottom: "res_stage_3_36_2_top"
  top: "res_stage_3_36_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_36_3"
  type: "BatchNorm"
  bottom: "res_stage_3_36_3"
  top: "res_stage_3_36_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_36_3"  
  type: "Scale"
  bottom: "res_stage_3_36_3"
  top: "res_stage_3_36_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_36"
  type: "Eltwise"
  bottom: "res_3_35"
  bottom: "res_stage_3_36_3_top"
  top: "res_3_36"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_36_relu"
  type: "ReLU"
  bottom: "res_3_36"
  top: "res_3_36"
}
layer {
  name: "res_stage_3_37_1"
  type: "Convolution"
  bottom: "res_3_36"
  top: "res_stage_3_37_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_37_1"
  type: "BatchNorm"
  bottom: "res_stage_3_37_1"
  top: "res_stage_3_37_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_37_1"  
  type: "Scale"
  bottom: "res_stage_3_37_1"
  top: "res_stage_3_37_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_37_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_37_1_top"
  top: "res_stage_3_37_1_top"
}
layer {
  name: "res_stage_3_37_2"
  type: "Convolution"
  bottom: "res_stage_3_37_1_top"
  top: "res_stage_3_37_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_37_2"
  type: "BatchNorm"
  bottom: "res_stage_3_37_2"
  top: "res_stage_3_37_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_37_2"  
  type: "Scale"
  bottom: "res_stage_3_37_2"
  top: "res_stage_3_37_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_37_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_37_2_top"
  top: "res_stage_3_37_2_top"
}
layer {
  name: "res_stage_3_37_3"
  type: "Convolution"
  bottom: "res_stage_3_37_2_top"
  top: "res_stage_3_37_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_37_3"
  type: "BatchNorm"
  bottom: "res_stage_3_37_3"
  top: "res_stage_3_37_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_37_3"  
  type: "Scale"
  bottom: "res_stage_3_37_3"
  top: "res_stage_3_37_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_37"
  type: "Eltwise"
  bottom: "res_3_36"
  bottom: "res_stage_3_37_3_top"
  top: "res_3_37"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_37_relu"
  type: "ReLU"
  bottom: "res_3_37"
  top: "res_3_37"
}
layer {
  name: "res_stage_3_38_1"
  type: "Convolution"
  bottom: "res_3_37"
  top: "res_stage_3_38_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_38_1"
  type: "BatchNorm"
  bottom: "res_stage_3_38_1"
  top: "res_stage_3_38_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_38_1"  
  type: "Scale"
  bottom: "res_stage_3_38_1"
  top: "res_stage_3_38_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_38_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_38_1_top"
  top: "res_stage_3_38_1_top"
}
layer {
  name: "res_stage_3_38_2"
  type: "Convolution"
  bottom: "res_stage_3_38_1_top"
  top: "res_stage_3_38_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_38_2"
  type: "BatchNorm"
  bottom: "res_stage_3_38_2"
  top: "res_stage_3_38_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_38_2"  
  type: "Scale"
  bottom: "res_stage_3_38_2"
  top: "res_stage_3_38_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_38_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_38_2_top"
  top: "res_stage_3_38_2_top"
}
layer {
  name: "res_stage_3_38_3"
  type: "Convolution"
  bottom: "res_stage_3_38_2_top"
  top: "res_stage_3_38_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_38_3"
  type: "BatchNorm"
  bottom: "res_stage_3_38_3"
  top: "res_stage_3_38_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_38_3"  
  type: "Scale"
  bottom: "res_stage_3_38_3"
  top: "res_stage_3_38_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_38"
  type: "Eltwise"
  bottom: "res_3_37"
  bottom: "res_stage_3_38_3_top"
  top: "res_3_38"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_38_relu"
  type: "ReLU"
  bottom: "res_3_38"
  top: "res_3_38"
}
layer {
  name: "res_stage_3_39_1"
  type: "Convolution"
  bottom: "res_3_38"
  top: "res_stage_3_39_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_39_1"
  type: "BatchNorm"
  bottom: "res_stage_3_39_1"
  top: "res_stage_3_39_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_39_1"  
  type: "Scale"
  bottom: "res_stage_3_39_1"
  top: "res_stage_3_39_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_39_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_39_1_top"
  top: "res_stage_3_39_1_top"
}
layer {
  name: "res_stage_3_39_2"
  type: "Convolution"
  bottom: "res_stage_3_39_1_top"
  top: "res_stage_3_39_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_39_2"
  type: "BatchNorm"
  bottom: "res_stage_3_39_2"
  top: "res_stage_3_39_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_39_2"  
  type: "Scale"
  bottom: "res_stage_3_39_2"
  top: "res_stage_3_39_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_39_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_39_2_top"
  top: "res_stage_3_39_2_top"
}
layer {
  name: "res_stage_3_39_3"
  type: "Convolution"
  bottom: "res_stage_3_39_2_top"
  top: "res_stage_3_39_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_39_3"
  type: "BatchNorm"
  bottom: "res_stage_3_39_3"
  top: "res_stage_3_39_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_39_3"  
  type: "Scale"
  bottom: "res_stage_3_39_3"
  top: "res_stage_3_39_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_39"
  type: "Eltwise"
  bottom: "res_3_38"
  bottom: "res_stage_3_39_3_top"
  top: "res_3_39"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_39_relu"
  type: "ReLU"
  bottom: "res_3_39"
  top: "res_3_39"
}
layer {
  name: "res_stage_3_40_1"
  type: "Convolution"
  bottom: "res_3_39"
  top: "res_stage_3_40_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_40_1"
  type: "BatchNorm"
  bottom: "res_stage_3_40_1"
  top: "res_stage_3_40_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_40_1"  
  type: "Scale"
  bottom: "res_stage_3_40_1"
  top: "res_stage_3_40_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_40_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_40_1_top"
  top: "res_stage_3_40_1_top"
}
layer {
  name: "res_stage_3_40_2"
  type: "Convolution"
  bottom: "res_stage_3_40_1_top"
  top: "res_stage_3_40_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_40_2"
  type: "BatchNorm"
  bottom: "res_stage_3_40_2"
  top: "res_stage_3_40_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_40_2"  
  type: "Scale"
  bottom: "res_stage_3_40_2"
  top: "res_stage_3_40_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_40_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_40_2_top"
  top: "res_stage_3_40_2_top"
}
layer {
  name: "res_stage_3_40_3"
  type: "Convolution"
  bottom: "res_stage_3_40_2_top"
  top: "res_stage_3_40_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_40_3"
  type: "BatchNorm"
  bottom: "res_stage_3_40_3"
  top: "res_stage_3_40_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_40_3"  
  type: "Scale"
  bottom: "res_stage_3_40_3"
  top: "res_stage_3_40_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_40"
  type: "Eltwise"
  bottom: "res_3_39"
  bottom: "res_stage_3_40_3_top"
  top: "res_3_40"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_40_relu"
  type: "ReLU"
  bottom: "res_3_40"
  top: "res_3_40"
}
layer {
  name: "res_stage_3_41_1"
  type: "Convolution"
  bottom: "res_3_40"
  top: "res_stage_3_41_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_41_1"
  type: "BatchNorm"
  bottom: "res_stage_3_41_1"
  top: "res_stage_3_41_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_41_1"  
  type: "Scale"
  bottom: "res_stage_3_41_1"
  top: "res_stage_3_41_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_41_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_41_1_top"
  top: "res_stage_3_41_1_top"
}
layer {
  name: "res_stage_3_41_2"
  type: "Convolution"
  bottom: "res_stage_3_41_1_top"
  top: "res_stage_3_41_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_41_2"
  type: "BatchNorm"
  bottom: "res_stage_3_41_2"
  top: "res_stage_3_41_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_41_2"  
  type: "Scale"
  bottom: "res_stage_3_41_2"
  top: "res_stage_3_41_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_41_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_41_2_top"
  top: "res_stage_3_41_2_top"
}
layer {
  name: "res_stage_3_41_3"
  type: "Convolution"
  bottom: "res_stage_3_41_2_top"
  top: "res_stage_3_41_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_41_3"
  type: "BatchNorm"
  bottom: "res_stage_3_41_3"
  top: "res_stage_3_41_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_41_3"  
  type: "Scale"
  bottom: "res_stage_3_41_3"
  top: "res_stage_3_41_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_41"
  type: "Eltwise"
  bottom: "res_3_40"
  bottom: "res_stage_3_41_3_top"
  top: "res_3_41"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_41_relu"
  type: "ReLU"
  bottom: "res_3_41"
  top: "res_3_41"
}
layer {
  name: "res_stage_3_42_1"
  type: "Convolution"
  bottom: "res_3_41"
  top: "res_stage_3_42_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_42_1"
  type: "BatchNorm"
  bottom: "res_stage_3_42_1"
  top: "res_stage_3_42_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_42_1"  
  type: "Scale"
  bottom: "res_stage_3_42_1"
  top: "res_stage_3_42_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_42_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_42_1_top"
  top: "res_stage_3_42_1_top"
}
layer {
  name: "res_stage_3_42_2"
  type: "Convolution"
  bottom: "res_stage_3_42_1_top"
  top: "res_stage_3_42_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_42_2"
  type: "BatchNorm"
  bottom: "res_stage_3_42_2"
  top: "res_stage_3_42_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_42_2"  
  type: "Scale"
  bottom: "res_stage_3_42_2"
  top: "res_stage_3_42_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_42_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_42_2_top"
  top: "res_stage_3_42_2_top"
}
layer {
  name: "res_stage_3_42_3"
  type: "Convolution"
  bottom: "res_stage_3_42_2_top"
  top: "res_stage_3_42_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_42_3"
  type: "BatchNorm"
  bottom: "res_stage_3_42_3"
  top: "res_stage_3_42_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_42_3"  
  type: "Scale"
  bottom: "res_stage_3_42_3"
  top: "res_stage_3_42_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_42"
  type: "Eltwise"
  bottom: "res_3_41"
  bottom: "res_stage_3_42_3_top"
  top: "res_3_42"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_42_relu"
  type: "ReLU"
  bottom: "res_3_42"
  top: "res_3_42"
}
layer {
  name: "res_stage_3_43_1"
  type: "Convolution"
  bottom: "res_3_42"
  top: "res_stage_3_43_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_43_1"
  type: "BatchNorm"
  bottom: "res_stage_3_43_1"
  top: "res_stage_3_43_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_43_1"  
  type: "Scale"
  bottom: "res_stage_3_43_1"
  top: "res_stage_3_43_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_43_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_43_1_top"
  top: "res_stage_3_43_1_top"
}
layer {
  name: "res_stage_3_43_2"
  type: "Convolution"
  bottom: "res_stage_3_43_1_top"
  top: "res_stage_3_43_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_43_2"
  type: "BatchNorm"
  bottom: "res_stage_3_43_2"
  top: "res_stage_3_43_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_43_2"  
  type: "Scale"
  bottom: "res_stage_3_43_2"
  top: "res_stage_3_43_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_43_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_43_2_top"
  top: "res_stage_3_43_2_top"
}
layer {
  name: "res_stage_3_43_3"
  type: "Convolution"
  bottom: "res_stage_3_43_2_top"
  top: "res_stage_3_43_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_43_3"
  type: "BatchNorm"
  bottom: "res_stage_3_43_3"
  top: "res_stage_3_43_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_43_3"  
  type: "Scale"
  bottom: "res_stage_3_43_3"
  top: "res_stage_3_43_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_43"
  type: "Eltwise"
  bottom: "res_3_42"
  bottom: "res_stage_3_43_3_top"
  top: "res_3_43"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_43_relu"
  type: "ReLU"
  bottom: "res_3_43"
  top: "res_3_43"
}
layer {
  name: "res_stage_3_44_1"
  type: "Convolution"
  bottom: "res_3_43"
  top: "res_stage_3_44_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_44_1"
  type: "BatchNorm"
  bottom: "res_stage_3_44_1"
  top: "res_stage_3_44_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_44_1"  
  type: "Scale"
  bottom: "res_stage_3_44_1"
  top: "res_stage_3_44_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_44_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_44_1_top"
  top: "res_stage_3_44_1_top"
}
layer {
  name: "res_stage_3_44_2"
  type: "Convolution"
  bottom: "res_stage_3_44_1_top"
  top: "res_stage_3_44_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_44_2"
  type: "BatchNorm"
  bottom: "res_stage_3_44_2"
  top: "res_stage_3_44_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_44_2"  
  type: "Scale"
  bottom: "res_stage_3_44_2"
  top: "res_stage_3_44_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_44_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_44_2_top"
  top: "res_stage_3_44_2_top"
}
layer {
  name: "res_stage_3_44_3"
  type: "Convolution"
  bottom: "res_stage_3_44_2_top"
  top: "res_stage_3_44_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_44_3"
  type: "BatchNorm"
  bottom: "res_stage_3_44_3"
  top: "res_stage_3_44_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_44_3"  
  type: "Scale"
  bottom: "res_stage_3_44_3"
  top: "res_stage_3_44_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_44"
  type: "Eltwise"
  bottom: "res_3_43"
  bottom: "res_stage_3_44_3_top"
  top: "res_3_44"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_44_relu"
  type: "ReLU"
  bottom: "res_3_44"
  top: "res_3_44"
}
layer {
  name: "res_stage_3_45_1"
  type: "Convolution"
  bottom: "res_3_44"
  top: "res_stage_3_45_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_45_1"
  type: "BatchNorm"
  bottom: "res_stage_3_45_1"
  top: "res_stage_3_45_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_45_1"  
  type: "Scale"
  bottom: "res_stage_3_45_1"
  top: "res_stage_3_45_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_45_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_45_1_top"
  top: "res_stage_3_45_1_top"
}
layer {
  name: "res_stage_3_45_2"
  type: "Convolution"
  bottom: "res_stage_3_45_1_top"
  top: "res_stage_3_45_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_45_2"
  type: "BatchNorm"
  bottom: "res_stage_3_45_2"
  top: "res_stage_3_45_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_45_2"  
  type: "Scale"
  bottom: "res_stage_3_45_2"
  top: "res_stage_3_45_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_45_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_45_2_top"
  top: "res_stage_3_45_2_top"
}
layer {
  name: "res_stage_3_45_3"
  type: "Convolution"
  bottom: "res_stage_3_45_2_top"
  top: "res_stage_3_45_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_45_3"
  type: "BatchNorm"
  bottom: "res_stage_3_45_3"
  top: "res_stage_3_45_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_45_3"  
  type: "Scale"
  bottom: "res_stage_3_45_3"
  top: "res_stage_3_45_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_45"
  type: "Eltwise"
  bottom: "res_3_44"
  bottom: "res_stage_3_45_3_top"
  top: "res_3_45"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_45_relu"
  type: "ReLU"
  bottom: "res_3_45"
  top: "res_3_45"
}
layer {
  name: "res_stage_3_46_1"
  type: "Convolution"
  bottom: "res_3_45"
  top: "res_stage_3_46_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_46_1"
  type: "BatchNorm"
  bottom: "res_stage_3_46_1"
  top: "res_stage_3_46_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_46_1"  
  type: "Scale"
  bottom: "res_stage_3_46_1"
  top: "res_stage_3_46_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_46_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_46_1_top"
  top: "res_stage_3_46_1_top"
}
layer {
  name: "res_stage_3_46_2"
  type: "Convolution"
  bottom: "res_stage_3_46_1_top"
  top: "res_stage_3_46_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_46_2"
  type: "BatchNorm"
  bottom: "res_stage_3_46_2"
  top: "res_stage_3_46_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_46_2"  
  type: "Scale"
  bottom: "res_stage_3_46_2"
  top: "res_stage_3_46_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_46_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_46_2_top"
  top: "res_stage_3_46_2_top"
}
layer {
  name: "res_stage_3_46_3"
  type: "Convolution"
  bottom: "res_stage_3_46_2_top"
  top: "res_stage_3_46_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_46_3"
  type: "BatchNorm"
  bottom: "res_stage_3_46_3"
  top: "res_stage_3_46_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_46_3"  
  type: "Scale"
  bottom: "res_stage_3_46_3"
  top: "res_stage_3_46_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_46"
  type: "Eltwise"
  bottom: "res_3_45"
  bottom: "res_stage_3_46_3_top"
  top: "res_3_46"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_46_relu"
  type: "ReLU"
  bottom: "res_3_46"
  top: "res_3_46"
}
layer {
  name: "res_stage_3_47_1"
  type: "Convolution"
  bottom: "res_3_46"
  top: "res_stage_3_47_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_47_1"
  type: "BatchNorm"
  bottom: "res_stage_3_47_1"
  top: "res_stage_3_47_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_47_1"  
  type: "Scale"
  bottom: "res_stage_3_47_1"
  top: "res_stage_3_47_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_47_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_47_1_top"
  top: "res_stage_3_47_1_top"
}
layer {
  name: "res_stage_3_47_2"
  type: "Convolution"
  bottom: "res_stage_3_47_1_top"
  top: "res_stage_3_47_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_47_2"
  type: "BatchNorm"
  bottom: "res_stage_3_47_2"
  top: "res_stage_3_47_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_47_2"  
  type: "Scale"
  bottom: "res_stage_3_47_2"
  top: "res_stage_3_47_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_47_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_47_2_top"
  top: "res_stage_3_47_2_top"
}
layer {
  name: "res_stage_3_47_3"
  type: "Convolution"
  bottom: "res_stage_3_47_2_top"
  top: "res_stage_3_47_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_47_3"
  type: "BatchNorm"
  bottom: "res_stage_3_47_3"
  top: "res_stage_3_47_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_47_3"  
  type: "Scale"
  bottom: "res_stage_3_47_3"
  top: "res_stage_3_47_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_47"
  type: "Eltwise"
  bottom: "res_3_46"
  bottom: "res_stage_3_47_3_top"
  top: "res_3_47"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_47_relu"
  type: "ReLU"
  bottom: "res_3_47"
  top: "res_3_47"
}
layer {
  name: "res_stage_3_48_1"
  type: "Convolution"
  bottom: "res_3_47"
  top: "res_stage_3_48_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_48_1"
  type: "BatchNorm"
  bottom: "res_stage_3_48_1"
  top: "res_stage_3_48_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_48_1"  
  type: "Scale"
  bottom: "res_stage_3_48_1"
  top: "res_stage_3_48_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_48_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_48_1_top"
  top: "res_stage_3_48_1_top"
}
layer {
  name: "res_stage_3_48_2"
  type: "Convolution"
  bottom: "res_stage_3_48_1_top"
  top: "res_stage_3_48_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_48_2"
  type: "BatchNorm"
  bottom: "res_stage_3_48_2"
  top: "res_stage_3_48_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_48_2"  
  type: "Scale"
  bottom: "res_stage_3_48_2"
  top: "res_stage_3_48_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_48_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_48_2_top"
  top: "res_stage_3_48_2_top"
}
layer {
  name: "res_stage_3_48_3"
  type: "Convolution"
  bottom: "res_stage_3_48_2_top"
  top: "res_stage_3_48_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_48_3"
  type: "BatchNorm"
  bottom: "res_stage_3_48_3"
  top: "res_stage_3_48_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_48_3"  
  type: "Scale"
  bottom: "res_stage_3_48_3"
  top: "res_stage_3_48_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_48"
  type: "Eltwise"
  bottom: "res_3_47"
  bottom: "res_stage_3_48_3_top"
  top: "res_3_48"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_48_relu"
  type: "ReLU"
  bottom: "res_3_48"
  top: "res_3_48"
}
layer {
  name: "res_stage_3_49_1"
  type: "Convolution"
  bottom: "res_3_48"
  top: "res_stage_3_49_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_49_1"
  type: "BatchNorm"
  bottom: "res_stage_3_49_1"
  top: "res_stage_3_49_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_49_1"  
  type: "Scale"
  bottom: "res_stage_3_49_1"
  top: "res_stage_3_49_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_49_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_49_1_top"
  top: "res_stage_3_49_1_top"
}
layer {
  name: "res_stage_3_49_2"
  type: "Convolution"
  bottom: "res_stage_3_49_1_top"
  top: "res_stage_3_49_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_49_2"
  type: "BatchNorm"
  bottom: "res_stage_3_49_2"
  top: "res_stage_3_49_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_49_2"  
  type: "Scale"
  bottom: "res_stage_3_49_2"
  top: "res_stage_3_49_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_49_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_49_2_top"
  top: "res_stage_3_49_2_top"
}
layer {
  name: "res_stage_3_49_3"
  type: "Convolution"
  bottom: "res_stage_3_49_2_top"
  top: "res_stage_3_49_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_49_3"
  type: "BatchNorm"
  bottom: "res_stage_3_49_3"
  top: "res_stage_3_49_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_49_3"  
  type: "Scale"
  bottom: "res_stage_3_49_3"
  top: "res_stage_3_49_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_49"
  type: "Eltwise"
  bottom: "res_3_48"
  bottom: "res_stage_3_49_3_top"
  top: "res_3_49"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_49_relu"
  type: "ReLU"
  bottom: "res_3_49"
  top: "res_3_49"
}
layer {
  name: "res_stage_3_50_1"
  type: "Convolution"
  bottom: "res_3_49"
  top: "res_stage_3_50_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_50_1"
  type: "BatchNorm"
  bottom: "res_stage_3_50_1"
  top: "res_stage_3_50_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_50_1"  
  type: "Scale"
  bottom: "res_stage_3_50_1"
  top: "res_stage_3_50_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_50_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_50_1_top"
  top: "res_stage_3_50_1_top"
}
layer {
  name: "res_stage_3_50_2"
  type: "Convolution"
  bottom: "res_stage_3_50_1_top"
  top: "res_stage_3_50_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_50_2"
  type: "BatchNorm"
  bottom: "res_stage_3_50_2"
  top: "res_stage_3_50_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_50_2"  
  type: "Scale"
  bottom: "res_stage_3_50_2"
  top: "res_stage_3_50_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_50_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_50_2_top"
  top: "res_stage_3_50_2_top"
}
layer {
  name: "res_stage_3_50_3"
  type: "Convolution"
  bottom: "res_stage_3_50_2_top"
  top: "res_stage_3_50_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_50_3"
  type: "BatchNorm"
  bottom: "res_stage_3_50_3"
  top: "res_stage_3_50_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_50_3"  
  type: "Scale"
  bottom: "res_stage_3_50_3"
  top: "res_stage_3_50_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_50"
  type: "Eltwise"
  bottom: "res_3_49"
  bottom: "res_stage_3_50_3_top"
  top: "res_3_50"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_50_relu"
  type: "ReLU"
  bottom: "res_3_50"
  top: "res_3_50"
}
layer {
  name: "res_stage_3_51_1"
  type: "Convolution"
  bottom: "res_3_50"
  top: "res_stage_3_51_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_51_1"
  type: "BatchNorm"
  bottom: "res_stage_3_51_1"
  top: "res_stage_3_51_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_51_1"  
  type: "Scale"
  bottom: "res_stage_3_51_1"
  top: "res_stage_3_51_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_51_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_51_1_top"
  top: "res_stage_3_51_1_top"
}
layer {
  name: "res_stage_3_51_2"
  type: "Convolution"
  bottom: "res_stage_3_51_1_top"
  top: "res_stage_3_51_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_51_2"
  type: "BatchNorm"
  bottom: "res_stage_3_51_2"
  top: "res_stage_3_51_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_51_2"  
  type: "Scale"
  bottom: "res_stage_3_51_2"
  top: "res_stage_3_51_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_51_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_51_2_top"
  top: "res_stage_3_51_2_top"
}
layer {
  name: "res_stage_3_51_3"
  type: "Convolution"
  bottom: "res_stage_3_51_2_top"
  top: "res_stage_3_51_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_51_3"
  type: "BatchNorm"
  bottom: "res_stage_3_51_3"
  top: "res_stage_3_51_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_51_3"  
  type: "Scale"
  bottom: "res_stage_3_51_3"
  top: "res_stage_3_51_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_51"
  type: "Eltwise"
  bottom: "res_3_50"
  bottom: "res_stage_3_51_3_top"
  top: "res_3_51"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_51_relu"
  type: "ReLU"
  bottom: "res_3_51"
  top: "res_3_51"
}
layer {
  name: "res_stage_3_52_1"
  type: "Convolution"
  bottom: "res_3_51"
  top: "res_stage_3_52_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_52_1"
  type: "BatchNorm"
  bottom: "res_stage_3_52_1"
  top: "res_stage_3_52_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_52_1"  
  type: "Scale"
  bottom: "res_stage_3_52_1"
  top: "res_stage_3_52_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_52_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_52_1_top"
  top: "res_stage_3_52_1_top"
}
layer {
  name: "res_stage_3_52_2"
  type: "Convolution"
  bottom: "res_stage_3_52_1_top"
  top: "res_stage_3_52_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_52_2"
  type: "BatchNorm"
  bottom: "res_stage_3_52_2"
  top: "res_stage_3_52_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_52_2"  
  type: "Scale"
  bottom: "res_stage_3_52_2"
  top: "res_stage_3_52_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_52_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_52_2_top"
  top: "res_stage_3_52_2_top"
}
layer {
  name: "res_stage_3_52_3"
  type: "Convolution"
  bottom: "res_stage_3_52_2_top"
  top: "res_stage_3_52_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_52_3"
  type: "BatchNorm"
  bottom: "res_stage_3_52_3"
  top: "res_stage_3_52_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_52_3"  
  type: "Scale"
  bottom: "res_stage_3_52_3"
  top: "res_stage_3_52_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_52"
  type: "Eltwise"
  bottom: "res_3_51"
  bottom: "res_stage_3_52_3_top"
  top: "res_3_52"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_52_relu"
  type: "ReLU"
  bottom: "res_3_52"
  top: "res_3_52"
}
layer {
  name: "res_stage_3_53_1"
  type: "Convolution"
  bottom: "res_3_52"
  top: "res_stage_3_53_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_53_1"
  type: "BatchNorm"
  bottom: "res_stage_3_53_1"
  top: "res_stage_3_53_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_53_1"  
  type: "Scale"
  bottom: "res_stage_3_53_1"
  top: "res_stage_3_53_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_53_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_53_1_top"
  top: "res_stage_3_53_1_top"
}
layer {
  name: "res_stage_3_53_2"
  type: "Convolution"
  bottom: "res_stage_3_53_1_top"
  top: "res_stage_3_53_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_53_2"
  type: "BatchNorm"
  bottom: "res_stage_3_53_2"
  top: "res_stage_3_53_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_53_2"  
  type: "Scale"
  bottom: "res_stage_3_53_2"
  top: "res_stage_3_53_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_53_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_53_2_top"
  top: "res_stage_3_53_2_top"
}
layer {
  name: "res_stage_3_53_3"
  type: "Convolution"
  bottom: "res_stage_3_53_2_top"
  top: "res_stage_3_53_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_53_3"
  type: "BatchNorm"
  bottom: "res_stage_3_53_3"
  top: "res_stage_3_53_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_53_3"  
  type: "Scale"
  bottom: "res_stage_3_53_3"
  top: "res_stage_3_53_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_53"
  type: "Eltwise"
  bottom: "res_3_52"
  bottom: "res_stage_3_53_3_top"
  top: "res_3_53"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_53_relu"
  type: "ReLU"
  bottom: "res_3_53"
  top: "res_3_53"
}
layer {
  name: "res_stage_3_54_1"
  type: "Convolution"
  bottom: "res_3_53"
  top: "res_stage_3_54_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_54_1"
  type: "BatchNorm"
  bottom: "res_stage_3_54_1"
  top: "res_stage_3_54_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_54_1"  
  type: "Scale"
  bottom: "res_stage_3_54_1"
  top: "res_stage_3_54_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_54_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_54_1_top"
  top: "res_stage_3_54_1_top"
}
layer {
  name: "res_stage_3_54_2"
  type: "Convolution"
  bottom: "res_stage_3_54_1_top"
  top: "res_stage_3_54_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_54_2"
  type: "BatchNorm"
  bottom: "res_stage_3_54_2"
  top: "res_stage_3_54_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_54_2"  
  type: "Scale"
  bottom: "res_stage_3_54_2"
  top: "res_stage_3_54_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_54_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_54_2_top"
  top: "res_stage_3_54_2_top"
}
layer {
  name: "res_stage_3_54_3"
  type: "Convolution"
  bottom: "res_stage_3_54_2_top"
  top: "res_stage_3_54_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_54_3"
  type: "BatchNorm"
  bottom: "res_stage_3_54_3"
  top: "res_stage_3_54_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_54_3"  
  type: "Scale"
  bottom: "res_stage_3_54_3"
  top: "res_stage_3_54_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_54"
  type: "Eltwise"
  bottom: "res_3_53"
  bottom: "res_stage_3_54_3_top"
  top: "res_3_54"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_54_relu"
  type: "ReLU"
  bottom: "res_3_54"
  top: "res_3_54"
}
layer {
  name: "res_stage_3_55_1"
  type: "Convolution"
  bottom: "res_3_54"
  top: "res_stage_3_55_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_55_1"
  type: "BatchNorm"
  bottom: "res_stage_3_55_1"
  top: "res_stage_3_55_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_55_1"  
  type: "Scale"
  bottom: "res_stage_3_55_1"
  top: "res_stage_3_55_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_55_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_55_1_top"
  top: "res_stage_3_55_1_top"
}
layer {
  name: "res_stage_3_55_2"
  type: "Convolution"
  bottom: "res_stage_3_55_1_top"
  top: "res_stage_3_55_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_55_2"
  type: "BatchNorm"
  bottom: "res_stage_3_55_2"
  top: "res_stage_3_55_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_55_2"  
  type: "Scale"
  bottom: "res_stage_3_55_2"
  top: "res_stage_3_55_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_55_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_55_2_top"
  top: "res_stage_3_55_2_top"
}
layer {
  name: "res_stage_3_55_3"
  type: "Convolution"
  bottom: "res_stage_3_55_2_top"
  top: "res_stage_3_55_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_55_3"
  type: "BatchNorm"
  bottom: "res_stage_3_55_3"
  top: "res_stage_3_55_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_55_3"  
  type: "Scale"
  bottom: "res_stage_3_55_3"
  top: "res_stage_3_55_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_55"
  type: "Eltwise"
  bottom: "res_3_54"
  bottom: "res_stage_3_55_3_top"
  top: "res_3_55"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_55_relu"
  type: "ReLU"
  bottom: "res_3_55"
  top: "res_3_55"
}
layer {
  name: "res_stage_3_56_1"
  type: "Convolution"
  bottom: "res_3_55"
  top: "res_stage_3_56_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_56_1"
  type: "BatchNorm"
  bottom: "res_stage_3_56_1"
  top: "res_stage_3_56_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_56_1"  
  type: "Scale"
  bottom: "res_stage_3_56_1"
  top: "res_stage_3_56_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_56_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_56_1_top"
  top: "res_stage_3_56_1_top"
}
layer {
  name: "res_stage_3_56_2"
  type: "Convolution"
  bottom: "res_stage_3_56_1_top"
  top: "res_stage_3_56_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_56_2"
  type: "BatchNorm"
  bottom: "res_stage_3_56_2"
  top: "res_stage_3_56_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_56_2"  
  type: "Scale"
  bottom: "res_stage_3_56_2"
  top: "res_stage_3_56_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_56_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_56_2_top"
  top: "res_stage_3_56_2_top"
}
layer {
  name: "res_stage_3_56_3"
  type: "Convolution"
  bottom: "res_stage_3_56_2_top"
  top: "res_stage_3_56_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_56_3"
  type: "BatchNorm"
  bottom: "res_stage_3_56_3"
  top: "res_stage_3_56_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_56_3"  
  type: "Scale"
  bottom: "res_stage_3_56_3"
  top: "res_stage_3_56_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_56"
  type: "Eltwise"
  bottom: "res_3_55"
  bottom: "res_stage_3_56_3_top"
  top: "res_3_56"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_56_relu"
  type: "ReLU"
  bottom: "res_3_56"
  top: "res_3_56"
}
layer {
  name: "res_stage_3_57_1"
  type: "Convolution"
  bottom: "res_3_56"
  top: "res_stage_3_57_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_57_1"
  type: "BatchNorm"
  bottom: "res_stage_3_57_1"
  top: "res_stage_3_57_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_57_1"  
  type: "Scale"
  bottom: "res_stage_3_57_1"
  top: "res_stage_3_57_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_57_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_57_1_top"
  top: "res_stage_3_57_1_top"
}
layer {
  name: "res_stage_3_57_2"
  type: "Convolution"
  bottom: "res_stage_3_57_1_top"
  top: "res_stage_3_57_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_57_2"
  type: "BatchNorm"
  bottom: "res_stage_3_57_2"
  top: "res_stage_3_57_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_57_2"  
  type: "Scale"
  bottom: "res_stage_3_57_2"
  top: "res_stage_3_57_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_57_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_57_2_top"
  top: "res_stage_3_57_2_top"
}
layer {
  name: "res_stage_3_57_3"
  type: "Convolution"
  bottom: "res_stage_3_57_2_top"
  top: "res_stage_3_57_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_57_3"
  type: "BatchNorm"
  bottom: "res_stage_3_57_3"
  top: "res_stage_3_57_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_57_3"  
  type: "Scale"
  bottom: "res_stage_3_57_3"
  top: "res_stage_3_57_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_57"
  type: "Eltwise"
  bottom: "res_3_56"
  bottom: "res_stage_3_57_3_top"
  top: "res_3_57"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_57_relu"
  type: "ReLU"
  bottom: "res_3_57"
  top: "res_3_57"
}
layer {
  name: "res_stage_3_58_1"
  type: "Convolution"
  bottom: "res_3_57"
  top: "res_stage_3_58_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_58_1"
  type: "BatchNorm"
  bottom: "res_stage_3_58_1"
  top: "res_stage_3_58_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_58_1"  
  type: "Scale"
  bottom: "res_stage_3_58_1"
  top: "res_stage_3_58_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_58_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_58_1_top"
  top: "res_stage_3_58_1_top"
}
layer {
  name: "res_stage_3_58_2"
  type: "Convolution"
  bottom: "res_stage_3_58_1_top"
  top: "res_stage_3_58_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_58_2"
  type: "BatchNorm"
  bottom: "res_stage_3_58_2"
  top: "res_stage_3_58_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_58_2"  
  type: "Scale"
  bottom: "res_stage_3_58_2"
  top: "res_stage_3_58_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_58_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_58_2_top"
  top: "res_stage_3_58_2_top"
}
layer {
  name: "res_stage_3_58_3"
  type: "Convolution"
  bottom: "res_stage_3_58_2_top"
  top: "res_stage_3_58_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_58_3"
  type: "BatchNorm"
  bottom: "res_stage_3_58_3"
  top: "res_stage_3_58_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_58_3"  
  type: "Scale"
  bottom: "res_stage_3_58_3"
  top: "res_stage_3_58_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_58"
  type: "Eltwise"
  bottom: "res_3_57"
  bottom: "res_stage_3_58_3_top"
  top: "res_3_58"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_58_relu"
  type: "ReLU"
  bottom: "res_3_58"
  top: "res_3_58"
}
layer {
  name: "res_stage_3_59_1"
  type: "Convolution"
  bottom: "res_3_58"
  top: "res_stage_3_59_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_59_1"
  type: "BatchNorm"
  bottom: "res_stage_3_59_1"
  top: "res_stage_3_59_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_59_1"  
  type: "Scale"
  bottom: "res_stage_3_59_1"
  top: "res_stage_3_59_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_59_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_59_1_top"
  top: "res_stage_3_59_1_top"
}
layer {
  name: "res_stage_3_59_2"
  type: "Convolution"
  bottom: "res_stage_3_59_1_top"
  top: "res_stage_3_59_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_59_2"
  type: "BatchNorm"
  bottom: "res_stage_3_59_2"
  top: "res_stage_3_59_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_59_2"  
  type: "Scale"
  bottom: "res_stage_3_59_2"
  top: "res_stage_3_59_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_59_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_59_2_top"
  top: "res_stage_3_59_2_top"
}
layer {
  name: "res_stage_3_59_3"
  type: "Convolution"
  bottom: "res_stage_3_59_2_top"
  top: "res_stage_3_59_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_59_3"
  type: "BatchNorm"
  bottom: "res_stage_3_59_3"
  top: "res_stage_3_59_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_59_3"  
  type: "Scale"
  bottom: "res_stage_3_59_3"
  top: "res_stage_3_59_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_59"
  type: "Eltwise"
  bottom: "res_3_58"
  bottom: "res_stage_3_59_3_top"
  top: "res_3_59"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_59_relu"
  type: "ReLU"
  bottom: "res_3_59"
  top: "res_3_59"
}
layer {
  name: "res_stage_3_60_1"
  type: "Convolution"
  bottom: "res_3_59"
  top: "res_stage_3_60_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_60_1"
  type: "BatchNorm"
  bottom: "res_stage_3_60_1"
  top: "res_stage_3_60_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_60_1"  
  type: "Scale"
  bottom: "res_stage_3_60_1"
  top: "res_stage_3_60_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_60_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_60_1_top"
  top: "res_stage_3_60_1_top"
}
layer {
  name: "res_stage_3_60_2"
  type: "Convolution"
  bottom: "res_stage_3_60_1_top"
  top: "res_stage_3_60_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_60_2"
  type: "BatchNorm"
  bottom: "res_stage_3_60_2"
  top: "res_stage_3_60_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_60_2"  
  type: "Scale"
  bottom: "res_stage_3_60_2"
  top: "res_stage_3_60_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_60_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_60_2_top"
  top: "res_stage_3_60_2_top"
}
layer {
  name: "res_stage_3_60_3"
  type: "Convolution"
  bottom: "res_stage_3_60_2_top"
  top: "res_stage_3_60_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_60_3"
  type: "BatchNorm"
  bottom: "res_stage_3_60_3"
  top: "res_stage_3_60_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_60_3"  
  type: "Scale"
  bottom: "res_stage_3_60_3"
  top: "res_stage_3_60_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_60"
  type: "Eltwise"
  bottom: "res_3_59"
  bottom: "res_stage_3_60_3_top"
  top: "res_3_60"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_60_relu"
  type: "ReLU"
  bottom: "res_3_60"
  top: "res_3_60"
}
layer {
  name: "res_stage_3_61_1"
  type: "Convolution"
  bottom: "res_3_60"
  top: "res_stage_3_61_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_61_1"
  type: "BatchNorm"
  bottom: "res_stage_3_61_1"
  top: "res_stage_3_61_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_61_1"  
  type: "Scale"
  bottom: "res_stage_3_61_1"
  top: "res_stage_3_61_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_61_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_61_1_top"
  top: "res_stage_3_61_1_top"
}
layer {
  name: "res_stage_3_61_2"
  type: "Convolution"
  bottom: "res_stage_3_61_1_top"
  top: "res_stage_3_61_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_61_2"
  type: "BatchNorm"
  bottom: "res_stage_3_61_2"
  top: "res_stage_3_61_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_61_2"  
  type: "Scale"
  bottom: "res_stage_3_61_2"
  top: "res_stage_3_61_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_61_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_61_2_top"
  top: "res_stage_3_61_2_top"
}
layer {
  name: "res_stage_3_61_3"
  type: "Convolution"
  bottom: "res_stage_3_61_2_top"
  top: "res_stage_3_61_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_61_3"
  type: "BatchNorm"
  bottom: "res_stage_3_61_3"
  top: "res_stage_3_61_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_61_3"  
  type: "Scale"
  bottom: "res_stage_3_61_3"
  top: "res_stage_3_61_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_61"
  type: "Eltwise"
  bottom: "res_3_60"
  bottom: "res_stage_3_61_3_top"
  top: "res_3_61"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_61_relu"
  type: "ReLU"
  bottom: "res_3_61"
  top: "res_3_61"
}
layer {
  name: "res_stage_3_62_1"
  type: "Convolution"
  bottom: "res_3_61"
  top: "res_stage_3_62_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_62_1"
  type: "BatchNorm"
  bottom: "res_stage_3_62_1"
  top: "res_stage_3_62_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_62_1"  
  type: "Scale"
  bottom: "res_stage_3_62_1"
  top: "res_stage_3_62_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_62_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_62_1_top"
  top: "res_stage_3_62_1_top"
}
layer {
  name: "res_stage_3_62_2"
  type: "Convolution"
  bottom: "res_stage_3_62_1_top"
  top: "res_stage_3_62_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_62_2"
  type: "BatchNorm"
  bottom: "res_stage_3_62_2"
  top: "res_stage_3_62_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_62_2"  
  type: "Scale"
  bottom: "res_stage_3_62_2"
  top: "res_stage_3_62_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_62_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_62_2_top"
  top: "res_stage_3_62_2_top"
}
layer {
  name: "res_stage_3_62_3"
  type: "Convolution"
  bottom: "res_stage_3_62_2_top"
  top: "res_stage_3_62_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_62_3"
  type: "BatchNorm"
  bottom: "res_stage_3_62_3"
  top: "res_stage_3_62_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_62_3"  
  type: "Scale"
  bottom: "res_stage_3_62_3"
  top: "res_stage_3_62_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_62"
  type: "Eltwise"
  bottom: "res_3_61"
  bottom: "res_stage_3_62_3_top"
  top: "res_3_62"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_62_relu"
  type: "ReLU"
  bottom: "res_3_62"
  top: "res_3_62"
}
layer {
  name: "res_stage_3_63_1"
  type: "Convolution"
  bottom: "res_3_62"
  top: "res_stage_3_63_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_63_1"
  type: "BatchNorm"
  bottom: "res_stage_3_63_1"
  top: "res_stage_3_63_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_63_1"  
  type: "Scale"
  bottom: "res_stage_3_63_1"
  top: "res_stage_3_63_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_63_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_63_1_top"
  top: "res_stage_3_63_1_top"
}
layer {
  name: "res_stage_3_63_2"
  type: "Convolution"
  bottom: "res_stage_3_63_1_top"
  top: "res_stage_3_63_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_63_2"
  type: "BatchNorm"
  bottom: "res_stage_3_63_2"
  top: "res_stage_3_63_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_63_2"  
  type: "Scale"
  bottom: "res_stage_3_63_2"
  top: "res_stage_3_63_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_63_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_63_2_top"
  top: "res_stage_3_63_2_top"
}
layer {
  name: "res_stage_3_63_3"
  type: "Convolution"
  bottom: "res_stage_3_63_2_top"
  top: "res_stage_3_63_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_63_3"
  type: "BatchNorm"
  bottom: "res_stage_3_63_3"
  top: "res_stage_3_63_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_63_3"  
  type: "Scale"
  bottom: "res_stage_3_63_3"
  top: "res_stage_3_63_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_63"
  type: "Eltwise"
  bottom: "res_3_62"
  bottom: "res_stage_3_63_3_top"
  top: "res_3_63"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_63_relu"
  type: "ReLU"
  bottom: "res_3_63"
  top: "res_3_63"
}
layer {
  name: "res_stage_3_64_1"
  type: "Convolution"
  bottom: "res_3_63"
  top: "res_stage_3_64_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_64_1"
  type: "BatchNorm"
  bottom: "res_stage_3_64_1"
  top: "res_stage_3_64_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_64_1"  
  type: "Scale"
  bottom: "res_stage_3_64_1"
  top: "res_stage_3_64_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_64_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_64_1_top"
  top: "res_stage_3_64_1_top"
}
layer {
  name: "res_stage_3_64_2"
  type: "Convolution"
  bottom: "res_stage_3_64_1_top"
  top: "res_stage_3_64_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_64_2"
  type: "BatchNorm"
  bottom: "res_stage_3_64_2"
  top: "res_stage_3_64_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_64_2"  
  type: "Scale"
  bottom: "res_stage_3_64_2"
  top: "res_stage_3_64_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_64_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_64_2_top"
  top: "res_stage_3_64_2_top"
}
layer {
  name: "res_stage_3_64_3"
  type: "Convolution"
  bottom: "res_stage_3_64_2_top"
  top: "res_stage_3_64_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_64_3"
  type: "BatchNorm"
  bottom: "res_stage_3_64_3"
  top: "res_stage_3_64_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_64_3"  
  type: "Scale"
  bottom: "res_stage_3_64_3"
  top: "res_stage_3_64_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_64"
  type: "Eltwise"
  bottom: "res_3_63"
  bottom: "res_stage_3_64_3_top"
  top: "res_3_64"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_64_relu"
  type: "ReLU"
  bottom: "res_3_64"
  top: "res_3_64"
}
layer {
  name: "res_stage_3_65_1"
  type: "Convolution"
  bottom: "res_3_64"
  top: "res_stage_3_65_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_65_1"
  type: "BatchNorm"
  bottom: "res_stage_3_65_1"
  top: "res_stage_3_65_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_65_1"  
  type: "Scale"
  bottom: "res_stage_3_65_1"
  top: "res_stage_3_65_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_65_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_65_1_top"
  top: "res_stage_3_65_1_top"
}
layer {
  name: "res_stage_3_65_2"
  type: "Convolution"
  bottom: "res_stage_3_65_1_top"
  top: "res_stage_3_65_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_65_2"
  type: "BatchNorm"
  bottom: "res_stage_3_65_2"
  top: "res_stage_3_65_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_65_2"  
  type: "Scale"
  bottom: "res_stage_3_65_2"
  top: "res_stage_3_65_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_65_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_65_2_top"
  top: "res_stage_3_65_2_top"
}
layer {
  name: "res_stage_3_65_3"
  type: "Convolution"
  bottom: "res_stage_3_65_2_top"
  top: "res_stage_3_65_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_65_3"
  type: "BatchNorm"
  bottom: "res_stage_3_65_3"
  top: "res_stage_3_65_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_65_3"  
  type: "Scale"
  bottom: "res_stage_3_65_3"
  top: "res_stage_3_65_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_65"
  type: "Eltwise"
  bottom: "res_3_64"
  bottom: "res_stage_3_65_3_top"
  top: "res_3_65"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_65_relu"
  type: "ReLU"
  bottom: "res_3_65"
  top: "res_3_65"
}
layer {
  name: "res_stage_3_66_1"
  type: "Convolution"
  bottom: "res_3_65"
  top: "res_stage_3_66_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_66_1"
  type: "BatchNorm"
  bottom: "res_stage_3_66_1"
  top: "res_stage_3_66_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_66_1"  
  type: "Scale"
  bottom: "res_stage_3_66_1"
  top: "res_stage_3_66_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_66_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_66_1_top"
  top: "res_stage_3_66_1_top"
}
layer {
  name: "res_stage_3_66_2"
  type: "Convolution"
  bottom: "res_stage_3_66_1_top"
  top: "res_stage_3_66_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_66_2"
  type: "BatchNorm"
  bottom: "res_stage_3_66_2"
  top: "res_stage_3_66_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_66_2"  
  type: "Scale"
  bottom: "res_stage_3_66_2"
  top: "res_stage_3_66_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_66_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_66_2_top"
  top: "res_stage_3_66_2_top"
}
layer {
  name: "res_stage_3_66_3"
  type: "Convolution"
  bottom: "res_stage_3_66_2_top"
  top: "res_stage_3_66_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_66_3"
  type: "BatchNorm"
  bottom: "res_stage_3_66_3"
  top: "res_stage_3_66_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_66_3"  
  type: "Scale"
  bottom: "res_stage_3_66_3"
  top: "res_stage_3_66_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_66"
  type: "Eltwise"
  bottom: "res_3_65"
  bottom: "res_stage_3_66_3_top"
  top: "res_3_66"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_66_relu"
  type: "ReLU"
  bottom: "res_3_66"
  top: "res_3_66"
}
layer {
  name: "res_stage_3_67_1"
  type: "Convolution"
  bottom: "res_3_66"
  top: "res_stage_3_67_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_67_1"
  type: "BatchNorm"
  bottom: "res_stage_3_67_1"
  top: "res_stage_3_67_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_67_1"  
  type: "Scale"
  bottom: "res_stage_3_67_1"
  top: "res_stage_3_67_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_67_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_67_1_top"
  top: "res_stage_3_67_1_top"
}
layer {
  name: "res_stage_3_67_2"
  type: "Convolution"
  bottom: "res_stage_3_67_1_top"
  top: "res_stage_3_67_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_67_2"
  type: "BatchNorm"
  bottom: "res_stage_3_67_2"
  top: "res_stage_3_67_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_67_2"  
  type: "Scale"
  bottom: "res_stage_3_67_2"
  top: "res_stage_3_67_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_67_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_67_2_top"
  top: "res_stage_3_67_2_top"
}
layer {
  name: "res_stage_3_67_3"
  type: "Convolution"
  bottom: "res_stage_3_67_2_top"
  top: "res_stage_3_67_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_67_3"
  type: "BatchNorm"
  bottom: "res_stage_3_67_3"
  top: "res_stage_3_67_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_67_3"  
  type: "Scale"
  bottom: "res_stage_3_67_3"
  top: "res_stage_3_67_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_67"
  type: "Eltwise"
  bottom: "res_3_66"
  bottom: "res_stage_3_67_3_top"
  top: "res_3_67"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_67_relu"
  type: "ReLU"
  bottom: "res_3_67"
  top: "res_3_67"
}
layer {
  name: "res_stage_3_68_1"
  type: "Convolution"
  bottom: "res_3_67"
  top: "res_stage_3_68_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_68_1"
  type: "BatchNorm"
  bottom: "res_stage_3_68_1"
  top: "res_stage_3_68_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_68_1"  
  type: "Scale"
  bottom: "res_stage_3_68_1"
  top: "res_stage_3_68_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_68_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_68_1_top"
  top: "res_stage_3_68_1_top"
}
layer {
  name: "res_stage_3_68_2"
  type: "Convolution"
  bottom: "res_stage_3_68_1_top"
  top: "res_stage_3_68_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_68_2"
  type: "BatchNorm"
  bottom: "res_stage_3_68_2"
  top: "res_stage_3_68_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_68_2"  
  type: "Scale"
  bottom: "res_stage_3_68_2"
  top: "res_stage_3_68_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_68_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_68_2_top"
  top: "res_stage_3_68_2_top"
}
layer {
  name: "res_stage_3_68_3"
  type: "Convolution"
  bottom: "res_stage_3_68_2_top"
  top: "res_stage_3_68_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_68_3"
  type: "BatchNorm"
  bottom: "res_stage_3_68_3"
  top: "res_stage_3_68_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_68_3"  
  type: "Scale"
  bottom: "res_stage_3_68_3"
  top: "res_stage_3_68_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_68"
  type: "Eltwise"
  bottom: "res_3_67"
  bottom: "res_stage_3_68_3_top"
  top: "res_3_68"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_68_relu"
  type: "ReLU"
  bottom: "res_3_68"
  top: "res_3_68"
}
layer {
  name: "res_stage_3_69_1"
  type: "Convolution"
  bottom: "res_3_68"
  top: "res_stage_3_69_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_69_1"
  type: "BatchNorm"
  bottom: "res_stage_3_69_1"
  top: "res_stage_3_69_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_69_1"  
  type: "Scale"
  bottom: "res_stage_3_69_1"
  top: "res_stage_3_69_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_69_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_69_1_top"
  top: "res_stage_3_69_1_top"
}
layer {
  name: "res_stage_3_69_2"
  type: "Convolution"
  bottom: "res_stage_3_69_1_top"
  top: "res_stage_3_69_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_69_2"
  type: "BatchNorm"
  bottom: "res_stage_3_69_2"
  top: "res_stage_3_69_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_69_2"  
  type: "Scale"
  bottom: "res_stage_3_69_2"
  top: "res_stage_3_69_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_69_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_69_2_top"
  top: "res_stage_3_69_2_top"
}
layer {
  name: "res_stage_3_69_3"
  type: "Convolution"
  bottom: "res_stage_3_69_2_top"
  top: "res_stage_3_69_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_69_3"
  type: "BatchNorm"
  bottom: "res_stage_3_69_3"
  top: "res_stage_3_69_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_69_3"  
  type: "Scale"
  bottom: "res_stage_3_69_3"
  top: "res_stage_3_69_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_69"
  type: "Eltwise"
  bottom: "res_3_68"
  bottom: "res_stage_3_69_3_top"
  top: "res_3_69"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_69_relu"
  type: "ReLU"
  bottom: "res_3_69"
  top: "res_3_69"
}
layer {
  name: "res_stage_3_70_1"
  type: "Convolution"
  bottom: "res_3_69"
  top: "res_stage_3_70_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_70_1"
  type: "BatchNorm"
  bottom: "res_stage_3_70_1"
  top: "res_stage_3_70_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_70_1"  
  type: "Scale"
  bottom: "res_stage_3_70_1"
  top: "res_stage_3_70_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_70_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_70_1_top"
  top: "res_stage_3_70_1_top"
}
layer {
  name: "res_stage_3_70_2"
  type: "Convolution"
  bottom: "res_stage_3_70_1_top"
  top: "res_stage_3_70_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_70_2"
  type: "BatchNorm"
  bottom: "res_stage_3_70_2"
  top: "res_stage_3_70_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_70_2"  
  type: "Scale"
  bottom: "res_stage_3_70_2"
  top: "res_stage_3_70_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_70_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_70_2_top"
  top: "res_stage_3_70_2_top"
}
layer {
  name: "res_stage_3_70_3"
  type: "Convolution"
  bottom: "res_stage_3_70_2_top"
  top: "res_stage_3_70_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_70_3"
  type: "BatchNorm"
  bottom: "res_stage_3_70_3"
  top: "res_stage_3_70_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_70_3"  
  type: "Scale"
  bottom: "res_stage_3_70_3"
  top: "res_stage_3_70_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_70"
  type: "Eltwise"
  bottom: "res_3_69"
  bottom: "res_stage_3_70_3_top"
  top: "res_3_70"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_70_relu"
  type: "ReLU"
  bottom: "res_3_70"
  top: "res_3_70"
}
layer {
  name: "res_stage_3_71_1"
  type: "Convolution"
  bottom: "res_3_70"
  top: "res_stage_3_71_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_71_1"
  type: "BatchNorm"
  bottom: "res_stage_3_71_1"
  top: "res_stage_3_71_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_71_1"  
  type: "Scale"
  bottom: "res_stage_3_71_1"
  top: "res_stage_3_71_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_71_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_71_1_top"
  top: "res_stage_3_71_1_top"
}
layer {
  name: "res_stage_3_71_2"
  type: "Convolution"
  bottom: "res_stage_3_71_1_top"
  top: "res_stage_3_71_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_71_2"
  type: "BatchNorm"
  bottom: "res_stage_3_71_2"
  top: "res_stage_3_71_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_71_2"  
  type: "Scale"
  bottom: "res_stage_3_71_2"
  top: "res_stage_3_71_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_71_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_71_2_top"
  top: "res_stage_3_71_2_top"
}
layer {
  name: "res_stage_3_71_3"
  type: "Convolution"
  bottom: "res_stage_3_71_2_top"
  top: "res_stage_3_71_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_71_3"
  type: "BatchNorm"
  bottom: "res_stage_3_71_3"
  top: "res_stage_3_71_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_71_3"  
  type: "Scale"
  bottom: "res_stage_3_71_3"
  top: "res_stage_3_71_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_71"
  type: "Eltwise"
  bottom: "res_3_70"
  bottom: "res_stage_3_71_3_top"
  top: "res_3_71"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_71_relu"
  type: "ReLU"
  bottom: "res_3_71"
  top: "res_3_71"
}
layer {
  name: "res_stage_3_72_1"
  type: "Convolution"
  bottom: "res_3_71"
  top: "res_stage_3_72_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_72_1"
  type: "BatchNorm"
  bottom: "res_stage_3_72_1"
  top: "res_stage_3_72_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_72_1"  
  type: "Scale"
  bottom: "res_stage_3_72_1"
  top: "res_stage_3_72_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_72_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_72_1_top"
  top: "res_stage_3_72_1_top"
}
layer {
  name: "res_stage_3_72_2"
  type: "Convolution"
  bottom: "res_stage_3_72_1_top"
  top: "res_stage_3_72_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_72_2"
  type: "BatchNorm"
  bottom: "res_stage_3_72_2"
  top: "res_stage_3_72_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_72_2"  
  type: "Scale"
  bottom: "res_stage_3_72_2"
  top: "res_stage_3_72_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_72_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_72_2_top"
  top: "res_stage_3_72_2_top"
}
layer {
  name: "res_stage_3_72_3"
  type: "Convolution"
  bottom: "res_stage_3_72_2_top"
  top: "res_stage_3_72_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_72_3"
  type: "BatchNorm"
  bottom: "res_stage_3_72_3"
  top: "res_stage_3_72_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_72_3"  
  type: "Scale"
  bottom: "res_stage_3_72_3"
  top: "res_stage_3_72_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_72"
  type: "Eltwise"
  bottom: "res_3_71"
  bottom: "res_stage_3_72_3_top"
  top: "res_3_72"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_72_relu"
  type: "ReLU"
  bottom: "res_3_72"
  top: "res_3_72"
}
layer {
  name: "res_stage_3_73_1"
  type: "Convolution"
  bottom: "res_3_72"
  top: "res_stage_3_73_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_73_1"
  type: "BatchNorm"
  bottom: "res_stage_3_73_1"
  top: "res_stage_3_73_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_73_1"  
  type: "Scale"
  bottom: "res_stage_3_73_1"
  top: "res_stage_3_73_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_73_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_73_1_top"
  top: "res_stage_3_73_1_top"
}
layer {
  name: "res_stage_3_73_2"
  type: "Convolution"
  bottom: "res_stage_3_73_1_top"
  top: "res_stage_3_73_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_73_2"
  type: "BatchNorm"
  bottom: "res_stage_3_73_2"
  top: "res_stage_3_73_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_73_2"  
  type: "Scale"
  bottom: "res_stage_3_73_2"
  top: "res_stage_3_73_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_73_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_73_2_top"
  top: "res_stage_3_73_2_top"
}
layer {
  name: "res_stage_3_73_3"
  type: "Convolution"
  bottom: "res_stage_3_73_2_top"
  top: "res_stage_3_73_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_73_3"
  type: "BatchNorm"
  bottom: "res_stage_3_73_3"
  top: "res_stage_3_73_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_73_3"  
  type: "Scale"
  bottom: "res_stage_3_73_3"
  top: "res_stage_3_73_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_73"
  type: "Eltwise"
  bottom: "res_3_72"
  bottom: "res_stage_3_73_3_top"
  top: "res_3_73"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_73_relu"
  type: "ReLU"
  bottom: "res_3_73"
  top: "res_3_73"
}
layer {
  name: "res_stage_3_74_1"
  type: "Convolution"
  bottom: "res_3_73"
  top: "res_stage_3_74_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_74_1"
  type: "BatchNorm"
  bottom: "res_stage_3_74_1"
  top: "res_stage_3_74_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_74_1"  
  type: "Scale"
  bottom: "res_stage_3_74_1"
  top: "res_stage_3_74_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_74_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_74_1_top"
  top: "res_stage_3_74_1_top"
}
layer {
  name: "res_stage_3_74_2"
  type: "Convolution"
  bottom: "res_stage_3_74_1_top"
  top: "res_stage_3_74_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_74_2"
  type: "BatchNorm"
  bottom: "res_stage_3_74_2"
  top: "res_stage_3_74_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_74_2"  
  type: "Scale"
  bottom: "res_stage_3_74_2"
  top: "res_stage_3_74_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_74_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_74_2_top"
  top: "res_stage_3_74_2_top"
}
layer {
  name: "res_stage_3_74_3"
  type: "Convolution"
  bottom: "res_stage_3_74_2_top"
  top: "res_stage_3_74_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_74_3"
  type: "BatchNorm"
  bottom: "res_stage_3_74_3"
  top: "res_stage_3_74_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_74_3"  
  type: "Scale"
  bottom: "res_stage_3_74_3"
  top: "res_stage_3_74_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_74"
  type: "Eltwise"
  bottom: "res_3_73"
  bottom: "res_stage_3_74_3_top"
  top: "res_3_74"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_74_relu"
  type: "ReLU"
  bottom: "res_3_74"
  top: "res_3_74"
}
layer {
  name: "res_stage_3_75_1"
  type: "Convolution"
  bottom: "res_3_74"
  top: "res_stage_3_75_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_75_1"
  type: "BatchNorm"
  bottom: "res_stage_3_75_1"
  top: "res_stage_3_75_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_75_1"  
  type: "Scale"
  bottom: "res_stage_3_75_1"
  top: "res_stage_3_75_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_75_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_75_1_top"
  top: "res_stage_3_75_1_top"
}
layer {
  name: "res_stage_3_75_2"
  type: "Convolution"
  bottom: "res_stage_3_75_1_top"
  top: "res_stage_3_75_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_75_2"
  type: "BatchNorm"
  bottom: "res_stage_3_75_2"
  top: "res_stage_3_75_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_75_2"  
  type: "Scale"
  bottom: "res_stage_3_75_2"
  top: "res_stage_3_75_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_75_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_75_2_top"
  top: "res_stage_3_75_2_top"
}
layer {
  name: "res_stage_3_75_3"
  type: "Convolution"
  bottom: "res_stage_3_75_2_top"
  top: "res_stage_3_75_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_75_3"
  type: "BatchNorm"
  bottom: "res_stage_3_75_3"
  top: "res_stage_3_75_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_75_3"  
  type: "Scale"
  bottom: "res_stage_3_75_3"
  top: "res_stage_3_75_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_75"
  type: "Eltwise"
  bottom: "res_3_74"
  bottom: "res_stage_3_75_3_top"
  top: "res_3_75"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_75_relu"
  type: "ReLU"
  bottom: "res_3_75"
  top: "res_3_75"
}
layer {
  name: "res_stage_3_76_1"
  type: "Convolution"
  bottom: "res_3_75"
  top: "res_stage_3_76_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_76_1"
  type: "BatchNorm"
  bottom: "res_stage_3_76_1"
  top: "res_stage_3_76_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_76_1"  
  type: "Scale"
  bottom: "res_stage_3_76_1"
  top: "res_stage_3_76_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_76_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_76_1_top"
  top: "res_stage_3_76_1_top"
}
layer {
  name: "res_stage_3_76_2"
  type: "Convolution"
  bottom: "res_stage_3_76_1_top"
  top: "res_stage_3_76_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_76_2"
  type: "BatchNorm"
  bottom: "res_stage_3_76_2"
  top: "res_stage_3_76_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_76_2"  
  type: "Scale"
  bottom: "res_stage_3_76_2"
  top: "res_stage_3_76_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_76_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_76_2_top"
  top: "res_stage_3_76_2_top"
}
layer {
  name: "res_stage_3_76_3"
  type: "Convolution"
  bottom: "res_stage_3_76_2_top"
  top: "res_stage_3_76_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_76_3"
  type: "BatchNorm"
  bottom: "res_stage_3_76_3"
  top: "res_stage_3_76_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_76_3"  
  type: "Scale"
  bottom: "res_stage_3_76_3"
  top: "res_stage_3_76_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_76"
  type: "Eltwise"
  bottom: "res_3_75"
  bottom: "res_stage_3_76_3_top"
  top: "res_3_76"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_76_relu"
  type: "ReLU"
  bottom: "res_3_76"
  top: "res_3_76"
}
layer {
  name: "res_stage_3_77_1"
  type: "Convolution"
  bottom: "res_3_76"
  top: "res_stage_3_77_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_77_1"
  type: "BatchNorm"
  bottom: "res_stage_3_77_1"
  top: "res_stage_3_77_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_77_1"  
  type: "Scale"
  bottom: "res_stage_3_77_1"
  top: "res_stage_3_77_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_77_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_77_1_top"
  top: "res_stage_3_77_1_top"
}
layer {
  name: "res_stage_3_77_2"
  type: "Convolution"
  bottom: "res_stage_3_77_1_top"
  top: "res_stage_3_77_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_77_2"
  type: "BatchNorm"
  bottom: "res_stage_3_77_2"
  top: "res_stage_3_77_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_77_2"  
  type: "Scale"
  bottom: "res_stage_3_77_2"
  top: "res_stage_3_77_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_77_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_77_2_top"
  top: "res_stage_3_77_2_top"
}
layer {
  name: "res_stage_3_77_3"
  type: "Convolution"
  bottom: "res_stage_3_77_2_top"
  top: "res_stage_3_77_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_77_3"
  type: "BatchNorm"
  bottom: "res_stage_3_77_3"
  top: "res_stage_3_77_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_77_3"  
  type: "Scale"
  bottom: "res_stage_3_77_3"
  top: "res_stage_3_77_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_77"
  type: "Eltwise"
  bottom: "res_3_76"
  bottom: "res_stage_3_77_3_top"
  top: "res_3_77"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_77_relu"
  type: "ReLU"
  bottom: "res_3_77"
  top: "res_3_77"
}
layer {
  name: "res_stage_3_78_1"
  type: "Convolution"
  bottom: "res_3_77"
  top: "res_stage_3_78_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_78_1"
  type: "BatchNorm"
  bottom: "res_stage_3_78_1"
  top: "res_stage_3_78_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_78_1"  
  type: "Scale"
  bottom: "res_stage_3_78_1"
  top: "res_stage_3_78_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_78_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_78_1_top"
  top: "res_stage_3_78_1_top"
}
layer {
  name: "res_stage_3_78_2"
  type: "Convolution"
  bottom: "res_stage_3_78_1_top"
  top: "res_stage_3_78_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_78_2"
  type: "BatchNorm"
  bottom: "res_stage_3_78_2"
  top: "res_stage_3_78_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_78_2"  
  type: "Scale"
  bottom: "res_stage_3_78_2"
  top: "res_stage_3_78_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_78_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_78_2_top"
  top: "res_stage_3_78_2_top"
}
layer {
  name: "res_stage_3_78_3"
  type: "Convolution"
  bottom: "res_stage_3_78_2_top"
  top: "res_stage_3_78_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_78_3"
  type: "BatchNorm"
  bottom: "res_stage_3_78_3"
  top: "res_stage_3_78_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_78_3"  
  type: "Scale"
  bottom: "res_stage_3_78_3"
  top: "res_stage_3_78_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_78"
  type: "Eltwise"
  bottom: "res_3_77"
  bottom: "res_stage_3_78_3_top"
  top: "res_3_78"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_78_relu"
  type: "ReLU"
  bottom: "res_3_78"
  top: "res_3_78"
}
layer {
  name: "res_stage_3_79_1"
  type: "Convolution"
  bottom: "res_3_78"
  top: "res_stage_3_79_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_79_1"
  type: "BatchNorm"
  bottom: "res_stage_3_79_1"
  top: "res_stage_3_79_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_79_1"  
  type: "Scale"
  bottom: "res_stage_3_79_1"
  top: "res_stage_3_79_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_79_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_79_1_top"
  top: "res_stage_3_79_1_top"
}
layer {
  name: "res_stage_3_79_2"
  type: "Convolution"
  bottom: "res_stage_3_79_1_top"
  top: "res_stage_3_79_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_79_2"
  type: "BatchNorm"
  bottom: "res_stage_3_79_2"
  top: "res_stage_3_79_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_79_2"  
  type: "Scale"
  bottom: "res_stage_3_79_2"
  top: "res_stage_3_79_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_79_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_79_2_top"
  top: "res_stage_3_79_2_top"
}
layer {
  name: "res_stage_3_79_3"
  type: "Convolution"
  bottom: "res_stage_3_79_2_top"
  top: "res_stage_3_79_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_79_3"
  type: "BatchNorm"
  bottom: "res_stage_3_79_3"
  top: "res_stage_3_79_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_79_3"  
  type: "Scale"
  bottom: "res_stage_3_79_3"
  top: "res_stage_3_79_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_79"
  type: "Eltwise"
  bottom: "res_3_78"
  bottom: "res_stage_3_79_3_top"
  top: "res_3_79"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_79_relu"
  type: "ReLU"
  bottom: "res_3_79"
  top: "res_3_79"
}
layer {
  name: "res_stage_3_80_1"
  type: "Convolution"
  bottom: "res_3_79"
  top: "res_stage_3_80_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_80_1"
  type: "BatchNorm"
  bottom: "res_stage_3_80_1"
  top: "res_stage_3_80_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_80_1"  
  type: "Scale"
  bottom: "res_stage_3_80_1"
  top: "res_stage_3_80_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_80_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_80_1_top"
  top: "res_stage_3_80_1_top"
}
layer {
  name: "res_stage_3_80_2"
  type: "Convolution"
  bottom: "res_stage_3_80_1_top"
  top: "res_stage_3_80_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_80_2"
  type: "BatchNorm"
  bottom: "res_stage_3_80_2"
  top: "res_stage_3_80_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_80_2"  
  type: "Scale"
  bottom: "res_stage_3_80_2"
  top: "res_stage_3_80_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_80_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_80_2_top"
  top: "res_stage_3_80_2_top"
}
layer {
  name: "res_stage_3_80_3"
  type: "Convolution"
  bottom: "res_stage_3_80_2_top"
  top: "res_stage_3_80_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_80_3"
  type: "BatchNorm"
  bottom: "res_stage_3_80_3"
  top: "res_stage_3_80_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_80_3"  
  type: "Scale"
  bottom: "res_stage_3_80_3"
  top: "res_stage_3_80_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_80"
  type: "Eltwise"
  bottom: "res_3_79"
  bottom: "res_stage_3_80_3_top"
  top: "res_3_80"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_80_relu"
  type: "ReLU"
  bottom: "res_3_80"
  top: "res_3_80"
}
layer {
  name: "res_stage_3_81_1"
  type: "Convolution"
  bottom: "res_3_80"
  top: "res_stage_3_81_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_81_1"
  type: "BatchNorm"
  bottom: "res_stage_3_81_1"
  top: "res_stage_3_81_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_81_1"  
  type: "Scale"
  bottom: "res_stage_3_81_1"
  top: "res_stage_3_81_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_81_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_81_1_top"
  top: "res_stage_3_81_1_top"
}
layer {
  name: "res_stage_3_81_2"
  type: "Convolution"
  bottom: "res_stage_3_81_1_top"
  top: "res_stage_3_81_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_81_2"
  type: "BatchNorm"
  bottom: "res_stage_3_81_2"
  top: "res_stage_3_81_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_81_2"  
  type: "Scale"
  bottom: "res_stage_3_81_2"
  top: "res_stage_3_81_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_81_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_81_2_top"
  top: "res_stage_3_81_2_top"
}
layer {
  name: "res_stage_3_81_3"
  type: "Convolution"
  bottom: "res_stage_3_81_2_top"
  top: "res_stage_3_81_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_81_3"
  type: "BatchNorm"
  bottom: "res_stage_3_81_3"
  top: "res_stage_3_81_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_81_3"  
  type: "Scale"
  bottom: "res_stage_3_81_3"
  top: "res_stage_3_81_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_81"
  type: "Eltwise"
  bottom: "res_3_80"
  bottom: "res_stage_3_81_3_top"
  top: "res_3_81"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_81_relu"
  type: "ReLU"
  bottom: "res_3_81"
  top: "res_3_81"
}
layer {
  name: "res_stage_3_82_1"
  type: "Convolution"
  bottom: "res_3_81"
  top: "res_stage_3_82_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_82_1"
  type: "BatchNorm"
  bottom: "res_stage_3_82_1"
  top: "res_stage_3_82_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_82_1"  
  type: "Scale"
  bottom: "res_stage_3_82_1"
  top: "res_stage_3_82_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_82_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_82_1_top"
  top: "res_stage_3_82_1_top"
}
layer {
  name: "res_stage_3_82_2"
  type: "Convolution"
  bottom: "res_stage_3_82_1_top"
  top: "res_stage_3_82_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_82_2"
  type: "BatchNorm"
  bottom: "res_stage_3_82_2"
  top: "res_stage_3_82_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_82_2"  
  type: "Scale"
  bottom: "res_stage_3_82_2"
  top: "res_stage_3_82_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_82_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_82_2_top"
  top: "res_stage_3_82_2_top"
}
layer {
  name: "res_stage_3_82_3"
  type: "Convolution"
  bottom: "res_stage_3_82_2_top"
  top: "res_stage_3_82_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_82_3"
  type: "BatchNorm"
  bottom: "res_stage_3_82_3"
  top: "res_stage_3_82_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_82_3"  
  type: "Scale"
  bottom: "res_stage_3_82_3"
  top: "res_stage_3_82_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_82"
  type: "Eltwise"
  bottom: "res_3_81"
  bottom: "res_stage_3_82_3_top"
  top: "res_3_82"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_82_relu"
  type: "ReLU"
  bottom: "res_3_82"
  top: "res_3_82"
}
layer {
  name: "res_stage_3_83_1"
  type: "Convolution"
  bottom: "res_3_82"
  top: "res_stage_3_83_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_83_1"
  type: "BatchNorm"
  bottom: "res_stage_3_83_1"
  top: "res_stage_3_83_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_83_1"  
  type: "Scale"
  bottom: "res_stage_3_83_1"
  top: "res_stage_3_83_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_83_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_83_1_top"
  top: "res_stage_3_83_1_top"
}
layer {
  name: "res_stage_3_83_2"
  type: "Convolution"
  bottom: "res_stage_3_83_1_top"
  top: "res_stage_3_83_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_83_2"
  type: "BatchNorm"
  bottom: "res_stage_3_83_2"
  top: "res_stage_3_83_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_83_2"  
  type: "Scale"
  bottom: "res_stage_3_83_2"
  top: "res_stage_3_83_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_83_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_83_2_top"
  top: "res_stage_3_83_2_top"
}
layer {
  name: "res_stage_3_83_3"
  type: "Convolution"
  bottom: "res_stage_3_83_2_top"
  top: "res_stage_3_83_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_83_3"
  type: "BatchNorm"
  bottom: "res_stage_3_83_3"
  top: "res_stage_3_83_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_83_3"  
  type: "Scale"
  bottom: "res_stage_3_83_3"
  top: "res_stage_3_83_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_83"
  type: "Eltwise"
  bottom: "res_3_82"
  bottom: "res_stage_3_83_3_top"
  top: "res_3_83"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_83_relu"
  type: "ReLU"
  bottom: "res_3_83"
  top: "res_3_83"
}
layer {
  name: "res_stage_3_84_1"
  type: "Convolution"
  bottom: "res_3_83"
  top: "res_stage_3_84_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_84_1"
  type: "BatchNorm"
  bottom: "res_stage_3_84_1"
  top: "res_stage_3_84_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_84_1"  
  type: "Scale"
  bottom: "res_stage_3_84_1"
  top: "res_stage_3_84_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_84_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_84_1_top"
  top: "res_stage_3_84_1_top"
}
layer {
  name: "res_stage_3_84_2"
  type: "Convolution"
  bottom: "res_stage_3_84_1_top"
  top: "res_stage_3_84_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_84_2"
  type: "BatchNorm"
  bottom: "res_stage_3_84_2"
  top: "res_stage_3_84_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_84_2"  
  type: "Scale"
  bottom: "res_stage_3_84_2"
  top: "res_stage_3_84_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_84_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_84_2_top"
  top: "res_stage_3_84_2_top"
}
layer {
  name: "res_stage_3_84_3"
  type: "Convolution"
  bottom: "res_stage_3_84_2_top"
  top: "res_stage_3_84_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_84_3"
  type: "BatchNorm"
  bottom: "res_stage_3_84_3"
  top: "res_stage_3_84_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_84_3"  
  type: "Scale"
  bottom: "res_stage_3_84_3"
  top: "res_stage_3_84_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_84"
  type: "Eltwise"
  bottom: "res_3_83"
  bottom: "res_stage_3_84_3_top"
  top: "res_3_84"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_84_relu"
  type: "ReLU"
  bottom: "res_3_84"
  top: "res_3_84"
}
layer {
  name: "res_stage_3_85_1"
  type: "Convolution"
  bottom: "res_3_84"
  top: "res_stage_3_85_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_85_1"
  type: "BatchNorm"
  bottom: "res_stage_3_85_1"
  top: "res_stage_3_85_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_85_1"  
  type: "Scale"
  bottom: "res_stage_3_85_1"
  top: "res_stage_3_85_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_85_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_85_1_top"
  top: "res_stage_3_85_1_top"
}
layer {
  name: "res_stage_3_85_2"
  type: "Convolution"
  bottom: "res_stage_3_85_1_top"
  top: "res_stage_3_85_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_85_2"
  type: "BatchNorm"
  bottom: "res_stage_3_85_2"
  top: "res_stage_3_85_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_85_2"  
  type: "Scale"
  bottom: "res_stage_3_85_2"
  top: "res_stage_3_85_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_85_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_85_2_top"
  top: "res_stage_3_85_2_top"
}
layer {
  name: "res_stage_3_85_3"
  type: "Convolution"
  bottom: "res_stage_3_85_2_top"
  top: "res_stage_3_85_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_85_3"
  type: "BatchNorm"
  bottom: "res_stage_3_85_3"
  top: "res_stage_3_85_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_85_3"  
  type: "Scale"
  bottom: "res_stage_3_85_3"
  top: "res_stage_3_85_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_85"
  type: "Eltwise"
  bottom: "res_3_84"
  bottom: "res_stage_3_85_3_top"
  top: "res_3_85"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_85_relu"
  type: "ReLU"
  bottom: "res_3_85"
  top: "res_3_85"
}
layer {
  name: "res_stage_3_86_1"
  type: "Convolution"
  bottom: "res_3_85"
  top: "res_stage_3_86_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_86_1"
  type: "BatchNorm"
  bottom: "res_stage_3_86_1"
  top: "res_stage_3_86_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_86_1"  
  type: "Scale"
  bottom: "res_stage_3_86_1"
  top: "res_stage_3_86_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_86_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_86_1_top"
  top: "res_stage_3_86_1_top"
}
layer {
  name: "res_stage_3_86_2"
  type: "Convolution"
  bottom: "res_stage_3_86_1_top"
  top: "res_stage_3_86_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_86_2"
  type: "BatchNorm"
  bottom: "res_stage_3_86_2"
  top: "res_stage_3_86_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_86_2"  
  type: "Scale"
  bottom: "res_stage_3_86_2"
  top: "res_stage_3_86_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_86_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_86_2_top"
  top: "res_stage_3_86_2_top"
}
layer {
  name: "res_stage_3_86_3"
  type: "Convolution"
  bottom: "res_stage_3_86_2_top"
  top: "res_stage_3_86_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_86_3"
  type: "BatchNorm"
  bottom: "res_stage_3_86_3"
  top: "res_stage_3_86_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_86_3"  
  type: "Scale"
  bottom: "res_stage_3_86_3"
  top: "res_stage_3_86_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_86"
  type: "Eltwise"
  bottom: "res_3_85"
  bottom: "res_stage_3_86_3_top"
  top: "res_3_86"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_86_relu"
  type: "ReLU"
  bottom: "res_3_86"
  top: "res_3_86"
}
layer {
  name: "res_stage_3_87_1"
  type: "Convolution"
  bottom: "res_3_86"
  top: "res_stage_3_87_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_87_1"
  type: "BatchNorm"
  bottom: "res_stage_3_87_1"
  top: "res_stage_3_87_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_87_1"  
  type: "Scale"
  bottom: "res_stage_3_87_1"
  top: "res_stage_3_87_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_87_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_87_1_top"
  top: "res_stage_3_87_1_top"
}
layer {
  name: "res_stage_3_87_2"
  type: "Convolution"
  bottom: "res_stage_3_87_1_top"
  top: "res_stage_3_87_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_87_2"
  type: "BatchNorm"
  bottom: "res_stage_3_87_2"
  top: "res_stage_3_87_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_87_2"  
  type: "Scale"
  bottom: "res_stage_3_87_2"
  top: "res_stage_3_87_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_87_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_87_2_top"
  top: "res_stage_3_87_2_top"
}
layer {
  name: "res_stage_3_87_3"
  type: "Convolution"
  bottom: "res_stage_3_87_2_top"
  top: "res_stage_3_87_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_87_3"
  type: "BatchNorm"
  bottom: "res_stage_3_87_3"
  top: "res_stage_3_87_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_87_3"  
  type: "Scale"
  bottom: "res_stage_3_87_3"
  top: "res_stage_3_87_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_87"
  type: "Eltwise"
  bottom: "res_3_86"
  bottom: "res_stage_3_87_3_top"
  top: "res_3_87"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_87_relu"
  type: "ReLU"
  bottom: "res_3_87"
  top: "res_3_87"
}
layer {
  name: "res_stage_3_88_1"
  type: "Convolution"
  bottom: "res_3_87"
  top: "res_stage_3_88_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_88_1"
  type: "BatchNorm"
  bottom: "res_stage_3_88_1"
  top: "res_stage_3_88_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_88_1"  
  type: "Scale"
  bottom: "res_stage_3_88_1"
  top: "res_stage_3_88_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_88_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_88_1_top"
  top: "res_stage_3_88_1_top"
}
layer {
  name: "res_stage_3_88_2"
  type: "Convolution"
  bottom: "res_stage_3_88_1_top"
  top: "res_stage_3_88_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_88_2"
  type: "BatchNorm"
  bottom: "res_stage_3_88_2"
  top: "res_stage_3_88_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_88_2"  
  type: "Scale"
  bottom: "res_stage_3_88_2"
  top: "res_stage_3_88_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_88_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_88_2_top"
  top: "res_stage_3_88_2_top"
}
layer {
  name: "res_stage_3_88_3"
  type: "Convolution"
  bottom: "res_stage_3_88_2_top"
  top: "res_stage_3_88_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_88_3"
  type: "BatchNorm"
  bottom: "res_stage_3_88_3"
  top: "res_stage_3_88_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_88_3"  
  type: "Scale"
  bottom: "res_stage_3_88_3"
  top: "res_stage_3_88_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_88"
  type: "Eltwise"
  bottom: "res_3_87"
  bottom: "res_stage_3_88_3_top"
  top: "res_3_88"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_88_relu"
  type: "ReLU"
  bottom: "res_3_88"
  top: "res_3_88"
}
layer {
  name: "res_stage_3_89_1"
  type: "Convolution"
  bottom: "res_3_88"
  top: "res_stage_3_89_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_89_1"
  type: "BatchNorm"
  bottom: "res_stage_3_89_1"
  top: "res_stage_3_89_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_89_1"  
  type: "Scale"
  bottom: "res_stage_3_89_1"
  top: "res_stage_3_89_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_89_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_89_1_top"
  top: "res_stage_3_89_1_top"
}
layer {
  name: "res_stage_3_89_2"
  type: "Convolution"
  bottom: "res_stage_3_89_1_top"
  top: "res_stage_3_89_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_89_2"
  type: "BatchNorm"
  bottom: "res_stage_3_89_2"
  top: "res_stage_3_89_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_89_2"  
  type: "Scale"
  bottom: "res_stage_3_89_2"
  top: "res_stage_3_89_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_89_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_89_2_top"
  top: "res_stage_3_89_2_top"
}
layer {
  name: "res_stage_3_89_3"
  type: "Convolution"
  bottom: "res_stage_3_89_2_top"
  top: "res_stage_3_89_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_89_3"
  type: "BatchNorm"
  bottom: "res_stage_3_89_3"
  top: "res_stage_3_89_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_89_3"  
  type: "Scale"
  bottom: "res_stage_3_89_3"
  top: "res_stage_3_89_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_89"
  type: "Eltwise"
  bottom: "res_3_88"
  bottom: "res_stage_3_89_3_top"
  top: "res_3_89"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_89_relu"
  type: "ReLU"
  bottom: "res_3_89"
  top: "res_3_89"
}
layer {
  name: "res_stage_3_90_1"
  type: "Convolution"
  bottom: "res_3_89"
  top: "res_stage_3_90_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_90_1"
  type: "BatchNorm"
  bottom: "res_stage_3_90_1"
  top: "res_stage_3_90_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_90_1"  
  type: "Scale"
  bottom: "res_stage_3_90_1"
  top: "res_stage_3_90_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_90_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_90_1_top"
  top: "res_stage_3_90_1_top"
}
layer {
  name: "res_stage_3_90_2"
  type: "Convolution"
  bottom: "res_stage_3_90_1_top"
  top: "res_stage_3_90_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_90_2"
  type: "BatchNorm"
  bottom: "res_stage_3_90_2"
  top: "res_stage_3_90_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_90_2"  
  type: "Scale"
  bottom: "res_stage_3_90_2"
  top: "res_stage_3_90_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_90_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_90_2_top"
  top: "res_stage_3_90_2_top"
}
layer {
  name: "res_stage_3_90_3"
  type: "Convolution"
  bottom: "res_stage_3_90_2_top"
  top: "res_stage_3_90_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_90_3"
  type: "BatchNorm"
  bottom: "res_stage_3_90_3"
  top: "res_stage_3_90_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_90_3"  
  type: "Scale"
  bottom: "res_stage_3_90_3"
  top: "res_stage_3_90_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_90"
  type: "Eltwise"
  bottom: "res_3_89"
  bottom: "res_stage_3_90_3_top"
  top: "res_3_90"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_90_relu"
  type: "ReLU"
  bottom: "res_3_90"
  top: "res_3_90"
}
layer {
  name: "res_stage_3_91_1"
  type: "Convolution"
  bottom: "res_3_90"
  top: "res_stage_3_91_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_91_1"
  type: "BatchNorm"
  bottom: "res_stage_3_91_1"
  top: "res_stage_3_91_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_91_1"  
  type: "Scale"
  bottom: "res_stage_3_91_1"
  top: "res_stage_3_91_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_91_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_91_1_top"
  top: "res_stage_3_91_1_top"
}
layer {
  name: "res_stage_3_91_2"
  type: "Convolution"
  bottom: "res_stage_3_91_1_top"
  top: "res_stage_3_91_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_91_2"
  type: "BatchNorm"
  bottom: "res_stage_3_91_2"
  top: "res_stage_3_91_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_91_2"  
  type: "Scale"
  bottom: "res_stage_3_91_2"
  top: "res_stage_3_91_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_91_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_91_2_top"
  top: "res_stage_3_91_2_top"
}
layer {
  name: "res_stage_3_91_3"
  type: "Convolution"
  bottom: "res_stage_3_91_2_top"
  top: "res_stage_3_91_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_91_3"
  type: "BatchNorm"
  bottom: "res_stage_3_91_3"
  top: "res_stage_3_91_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_91_3"  
  type: "Scale"
  bottom: "res_stage_3_91_3"
  top: "res_stage_3_91_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_91"
  type: "Eltwise"
  bottom: "res_3_90"
  bottom: "res_stage_3_91_3_top"
  top: "res_3_91"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_91_relu"
  type: "ReLU"
  bottom: "res_3_91"
  top: "res_3_91"
}
layer {
  name: "res_stage_3_92_1"
  type: "Convolution"
  bottom: "res_3_91"
  top: "res_stage_3_92_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_92_1"
  type: "BatchNorm"
  bottom: "res_stage_3_92_1"
  top: "res_stage_3_92_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_92_1"  
  type: "Scale"
  bottom: "res_stage_3_92_1"
  top: "res_stage_3_92_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_92_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_92_1_top"
  top: "res_stage_3_92_1_top"
}
layer {
  name: "res_stage_3_92_2"
  type: "Convolution"
  bottom: "res_stage_3_92_1_top"
  top: "res_stage_3_92_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_92_2"
  type: "BatchNorm"
  bottom: "res_stage_3_92_2"
  top: "res_stage_3_92_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_92_2"  
  type: "Scale"
  bottom: "res_stage_3_92_2"
  top: "res_stage_3_92_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_92_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_92_2_top"
  top: "res_stage_3_92_2_top"
}
layer {
  name: "res_stage_3_92_3"
  type: "Convolution"
  bottom: "res_stage_3_92_2_top"
  top: "res_stage_3_92_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_92_3"
  type: "BatchNorm"
  bottom: "res_stage_3_92_3"
  top: "res_stage_3_92_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_92_3"  
  type: "Scale"
  bottom: "res_stage_3_92_3"
  top: "res_stage_3_92_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_92"
  type: "Eltwise"
  bottom: "res_3_91"
  bottom: "res_stage_3_92_3_top"
  top: "res_3_92"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_92_relu"
  type: "ReLU"
  bottom: "res_3_92"
  top: "res_3_92"
}
layer {
  name: "res_stage_3_93_1"
  type: "Convolution"
  bottom: "res_3_92"
  top: "res_stage_3_93_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_93_1"
  type: "BatchNorm"
  bottom: "res_stage_3_93_1"
  top: "res_stage_3_93_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_93_1"  
  type: "Scale"
  bottom: "res_stage_3_93_1"
  top: "res_stage_3_93_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_93_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_93_1_top"
  top: "res_stage_3_93_1_top"
}
layer {
  name: "res_stage_3_93_2"
  type: "Convolution"
  bottom: "res_stage_3_93_1_top"
  top: "res_stage_3_93_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_93_2"
  type: "BatchNorm"
  bottom: "res_stage_3_93_2"
  top: "res_stage_3_93_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_93_2"  
  type: "Scale"
  bottom: "res_stage_3_93_2"
  top: "res_stage_3_93_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_93_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_93_2_top"
  top: "res_stage_3_93_2_top"
}
layer {
  name: "res_stage_3_93_3"
  type: "Convolution"
  bottom: "res_stage_3_93_2_top"
  top: "res_stage_3_93_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_93_3"
  type: "BatchNorm"
  bottom: "res_stage_3_93_3"
  top: "res_stage_3_93_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_93_3"  
  type: "Scale"
  bottom: "res_stage_3_93_3"
  top: "res_stage_3_93_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_93"
  type: "Eltwise"
  bottom: "res_3_92"
  bottom: "res_stage_3_93_3_top"
  top: "res_3_93"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_93_relu"
  type: "ReLU"
  bottom: "res_3_93"
  top: "res_3_93"
}
layer {
  name: "res_stage_3_94_1"
  type: "Convolution"
  bottom: "res_3_93"
  top: "res_stage_3_94_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_94_1"
  type: "BatchNorm"
  bottom: "res_stage_3_94_1"
  top: "res_stage_3_94_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_94_1"  
  type: "Scale"
  bottom: "res_stage_3_94_1"
  top: "res_stage_3_94_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_94_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_94_1_top"
  top: "res_stage_3_94_1_top"
}
layer {
  name: "res_stage_3_94_2"
  type: "Convolution"
  bottom: "res_stage_3_94_1_top"
  top: "res_stage_3_94_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_94_2"
  type: "BatchNorm"
  bottom: "res_stage_3_94_2"
  top: "res_stage_3_94_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_94_2"  
  type: "Scale"
  bottom: "res_stage_3_94_2"
  top: "res_stage_3_94_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_94_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_94_2_top"
  top: "res_stage_3_94_2_top"
}
layer {
  name: "res_stage_3_94_3"
  type: "Convolution"
  bottom: "res_stage_3_94_2_top"
  top: "res_stage_3_94_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_94_3"
  type: "BatchNorm"
  bottom: "res_stage_3_94_3"
  top: "res_stage_3_94_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_94_3"  
  type: "Scale"
  bottom: "res_stage_3_94_3"
  top: "res_stage_3_94_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_94"
  type: "Eltwise"
  bottom: "res_3_93"
  bottom: "res_stage_3_94_3_top"
  top: "res_3_94"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_94_relu"
  type: "ReLU"
  bottom: "res_3_94"
  top: "res_3_94"
}
layer {
  name: "res_stage_3_95_1"
  type: "Convolution"
  bottom: "res_3_94"
  top: "res_stage_3_95_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_95_1"
  type: "BatchNorm"
  bottom: "res_stage_3_95_1"
  top: "res_stage_3_95_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_95_1"  
  type: "Scale"
  bottom: "res_stage_3_95_1"
  top: "res_stage_3_95_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_95_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_95_1_top"
  top: "res_stage_3_95_1_top"
}
layer {
  name: "res_stage_3_95_2"
  type: "Convolution"
  bottom: "res_stage_3_95_1_top"
  top: "res_stage_3_95_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_95_2"
  type: "BatchNorm"
  bottom: "res_stage_3_95_2"
  top: "res_stage_3_95_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_95_2"  
  type: "Scale"
  bottom: "res_stage_3_95_2"
  top: "res_stage_3_95_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_95_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_95_2_top"
  top: "res_stage_3_95_2_top"
}
layer {
  name: "res_stage_3_95_3"
  type: "Convolution"
  bottom: "res_stage_3_95_2_top"
  top: "res_stage_3_95_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_95_3"
  type: "BatchNorm"
  bottom: "res_stage_3_95_3"
  top: "res_stage_3_95_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_95_3"  
  type: "Scale"
  bottom: "res_stage_3_95_3"
  top: "res_stage_3_95_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_95"
  type: "Eltwise"
  bottom: "res_3_94"
  bottom: "res_stage_3_95_3_top"
  top: "res_3_95"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_95_relu"
  type: "ReLU"
  bottom: "res_3_95"
  top: "res_3_95"
}
layer {
  name: "res_stage_3_96_1"
  type: "Convolution"
  bottom: "res_3_95"
  top: "res_stage_3_96_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_96_1"
  type: "BatchNorm"
  bottom: "res_stage_3_96_1"
  top: "res_stage_3_96_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_96_1"  
  type: "Scale"
  bottom: "res_stage_3_96_1"
  top: "res_stage_3_96_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_96_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_96_1_top"
  top: "res_stage_3_96_1_top"
}
layer {
  name: "res_stage_3_96_2"
  type: "Convolution"
  bottom: "res_stage_3_96_1_top"
  top: "res_stage_3_96_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_96_2"
  type: "BatchNorm"
  bottom: "res_stage_3_96_2"
  top: "res_stage_3_96_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_96_2"  
  type: "Scale"
  bottom: "res_stage_3_96_2"
  top: "res_stage_3_96_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_96_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_96_2_top"
  top: "res_stage_3_96_2_top"
}
layer {
  name: "res_stage_3_96_3"
  type: "Convolution"
  bottom: "res_stage_3_96_2_top"
  top: "res_stage_3_96_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_96_3"
  type: "BatchNorm"
  bottom: "res_stage_3_96_3"
  top: "res_stage_3_96_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_96_3"  
  type: "Scale"
  bottom: "res_stage_3_96_3"
  top: "res_stage_3_96_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_96"
  type: "Eltwise"
  bottom: "res_3_95"
  bottom: "res_stage_3_96_3_top"
  top: "res_3_96"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_96_relu"
  type: "ReLU"
  bottom: "res_3_96"
  top: "res_3_96"
}
layer {
  name: "res_stage_3_97_1"
  type: "Convolution"
  bottom: "res_3_96"
  top: "res_stage_3_97_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_97_1"
  type: "BatchNorm"
  bottom: "res_stage_3_97_1"
  top: "res_stage_3_97_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_97_1"  
  type: "Scale"
  bottom: "res_stage_3_97_1"
  top: "res_stage_3_97_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_97_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_97_1_top"
  top: "res_stage_3_97_1_top"
}
layer {
  name: "res_stage_3_97_2"
  type: "Convolution"
  bottom: "res_stage_3_97_1_top"
  top: "res_stage_3_97_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_97_2"
  type: "BatchNorm"
  bottom: "res_stage_3_97_2"
  top: "res_stage_3_97_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_97_2"  
  type: "Scale"
  bottom: "res_stage_3_97_2"
  top: "res_stage_3_97_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_97_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_97_2_top"
  top: "res_stage_3_97_2_top"
}
layer {
  name: "res_stage_3_97_3"
  type: "Convolution"
  bottom: "res_stage_3_97_2_top"
  top: "res_stage_3_97_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_97_3"
  type: "BatchNorm"
  bottom: "res_stage_3_97_3"
  top: "res_stage_3_97_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_97_3"  
  type: "Scale"
  bottom: "res_stage_3_97_3"
  top: "res_stage_3_97_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_97"
  type: "Eltwise"
  bottom: "res_3_96"
  bottom: "res_stage_3_97_3_top"
  top: "res_3_97"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_97_relu"
  type: "ReLU"
  bottom: "res_3_97"
  top: "res_3_97"
}
layer {
  name: "res_stage_3_98_1"
  type: "Convolution"
  bottom: "res_3_97"
  top: "res_stage_3_98_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_98_1"
  type: "BatchNorm"
  bottom: "res_stage_3_98_1"
  top: "res_stage_3_98_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_98_1"  
  type: "Scale"
  bottom: "res_stage_3_98_1"
  top: "res_stage_3_98_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_98_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_98_1_top"
  top: "res_stage_3_98_1_top"
}
layer {
  name: "res_stage_3_98_2"
  type: "Convolution"
  bottom: "res_stage_3_98_1_top"
  top: "res_stage_3_98_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_98_2"
  type: "BatchNorm"
  bottom: "res_stage_3_98_2"
  top: "res_stage_3_98_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_98_2"  
  type: "Scale"
  bottom: "res_stage_3_98_2"
  top: "res_stage_3_98_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_98_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_98_2_top"
  top: "res_stage_3_98_2_top"
}
layer {
  name: "res_stage_3_98_3"
  type: "Convolution"
  bottom: "res_stage_3_98_2_top"
  top: "res_stage_3_98_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_98_3"
  type: "BatchNorm"
  bottom: "res_stage_3_98_3"
  top: "res_stage_3_98_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_98_3"  
  type: "Scale"
  bottom: "res_stage_3_98_3"
  top: "res_stage_3_98_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_98"
  type: "Eltwise"
  bottom: "res_3_97"
  bottom: "res_stage_3_98_3_top"
  top: "res_3_98"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_98_relu"
  type: "ReLU"
  bottom: "res_3_98"
  top: "res_3_98"
}
layer {
  name: "res_stage_3_99_1"
  type: "Convolution"
  bottom: "res_3_98"
  top: "res_stage_3_99_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_99_1"
  type: "BatchNorm"
  bottom: "res_stage_3_99_1"
  top: "res_stage_3_99_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_99_1"  
  type: "Scale"
  bottom: "res_stage_3_99_1"
  top: "res_stage_3_99_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_99_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_99_1_top"
  top: "res_stage_3_99_1_top"
}
layer {
  name: "res_stage_3_99_2"
  type: "Convolution"
  bottom: "res_stage_3_99_1_top"
  top: "res_stage_3_99_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_99_2"
  type: "BatchNorm"
  bottom: "res_stage_3_99_2"
  top: "res_stage_3_99_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_99_2"  
  type: "Scale"
  bottom: "res_stage_3_99_2"
  top: "res_stage_3_99_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_99_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_99_2_top"
  top: "res_stage_3_99_2_top"
}
layer {
  name: "res_stage_3_99_3"
  type: "Convolution"
  bottom: "res_stage_3_99_2_top"
  top: "res_stage_3_99_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_99_3"
  type: "BatchNorm"
  bottom: "res_stage_3_99_3"
  top: "res_stage_3_99_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_99_3"  
  type: "Scale"
  bottom: "res_stage_3_99_3"
  top: "res_stage_3_99_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_99"
  type: "Eltwise"
  bottom: "res_3_98"
  bottom: "res_stage_3_99_3_top"
  top: "res_3_99"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_99_relu"
  type: "ReLU"
  bottom: "res_3_99"
  top: "res_3_99"
}
layer {
  name: "res_stage_3_100_1"
  type: "Convolution"
  bottom: "res_3_99"
  top: "res_stage_3_100_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_100_1"
  type: "BatchNorm"
  bottom: "res_stage_3_100_1"
  top: "res_stage_3_100_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_100_1"  
  type: "Scale"
  bottom: "res_stage_3_100_1"
  top: "res_stage_3_100_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_100_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_100_1_top"
  top: "res_stage_3_100_1_top"
}
layer {
  name: "res_stage_3_100_2"
  type: "Convolution"
  bottom: "res_stage_3_100_1_top"
  top: "res_stage_3_100_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_100_2"
  type: "BatchNorm"
  bottom: "res_stage_3_100_2"
  top: "res_stage_3_100_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_100_2"  
  type: "Scale"
  bottom: "res_stage_3_100_2"
  top: "res_stage_3_100_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_100_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_100_2_top"
  top: "res_stage_3_100_2_top"
}
layer {
  name: "res_stage_3_100_3"
  type: "Convolution"
  bottom: "res_stage_3_100_2_top"
  top: "res_stage_3_100_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_100_3"
  type: "BatchNorm"
  bottom: "res_stage_3_100_3"
  top: "res_stage_3_100_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_100_3"  
  type: "Scale"
  bottom: "res_stage_3_100_3"
  top: "res_stage_3_100_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_100"
  type: "Eltwise"
  bottom: "res_3_99"
  bottom: "res_stage_3_100_3_top"
  top: "res_3_100"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_100_relu"
  type: "ReLU"
  bottom: "res_3_100"
  top: "res_3_100"
}
layer {
  name: "res_stage_3_101_1"
  type: "Convolution"
  bottom: "res_3_100"
  top: "res_stage_3_101_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_101_1"
  type: "BatchNorm"
  bottom: "res_stage_3_101_1"
  top: "res_stage_3_101_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_101_1"  
  type: "Scale"
  bottom: "res_stage_3_101_1"
  top: "res_stage_3_101_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_101_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_101_1_top"
  top: "res_stage_3_101_1_top"
}
layer {
  name: "res_stage_3_101_2"
  type: "Convolution"
  bottom: "res_stage_3_101_1_top"
  top: "res_stage_3_101_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_101_2"
  type: "BatchNorm"
  bottom: "res_stage_3_101_2"
  top: "res_stage_3_101_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_101_2"  
  type: "Scale"
  bottom: "res_stage_3_101_2"
  top: "res_stage_3_101_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_101_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_101_2_top"
  top: "res_stage_3_101_2_top"
}
layer {
  name: "res_stage_3_101_3"
  type: "Convolution"
  bottom: "res_stage_3_101_2_top"
  top: "res_stage_3_101_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_101_3"
  type: "BatchNorm"
  bottom: "res_stage_3_101_3"
  top: "res_stage_3_101_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_101_3"  
  type: "Scale"
  bottom: "res_stage_3_101_3"
  top: "res_stage_3_101_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_101"
  type: "Eltwise"
  bottom: "res_3_100"
  bottom: "res_stage_3_101_3_top"
  top: "res_3_101"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_101_relu"
  type: "ReLU"
  bottom: "res_3_101"
  top: "res_3_101"
}
layer {
  name: "res_stage_3_102_1"
  type: "Convolution"
  bottom: "res_3_101"
  top: "res_stage_3_102_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_102_1"
  type: "BatchNorm"
  bottom: "res_stage_3_102_1"
  top: "res_stage_3_102_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_102_1"  
  type: "Scale"
  bottom: "res_stage_3_102_1"
  top: "res_stage_3_102_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_102_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_102_1_top"
  top: "res_stage_3_102_1_top"
}
layer {
  name: "res_stage_3_102_2"
  type: "Convolution"
  bottom: "res_stage_3_102_1_top"
  top: "res_stage_3_102_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_102_2"
  type: "BatchNorm"
  bottom: "res_stage_3_102_2"
  top: "res_stage_3_102_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_102_2"  
  type: "Scale"
  bottom: "res_stage_3_102_2"
  top: "res_stage_3_102_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_102_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_102_2_top"
  top: "res_stage_3_102_2_top"
}
layer {
  name: "res_stage_3_102_3"
  type: "Convolution"
  bottom: "res_stage_3_102_2_top"
  top: "res_stage_3_102_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_102_3"
  type: "BatchNorm"
  bottom: "res_stage_3_102_3"
  top: "res_stage_3_102_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_102_3"  
  type: "Scale"
  bottom: "res_stage_3_102_3"
  top: "res_stage_3_102_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_102"
  type: "Eltwise"
  bottom: "res_3_101"
  bottom: "res_stage_3_102_3_top"
  top: "res_3_102"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_102_relu"
  type: "ReLU"
  bottom: "res_3_102"
  top: "res_3_102"
}
layer {
  name: "res_stage_3_103_1"
  type: "Convolution"
  bottom: "res_3_102"
  top: "res_stage_3_103_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_103_1"
  type: "BatchNorm"
  bottom: "res_stage_3_103_1"
  top: "res_stage_3_103_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_103_1"  
  type: "Scale"
  bottom: "res_stage_3_103_1"
  top: "res_stage_3_103_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_103_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_103_1_top"
  top: "res_stage_3_103_1_top"
}
layer {
  name: "res_stage_3_103_2"
  type: "Convolution"
  bottom: "res_stage_3_103_1_top"
  top: "res_stage_3_103_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_103_2"
  type: "BatchNorm"
  bottom: "res_stage_3_103_2"
  top: "res_stage_3_103_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_103_2"  
  type: "Scale"
  bottom: "res_stage_3_103_2"
  top: "res_stage_3_103_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_103_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_103_2_top"
  top: "res_stage_3_103_2_top"
}
layer {
  name: "res_stage_3_103_3"
  type: "Convolution"
  bottom: "res_stage_3_103_2_top"
  top: "res_stage_3_103_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_103_3"
  type: "BatchNorm"
  bottom: "res_stage_3_103_3"
  top: "res_stage_3_103_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_103_3"  
  type: "Scale"
  bottom: "res_stage_3_103_3"
  top: "res_stage_3_103_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_103"
  type: "Eltwise"
  bottom: "res_3_102"
  bottom: "res_stage_3_103_3_top"
  top: "res_3_103"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_103_relu"
  type: "ReLU"
  bottom: "res_3_103"
  top: "res_3_103"
}
layer {
  name: "res_stage_3_104_1"
  type: "Convolution"
  bottom: "res_3_103"
  top: "res_stage_3_104_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_104_1"
  type: "BatchNorm"
  bottom: "res_stage_3_104_1"
  top: "res_stage_3_104_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_104_1"  
  type: "Scale"
  bottom: "res_stage_3_104_1"
  top: "res_stage_3_104_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_104_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_104_1_top"
  top: "res_stage_3_104_1_top"
}
layer {
  name: "res_stage_3_104_2"
  type: "Convolution"
  bottom: "res_stage_3_104_1_top"
  top: "res_stage_3_104_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_104_2"
  type: "BatchNorm"
  bottom: "res_stage_3_104_2"
  top: "res_stage_3_104_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_104_2"  
  type: "Scale"
  bottom: "res_stage_3_104_2"
  top: "res_stage_3_104_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_104_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_104_2_top"
  top: "res_stage_3_104_2_top"
}
layer {
  name: "res_stage_3_104_3"
  type: "Convolution"
  bottom: "res_stage_3_104_2_top"
  top: "res_stage_3_104_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_104_3"
  type: "BatchNorm"
  bottom: "res_stage_3_104_3"
  top: "res_stage_3_104_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_104_3"  
  type: "Scale"
  bottom: "res_stage_3_104_3"
  top: "res_stage_3_104_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_104"
  type: "Eltwise"
  bottom: "res_3_103"
  bottom: "res_stage_3_104_3_top"
  top: "res_3_104"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_104_relu"
  type: "ReLU"
  bottom: "res_3_104"
  top: "res_3_104"
}
layer {
  name: "res_stage_3_105_1"
  type: "Convolution"
  bottom: "res_3_104"
  top: "res_stage_3_105_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_105_1"
  type: "BatchNorm"
  bottom: "res_stage_3_105_1"
  top: "res_stage_3_105_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_105_1"  
  type: "Scale"
  bottom: "res_stage_3_105_1"
  top: "res_stage_3_105_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_105_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_105_1_top"
  top: "res_stage_3_105_1_top"
}
layer {
  name: "res_stage_3_105_2"
  type: "Convolution"
  bottom: "res_stage_3_105_1_top"
  top: "res_stage_3_105_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_105_2"
  type: "BatchNorm"
  bottom: "res_stage_3_105_2"
  top: "res_stage_3_105_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_105_2"  
  type: "Scale"
  bottom: "res_stage_3_105_2"
  top: "res_stage_3_105_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_105_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_105_2_top"
  top: "res_stage_3_105_2_top"
}
layer {
  name: "res_stage_3_105_3"
  type: "Convolution"
  bottom: "res_stage_3_105_2_top"
  top: "res_stage_3_105_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_105_3"
  type: "BatchNorm"
  bottom: "res_stage_3_105_3"
  top: "res_stage_3_105_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_105_3"  
  type: "Scale"
  bottom: "res_stage_3_105_3"
  top: "res_stage_3_105_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_105"
  type: "Eltwise"
  bottom: "res_3_104"
  bottom: "res_stage_3_105_3_top"
  top: "res_3_105"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_105_relu"
  type: "ReLU"
  bottom: "res_3_105"
  top: "res_3_105"
}
layer {
  name: "res_stage_3_106_1"
  type: "Convolution"
  bottom: "res_3_105"
  top: "res_stage_3_106_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_106_1"
  type: "BatchNorm"
  bottom: "res_stage_3_106_1"
  top: "res_stage_3_106_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_106_1"  
  type: "Scale"
  bottom: "res_stage_3_106_1"
  top: "res_stage_3_106_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_106_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_106_1_top"
  top: "res_stage_3_106_1_top"
}
layer {
  name: "res_stage_3_106_2"
  type: "Convolution"
  bottom: "res_stage_3_106_1_top"
  top: "res_stage_3_106_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_106_2"
  type: "BatchNorm"
  bottom: "res_stage_3_106_2"
  top: "res_stage_3_106_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_106_2"  
  type: "Scale"
  bottom: "res_stage_3_106_2"
  top: "res_stage_3_106_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_106_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_106_2_top"
  top: "res_stage_3_106_2_top"
}
layer {
  name: "res_stage_3_106_3"
  type: "Convolution"
  bottom: "res_stage_3_106_2_top"
  top: "res_stage_3_106_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_106_3"
  type: "BatchNorm"
  bottom: "res_stage_3_106_3"
  top: "res_stage_3_106_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_106_3"  
  type: "Scale"
  bottom: "res_stage_3_106_3"
  top: "res_stage_3_106_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_106"
  type: "Eltwise"
  bottom: "res_3_105"
  bottom: "res_stage_3_106_3_top"
  top: "res_3_106"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_106_relu"
  type: "ReLU"
  bottom: "res_3_106"
  top: "res_3_106"
}
layer {
  name: "res_stage_3_107_1"
  type: "Convolution"
  bottom: "res_3_106"
  top: "res_stage_3_107_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_107_1"
  type: "BatchNorm"
  bottom: "res_stage_3_107_1"
  top: "res_stage_3_107_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_107_1"  
  type: "Scale"
  bottom: "res_stage_3_107_1"
  top: "res_stage_3_107_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_107_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_107_1_top"
  top: "res_stage_3_107_1_top"
}
layer {
  name: "res_stage_3_107_2"
  type: "Convolution"
  bottom: "res_stage_3_107_1_top"
  top: "res_stage_3_107_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_107_2"
  type: "BatchNorm"
  bottom: "res_stage_3_107_2"
  top: "res_stage_3_107_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_107_2"  
  type: "Scale"
  bottom: "res_stage_3_107_2"
  top: "res_stage_3_107_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_107_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_107_2_top"
  top: "res_stage_3_107_2_top"
}
layer {
  name: "res_stage_3_107_3"
  type: "Convolution"
  bottom: "res_stage_3_107_2_top"
  top: "res_stage_3_107_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_107_3"
  type: "BatchNorm"
  bottom: "res_stage_3_107_3"
  top: "res_stage_3_107_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_107_3"  
  type: "Scale"
  bottom: "res_stage_3_107_3"
  top: "res_stage_3_107_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_107"
  type: "Eltwise"
  bottom: "res_3_106"
  bottom: "res_stage_3_107_3_top"
  top: "res_3_107"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_107_relu"
  type: "ReLU"
  bottom: "res_3_107"
  top: "res_3_107"
}
layer {
  name: "res_stage_3_108_1"
  type: "Convolution"
  bottom: "res_3_107"
  top: "res_stage_3_108_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_108_1"
  type: "BatchNorm"
  bottom: "res_stage_3_108_1"
  top: "res_stage_3_108_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_108_1"  
  type: "Scale"
  bottom: "res_stage_3_108_1"
  top: "res_stage_3_108_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_108_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_108_1_top"
  top: "res_stage_3_108_1_top"
}
layer {
  name: "res_stage_3_108_2"
  type: "Convolution"
  bottom: "res_stage_3_108_1_top"
  top: "res_stage_3_108_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_108_2"
  type: "BatchNorm"
  bottom: "res_stage_3_108_2"
  top: "res_stage_3_108_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_108_2"  
  type: "Scale"
  bottom: "res_stage_3_108_2"
  top: "res_stage_3_108_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_108_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_108_2_top"
  top: "res_stage_3_108_2_top"
}
layer {
  name: "res_stage_3_108_3"
  type: "Convolution"
  bottom: "res_stage_3_108_2_top"
  top: "res_stage_3_108_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_108_3"
  type: "BatchNorm"
  bottom: "res_stage_3_108_3"
  top: "res_stage_3_108_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_108_3"  
  type: "Scale"
  bottom: "res_stage_3_108_3"
  top: "res_stage_3_108_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_108"
  type: "Eltwise"
  bottom: "res_3_107"
  bottom: "res_stage_3_108_3_top"
  top: "res_3_108"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_108_relu"
  type: "ReLU"
  bottom: "res_3_108"
  top: "res_3_108"
}
layer {
  name: "res_stage_3_109_1"
  type: "Convolution"
  bottom: "res_3_108"
  top: "res_stage_3_109_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_109_1"
  type: "BatchNorm"
  bottom: "res_stage_3_109_1"
  top: "res_stage_3_109_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_109_1"  
  type: "Scale"
  bottom: "res_stage_3_109_1"
  top: "res_stage_3_109_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_109_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_109_1_top"
  top: "res_stage_3_109_1_top"
}
layer {
  name: "res_stage_3_109_2"
  type: "Convolution"
  bottom: "res_stage_3_109_1_top"
  top: "res_stage_3_109_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_109_2"
  type: "BatchNorm"
  bottom: "res_stage_3_109_2"
  top: "res_stage_3_109_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_109_2"  
  type: "Scale"
  bottom: "res_stage_3_109_2"
  top: "res_stage_3_109_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_109_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_109_2_top"
  top: "res_stage_3_109_2_top"
}
layer {
  name: "res_stage_3_109_3"
  type: "Convolution"
  bottom: "res_stage_3_109_2_top"
  top: "res_stage_3_109_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_109_3"
  type: "BatchNorm"
  bottom: "res_stage_3_109_3"
  top: "res_stage_3_109_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_109_3"  
  type: "Scale"
  bottom: "res_stage_3_109_3"
  top: "res_stage_3_109_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_109"
  type: "Eltwise"
  bottom: "res_3_108"
  bottom: "res_stage_3_109_3_top"
  top: "res_3_109"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_109_relu"
  type: "ReLU"
  bottom: "res_3_109"
  top: "res_3_109"
}
layer {
  name: "res_stage_3_110_1"
  type: "Convolution"
  bottom: "res_3_109"
  top: "res_stage_3_110_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_110_1"
  type: "BatchNorm"
  bottom: "res_stage_3_110_1"
  top: "res_stage_3_110_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_110_1"  
  type: "Scale"
  bottom: "res_stage_3_110_1"
  top: "res_stage_3_110_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_110_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_110_1_top"
  top: "res_stage_3_110_1_top"
}
layer {
  name: "res_stage_3_110_2"
  type: "Convolution"
  bottom: "res_stage_3_110_1_top"
  top: "res_stage_3_110_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_110_2"
  type: "BatchNorm"
  bottom: "res_stage_3_110_2"
  top: "res_stage_3_110_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_110_2"  
  type: "Scale"
  bottom: "res_stage_3_110_2"
  top: "res_stage_3_110_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_110_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_110_2_top"
  top: "res_stage_3_110_2_top"
}
layer {
  name: "res_stage_3_110_3"
  type: "Convolution"
  bottom: "res_stage_3_110_2_top"
  top: "res_stage_3_110_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_110_3"
  type: "BatchNorm"
  bottom: "res_stage_3_110_3"
  top: "res_stage_3_110_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_110_3"  
  type: "Scale"
  bottom: "res_stage_3_110_3"
  top: "res_stage_3_110_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_110"
  type: "Eltwise"
  bottom: "res_3_109"
  bottom: "res_stage_3_110_3_top"
  top: "res_3_110"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_110_relu"
  type: "ReLU"
  bottom: "res_3_110"
  top: "res_3_110"
}
layer {
  name: "res_stage_3_111_1"
  type: "Convolution"
  bottom: "res_3_110"
  top: "res_stage_3_111_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_111_1"
  type: "BatchNorm"
  bottom: "res_stage_3_111_1"
  top: "res_stage_3_111_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_111_1"  
  type: "Scale"
  bottom: "res_stage_3_111_1"
  top: "res_stage_3_111_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_111_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_111_1_top"
  top: "res_stage_3_111_1_top"
}
layer {
  name: "res_stage_3_111_2"
  type: "Convolution"
  bottom: "res_stage_3_111_1_top"
  top: "res_stage_3_111_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_111_2"
  type: "BatchNorm"
  bottom: "res_stage_3_111_2"
  top: "res_stage_3_111_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_111_2"  
  type: "Scale"
  bottom: "res_stage_3_111_2"
  top: "res_stage_3_111_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_111_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_111_2_top"
  top: "res_stage_3_111_2_top"
}
layer {
  name: "res_stage_3_111_3"
  type: "Convolution"
  bottom: "res_stage_3_111_2_top"
  top: "res_stage_3_111_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_111_3"
  type: "BatchNorm"
  bottom: "res_stage_3_111_3"
  top: "res_stage_3_111_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_111_3"  
  type: "Scale"
  bottom: "res_stage_3_111_3"
  top: "res_stage_3_111_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_111"
  type: "Eltwise"
  bottom: "res_3_110"
  bottom: "res_stage_3_111_3_top"
  top: "res_3_111"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_111_relu"
  type: "ReLU"
  bottom: "res_3_111"
  top: "res_3_111"
}
layer {
  name: "res_stage_3_112_1"
  type: "Convolution"
  bottom: "res_3_111"
  top: "res_stage_3_112_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_112_1"
  type: "BatchNorm"
  bottom: "res_stage_3_112_1"
  top: "res_stage_3_112_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_112_1"  
  type: "Scale"
  bottom: "res_stage_3_112_1"
  top: "res_stage_3_112_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_112_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_112_1_top"
  top: "res_stage_3_112_1_top"
}
layer {
  name: "res_stage_3_112_2"
  type: "Convolution"
  bottom: "res_stage_3_112_1_top"
  top: "res_stage_3_112_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_112_2"
  type: "BatchNorm"
  bottom: "res_stage_3_112_2"
  top: "res_stage_3_112_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_112_2"  
  type: "Scale"
  bottom: "res_stage_3_112_2"
  top: "res_stage_3_112_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_112_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_112_2_top"
  top: "res_stage_3_112_2_top"
}
layer {
  name: "res_stage_3_112_3"
  type: "Convolution"
  bottom: "res_stage_3_112_2_top"
  top: "res_stage_3_112_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_112_3"
  type: "BatchNorm"
  bottom: "res_stage_3_112_3"
  top: "res_stage_3_112_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_112_3"  
  type: "Scale"
  bottom: "res_stage_3_112_3"
  top: "res_stage_3_112_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_112"
  type: "Eltwise"
  bottom: "res_3_111"
  bottom: "res_stage_3_112_3_top"
  top: "res_3_112"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_112_relu"
  type: "ReLU"
  bottom: "res_3_112"
  top: "res_3_112"
}
layer {
  name: "res_stage_3_113_1"
  type: "Convolution"
  bottom: "res_3_112"
  top: "res_stage_3_113_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_113_1"
  type: "BatchNorm"
  bottom: "res_stage_3_113_1"
  top: "res_stage_3_113_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_113_1"  
  type: "Scale"
  bottom: "res_stage_3_113_1"
  top: "res_stage_3_113_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_113_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_113_1_top"
  top: "res_stage_3_113_1_top"
}
layer {
  name: "res_stage_3_113_2"
  type: "Convolution"
  bottom: "res_stage_3_113_1_top"
  top: "res_stage_3_113_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_113_2"
  type: "BatchNorm"
  bottom: "res_stage_3_113_2"
  top: "res_stage_3_113_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_113_2"  
  type: "Scale"
  bottom: "res_stage_3_113_2"
  top: "res_stage_3_113_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_113_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_113_2_top"
  top: "res_stage_3_113_2_top"
}
layer {
  name: "res_stage_3_113_3"
  type: "Convolution"
  bottom: "res_stage_3_113_2_top"
  top: "res_stage_3_113_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_113_3"
  type: "BatchNorm"
  bottom: "res_stage_3_113_3"
  top: "res_stage_3_113_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_113_3"  
  type: "Scale"
  bottom: "res_stage_3_113_3"
  top: "res_stage_3_113_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_113"
  type: "Eltwise"
  bottom: "res_3_112"
  bottom: "res_stage_3_113_3_top"
  top: "res_3_113"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_113_relu"
  type: "ReLU"
  bottom: "res_3_113"
  top: "res_3_113"
}
layer {
  name: "res_stage_3_114_1"
  type: "Convolution"
  bottom: "res_3_113"
  top: "res_stage_3_114_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_114_1"
  type: "BatchNorm"
  bottom: "res_stage_3_114_1"
  top: "res_stage_3_114_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_114_1"  
  type: "Scale"
  bottom: "res_stage_3_114_1"
  top: "res_stage_3_114_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_114_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_114_1_top"
  top: "res_stage_3_114_1_top"
}
layer {
  name: "res_stage_3_114_2"
  type: "Convolution"
  bottom: "res_stage_3_114_1_top"
  top: "res_stage_3_114_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_114_2"
  type: "BatchNorm"
  bottom: "res_stage_3_114_2"
  top: "res_stage_3_114_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_114_2"  
  type: "Scale"
  bottom: "res_stage_3_114_2"
  top: "res_stage_3_114_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_114_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_114_2_top"
  top: "res_stage_3_114_2_top"
}
layer {
  name: "res_stage_3_114_3"
  type: "Convolution"
  bottom: "res_stage_3_114_2_top"
  top: "res_stage_3_114_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_114_3"
  type: "BatchNorm"
  bottom: "res_stage_3_114_3"
  top: "res_stage_3_114_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_114_3"  
  type: "Scale"
  bottom: "res_stage_3_114_3"
  top: "res_stage_3_114_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_114"
  type: "Eltwise"
  bottom: "res_3_113"
  bottom: "res_stage_3_114_3_top"
  top: "res_3_114"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_114_relu"
  type: "ReLU"
  bottom: "res_3_114"
  top: "res_3_114"
}
layer {
  name: "res_stage_3_115_1"
  type: "Convolution"
  bottom: "res_3_114"
  top: "res_stage_3_115_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_115_1"
  type: "BatchNorm"
  bottom: "res_stage_3_115_1"
  top: "res_stage_3_115_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_115_1"  
  type: "Scale"
  bottom: "res_stage_3_115_1"
  top: "res_stage_3_115_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_115_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_115_1_top"
  top: "res_stage_3_115_1_top"
}
layer {
  name: "res_stage_3_115_2"
  type: "Convolution"
  bottom: "res_stage_3_115_1_top"
  top: "res_stage_3_115_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_115_2"
  type: "BatchNorm"
  bottom: "res_stage_3_115_2"
  top: "res_stage_3_115_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_115_2"  
  type: "Scale"
  bottom: "res_stage_3_115_2"
  top: "res_stage_3_115_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_115_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_115_2_top"
  top: "res_stage_3_115_2_top"
}
layer {
  name: "res_stage_3_115_3"
  type: "Convolution"
  bottom: "res_stage_3_115_2_top"
  top: "res_stage_3_115_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_115_3"
  type: "BatchNorm"
  bottom: "res_stage_3_115_3"
  top: "res_stage_3_115_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_115_3"  
  type: "Scale"
  bottom: "res_stage_3_115_3"
  top: "res_stage_3_115_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_115"
  type: "Eltwise"
  bottom: "res_3_114"
  bottom: "res_stage_3_115_3_top"
  top: "res_3_115"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_115_relu"
  type: "ReLU"
  bottom: "res_3_115"
  top: "res_3_115"
}
layer {
  name: "res_stage_3_116_1"
  type: "Convolution"
  bottom: "res_3_115"
  top: "res_stage_3_116_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_116_1"
  type: "BatchNorm"
  bottom: "res_stage_3_116_1"
  top: "res_stage_3_116_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_116_1"  
  type: "Scale"
  bottom: "res_stage_3_116_1"
  top: "res_stage_3_116_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_116_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_116_1_top"
  top: "res_stage_3_116_1_top"
}
layer {
  name: "res_stage_3_116_2"
  type: "Convolution"
  bottom: "res_stage_3_116_1_top"
  top: "res_stage_3_116_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_116_2"
  type: "BatchNorm"
  bottom: "res_stage_3_116_2"
  top: "res_stage_3_116_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_116_2"  
  type: "Scale"
  bottom: "res_stage_3_116_2"
  top: "res_stage_3_116_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_116_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_116_2_top"
  top: "res_stage_3_116_2_top"
}
layer {
  name: "res_stage_3_116_3"
  type: "Convolution"
  bottom: "res_stage_3_116_2_top"
  top: "res_stage_3_116_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_116_3"
  type: "BatchNorm"
  bottom: "res_stage_3_116_3"
  top: "res_stage_3_116_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_116_3"  
  type: "Scale"
  bottom: "res_stage_3_116_3"
  top: "res_stage_3_116_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_116"
  type: "Eltwise"
  bottom: "res_3_115"
  bottom: "res_stage_3_116_3_top"
  top: "res_3_116"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_116_relu"
  type: "ReLU"
  bottom: "res_3_116"
  top: "res_3_116"
}
layer {
  name: "res_stage_3_117_1"
  type: "Convolution"
  bottom: "res_3_116"
  top: "res_stage_3_117_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_117_1"
  type: "BatchNorm"
  bottom: "res_stage_3_117_1"
  top: "res_stage_3_117_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_117_1"  
  type: "Scale"
  bottom: "res_stage_3_117_1"
  top: "res_stage_3_117_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_117_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_117_1_top"
  top: "res_stage_3_117_1_top"
}
layer {
  name: "res_stage_3_117_2"
  type: "Convolution"
  bottom: "res_stage_3_117_1_top"
  top: "res_stage_3_117_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_117_2"
  type: "BatchNorm"
  bottom: "res_stage_3_117_2"
  top: "res_stage_3_117_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_117_2"  
  type: "Scale"
  bottom: "res_stage_3_117_2"
  top: "res_stage_3_117_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_117_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_117_2_top"
  top: "res_stage_3_117_2_top"
}
layer {
  name: "res_stage_3_117_3"
  type: "Convolution"
  bottom: "res_stage_3_117_2_top"
  top: "res_stage_3_117_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_117_3"
  type: "BatchNorm"
  bottom: "res_stage_3_117_3"
  top: "res_stage_3_117_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_117_3"  
  type: "Scale"
  bottom: "res_stage_3_117_3"
  top: "res_stage_3_117_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_117"
  type: "Eltwise"
  bottom: "res_3_116"
  bottom: "res_stage_3_117_3_top"
  top: "res_3_117"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_117_relu"
  type: "ReLU"
  bottom: "res_3_117"
  top: "res_3_117"
}
layer {
  name: "res_stage_3_118_1"
  type: "Convolution"
  bottom: "res_3_117"
  top: "res_stage_3_118_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_118_1"
  type: "BatchNorm"
  bottom: "res_stage_3_118_1"
  top: "res_stage_3_118_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_118_1"  
  type: "Scale"
  bottom: "res_stage_3_118_1"
  top: "res_stage_3_118_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_118_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_118_1_top"
  top: "res_stage_3_118_1_top"
}
layer {
  name: "res_stage_3_118_2"
  type: "Convolution"
  bottom: "res_stage_3_118_1_top"
  top: "res_stage_3_118_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_118_2"
  type: "BatchNorm"
  bottom: "res_stage_3_118_2"
  top: "res_stage_3_118_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_118_2"  
  type: "Scale"
  bottom: "res_stage_3_118_2"
  top: "res_stage_3_118_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_118_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_118_2_top"
  top: "res_stage_3_118_2_top"
}
layer {
  name: "res_stage_3_118_3"
  type: "Convolution"
  bottom: "res_stage_3_118_2_top"
  top: "res_stage_3_118_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_118_3"
  type: "BatchNorm"
  bottom: "res_stage_3_118_3"
  top: "res_stage_3_118_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_118_3"  
  type: "Scale"
  bottom: "res_stage_3_118_3"
  top: "res_stage_3_118_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_118"
  type: "Eltwise"
  bottom: "res_3_117"
  bottom: "res_stage_3_118_3_top"
  top: "res_3_118"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_118_relu"
  type: "ReLU"
  bottom: "res_3_118"
  top: "res_3_118"
}
layer {
  name: "res_stage_3_119_1"
  type: "Convolution"
  bottom: "res_3_118"
  top: "res_stage_3_119_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_119_1"
  type: "BatchNorm"
  bottom: "res_stage_3_119_1"
  top: "res_stage_3_119_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_119_1"  
  type: "Scale"
  bottom: "res_stage_3_119_1"
  top: "res_stage_3_119_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_119_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_119_1_top"
  top: "res_stage_3_119_1_top"
}
layer {
  name: "res_stage_3_119_2"
  type: "Convolution"
  bottom: "res_stage_3_119_1_top"
  top: "res_stage_3_119_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_119_2"
  type: "BatchNorm"
  bottom: "res_stage_3_119_2"
  top: "res_stage_3_119_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_119_2"  
  type: "Scale"
  bottom: "res_stage_3_119_2"
  top: "res_stage_3_119_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_119_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_119_2_top"
  top: "res_stage_3_119_2_top"
}
layer {
  name: "res_stage_3_119_3"
  type: "Convolution"
  bottom: "res_stage_3_119_2_top"
  top: "res_stage_3_119_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_119_3"
  type: "BatchNorm"
  bottom: "res_stage_3_119_3"
  top: "res_stage_3_119_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_119_3"  
  type: "Scale"
  bottom: "res_stage_3_119_3"
  top: "res_stage_3_119_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_119"
  type: "Eltwise"
  bottom: "res_3_118"
  bottom: "res_stage_3_119_3_top"
  top: "res_3_119"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_119_relu"
  type: "ReLU"
  bottom: "res_3_119"
  top: "res_3_119"
}
layer {
  name: "res_stage_3_120_1"
  type: "Convolution"
  bottom: "res_3_119"
  top: "res_stage_3_120_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_120_1"
  type: "BatchNorm"
  bottom: "res_stage_3_120_1"
  top: "res_stage_3_120_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_120_1"  
  type: "Scale"
  bottom: "res_stage_3_120_1"
  top: "res_stage_3_120_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_120_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_120_1_top"
  top: "res_stage_3_120_1_top"
}
layer {
  name: "res_stage_3_120_2"
  type: "Convolution"
  bottom: "res_stage_3_120_1_top"
  top: "res_stage_3_120_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_120_2"
  type: "BatchNorm"
  bottom: "res_stage_3_120_2"
  top: "res_stage_3_120_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_120_2"  
  type: "Scale"
  bottom: "res_stage_3_120_2"
  top: "res_stage_3_120_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_120_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_120_2_top"
  top: "res_stage_3_120_2_top"
}
layer {
  name: "res_stage_3_120_3"
  type: "Convolution"
  bottom: "res_stage_3_120_2_top"
  top: "res_stage_3_120_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_120_3"
  type: "BatchNorm"
  bottom: "res_stage_3_120_3"
  top: "res_stage_3_120_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_120_3"  
  type: "Scale"
  bottom: "res_stage_3_120_3"
  top: "res_stage_3_120_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_120"
  type: "Eltwise"
  bottom: "res_3_119"
  bottom: "res_stage_3_120_3_top"
  top: "res_3_120"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_120_relu"
  type: "ReLU"
  bottom: "res_3_120"
  top: "res_3_120"
}
layer {
  name: "res_stage_3_121_1"
  type: "Convolution"
  bottom: "res_3_120"
  top: "res_stage_3_121_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_121_1"
  type: "BatchNorm"
  bottom: "res_stage_3_121_1"
  top: "res_stage_3_121_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_121_1"  
  type: "Scale"
  bottom: "res_stage_3_121_1"
  top: "res_stage_3_121_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_121_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_121_1_top"
  top: "res_stage_3_121_1_top"
}
layer {
  name: "res_stage_3_121_2"
  type: "Convolution"
  bottom: "res_stage_3_121_1_top"
  top: "res_stage_3_121_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_121_2"
  type: "BatchNorm"
  bottom: "res_stage_3_121_2"
  top: "res_stage_3_121_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_121_2"  
  type: "Scale"
  bottom: "res_stage_3_121_2"
  top: "res_stage_3_121_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_121_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_121_2_top"
  top: "res_stage_3_121_2_top"
}
layer {
  name: "res_stage_3_121_3"
  type: "Convolution"
  bottom: "res_stage_3_121_2_top"
  top: "res_stage_3_121_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_121_3"
  type: "BatchNorm"
  bottom: "res_stage_3_121_3"
  top: "res_stage_3_121_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_121_3"  
  type: "Scale"
  bottom: "res_stage_3_121_3"
  top: "res_stage_3_121_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_121"
  type: "Eltwise"
  bottom: "res_3_120"
  bottom: "res_stage_3_121_3_top"
  top: "res_3_121"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_121_relu"
  type: "ReLU"
  bottom: "res_3_121"
  top: "res_3_121"
}
layer {
  name: "res_stage_3_122_1"
  type: "Convolution"
  bottom: "res_3_121"
  top: "res_stage_3_122_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_122_1"
  type: "BatchNorm"
  bottom: "res_stage_3_122_1"
  top: "res_stage_3_122_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_122_1"  
  type: "Scale"
  bottom: "res_stage_3_122_1"
  top: "res_stage_3_122_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_122_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_122_1_top"
  top: "res_stage_3_122_1_top"
}
layer {
  name: "res_stage_3_122_2"
  type: "Convolution"
  bottom: "res_stage_3_122_1_top"
  top: "res_stage_3_122_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_122_2"
  type: "BatchNorm"
  bottom: "res_stage_3_122_2"
  top: "res_stage_3_122_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_122_2"  
  type: "Scale"
  bottom: "res_stage_3_122_2"
  top: "res_stage_3_122_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_122_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_122_2_top"
  top: "res_stage_3_122_2_top"
}
layer {
  name: "res_stage_3_122_3"
  type: "Convolution"
  bottom: "res_stage_3_122_2_top"
  top: "res_stage_3_122_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_122_3"
  type: "BatchNorm"
  bottom: "res_stage_3_122_3"
  top: "res_stage_3_122_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_122_3"  
  type: "Scale"
  bottom: "res_stage_3_122_3"
  top: "res_stage_3_122_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_122"
  type: "Eltwise"
  bottom: "res_3_121"
  bottom: "res_stage_3_122_3_top"
  top: "res_3_122"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_122_relu"
  type: "ReLU"
  bottom: "res_3_122"
  top: "res_3_122"
}
layer {
  name: "res_stage_3_123_1"
  type: "Convolution"
  bottom: "res_3_122"
  top: "res_stage_3_123_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_123_1"
  type: "BatchNorm"
  bottom: "res_stage_3_123_1"
  top: "res_stage_3_123_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_123_1"  
  type: "Scale"
  bottom: "res_stage_3_123_1"
  top: "res_stage_3_123_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_123_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_123_1_top"
  top: "res_stage_3_123_1_top"
}
layer {
  name: "res_stage_3_123_2"
  type: "Convolution"
  bottom: "res_stage_3_123_1_top"
  top: "res_stage_3_123_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_123_2"
  type: "BatchNorm"
  bottom: "res_stage_3_123_2"
  top: "res_stage_3_123_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_123_2"  
  type: "Scale"
  bottom: "res_stage_3_123_2"
  top: "res_stage_3_123_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_123_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_123_2_top"
  top: "res_stage_3_123_2_top"
}
layer {
  name: "res_stage_3_123_3"
  type: "Convolution"
  bottom: "res_stage_3_123_2_top"
  top: "res_stage_3_123_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_123_3"
  type: "BatchNorm"
  bottom: "res_stage_3_123_3"
  top: "res_stage_3_123_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_123_3"  
  type: "Scale"
  bottom: "res_stage_3_123_3"
  top: "res_stage_3_123_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_123"
  type: "Eltwise"
  bottom: "res_3_122"
  bottom: "res_stage_3_123_3_top"
  top: "res_3_123"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_123_relu"
  type: "ReLU"
  bottom: "res_3_123"
  top: "res_3_123"
}
layer {
  name: "res_stage_3_124_1"
  type: "Convolution"
  bottom: "res_3_123"
  top: "res_stage_3_124_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_124_1"
  type: "BatchNorm"
  bottom: "res_stage_3_124_1"
  top: "res_stage_3_124_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_124_1"  
  type: "Scale"
  bottom: "res_stage_3_124_1"
  top: "res_stage_3_124_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_124_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_124_1_top"
  top: "res_stage_3_124_1_top"
}
layer {
  name: "res_stage_3_124_2"
  type: "Convolution"
  bottom: "res_stage_3_124_1_top"
  top: "res_stage_3_124_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_124_2"
  type: "BatchNorm"
  bottom: "res_stage_3_124_2"
  top: "res_stage_3_124_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_124_2"  
  type: "Scale"
  bottom: "res_stage_3_124_2"
  top: "res_stage_3_124_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_124_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_124_2_top"
  top: "res_stage_3_124_2_top"
}
layer {
  name: "res_stage_3_124_3"
  type: "Convolution"
  bottom: "res_stage_3_124_2_top"
  top: "res_stage_3_124_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_124_3"
  type: "BatchNorm"
  bottom: "res_stage_3_124_3"
  top: "res_stage_3_124_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_124_3"  
  type: "Scale"
  bottom: "res_stage_3_124_3"
  top: "res_stage_3_124_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_124"
  type: "Eltwise"
  bottom: "res_3_123"
  bottom: "res_stage_3_124_3_top"
  top: "res_3_124"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_124_relu"
  type: "ReLU"
  bottom: "res_3_124"
  top: "res_3_124"
}
layer {
  name: "res_stage_3_125_1"
  type: "Convolution"
  bottom: "res_3_124"
  top: "res_stage_3_125_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_125_1"
  type: "BatchNorm"
  bottom: "res_stage_3_125_1"
  top: "res_stage_3_125_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_125_1"  
  type: "Scale"
  bottom: "res_stage_3_125_1"
  top: "res_stage_3_125_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_125_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_125_1_top"
  top: "res_stage_3_125_1_top"
}
layer {
  name: "res_stage_3_125_2"
  type: "Convolution"
  bottom: "res_stage_3_125_1_top"
  top: "res_stage_3_125_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_125_2"
  type: "BatchNorm"
  bottom: "res_stage_3_125_2"
  top: "res_stage_3_125_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_125_2"  
  type: "Scale"
  bottom: "res_stage_3_125_2"
  top: "res_stage_3_125_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_125_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_125_2_top"
  top: "res_stage_3_125_2_top"
}
layer {
  name: "res_stage_3_125_3"
  type: "Convolution"
  bottom: "res_stage_3_125_2_top"
  top: "res_stage_3_125_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_125_3"
  type: "BatchNorm"
  bottom: "res_stage_3_125_3"
  top: "res_stage_3_125_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_125_3"  
  type: "Scale"
  bottom: "res_stage_3_125_3"
  top: "res_stage_3_125_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_125"
  type: "Eltwise"
  bottom: "res_3_124"
  bottom: "res_stage_3_125_3_top"
  top: "res_3_125"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_125_relu"
  type: "ReLU"
  bottom: "res_3_125"
  top: "res_3_125"
}
layer {
  name: "res_stage_3_126_1"
  type: "Convolution"
  bottom: "res_3_125"
  top: "res_stage_3_126_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_126_1"
  type: "BatchNorm"
  bottom: "res_stage_3_126_1"
  top: "res_stage_3_126_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_126_1"  
  type: "Scale"
  bottom: "res_stage_3_126_1"
  top: "res_stage_3_126_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_126_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_126_1_top"
  top: "res_stage_3_126_1_top"
}
layer {
  name: "res_stage_3_126_2"
  type: "Convolution"
  bottom: "res_stage_3_126_1_top"
  top: "res_stage_3_126_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_126_2"
  type: "BatchNorm"
  bottom: "res_stage_3_126_2"
  top: "res_stage_3_126_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_126_2"  
  type: "Scale"
  bottom: "res_stage_3_126_2"
  top: "res_stage_3_126_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_126_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_126_2_top"
  top: "res_stage_3_126_2_top"
}
layer {
  name: "res_stage_3_126_3"
  type: "Convolution"
  bottom: "res_stage_3_126_2_top"
  top: "res_stage_3_126_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_126_3"
  type: "BatchNorm"
  bottom: "res_stage_3_126_3"
  top: "res_stage_3_126_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_126_3"  
  type: "Scale"
  bottom: "res_stage_3_126_3"
  top: "res_stage_3_126_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_126"
  type: "Eltwise"
  bottom: "res_3_125"
  bottom: "res_stage_3_126_3_top"
  top: "res_3_126"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_126_relu"
  type: "ReLU"
  bottom: "res_3_126"
  top: "res_3_126"
}
layer {
  name: "res_stage_3_127_1"
  type: "Convolution"
  bottom: "res_3_126"
  top: "res_stage_3_127_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_127_1"
  type: "BatchNorm"
  bottom: "res_stage_3_127_1"
  top: "res_stage_3_127_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_127_1"  
  type: "Scale"
  bottom: "res_stage_3_127_1"
  top: "res_stage_3_127_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_127_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_127_1_top"
  top: "res_stage_3_127_1_top"
}
layer {
  name: "res_stage_3_127_2"
  type: "Convolution"
  bottom: "res_stage_3_127_1_top"
  top: "res_stage_3_127_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_127_2"
  type: "BatchNorm"
  bottom: "res_stage_3_127_2"
  top: "res_stage_3_127_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_127_2"  
  type: "Scale"
  bottom: "res_stage_3_127_2"
  top: "res_stage_3_127_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_127_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_127_2_top"
  top: "res_stage_3_127_2_top"
}
layer {
  name: "res_stage_3_127_3"
  type: "Convolution"
  bottom: "res_stage_3_127_2_top"
  top: "res_stage_3_127_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_127_3"
  type: "BatchNorm"
  bottom: "res_stage_3_127_3"
  top: "res_stage_3_127_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_127_3"  
  type: "Scale"
  bottom: "res_stage_3_127_3"
  top: "res_stage_3_127_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_127"
  type: "Eltwise"
  bottom: "res_3_126"
  bottom: "res_stage_3_127_3_top"
  top: "res_3_127"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_127_relu"
  type: "ReLU"
  bottom: "res_3_127"
  top: "res_3_127"
}
layer {
  name: "res_stage_3_128_1"
  type: "Convolution"
  bottom: "res_3_127"
  top: "res_stage_3_128_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_128_1"
  type: "BatchNorm"
  bottom: "res_stage_3_128_1"
  top: "res_stage_3_128_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_128_1"  
  type: "Scale"
  bottom: "res_stage_3_128_1"
  top: "res_stage_3_128_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_128_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_128_1_top"
  top: "res_stage_3_128_1_top"
}
layer {
  name: "res_stage_3_128_2"
  type: "Convolution"
  bottom: "res_stage_3_128_1_top"
  top: "res_stage_3_128_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_128_2"
  type: "BatchNorm"
  bottom: "res_stage_3_128_2"
  top: "res_stage_3_128_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_128_2"  
  type: "Scale"
  bottom: "res_stage_3_128_2"
  top: "res_stage_3_128_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_128_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_128_2_top"
  top: "res_stage_3_128_2_top"
}
layer {
  name: "res_stage_3_128_3"
  type: "Convolution"
  bottom: "res_stage_3_128_2_top"
  top: "res_stage_3_128_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_128_3"
  type: "BatchNorm"
  bottom: "res_stage_3_128_3"
  top: "res_stage_3_128_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_128_3"  
  type: "Scale"
  bottom: "res_stage_3_128_3"
  top: "res_stage_3_128_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_128"
  type: "Eltwise"
  bottom: "res_3_127"
  bottom: "res_stage_3_128_3_top"
  top: "res_3_128"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_128_relu"
  type: "ReLU"
  bottom: "res_3_128"
  top: "res_3_128"
}
layer {
  name: "res_stage_3_129_1"
  type: "Convolution"
  bottom: "res_3_128"
  top: "res_stage_3_129_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_129_1"
  type: "BatchNorm"
  bottom: "res_stage_3_129_1"
  top: "res_stage_3_129_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_129_1"  
  type: "Scale"
  bottom: "res_stage_3_129_1"
  top: "res_stage_3_129_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_129_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_129_1_top"
  top: "res_stage_3_129_1_top"
}
layer {
  name: "res_stage_3_129_2"
  type: "Convolution"
  bottom: "res_stage_3_129_1_top"
  top: "res_stage_3_129_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_129_2"
  type: "BatchNorm"
  bottom: "res_stage_3_129_2"
  top: "res_stage_3_129_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_129_2"  
  type: "Scale"
  bottom: "res_stage_3_129_2"
  top: "res_stage_3_129_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_129_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_129_2_top"
  top: "res_stage_3_129_2_top"
}
layer {
  name: "res_stage_3_129_3"
  type: "Convolution"
  bottom: "res_stage_3_129_2_top"
  top: "res_stage_3_129_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_129_3"
  type: "BatchNorm"
  bottom: "res_stage_3_129_3"
  top: "res_stage_3_129_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_129_3"  
  type: "Scale"
  bottom: "res_stage_3_129_3"
  top: "res_stage_3_129_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_129"
  type: "Eltwise"
  bottom: "res_3_128"
  bottom: "res_stage_3_129_3_top"
  top: "res_3_129"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_129_relu"
  type: "ReLU"
  bottom: "res_3_129"
  top: "res_3_129"
}
layer {
  name: "res_stage_3_130_1"
  type: "Convolution"
  bottom: "res_3_129"
  top: "res_stage_3_130_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_130_1"
  type: "BatchNorm"
  bottom: "res_stage_3_130_1"
  top: "res_stage_3_130_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_130_1"  
  type: "Scale"
  bottom: "res_stage_3_130_1"
  top: "res_stage_3_130_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_130_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_130_1_top"
  top: "res_stage_3_130_1_top"
}
layer {
  name: "res_stage_3_130_2"
  type: "Convolution"
  bottom: "res_stage_3_130_1_top"
  top: "res_stage_3_130_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_130_2"
  type: "BatchNorm"
  bottom: "res_stage_3_130_2"
  top: "res_stage_3_130_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_130_2"  
  type: "Scale"
  bottom: "res_stage_3_130_2"
  top: "res_stage_3_130_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_130_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_130_2_top"
  top: "res_stage_3_130_2_top"
}
layer {
  name: "res_stage_3_130_3"
  type: "Convolution"
  bottom: "res_stage_3_130_2_top"
  top: "res_stage_3_130_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_130_3"
  type: "BatchNorm"
  bottom: "res_stage_3_130_3"
  top: "res_stage_3_130_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_130_3"  
  type: "Scale"
  bottom: "res_stage_3_130_3"
  top: "res_stage_3_130_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_130"
  type: "Eltwise"
  bottom: "res_3_129"
  bottom: "res_stage_3_130_3_top"
  top: "res_3_130"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_130_relu"
  type: "ReLU"
  bottom: "res_3_130"
  top: "res_3_130"
}
layer {
  name: "res_stage_3_131_1"
  type: "Convolution"
  bottom: "res_3_130"
  top: "res_stage_3_131_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_131_1"
  type: "BatchNorm"
  bottom: "res_stage_3_131_1"
  top: "res_stage_3_131_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_131_1"  
  type: "Scale"
  bottom: "res_stage_3_131_1"
  top: "res_stage_3_131_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_131_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_131_1_top"
  top: "res_stage_3_131_1_top"
}
layer {
  name: "res_stage_3_131_2"
  type: "Convolution"
  bottom: "res_stage_3_131_1_top"
  top: "res_stage_3_131_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_131_2"
  type: "BatchNorm"
  bottom: "res_stage_3_131_2"
  top: "res_stage_3_131_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_131_2"  
  type: "Scale"
  bottom: "res_stage_3_131_2"
  top: "res_stage_3_131_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_131_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_131_2_top"
  top: "res_stage_3_131_2_top"
}
layer {
  name: "res_stage_3_131_3"
  type: "Convolution"
  bottom: "res_stage_3_131_2_top"
  top: "res_stage_3_131_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_131_3"
  type: "BatchNorm"
  bottom: "res_stage_3_131_3"
  top: "res_stage_3_131_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_131_3"  
  type: "Scale"
  bottom: "res_stage_3_131_3"
  top: "res_stage_3_131_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_131"
  type: "Eltwise"
  bottom: "res_3_130"
  bottom: "res_stage_3_131_3_top"
  top: "res_3_131"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_131_relu"
  type: "ReLU"
  bottom: "res_3_131"
  top: "res_3_131"
}
layer {
  name: "res_stage_3_132_1"
  type: "Convolution"
  bottom: "res_3_131"
  top: "res_stage_3_132_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_132_1"
  type: "BatchNorm"
  bottom: "res_stage_3_132_1"
  top: "res_stage_3_132_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_132_1"  
  type: "Scale"
  bottom: "res_stage_3_132_1"
  top: "res_stage_3_132_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_132_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_132_1_top"
  top: "res_stage_3_132_1_top"
}
layer {
  name: "res_stage_3_132_2"
  type: "Convolution"
  bottom: "res_stage_3_132_1_top"
  top: "res_stage_3_132_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_132_2"
  type: "BatchNorm"
  bottom: "res_stage_3_132_2"
  top: "res_stage_3_132_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_132_2"  
  type: "Scale"
  bottom: "res_stage_3_132_2"
  top: "res_stage_3_132_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_132_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_132_2_top"
  top: "res_stage_3_132_2_top"
}
layer {
  name: "res_stage_3_132_3"
  type: "Convolution"
  bottom: "res_stage_3_132_2_top"
  top: "res_stage_3_132_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_132_3"
  type: "BatchNorm"
  bottom: "res_stage_3_132_3"
  top: "res_stage_3_132_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_132_3"  
  type: "Scale"
  bottom: "res_stage_3_132_3"
  top: "res_stage_3_132_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_132"
  type: "Eltwise"
  bottom: "res_3_131"
  bottom: "res_stage_3_132_3_top"
  top: "res_3_132"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_132_relu"
  type: "ReLU"
  bottom: "res_3_132"
  top: "res_3_132"
}
layer {
  name: "res_stage_3_133_1"
  type: "Convolution"
  bottom: "res_3_132"
  top: "res_stage_3_133_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_133_1"
  type: "BatchNorm"
  bottom: "res_stage_3_133_1"
  top: "res_stage_3_133_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_133_1"  
  type: "Scale"
  bottom: "res_stage_3_133_1"
  top: "res_stage_3_133_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_133_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_133_1_top"
  top: "res_stage_3_133_1_top"
}
layer {
  name: "res_stage_3_133_2"
  type: "Convolution"
  bottom: "res_stage_3_133_1_top"
  top: "res_stage_3_133_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_133_2"
  type: "BatchNorm"
  bottom: "res_stage_3_133_2"
  top: "res_stage_3_133_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_133_2"  
  type: "Scale"
  bottom: "res_stage_3_133_2"
  top: "res_stage_3_133_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_133_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_133_2_top"
  top: "res_stage_3_133_2_top"
}
layer {
  name: "res_stage_3_133_3"
  type: "Convolution"
  bottom: "res_stage_3_133_2_top"
  top: "res_stage_3_133_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_133_3"
  type: "BatchNorm"
  bottom: "res_stage_3_133_3"
  top: "res_stage_3_133_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_133_3"  
  type: "Scale"
  bottom: "res_stage_3_133_3"
  top: "res_stage_3_133_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_133"
  type: "Eltwise"
  bottom: "res_3_132"
  bottom: "res_stage_3_133_3_top"
  top: "res_3_133"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_133_relu"
  type: "ReLU"
  bottom: "res_3_133"
  top: "res_3_133"
}
layer {
  name: "res_stage_3_134_1"
  type: "Convolution"
  bottom: "res_3_133"
  top: "res_stage_3_134_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_134_1"
  type: "BatchNorm"
  bottom: "res_stage_3_134_1"
  top: "res_stage_3_134_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_134_1"  
  type: "Scale"
  bottom: "res_stage_3_134_1"
  top: "res_stage_3_134_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_134_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_134_1_top"
  top: "res_stage_3_134_1_top"
}
layer {
  name: "res_stage_3_134_2"
  type: "Convolution"
  bottom: "res_stage_3_134_1_top"
  top: "res_stage_3_134_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_134_2"
  type: "BatchNorm"
  bottom: "res_stage_3_134_2"
  top: "res_stage_3_134_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_134_2"  
  type: "Scale"
  bottom: "res_stage_3_134_2"
  top: "res_stage_3_134_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_134_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_134_2_top"
  top: "res_stage_3_134_2_top"
}
layer {
  name: "res_stage_3_134_3"
  type: "Convolution"
  bottom: "res_stage_3_134_2_top"
  top: "res_stage_3_134_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_134_3"
  type: "BatchNorm"
  bottom: "res_stage_3_134_3"
  top: "res_stage_3_134_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_134_3"  
  type: "Scale"
  bottom: "res_stage_3_134_3"
  top: "res_stage_3_134_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_134"
  type: "Eltwise"
  bottom: "res_3_133"
  bottom: "res_stage_3_134_3_top"
  top: "res_3_134"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_134_relu"
  type: "ReLU"
  bottom: "res_3_134"
  top: "res_3_134"
}
layer {
  name: "res_stage_3_135_1"
  type: "Convolution"
  bottom: "res_3_134"
  top: "res_stage_3_135_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_135_1"
  type: "BatchNorm"
  bottom: "res_stage_3_135_1"
  top: "res_stage_3_135_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_135_1"  
  type: "Scale"
  bottom: "res_stage_3_135_1"
  top: "res_stage_3_135_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_135_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_135_1_top"
  top: "res_stage_3_135_1_top"
}
layer {
  name: "res_stage_3_135_2"
  type: "Convolution"
  bottom: "res_stage_3_135_1_top"
  top: "res_stage_3_135_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_135_2"
  type: "BatchNorm"
  bottom: "res_stage_3_135_2"
  top: "res_stage_3_135_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_135_2"  
  type: "Scale"
  bottom: "res_stage_3_135_2"
  top: "res_stage_3_135_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_135_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_135_2_top"
  top: "res_stage_3_135_2_top"
}
layer {
  name: "res_stage_3_135_3"
  type: "Convolution"
  bottom: "res_stage_3_135_2_top"
  top: "res_stage_3_135_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_135_3"
  type: "BatchNorm"
  bottom: "res_stage_3_135_3"
  top: "res_stage_3_135_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_135_3"  
  type: "Scale"
  bottom: "res_stage_3_135_3"
  top: "res_stage_3_135_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_135"
  type: "Eltwise"
  bottom: "res_3_134"
  bottom: "res_stage_3_135_3_top"
  top: "res_3_135"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_135_relu"
  type: "ReLU"
  bottom: "res_3_135"
  top: "res_3_135"
}
layer {
  name: "res_stage_3_136_1"
  type: "Convolution"
  bottom: "res_3_135"
  top: "res_stage_3_136_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_136_1"
  type: "BatchNorm"
  bottom: "res_stage_3_136_1"
  top: "res_stage_3_136_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_136_1"  
  type: "Scale"
  bottom: "res_stage_3_136_1"
  top: "res_stage_3_136_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_136_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_136_1_top"
  top: "res_stage_3_136_1_top"
}
layer {
  name: "res_stage_3_136_2"
  type: "Convolution"
  bottom: "res_stage_3_136_1_top"
  top: "res_stage_3_136_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_136_2"
  type: "BatchNorm"
  bottom: "res_stage_3_136_2"
  top: "res_stage_3_136_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_136_2"  
  type: "Scale"
  bottom: "res_stage_3_136_2"
  top: "res_stage_3_136_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_136_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_136_2_top"
  top: "res_stage_3_136_2_top"
}
layer {
  name: "res_stage_3_136_3"
  type: "Convolution"
  bottom: "res_stage_3_136_2_top"
  top: "res_stage_3_136_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_136_3"
  type: "BatchNorm"
  bottom: "res_stage_3_136_3"
  top: "res_stage_3_136_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_136_3"  
  type: "Scale"
  bottom: "res_stage_3_136_3"
  top: "res_stage_3_136_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_136"
  type: "Eltwise"
  bottom: "res_3_135"
  bottom: "res_stage_3_136_3_top"
  top: "res_3_136"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_136_relu"
  type: "ReLU"
  bottom: "res_3_136"
  top: "res_3_136"
}
layer {
  name: "res_stage_3_137_1"
  type: "Convolution"
  bottom: "res_3_136"
  top: "res_stage_3_137_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_137_1"
  type: "BatchNorm"
  bottom: "res_stage_3_137_1"
  top: "res_stage_3_137_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_137_1"  
  type: "Scale"
  bottom: "res_stage_3_137_1"
  top: "res_stage_3_137_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_137_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_137_1_top"
  top: "res_stage_3_137_1_top"
}
layer {
  name: "res_stage_3_137_2"
  type: "Convolution"
  bottom: "res_stage_3_137_1_top"
  top: "res_stage_3_137_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_137_2"
  type: "BatchNorm"
  bottom: "res_stage_3_137_2"
  top: "res_stage_3_137_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_137_2"  
  type: "Scale"
  bottom: "res_stage_3_137_2"
  top: "res_stage_3_137_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_137_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_137_2_top"
  top: "res_stage_3_137_2_top"
}
layer {
  name: "res_stage_3_137_3"
  type: "Convolution"
  bottom: "res_stage_3_137_2_top"
  top: "res_stage_3_137_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_137_3"
  type: "BatchNorm"
  bottom: "res_stage_3_137_3"
  top: "res_stage_3_137_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_137_3"  
  type: "Scale"
  bottom: "res_stage_3_137_3"
  top: "res_stage_3_137_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_137"
  type: "Eltwise"
  bottom: "res_3_136"
  bottom: "res_stage_3_137_3_top"
  top: "res_3_137"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_137_relu"
  type: "ReLU"
  bottom: "res_3_137"
  top: "res_3_137"
}
layer {
  name: "res_stage_3_138_1"
  type: "Convolution"
  bottom: "res_3_137"
  top: "res_stage_3_138_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_138_1"
  type: "BatchNorm"
  bottom: "res_stage_3_138_1"
  top: "res_stage_3_138_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_138_1"  
  type: "Scale"
  bottom: "res_stage_3_138_1"
  top: "res_stage_3_138_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_138_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_138_1_top"
  top: "res_stage_3_138_1_top"
}
layer {
  name: "res_stage_3_138_2"
  type: "Convolution"
  bottom: "res_stage_3_138_1_top"
  top: "res_stage_3_138_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_138_2"
  type: "BatchNorm"
  bottom: "res_stage_3_138_2"
  top: "res_stage_3_138_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_138_2"  
  type: "Scale"
  bottom: "res_stage_3_138_2"
  top: "res_stage_3_138_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_138_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_138_2_top"
  top: "res_stage_3_138_2_top"
}
layer {
  name: "res_stage_3_138_3"
  type: "Convolution"
  bottom: "res_stage_3_138_2_top"
  top: "res_stage_3_138_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_138_3"
  type: "BatchNorm"
  bottom: "res_stage_3_138_3"
  top: "res_stage_3_138_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_138_3"  
  type: "Scale"
  bottom: "res_stage_3_138_3"
  top: "res_stage_3_138_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_138"
  type: "Eltwise"
  bottom: "res_3_137"
  bottom: "res_stage_3_138_3_top"
  top: "res_3_138"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_138_relu"
  type: "ReLU"
  bottom: "res_3_138"
  top: "res_3_138"
}
layer {
  name: "res_stage_3_139_1"
  type: "Convolution"
  bottom: "res_3_138"
  top: "res_stage_3_139_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_139_1"
  type: "BatchNorm"
  bottom: "res_stage_3_139_1"
  top: "res_stage_3_139_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_139_1"  
  type: "Scale"
  bottom: "res_stage_3_139_1"
  top: "res_stage_3_139_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_139_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_139_1_top"
  top: "res_stage_3_139_1_top"
}
layer {
  name: "res_stage_3_139_2"
  type: "Convolution"
  bottom: "res_stage_3_139_1_top"
  top: "res_stage_3_139_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_139_2"
  type: "BatchNorm"
  bottom: "res_stage_3_139_2"
  top: "res_stage_3_139_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_139_2"  
  type: "Scale"
  bottom: "res_stage_3_139_2"
  top: "res_stage_3_139_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_139_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_139_2_top"
  top: "res_stage_3_139_2_top"
}
layer {
  name: "res_stage_3_139_3"
  type: "Convolution"
  bottom: "res_stage_3_139_2_top"
  top: "res_stage_3_139_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_139_3"
  type: "BatchNorm"
  bottom: "res_stage_3_139_3"
  top: "res_stage_3_139_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_139_3"  
  type: "Scale"
  bottom: "res_stage_3_139_3"
  top: "res_stage_3_139_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_139"
  type: "Eltwise"
  bottom: "res_3_138"
  bottom: "res_stage_3_139_3_top"
  top: "res_3_139"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_139_relu"
  type: "ReLU"
  bottom: "res_3_139"
  top: "res_3_139"
}
layer {
  name: "res_stage_3_140_1"
  type: "Convolution"
  bottom: "res_3_139"
  top: "res_stage_3_140_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_140_1"
  type: "BatchNorm"
  bottom: "res_stage_3_140_1"
  top: "res_stage_3_140_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_140_1"  
  type: "Scale"
  bottom: "res_stage_3_140_1"
  top: "res_stage_3_140_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_140_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_140_1_top"
  top: "res_stage_3_140_1_top"
}
layer {
  name: "res_stage_3_140_2"
  type: "Convolution"
  bottom: "res_stage_3_140_1_top"
  top: "res_stage_3_140_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_140_2"
  type: "BatchNorm"
  bottom: "res_stage_3_140_2"
  top: "res_stage_3_140_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_140_2"  
  type: "Scale"
  bottom: "res_stage_3_140_2"
  top: "res_stage_3_140_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_140_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_140_2_top"
  top: "res_stage_3_140_2_top"
}
layer {
  name: "res_stage_3_140_3"
  type: "Convolution"
  bottom: "res_stage_3_140_2_top"
  top: "res_stage_3_140_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_140_3"
  type: "BatchNorm"
  bottom: "res_stage_3_140_3"
  top: "res_stage_3_140_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_140_3"  
  type: "Scale"
  bottom: "res_stage_3_140_3"
  top: "res_stage_3_140_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_140"
  type: "Eltwise"
  bottom: "res_3_139"
  bottom: "res_stage_3_140_3_top"
  top: "res_3_140"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_140_relu"
  type: "ReLU"
  bottom: "res_3_140"
  top: "res_3_140"
}
layer {
  name: "res_stage_3_141_1"
  type: "Convolution"
  bottom: "res_3_140"
  top: "res_stage_3_141_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_141_1"
  type: "BatchNorm"
  bottom: "res_stage_3_141_1"
  top: "res_stage_3_141_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_141_1"  
  type: "Scale"
  bottom: "res_stage_3_141_1"
  top: "res_stage_3_141_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_141_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_141_1_top"
  top: "res_stage_3_141_1_top"
}
layer {
  name: "res_stage_3_141_2"
  type: "Convolution"
  bottom: "res_stage_3_141_1_top"
  top: "res_stage_3_141_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_141_2"
  type: "BatchNorm"
  bottom: "res_stage_3_141_2"
  top: "res_stage_3_141_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_141_2"  
  type: "Scale"
  bottom: "res_stage_3_141_2"
  top: "res_stage_3_141_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_141_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_141_2_top"
  top: "res_stage_3_141_2_top"
}
layer {
  name: "res_stage_3_141_3"
  type: "Convolution"
  bottom: "res_stage_3_141_2_top"
  top: "res_stage_3_141_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_141_3"
  type: "BatchNorm"
  bottom: "res_stage_3_141_3"
  top: "res_stage_3_141_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_141_3"  
  type: "Scale"
  bottom: "res_stage_3_141_3"
  top: "res_stage_3_141_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_141"
  type: "Eltwise"
  bottom: "res_3_140"
  bottom: "res_stage_3_141_3_top"
  top: "res_3_141"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_141_relu"
  type: "ReLU"
  bottom: "res_3_141"
  top: "res_3_141"
}
layer {
  name: "res_stage_3_142_1"
  type: "Convolution"
  bottom: "res_3_141"
  top: "res_stage_3_142_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_142_1"
  type: "BatchNorm"
  bottom: "res_stage_3_142_1"
  top: "res_stage_3_142_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_142_1"  
  type: "Scale"
  bottom: "res_stage_3_142_1"
  top: "res_stage_3_142_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_142_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_142_1_top"
  top: "res_stage_3_142_1_top"
}
layer {
  name: "res_stage_3_142_2"
  type: "Convolution"
  bottom: "res_stage_3_142_1_top"
  top: "res_stage_3_142_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_142_2"
  type: "BatchNorm"
  bottom: "res_stage_3_142_2"
  top: "res_stage_3_142_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_142_2"  
  type: "Scale"
  bottom: "res_stage_3_142_2"
  top: "res_stage_3_142_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_142_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_142_2_top"
  top: "res_stage_3_142_2_top"
}
layer {
  name: "res_stage_3_142_3"
  type: "Convolution"
  bottom: "res_stage_3_142_2_top"
  top: "res_stage_3_142_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_142_3"
  type: "BatchNorm"
  bottom: "res_stage_3_142_3"
  top: "res_stage_3_142_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_142_3"  
  type: "Scale"
  bottom: "res_stage_3_142_3"
  top: "res_stage_3_142_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_142"
  type: "Eltwise"
  bottom: "res_3_141"
  bottom: "res_stage_3_142_3_top"
  top: "res_3_142"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_142_relu"
  type: "ReLU"
  bottom: "res_3_142"
  top: "res_3_142"
}
layer {
  name: "res_stage_3_143_1"
  type: "Convolution"
  bottom: "res_3_142"
  top: "res_stage_3_143_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_143_1"
  type: "BatchNorm"
  bottom: "res_stage_3_143_1"
  top: "res_stage_3_143_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_143_1"  
  type: "Scale"
  bottom: "res_stage_3_143_1"
  top: "res_stage_3_143_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_143_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_143_1_top"
  top: "res_stage_3_143_1_top"
}
layer {
  name: "res_stage_3_143_2"
  type: "Convolution"
  bottom: "res_stage_3_143_1_top"
  top: "res_stage_3_143_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_143_2"
  type: "BatchNorm"
  bottom: "res_stage_3_143_2"
  top: "res_stage_3_143_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_143_2"  
  type: "Scale"
  bottom: "res_stage_3_143_2"
  top: "res_stage_3_143_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_143_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_143_2_top"
  top: "res_stage_3_143_2_top"
}
layer {
  name: "res_stage_3_143_3"
  type: "Convolution"
  bottom: "res_stage_3_143_2_top"
  top: "res_stage_3_143_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_143_3"
  type: "BatchNorm"
  bottom: "res_stage_3_143_3"
  top: "res_stage_3_143_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_143_3"  
  type: "Scale"
  bottom: "res_stage_3_143_3"
  top: "res_stage_3_143_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_143"
  type: "Eltwise"
  bottom: "res_3_142"
  bottom: "res_stage_3_143_3_top"
  top: "res_3_143"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_143_relu"
  type: "ReLU"
  bottom: "res_3_143"
  top: "res_3_143"
}
layer {
  name: "res_stage_3_144_1"
  type: "Convolution"
  bottom: "res_3_143"
  top: "res_stage_3_144_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_144_1"
  type: "BatchNorm"
  bottom: "res_stage_3_144_1"
  top: "res_stage_3_144_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_144_1"  
  type: "Scale"
  bottom: "res_stage_3_144_1"
  top: "res_stage_3_144_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_144_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_144_1_top"
  top: "res_stage_3_144_1_top"
}
layer {
  name: "res_stage_3_144_2"
  type: "Convolution"
  bottom: "res_stage_3_144_1_top"
  top: "res_stage_3_144_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_144_2"
  type: "BatchNorm"
  bottom: "res_stage_3_144_2"
  top: "res_stage_3_144_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_144_2"  
  type: "Scale"
  bottom: "res_stage_3_144_2"
  top: "res_stage_3_144_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_144_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_144_2_top"
  top: "res_stage_3_144_2_top"
}
layer {
  name: "res_stage_3_144_3"
  type: "Convolution"
  bottom: "res_stage_3_144_2_top"
  top: "res_stage_3_144_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_144_3"
  type: "BatchNorm"
  bottom: "res_stage_3_144_3"
  top: "res_stage_3_144_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_144_3"  
  type: "Scale"
  bottom: "res_stage_3_144_3"
  top: "res_stage_3_144_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_144"
  type: "Eltwise"
  bottom: "res_3_143"
  bottom: "res_stage_3_144_3_top"
  top: "res_3_144"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_144_relu"
  type: "ReLU"
  bottom: "res_3_144"
  top: "res_3_144"
}
layer {
  name: "res_stage_3_145_1"
  type: "Convolution"
  bottom: "res_3_144"
  top: "res_stage_3_145_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_145_1"
  type: "BatchNorm"
  bottom: "res_stage_3_145_1"
  top: "res_stage_3_145_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_145_1"  
  type: "Scale"
  bottom: "res_stage_3_145_1"
  top: "res_stage_3_145_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_145_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_145_1_top"
  top: "res_stage_3_145_1_top"
}
layer {
  name: "res_stage_3_145_2"
  type: "Convolution"
  bottom: "res_stage_3_145_1_top"
  top: "res_stage_3_145_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_145_2"
  type: "BatchNorm"
  bottom: "res_stage_3_145_2"
  top: "res_stage_3_145_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_145_2"  
  type: "Scale"
  bottom: "res_stage_3_145_2"
  top: "res_stage_3_145_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_145_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_145_2_top"
  top: "res_stage_3_145_2_top"
}
layer {
  name: "res_stage_3_145_3"
  type: "Convolution"
  bottom: "res_stage_3_145_2_top"
  top: "res_stage_3_145_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_145_3"
  type: "BatchNorm"
  bottom: "res_stage_3_145_3"
  top: "res_stage_3_145_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_145_3"  
  type: "Scale"
  bottom: "res_stage_3_145_3"
  top: "res_stage_3_145_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_145"
  type: "Eltwise"
  bottom: "res_3_144"
  bottom: "res_stage_3_145_3_top"
  top: "res_3_145"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_145_relu"
  type: "ReLU"
  bottom: "res_3_145"
  top: "res_3_145"
}
layer {
  name: "res_stage_3_146_1"
  type: "Convolution"
  bottom: "res_3_145"
  top: "res_stage_3_146_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_146_1"
  type: "BatchNorm"
  bottom: "res_stage_3_146_1"
  top: "res_stage_3_146_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_146_1"  
  type: "Scale"
  bottom: "res_stage_3_146_1"
  top: "res_stage_3_146_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_146_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_146_1_top"
  top: "res_stage_3_146_1_top"
}
layer {
  name: "res_stage_3_146_2"
  type: "Convolution"
  bottom: "res_stage_3_146_1_top"
  top: "res_stage_3_146_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_146_2"
  type: "BatchNorm"
  bottom: "res_stage_3_146_2"
  top: "res_stage_3_146_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_146_2"  
  type: "Scale"
  bottom: "res_stage_3_146_2"
  top: "res_stage_3_146_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_146_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_146_2_top"
  top: "res_stage_3_146_2_top"
}
layer {
  name: "res_stage_3_146_3"
  type: "Convolution"
  bottom: "res_stage_3_146_2_top"
  top: "res_stage_3_146_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_146_3"
  type: "BatchNorm"
  bottom: "res_stage_3_146_3"
  top: "res_stage_3_146_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_146_3"  
  type: "Scale"
  bottom: "res_stage_3_146_3"
  top: "res_stage_3_146_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_146"
  type: "Eltwise"
  bottom: "res_3_145"
  bottom: "res_stage_3_146_3_top"
  top: "res_3_146"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_146_relu"
  type: "ReLU"
  bottom: "res_3_146"
  top: "res_3_146"
}
layer {
  name: "res_stage_3_147_1"
  type: "Convolution"
  bottom: "res_3_146"
  top: "res_stage_3_147_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_147_1"
  type: "BatchNorm"
  bottom: "res_stage_3_147_1"
  top: "res_stage_3_147_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_147_1"  
  type: "Scale"
  bottom: "res_stage_3_147_1"
  top: "res_stage_3_147_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_147_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_147_1_top"
  top: "res_stage_3_147_1_top"
}
layer {
  name: "res_stage_3_147_2"
  type: "Convolution"
  bottom: "res_stage_3_147_1_top"
  top: "res_stage_3_147_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_147_2"
  type: "BatchNorm"
  bottom: "res_stage_3_147_2"
  top: "res_stage_3_147_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_147_2"  
  type: "Scale"
  bottom: "res_stage_3_147_2"
  top: "res_stage_3_147_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_147_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_147_2_top"
  top: "res_stage_3_147_2_top"
}
layer {
  name: "res_stage_3_147_3"
  type: "Convolution"
  bottom: "res_stage_3_147_2_top"
  top: "res_stage_3_147_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_147_3"
  type: "BatchNorm"
  bottom: "res_stage_3_147_3"
  top: "res_stage_3_147_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_147_3"  
  type: "Scale"
  bottom: "res_stage_3_147_3"
  top: "res_stage_3_147_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_147"
  type: "Eltwise"
  bottom: "res_3_146"
  bottom: "res_stage_3_147_3_top"
  top: "res_3_147"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_147_relu"
  type: "ReLU"
  bottom: "res_3_147"
  top: "res_3_147"
}
layer {
  name: "res_stage_3_148_1"
  type: "Convolution"
  bottom: "res_3_147"
  top: "res_stage_3_148_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_148_1"
  type: "BatchNorm"
  bottom: "res_stage_3_148_1"
  top: "res_stage_3_148_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_148_1"  
  type: "Scale"
  bottom: "res_stage_3_148_1"
  top: "res_stage_3_148_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_148_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_148_1_top"
  top: "res_stage_3_148_1_top"
}
layer {
  name: "res_stage_3_148_2"
  type: "Convolution"
  bottom: "res_stage_3_148_1_top"
  top: "res_stage_3_148_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_148_2"
  type: "BatchNorm"
  bottom: "res_stage_3_148_2"
  top: "res_stage_3_148_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_148_2"  
  type: "Scale"
  bottom: "res_stage_3_148_2"
  top: "res_stage_3_148_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_148_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_148_2_top"
  top: "res_stage_3_148_2_top"
}
layer {
  name: "res_stage_3_148_3"
  type: "Convolution"
  bottom: "res_stage_3_148_2_top"
  top: "res_stage_3_148_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_148_3"
  type: "BatchNorm"
  bottom: "res_stage_3_148_3"
  top: "res_stage_3_148_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_148_3"  
  type: "Scale"
  bottom: "res_stage_3_148_3"
  top: "res_stage_3_148_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_148"
  type: "Eltwise"
  bottom: "res_3_147"
  bottom: "res_stage_3_148_3_top"
  top: "res_3_148"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_148_relu"
  type: "ReLU"
  bottom: "res_3_148"
  top: "res_3_148"
}
layer {
  name: "res_stage_3_149_1"
  type: "Convolution"
  bottom: "res_3_148"
  top: "res_stage_3_149_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_149_1"
  type: "BatchNorm"
  bottom: "res_stage_3_149_1"
  top: "res_stage_3_149_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_149_1"  
  type: "Scale"
  bottom: "res_stage_3_149_1"
  top: "res_stage_3_149_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_149_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_149_1_top"
  top: "res_stage_3_149_1_top"
}
layer {
  name: "res_stage_3_149_2"
  type: "Convolution"
  bottom: "res_stage_3_149_1_top"
  top: "res_stage_3_149_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_149_2"
  type: "BatchNorm"
  bottom: "res_stage_3_149_2"
  top: "res_stage_3_149_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_149_2"  
  type: "Scale"
  bottom: "res_stage_3_149_2"
  top: "res_stage_3_149_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_149_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_149_2_top"
  top: "res_stage_3_149_2_top"
}
layer {
  name: "res_stage_3_149_3"
  type: "Convolution"
  bottom: "res_stage_3_149_2_top"
  top: "res_stage_3_149_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_149_3"
  type: "BatchNorm"
  bottom: "res_stage_3_149_3"
  top: "res_stage_3_149_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_149_3"  
  type: "Scale"
  bottom: "res_stage_3_149_3"
  top: "res_stage_3_149_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_149"
  type: "Eltwise"
  bottom: "res_3_148"
  bottom: "res_stage_3_149_3_top"
  top: "res_3_149"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_149_relu"
  type: "ReLU"
  bottom: "res_3_149"
  top: "res_3_149"
}
layer {
  name: "res_stage_3_150_1"
  type: "Convolution"
  bottom: "res_3_149"
  top: "res_stage_3_150_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_150_1"
  type: "BatchNorm"
  bottom: "res_stage_3_150_1"
  top: "res_stage_3_150_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_150_1"  
  type: "Scale"
  bottom: "res_stage_3_150_1"
  top: "res_stage_3_150_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_150_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_150_1_top"
  top: "res_stage_3_150_1_top"
}
layer {
  name: "res_stage_3_150_2"
  type: "Convolution"
  bottom: "res_stage_3_150_1_top"
  top: "res_stage_3_150_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_150_2"
  type: "BatchNorm"
  bottom: "res_stage_3_150_2"
  top: "res_stage_3_150_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_150_2"  
  type: "Scale"
  bottom: "res_stage_3_150_2"
  top: "res_stage_3_150_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_150_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_150_2_top"
  top: "res_stage_3_150_2_top"
}
layer {
  name: "res_stage_3_150_3"
  type: "Convolution"
  bottom: "res_stage_3_150_2_top"
  top: "res_stage_3_150_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_150_3"
  type: "BatchNorm"
  bottom: "res_stage_3_150_3"
  top: "res_stage_3_150_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_150_3"  
  type: "Scale"
  bottom: "res_stage_3_150_3"
  top: "res_stage_3_150_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_150"
  type: "Eltwise"
  bottom: "res_3_149"
  bottom: "res_stage_3_150_3_top"
  top: "res_3_150"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_150_relu"
  type: "ReLU"
  bottom: "res_3_150"
  top: "res_3_150"
}
layer {
  name: "res_stage_3_151_1"
  type: "Convolution"
  bottom: "res_3_150"
  top: "res_stage_3_151_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_151_1"
  type: "BatchNorm"
  bottom: "res_stage_3_151_1"
  top: "res_stage_3_151_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_151_1"  
  type: "Scale"
  bottom: "res_stage_3_151_1"
  top: "res_stage_3_151_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_151_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_151_1_top"
  top: "res_stage_3_151_1_top"
}
layer {
  name: "res_stage_3_151_2"
  type: "Convolution"
  bottom: "res_stage_3_151_1_top"
  top: "res_stage_3_151_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_151_2"
  type: "BatchNorm"
  bottom: "res_stage_3_151_2"
  top: "res_stage_3_151_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_151_2"  
  type: "Scale"
  bottom: "res_stage_3_151_2"
  top: "res_stage_3_151_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_151_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_151_2_top"
  top: "res_stage_3_151_2_top"
}
layer {
  name: "res_stage_3_151_3"
  type: "Convolution"
  bottom: "res_stage_3_151_2_top"
  top: "res_stage_3_151_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_151_3"
  type: "BatchNorm"
  bottom: "res_stage_3_151_3"
  top: "res_stage_3_151_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_151_3"  
  type: "Scale"
  bottom: "res_stage_3_151_3"
  top: "res_stage_3_151_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_151"
  type: "Eltwise"
  bottom: "res_3_150"
  bottom: "res_stage_3_151_3_top"
  top: "res_3_151"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_151_relu"
  type: "ReLU"
  bottom: "res_3_151"
  top: "res_3_151"
}
layer {
  name: "res_stage_3_152_1"
  type: "Convolution"
  bottom: "res_3_151"
  top: "res_stage_3_152_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_152_1"
  type: "BatchNorm"
  bottom: "res_stage_3_152_1"
  top: "res_stage_3_152_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_152_1"  
  type: "Scale"
  bottom: "res_stage_3_152_1"
  top: "res_stage_3_152_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_152_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_152_1_top"
  top: "res_stage_3_152_1_top"
}
layer {
  name: "res_stage_3_152_2"
  type: "Convolution"
  bottom: "res_stage_3_152_1_top"
  top: "res_stage_3_152_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_152_2"
  type: "BatchNorm"
  bottom: "res_stage_3_152_2"
  top: "res_stage_3_152_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_152_2"  
  type: "Scale"
  bottom: "res_stage_3_152_2"
  top: "res_stage_3_152_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_152_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_152_2_top"
  top: "res_stage_3_152_2_top"
}
layer {
  name: "res_stage_3_152_3"
  type: "Convolution"
  bottom: "res_stage_3_152_2_top"
  top: "res_stage_3_152_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_152_3"
  type: "BatchNorm"
  bottom: "res_stage_3_152_3"
  top: "res_stage_3_152_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_152_3"  
  type: "Scale"
  bottom: "res_stage_3_152_3"
  top: "res_stage_3_152_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_152"
  type: "Eltwise"
  bottom: "res_3_151"
  bottom: "res_stage_3_152_3_top"
  top: "res_3_152"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_152_relu"
  type: "ReLU"
  bottom: "res_3_152"
  top: "res_3_152"
}
layer {
  name: "res_stage_3_153_1"
  type: "Convolution"
  bottom: "res_3_152"
  top: "res_stage_3_153_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_153_1"
  type: "BatchNorm"
  bottom: "res_stage_3_153_1"
  top: "res_stage_3_153_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_153_1"  
  type: "Scale"
  bottom: "res_stage_3_153_1"
  top: "res_stage_3_153_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_153_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_153_1_top"
  top: "res_stage_3_153_1_top"
}
layer {
  name: "res_stage_3_153_2"
  type: "Convolution"
  bottom: "res_stage_3_153_1_top"
  top: "res_stage_3_153_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_153_2"
  type: "BatchNorm"
  bottom: "res_stage_3_153_2"
  top: "res_stage_3_153_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_153_2"  
  type: "Scale"
  bottom: "res_stage_3_153_2"
  top: "res_stage_3_153_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_153_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_153_2_top"
  top: "res_stage_3_153_2_top"
}
layer {
  name: "res_stage_3_153_3"
  type: "Convolution"
  bottom: "res_stage_3_153_2_top"
  top: "res_stage_3_153_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_153_3"
  type: "BatchNorm"
  bottom: "res_stage_3_153_3"
  top: "res_stage_3_153_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_153_3"  
  type: "Scale"
  bottom: "res_stage_3_153_3"
  top: "res_stage_3_153_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_153"
  type: "Eltwise"
  bottom: "res_3_152"
  bottom: "res_stage_3_153_3_top"
  top: "res_3_153"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_153_relu"
  type: "ReLU"
  bottom: "res_3_153"
  top: "res_3_153"
}
layer {
  name: "res_stage_3_154_1"
  type: "Convolution"
  bottom: "res_3_153"
  top: "res_stage_3_154_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_154_1"
  type: "BatchNorm"
  bottom: "res_stage_3_154_1"
  top: "res_stage_3_154_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_154_1"  
  type: "Scale"
  bottom: "res_stage_3_154_1"
  top: "res_stage_3_154_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_154_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_154_1_top"
  top: "res_stage_3_154_1_top"
}
layer {
  name: "res_stage_3_154_2"
  type: "Convolution"
  bottom: "res_stage_3_154_1_top"
  top: "res_stage_3_154_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_154_2"
  type: "BatchNorm"
  bottom: "res_stage_3_154_2"
  top: "res_stage_3_154_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_154_2"  
  type: "Scale"
  bottom: "res_stage_3_154_2"
  top: "res_stage_3_154_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_154_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_154_2_top"
  top: "res_stage_3_154_2_top"
}
layer {
  name: "res_stage_3_154_3"
  type: "Convolution"
  bottom: "res_stage_3_154_2_top"
  top: "res_stage_3_154_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_154_3"
  type: "BatchNorm"
  bottom: "res_stage_3_154_3"
  top: "res_stage_3_154_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_154_3"  
  type: "Scale"
  bottom: "res_stage_3_154_3"
  top: "res_stage_3_154_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_154"
  type: "Eltwise"
  bottom: "res_3_153"
  bottom: "res_stage_3_154_3_top"
  top: "res_3_154"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_154_relu"
  type: "ReLU"
  bottom: "res_3_154"
  top: "res_3_154"
}
layer {
  name: "res_stage_3_155_1"
  type: "Convolution"
  bottom: "res_3_154"
  top: "res_stage_3_155_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_155_1"
  type: "BatchNorm"
  bottom: "res_stage_3_155_1"
  top: "res_stage_3_155_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_155_1"  
  type: "Scale"
  bottom: "res_stage_3_155_1"
  top: "res_stage_3_155_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_155_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_155_1_top"
  top: "res_stage_3_155_1_top"
}
layer {
  name: "res_stage_3_155_2"
  type: "Convolution"
  bottom: "res_stage_3_155_1_top"
  top: "res_stage_3_155_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_155_2"
  type: "BatchNorm"
  bottom: "res_stage_3_155_2"
  top: "res_stage_3_155_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_155_2"  
  type: "Scale"
  bottom: "res_stage_3_155_2"
  top: "res_stage_3_155_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_155_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_155_2_top"
  top: "res_stage_3_155_2_top"
}
layer {
  name: "res_stage_3_155_3"
  type: "Convolution"
  bottom: "res_stage_3_155_2_top"
  top: "res_stage_3_155_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_155_3"
  type: "BatchNorm"
  bottom: "res_stage_3_155_3"
  top: "res_stage_3_155_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_155_3"  
  type: "Scale"
  bottom: "res_stage_3_155_3"
  top: "res_stage_3_155_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_155"
  type: "Eltwise"
  bottom: "res_3_154"
  bottom: "res_stage_3_155_3_top"
  top: "res_3_155"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_155_relu"
  type: "ReLU"
  bottom: "res_3_155"
  top: "res_3_155"
}
layer {
  name: "res_stage_3_156_1"
  type: "Convolution"
  bottom: "res_3_155"
  top: "res_stage_3_156_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_156_1"
  type: "BatchNorm"
  bottom: "res_stage_3_156_1"
  top: "res_stage_3_156_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_156_1"  
  type: "Scale"
  bottom: "res_stage_3_156_1"
  top: "res_stage_3_156_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_156_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_156_1_top"
  top: "res_stage_3_156_1_top"
}
layer {
  name: "res_stage_3_156_2"
  type: "Convolution"
  bottom: "res_stage_3_156_1_top"
  top: "res_stage_3_156_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_156_2"
  type: "BatchNorm"
  bottom: "res_stage_3_156_2"
  top: "res_stage_3_156_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_156_2"  
  type: "Scale"
  bottom: "res_stage_3_156_2"
  top: "res_stage_3_156_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_156_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_156_2_top"
  top: "res_stage_3_156_2_top"
}
layer {
  name: "res_stage_3_156_3"
  type: "Convolution"
  bottom: "res_stage_3_156_2_top"
  top: "res_stage_3_156_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_156_3"
  type: "BatchNorm"
  bottom: "res_stage_3_156_3"
  top: "res_stage_3_156_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_156_3"  
  type: "Scale"
  bottom: "res_stage_3_156_3"
  top: "res_stage_3_156_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_156"
  type: "Eltwise"
  bottom: "res_3_155"
  bottom: "res_stage_3_156_3_top"
  top: "res_3_156"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_156_relu"
  type: "ReLU"
  bottom: "res_3_156"
  top: "res_3_156"
}
layer {
  name: "res_stage_3_157_1"
  type: "Convolution"
  bottom: "res_3_156"
  top: "res_stage_3_157_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_157_1"
  type: "BatchNorm"
  bottom: "res_stage_3_157_1"
  top: "res_stage_3_157_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_157_1"  
  type: "Scale"
  bottom: "res_stage_3_157_1"
  top: "res_stage_3_157_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_157_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_157_1_top"
  top: "res_stage_3_157_1_top"
}
layer {
  name: "res_stage_3_157_2"
  type: "Convolution"
  bottom: "res_stage_3_157_1_top"
  top: "res_stage_3_157_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_157_2"
  type: "BatchNorm"
  bottom: "res_stage_3_157_2"
  top: "res_stage_3_157_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_157_2"  
  type: "Scale"
  bottom: "res_stage_3_157_2"
  top: "res_stage_3_157_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_157_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_157_2_top"
  top: "res_stage_3_157_2_top"
}
layer {
  name: "res_stage_3_157_3"
  type: "Convolution"
  bottom: "res_stage_3_157_2_top"
  top: "res_stage_3_157_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_157_3"
  type: "BatchNorm"
  bottom: "res_stage_3_157_3"
  top: "res_stage_3_157_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_157_3"  
  type: "Scale"
  bottom: "res_stage_3_157_3"
  top: "res_stage_3_157_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_157"
  type: "Eltwise"
  bottom: "res_3_156"
  bottom: "res_stage_3_157_3_top"
  top: "res_3_157"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_157_relu"
  type: "ReLU"
  bottom: "res_3_157"
  top: "res_3_157"
}
layer {
  name: "res_stage_3_158_1"
  type: "Convolution"
  bottom: "res_3_157"
  top: "res_stage_3_158_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_158_1"
  type: "BatchNorm"
  bottom: "res_stage_3_158_1"
  top: "res_stage_3_158_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_158_1"  
  type: "Scale"
  bottom: "res_stage_3_158_1"
  top: "res_stage_3_158_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_158_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_158_1_top"
  top: "res_stage_3_158_1_top"
}
layer {
  name: "res_stage_3_158_2"
  type: "Convolution"
  bottom: "res_stage_3_158_1_top"
  top: "res_stage_3_158_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_158_2"
  type: "BatchNorm"
  bottom: "res_stage_3_158_2"
  top: "res_stage_3_158_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_158_2"  
  type: "Scale"
  bottom: "res_stage_3_158_2"
  top: "res_stage_3_158_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_158_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_158_2_top"
  top: "res_stage_3_158_2_top"
}
layer {
  name: "res_stage_3_158_3"
  type: "Convolution"
  bottom: "res_stage_3_158_2_top"
  top: "res_stage_3_158_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_158_3"
  type: "BatchNorm"
  bottom: "res_stage_3_158_3"
  top: "res_stage_3_158_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_158_3"  
  type: "Scale"
  bottom: "res_stage_3_158_3"
  top: "res_stage_3_158_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_158"
  type: "Eltwise"
  bottom: "res_3_157"
  bottom: "res_stage_3_158_3_top"
  top: "res_3_158"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_158_relu"
  type: "ReLU"
  bottom: "res_3_158"
  top: "res_3_158"
}
layer {
  name: "res_stage_3_159_1"
  type: "Convolution"
  bottom: "res_3_158"
  top: "res_stage_3_159_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_159_1"
  type: "BatchNorm"
  bottom: "res_stage_3_159_1"
  top: "res_stage_3_159_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_159_1"  
  type: "Scale"
  bottom: "res_stage_3_159_1"
  top: "res_stage_3_159_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_159_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_159_1_top"
  top: "res_stage_3_159_1_top"
}
layer {
  name: "res_stage_3_159_2"
  type: "Convolution"
  bottom: "res_stage_3_159_1_top"
  top: "res_stage_3_159_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_159_2"
  type: "BatchNorm"
  bottom: "res_stage_3_159_2"
  top: "res_stage_3_159_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_159_2"  
  type: "Scale"
  bottom: "res_stage_3_159_2"
  top: "res_stage_3_159_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_159_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_159_2_top"
  top: "res_stage_3_159_2_top"
}
layer {
  name: "res_stage_3_159_3"
  type: "Convolution"
  bottom: "res_stage_3_159_2_top"
  top: "res_stage_3_159_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_159_3"
  type: "BatchNorm"
  bottom: "res_stage_3_159_3"
  top: "res_stage_3_159_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_159_3"  
  type: "Scale"
  bottom: "res_stage_3_159_3"
  top: "res_stage_3_159_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_159"
  type: "Eltwise"
  bottom: "res_3_158"
  bottom: "res_stage_3_159_3_top"
  top: "res_3_159"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_159_relu"
  type: "ReLU"
  bottom: "res_3_159"
  top: "res_3_159"
}
layer {
  name: "res_stage_3_160_1"
  type: "Convolution"
  bottom: "res_3_159"
  top: "res_stage_3_160_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_160_1"
  type: "BatchNorm"
  bottom: "res_stage_3_160_1"
  top: "res_stage_3_160_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_160_1"  
  type: "Scale"
  bottom: "res_stage_3_160_1"
  top: "res_stage_3_160_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_160_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_160_1_top"
  top: "res_stage_3_160_1_top"
}
layer {
  name: "res_stage_3_160_2"
  type: "Convolution"
  bottom: "res_stage_3_160_1_top"
  top: "res_stage_3_160_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_160_2"
  type: "BatchNorm"
  bottom: "res_stage_3_160_2"
  top: "res_stage_3_160_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_160_2"  
  type: "Scale"
  bottom: "res_stage_3_160_2"
  top: "res_stage_3_160_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_160_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_160_2_top"
  top: "res_stage_3_160_2_top"
}
layer {
  name: "res_stage_3_160_3"
  type: "Convolution"
  bottom: "res_stage_3_160_2_top"
  top: "res_stage_3_160_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_160_3"
  type: "BatchNorm"
  bottom: "res_stage_3_160_3"
  top: "res_stage_3_160_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_160_3"  
  type: "Scale"
  bottom: "res_stage_3_160_3"
  top: "res_stage_3_160_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_160"
  type: "Eltwise"
  bottom: "res_3_159"
  bottom: "res_stage_3_160_3_top"
  top: "res_3_160"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_160_relu"
  type: "ReLU"
  bottom: "res_3_160"
  top: "res_3_160"
}
layer {
  name: "res_stage_3_161_1"
  type: "Convolution"
  bottom: "res_3_160"
  top: "res_stage_3_161_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_161_1"
  type: "BatchNorm"
  bottom: "res_stage_3_161_1"
  top: "res_stage_3_161_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_161_1"  
  type: "Scale"
  bottom: "res_stage_3_161_1"
  top: "res_stage_3_161_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_161_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_161_1_top"
  top: "res_stage_3_161_1_top"
}
layer {
  name: "res_stage_3_161_2"
  type: "Convolution"
  bottom: "res_stage_3_161_1_top"
  top: "res_stage_3_161_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_161_2"
  type: "BatchNorm"
  bottom: "res_stage_3_161_2"
  top: "res_stage_3_161_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_161_2"  
  type: "Scale"
  bottom: "res_stage_3_161_2"
  top: "res_stage_3_161_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_161_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_161_2_top"
  top: "res_stage_3_161_2_top"
}
layer {
  name: "res_stage_3_161_3"
  type: "Convolution"
  bottom: "res_stage_3_161_2_top"
  top: "res_stage_3_161_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_161_3"
  type: "BatchNorm"
  bottom: "res_stage_3_161_3"
  top: "res_stage_3_161_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_161_3"  
  type: "Scale"
  bottom: "res_stage_3_161_3"
  top: "res_stage_3_161_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_161"
  type: "Eltwise"
  bottom: "res_3_160"
  bottom: "res_stage_3_161_3_top"
  top: "res_3_161"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_161_relu"
  type: "ReLU"
  bottom: "res_3_161"
  top: "res_3_161"
}
layer {
  name: "res_stage_3_162_1"
  type: "Convolution"
  bottom: "res_3_161"
  top: "res_stage_3_162_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_162_1"
  type: "BatchNorm"
  bottom: "res_stage_3_162_1"
  top: "res_stage_3_162_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_162_1"  
  type: "Scale"
  bottom: "res_stage_3_162_1"
  top: "res_stage_3_162_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_162_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_162_1_top"
  top: "res_stage_3_162_1_top"
}
layer {
  name: "res_stage_3_162_2"
  type: "Convolution"
  bottom: "res_stage_3_162_1_top"
  top: "res_stage_3_162_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_162_2"
  type: "BatchNorm"
  bottom: "res_stage_3_162_2"
  top: "res_stage_3_162_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_162_2"  
  type: "Scale"
  bottom: "res_stage_3_162_2"
  top: "res_stage_3_162_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_162_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_162_2_top"
  top: "res_stage_3_162_2_top"
}
layer {
  name: "res_stage_3_162_3"
  type: "Convolution"
  bottom: "res_stage_3_162_2_top"
  top: "res_stage_3_162_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_162_3"
  type: "BatchNorm"
  bottom: "res_stage_3_162_3"
  top: "res_stage_3_162_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_162_3"  
  type: "Scale"
  bottom: "res_stage_3_162_3"
  top: "res_stage_3_162_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_162"
  type: "Eltwise"
  bottom: "res_3_161"
  bottom: "res_stage_3_162_3_top"
  top: "res_3_162"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_162_relu"
  type: "ReLU"
  bottom: "res_3_162"
  top: "res_3_162"
}
layer {
  name: "res_stage_3_163_1"
  type: "Convolution"
  bottom: "res_3_162"
  top: "res_stage_3_163_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_163_1"
  type: "BatchNorm"
  bottom: "res_stage_3_163_1"
  top: "res_stage_3_163_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_163_1"  
  type: "Scale"
  bottom: "res_stage_3_163_1"
  top: "res_stage_3_163_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_163_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_163_1_top"
  top: "res_stage_3_163_1_top"
}
layer {
  name: "res_stage_3_163_2"
  type: "Convolution"
  bottom: "res_stage_3_163_1_top"
  top: "res_stage_3_163_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_163_2"
  type: "BatchNorm"
  bottom: "res_stage_3_163_2"
  top: "res_stage_3_163_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_163_2"  
  type: "Scale"
  bottom: "res_stage_3_163_2"
  top: "res_stage_3_163_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_163_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_163_2_top"
  top: "res_stage_3_163_2_top"
}
layer {
  name: "res_stage_3_163_3"
  type: "Convolution"
  bottom: "res_stage_3_163_2_top"
  top: "res_stage_3_163_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_163_3"
  type: "BatchNorm"
  bottom: "res_stage_3_163_3"
  top: "res_stage_3_163_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_163_3"  
  type: "Scale"
  bottom: "res_stage_3_163_3"
  top: "res_stage_3_163_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_163"
  type: "Eltwise"
  bottom: "res_3_162"
  bottom: "res_stage_3_163_3_top"
  top: "res_3_163"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_163_relu"
  type: "ReLU"
  bottom: "res_3_163"
  top: "res_3_163"
}
layer {
  name: "res_stage_3_164_1"
  type: "Convolution"
  bottom: "res_3_163"
  top: "res_stage_3_164_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_164_1"
  type: "BatchNorm"
  bottom: "res_stage_3_164_1"
  top: "res_stage_3_164_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_164_1"  
  type: "Scale"
  bottom: "res_stage_3_164_1"
  top: "res_stage_3_164_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_164_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_164_1_top"
  top: "res_stage_3_164_1_top"
}
layer {
  name: "res_stage_3_164_2"
  type: "Convolution"
  bottom: "res_stage_3_164_1_top"
  top: "res_stage_3_164_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_164_2"
  type: "BatchNorm"
  bottom: "res_stage_3_164_2"
  top: "res_stage_3_164_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_164_2"  
  type: "Scale"
  bottom: "res_stage_3_164_2"
  top: "res_stage_3_164_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_164_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_164_2_top"
  top: "res_stage_3_164_2_top"
}
layer {
  name: "res_stage_3_164_3"
  type: "Convolution"
  bottom: "res_stage_3_164_2_top"
  top: "res_stage_3_164_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_164_3"
  type: "BatchNorm"
  bottom: "res_stage_3_164_3"
  top: "res_stage_3_164_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_164_3"  
  type: "Scale"
  bottom: "res_stage_3_164_3"
  top: "res_stage_3_164_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_164"
  type: "Eltwise"
  bottom: "res_3_163"
  bottom: "res_stage_3_164_3_top"
  top: "res_3_164"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_164_relu"
  type: "ReLU"
  bottom: "res_3_164"
  top: "res_3_164"
}
layer {
  name: "res_stage_3_165_1"
  type: "Convolution"
  bottom: "res_3_164"
  top: "res_stage_3_165_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_165_1"
  type: "BatchNorm"
  bottom: "res_stage_3_165_1"
  top: "res_stage_3_165_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_165_1"  
  type: "Scale"
  bottom: "res_stage_3_165_1"
  top: "res_stage_3_165_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_165_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_165_1_top"
  top: "res_stage_3_165_1_top"
}
layer {
  name: "res_stage_3_165_2"
  type: "Convolution"
  bottom: "res_stage_3_165_1_top"
  top: "res_stage_3_165_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_165_2"
  type: "BatchNorm"
  bottom: "res_stage_3_165_2"
  top: "res_stage_3_165_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_165_2"  
  type: "Scale"
  bottom: "res_stage_3_165_2"
  top: "res_stage_3_165_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_165_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_165_2_top"
  top: "res_stage_3_165_2_top"
}
layer {
  name: "res_stage_3_165_3"
  type: "Convolution"
  bottom: "res_stage_3_165_2_top"
  top: "res_stage_3_165_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_165_3"
  type: "BatchNorm"
  bottom: "res_stage_3_165_3"
  top: "res_stage_3_165_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_165_3"  
  type: "Scale"
  bottom: "res_stage_3_165_3"
  top: "res_stage_3_165_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_165"
  type: "Eltwise"
  bottom: "res_3_164"
  bottom: "res_stage_3_165_3_top"
  top: "res_3_165"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_165_relu"
  type: "ReLU"
  bottom: "res_3_165"
  top: "res_3_165"
}
layer {
  name: "res_stage_3_166_1"
  type: "Convolution"
  bottom: "res_3_165"
  top: "res_stage_3_166_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_166_1"
  type: "BatchNorm"
  bottom: "res_stage_3_166_1"
  top: "res_stage_3_166_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_166_1"  
  type: "Scale"
  bottom: "res_stage_3_166_1"
  top: "res_stage_3_166_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_166_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_166_1_top"
  top: "res_stage_3_166_1_top"
}
layer {
  name: "res_stage_3_166_2"
  type: "Convolution"
  bottom: "res_stage_3_166_1_top"
  top: "res_stage_3_166_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_166_2"
  type: "BatchNorm"
  bottom: "res_stage_3_166_2"
  top: "res_stage_3_166_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_166_2"  
  type: "Scale"
  bottom: "res_stage_3_166_2"
  top: "res_stage_3_166_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_166_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_166_2_top"
  top: "res_stage_3_166_2_top"
}
layer {
  name: "res_stage_3_166_3"
  type: "Convolution"
  bottom: "res_stage_3_166_2_top"
  top: "res_stage_3_166_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_166_3"
  type: "BatchNorm"
  bottom: "res_stage_3_166_3"
  top: "res_stage_3_166_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_166_3"  
  type: "Scale"
  bottom: "res_stage_3_166_3"
  top: "res_stage_3_166_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_166"
  type: "Eltwise"
  bottom: "res_3_165"
  bottom: "res_stage_3_166_3_top"
  top: "res_3_166"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_166_relu"
  type: "ReLU"
  bottom: "res_3_166"
  top: "res_3_166"
}
layer {
  name: "res_stage_3_167_1"
  type: "Convolution"
  bottom: "res_3_166"
  top: "res_stage_3_167_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_167_1"
  type: "BatchNorm"
  bottom: "res_stage_3_167_1"
  top: "res_stage_3_167_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_167_1"  
  type: "Scale"
  bottom: "res_stage_3_167_1"
  top: "res_stage_3_167_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_167_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_167_1_top"
  top: "res_stage_3_167_1_top"
}
layer {
  name: "res_stage_3_167_2"
  type: "Convolution"
  bottom: "res_stage_3_167_1_top"
  top: "res_stage_3_167_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_167_2"
  type: "BatchNorm"
  bottom: "res_stage_3_167_2"
  top: "res_stage_3_167_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_167_2"  
  type: "Scale"
  bottom: "res_stage_3_167_2"
  top: "res_stage_3_167_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_167_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_167_2_top"
  top: "res_stage_3_167_2_top"
}
layer {
  name: "res_stage_3_167_3"
  type: "Convolution"
  bottom: "res_stage_3_167_2_top"
  top: "res_stage_3_167_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_167_3"
  type: "BatchNorm"
  bottom: "res_stage_3_167_3"
  top: "res_stage_3_167_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_167_3"  
  type: "Scale"
  bottom: "res_stage_3_167_3"
  top: "res_stage_3_167_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_167"
  type: "Eltwise"
  bottom: "res_3_166"
  bottom: "res_stage_3_167_3_top"
  top: "res_3_167"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_167_relu"
  type: "ReLU"
  bottom: "res_3_167"
  top: "res_3_167"
}
layer {
  name: "res_stage_3_168_1"
  type: "Convolution"
  bottom: "res_3_167"
  top: "res_stage_3_168_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_168_1"
  type: "BatchNorm"
  bottom: "res_stage_3_168_1"
  top: "res_stage_3_168_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_168_1"  
  type: "Scale"
  bottom: "res_stage_3_168_1"
  top: "res_stage_3_168_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_168_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_168_1_top"
  top: "res_stage_3_168_1_top"
}
layer {
  name: "res_stage_3_168_2"
  type: "Convolution"
  bottom: "res_stage_3_168_1_top"
  top: "res_stage_3_168_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_168_2"
  type: "BatchNorm"
  bottom: "res_stage_3_168_2"
  top: "res_stage_3_168_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_168_2"  
  type: "Scale"
  bottom: "res_stage_3_168_2"
  top: "res_stage_3_168_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_168_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_168_2_top"
  top: "res_stage_3_168_2_top"
}
layer {
  name: "res_stage_3_168_3"
  type: "Convolution"
  bottom: "res_stage_3_168_2_top"
  top: "res_stage_3_168_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_168_3"
  type: "BatchNorm"
  bottom: "res_stage_3_168_3"
  top: "res_stage_3_168_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_168_3"  
  type: "Scale"
  bottom: "res_stage_3_168_3"
  top: "res_stage_3_168_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_168"
  type: "Eltwise"
  bottom: "res_3_167"
  bottom: "res_stage_3_168_3_top"
  top: "res_3_168"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_168_relu"
  type: "ReLU"
  bottom: "res_3_168"
  top: "res_3_168"
}
layer {
  name: "res_stage_3_169_1"
  type: "Convolution"
  bottom: "res_3_168"
  top: "res_stage_3_169_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_169_1"
  type: "BatchNorm"
  bottom: "res_stage_3_169_1"
  top: "res_stage_3_169_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_169_1"  
  type: "Scale"
  bottom: "res_stage_3_169_1"
  top: "res_stage_3_169_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_169_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_169_1_top"
  top: "res_stage_3_169_1_top"
}
layer {
  name: "res_stage_3_169_2"
  type: "Convolution"
  bottom: "res_stage_3_169_1_top"
  top: "res_stage_3_169_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_169_2"
  type: "BatchNorm"
  bottom: "res_stage_3_169_2"
  top: "res_stage_3_169_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_169_2"  
  type: "Scale"
  bottom: "res_stage_3_169_2"
  top: "res_stage_3_169_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_169_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_169_2_top"
  top: "res_stage_3_169_2_top"
}
layer {
  name: "res_stage_3_169_3"
  type: "Convolution"
  bottom: "res_stage_3_169_2_top"
  top: "res_stage_3_169_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_169_3"
  type: "BatchNorm"
  bottom: "res_stage_3_169_3"
  top: "res_stage_3_169_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_169_3"  
  type: "Scale"
  bottom: "res_stage_3_169_3"
  top: "res_stage_3_169_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_169"
  type: "Eltwise"
  bottom: "res_3_168"
  bottom: "res_stage_3_169_3_top"
  top: "res_3_169"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_169_relu"
  type: "ReLU"
  bottom: "res_3_169"
  top: "res_3_169"
}
layer {
  name: "res_stage_3_170_1"
  type: "Convolution"
  bottom: "res_3_169"
  top: "res_stage_3_170_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_170_1"
  type: "BatchNorm"
  bottom: "res_stage_3_170_1"
  top: "res_stage_3_170_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_170_1"  
  type: "Scale"
  bottom: "res_stage_3_170_1"
  top: "res_stage_3_170_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_170_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_170_1_top"
  top: "res_stage_3_170_1_top"
}
layer {
  name: "res_stage_3_170_2"
  type: "Convolution"
  bottom: "res_stage_3_170_1_top"
  top: "res_stage_3_170_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_170_2"
  type: "BatchNorm"
  bottom: "res_stage_3_170_2"
  top: "res_stage_3_170_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_170_2"  
  type: "Scale"
  bottom: "res_stage_3_170_2"
  top: "res_stage_3_170_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_170_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_170_2_top"
  top: "res_stage_3_170_2_top"
}
layer {
  name: "res_stage_3_170_3"
  type: "Convolution"
  bottom: "res_stage_3_170_2_top"
  top: "res_stage_3_170_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_170_3"
  type: "BatchNorm"
  bottom: "res_stage_3_170_3"
  top: "res_stage_3_170_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_170_3"  
  type: "Scale"
  bottom: "res_stage_3_170_3"
  top: "res_stage_3_170_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_170"
  type: "Eltwise"
  bottom: "res_3_169"
  bottom: "res_stage_3_170_3_top"
  top: "res_3_170"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_170_relu"
  type: "ReLU"
  bottom: "res_3_170"
  top: "res_3_170"
}
layer {
  name: "res_stage_3_171_1"
  type: "Convolution"
  bottom: "res_3_170"
  top: "res_stage_3_171_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_171_1"
  type: "BatchNorm"
  bottom: "res_stage_3_171_1"
  top: "res_stage_3_171_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_171_1"  
  type: "Scale"
  bottom: "res_stage_3_171_1"
  top: "res_stage_3_171_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_171_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_171_1_top"
  top: "res_stage_3_171_1_top"
}
layer {
  name: "res_stage_3_171_2"
  type: "Convolution"
  bottom: "res_stage_3_171_1_top"
  top: "res_stage_3_171_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_171_2"
  type: "BatchNorm"
  bottom: "res_stage_3_171_2"
  top: "res_stage_3_171_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_171_2"  
  type: "Scale"
  bottom: "res_stage_3_171_2"
  top: "res_stage_3_171_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_171_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_171_2_top"
  top: "res_stage_3_171_2_top"
}
layer {
  name: "res_stage_3_171_3"
  type: "Convolution"
  bottom: "res_stage_3_171_2_top"
  top: "res_stage_3_171_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_171_3"
  type: "BatchNorm"
  bottom: "res_stage_3_171_3"
  top: "res_stage_3_171_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_171_3"  
  type: "Scale"
  bottom: "res_stage_3_171_3"
  top: "res_stage_3_171_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_171"
  type: "Eltwise"
  bottom: "res_3_170"
  bottom: "res_stage_3_171_3_top"
  top: "res_3_171"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_171_relu"
  type: "ReLU"
  bottom: "res_3_171"
  top: "res_3_171"
}
layer {
  name: "res_stage_3_172_1"
  type: "Convolution"
  bottom: "res_3_171"
  top: "res_stage_3_172_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_172_1"
  type: "BatchNorm"
  bottom: "res_stage_3_172_1"
  top: "res_stage_3_172_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_172_1"  
  type: "Scale"
  bottom: "res_stage_3_172_1"
  top: "res_stage_3_172_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_172_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_172_1_top"
  top: "res_stage_3_172_1_top"
}
layer {
  name: "res_stage_3_172_2"
  type: "Convolution"
  bottom: "res_stage_3_172_1_top"
  top: "res_stage_3_172_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_172_2"
  type: "BatchNorm"
  bottom: "res_stage_3_172_2"
  top: "res_stage_3_172_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_172_2"  
  type: "Scale"
  bottom: "res_stage_3_172_2"
  top: "res_stage_3_172_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_172_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_172_2_top"
  top: "res_stage_3_172_2_top"
}
layer {
  name: "res_stage_3_172_3"
  type: "Convolution"
  bottom: "res_stage_3_172_2_top"
  top: "res_stage_3_172_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_172_3"
  type: "BatchNorm"
  bottom: "res_stage_3_172_3"
  top: "res_stage_3_172_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_172_3"  
  type: "Scale"
  bottom: "res_stage_3_172_3"
  top: "res_stage_3_172_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_172"
  type: "Eltwise"
  bottom: "res_3_171"
  bottom: "res_stage_3_172_3_top"
  top: "res_3_172"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_172_relu"
  type: "ReLU"
  bottom: "res_3_172"
  top: "res_3_172"
}
layer {
  name: "res_stage_3_173_1"
  type: "Convolution"
  bottom: "res_3_172"
  top: "res_stage_3_173_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_173_1"
  type: "BatchNorm"
  bottom: "res_stage_3_173_1"
  top: "res_stage_3_173_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_173_1"  
  type: "Scale"
  bottom: "res_stage_3_173_1"
  top: "res_stage_3_173_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_173_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_173_1_top"
  top: "res_stage_3_173_1_top"
}
layer {
  name: "res_stage_3_173_2"
  type: "Convolution"
  bottom: "res_stage_3_173_1_top"
  top: "res_stage_3_173_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_173_2"
  type: "BatchNorm"
  bottom: "res_stage_3_173_2"
  top: "res_stage_3_173_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_173_2"  
  type: "Scale"
  bottom: "res_stage_3_173_2"
  top: "res_stage_3_173_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_173_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_173_2_top"
  top: "res_stage_3_173_2_top"
}
layer {
  name: "res_stage_3_173_3"
  type: "Convolution"
  bottom: "res_stage_3_173_2_top"
  top: "res_stage_3_173_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_173_3"
  type: "BatchNorm"
  bottom: "res_stage_3_173_3"
  top: "res_stage_3_173_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_173_3"  
  type: "Scale"
  bottom: "res_stage_3_173_3"
  top: "res_stage_3_173_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_173"
  type: "Eltwise"
  bottom: "res_3_172"
  bottom: "res_stage_3_173_3_top"
  top: "res_3_173"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_173_relu"
  type: "ReLU"
  bottom: "res_3_173"
  top: "res_3_173"
}
layer {
  name: "res_stage_3_174_1"
  type: "Convolution"
  bottom: "res_3_173"
  top: "res_stage_3_174_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_174_1"
  type: "BatchNorm"
  bottom: "res_stage_3_174_1"
  top: "res_stage_3_174_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_174_1"  
  type: "Scale"
  bottom: "res_stage_3_174_1"
  top: "res_stage_3_174_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_174_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_174_1_top"
  top: "res_stage_3_174_1_top"
}
layer {
  name: "res_stage_3_174_2"
  type: "Convolution"
  bottom: "res_stage_3_174_1_top"
  top: "res_stage_3_174_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_174_2"
  type: "BatchNorm"
  bottom: "res_stage_3_174_2"
  top: "res_stage_3_174_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_174_2"  
  type: "Scale"
  bottom: "res_stage_3_174_2"
  top: "res_stage_3_174_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_174_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_174_2_top"
  top: "res_stage_3_174_2_top"
}
layer {
  name: "res_stage_3_174_3"
  type: "Convolution"
  bottom: "res_stage_3_174_2_top"
  top: "res_stage_3_174_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_174_3"
  type: "BatchNorm"
  bottom: "res_stage_3_174_3"
  top: "res_stage_3_174_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_174_3"  
  type: "Scale"
  bottom: "res_stage_3_174_3"
  top: "res_stage_3_174_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_174"
  type: "Eltwise"
  bottom: "res_3_173"
  bottom: "res_stage_3_174_3_top"
  top: "res_3_174"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_174_relu"
  type: "ReLU"
  bottom: "res_3_174"
  top: "res_3_174"
}
layer {
  name: "res_stage_3_175_1"
  type: "Convolution"
  bottom: "res_3_174"
  top: "res_stage_3_175_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_175_1"
  type: "BatchNorm"
  bottom: "res_stage_3_175_1"
  top: "res_stage_3_175_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_175_1"  
  type: "Scale"
  bottom: "res_stage_3_175_1"
  top: "res_stage_3_175_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_175_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_175_1_top"
  top: "res_stage_3_175_1_top"
}
layer {
  name: "res_stage_3_175_2"
  type: "Convolution"
  bottom: "res_stage_3_175_1_top"
  top: "res_stage_3_175_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_175_2"
  type: "BatchNorm"
  bottom: "res_stage_3_175_2"
  top: "res_stage_3_175_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_175_2"  
  type: "Scale"
  bottom: "res_stage_3_175_2"
  top: "res_stage_3_175_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_175_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_175_2_top"
  top: "res_stage_3_175_2_top"
}
layer {
  name: "res_stage_3_175_3"
  type: "Convolution"
  bottom: "res_stage_3_175_2_top"
  top: "res_stage_3_175_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_175_3"
  type: "BatchNorm"
  bottom: "res_stage_3_175_3"
  top: "res_stage_3_175_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_175_3"  
  type: "Scale"
  bottom: "res_stage_3_175_3"
  top: "res_stage_3_175_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_175"
  type: "Eltwise"
  bottom: "res_3_174"
  bottom: "res_stage_3_175_3_top"
  top: "res_3_175"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_175_relu"
  type: "ReLU"
  bottom: "res_3_175"
  top: "res_3_175"
}
layer {
  name: "res_stage_3_176_1"
  type: "Convolution"
  bottom: "res_3_175"
  top: "res_stage_3_176_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_176_1"
  type: "BatchNorm"
  bottom: "res_stage_3_176_1"
  top: "res_stage_3_176_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_176_1"  
  type: "Scale"
  bottom: "res_stage_3_176_1"
  top: "res_stage_3_176_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_176_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_176_1_top"
  top: "res_stage_3_176_1_top"
}
layer {
  name: "res_stage_3_176_2"
  type: "Convolution"
  bottom: "res_stage_3_176_1_top"
  top: "res_stage_3_176_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_176_2"
  type: "BatchNorm"
  bottom: "res_stage_3_176_2"
  top: "res_stage_3_176_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_176_2"  
  type: "Scale"
  bottom: "res_stage_3_176_2"
  top: "res_stage_3_176_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_176_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_176_2_top"
  top: "res_stage_3_176_2_top"
}
layer {
  name: "res_stage_3_176_3"
  type: "Convolution"
  bottom: "res_stage_3_176_2_top"
  top: "res_stage_3_176_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_176_3"
  type: "BatchNorm"
  bottom: "res_stage_3_176_3"
  top: "res_stage_3_176_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_176_3"  
  type: "Scale"
  bottom: "res_stage_3_176_3"
  top: "res_stage_3_176_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_176"
  type: "Eltwise"
  bottom: "res_3_175"
  bottom: "res_stage_3_176_3_top"
  top: "res_3_176"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_176_relu"
  type: "ReLU"
  bottom: "res_3_176"
  top: "res_3_176"
}
layer {
  name: "res_stage_3_177_1"
  type: "Convolution"
  bottom: "res_3_176"
  top: "res_stage_3_177_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_177_1"
  type: "BatchNorm"
  bottom: "res_stage_3_177_1"
  top: "res_stage_3_177_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_177_1"  
  type: "Scale"
  bottom: "res_stage_3_177_1"
  top: "res_stage_3_177_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_177_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_177_1_top"
  top: "res_stage_3_177_1_top"
}
layer {
  name: "res_stage_3_177_2"
  type: "Convolution"
  bottom: "res_stage_3_177_1_top"
  top: "res_stage_3_177_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_177_2"
  type: "BatchNorm"
  bottom: "res_stage_3_177_2"
  top: "res_stage_3_177_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_177_2"  
  type: "Scale"
  bottom: "res_stage_3_177_2"
  top: "res_stage_3_177_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_177_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_177_2_top"
  top: "res_stage_3_177_2_top"
}
layer {
  name: "res_stage_3_177_3"
  type: "Convolution"
  bottom: "res_stage_3_177_2_top"
  top: "res_stage_3_177_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_177_3"
  type: "BatchNorm"
  bottom: "res_stage_3_177_3"
  top: "res_stage_3_177_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_177_3"  
  type: "Scale"
  bottom: "res_stage_3_177_3"
  top: "res_stage_3_177_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_177"
  type: "Eltwise"
  bottom: "res_3_176"
  bottom: "res_stage_3_177_3_top"
  top: "res_3_177"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_177_relu"
  type: "ReLU"
  bottom: "res_3_177"
  top: "res_3_177"
}
layer {
  name: "res_stage_3_178_1"
  type: "Convolution"
  bottom: "res_3_177"
  top: "res_stage_3_178_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_178_1"
  type: "BatchNorm"
  bottom: "res_stage_3_178_1"
  top: "res_stage_3_178_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_178_1"  
  type: "Scale"
  bottom: "res_stage_3_178_1"
  top: "res_stage_3_178_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_178_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_178_1_top"
  top: "res_stage_3_178_1_top"
}
layer {
  name: "res_stage_3_178_2"
  type: "Convolution"
  bottom: "res_stage_3_178_1_top"
  top: "res_stage_3_178_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_178_2"
  type: "BatchNorm"
  bottom: "res_stage_3_178_2"
  top: "res_stage_3_178_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_178_2"  
  type: "Scale"
  bottom: "res_stage_3_178_2"
  top: "res_stage_3_178_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_178_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_178_2_top"
  top: "res_stage_3_178_2_top"
}
layer {
  name: "res_stage_3_178_3"
  type: "Convolution"
  bottom: "res_stage_3_178_2_top"
  top: "res_stage_3_178_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_178_3"
  type: "BatchNorm"
  bottom: "res_stage_3_178_3"
  top: "res_stage_3_178_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_178_3"  
  type: "Scale"
  bottom: "res_stage_3_178_3"
  top: "res_stage_3_178_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_178"
  type: "Eltwise"
  bottom: "res_3_177"
  bottom: "res_stage_3_178_3_top"
  top: "res_3_178"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_178_relu"
  type: "ReLU"
  bottom: "res_3_178"
  top: "res_3_178"
}
layer {
  name: "res_stage_3_179_1"
  type: "Convolution"
  bottom: "res_3_178"
  top: "res_stage_3_179_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_179_1"
  type: "BatchNorm"
  bottom: "res_stage_3_179_1"
  top: "res_stage_3_179_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_179_1"  
  type: "Scale"
  bottom: "res_stage_3_179_1"
  top: "res_stage_3_179_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_179_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_179_1_top"
  top: "res_stage_3_179_1_top"
}
layer {
  name: "res_stage_3_179_2"
  type: "Convolution"
  bottom: "res_stage_3_179_1_top"
  top: "res_stage_3_179_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_179_2"
  type: "BatchNorm"
  bottom: "res_stage_3_179_2"
  top: "res_stage_3_179_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_179_2"  
  type: "Scale"
  bottom: "res_stage_3_179_2"
  top: "res_stage_3_179_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_179_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_179_2_top"
  top: "res_stage_3_179_2_top"
}
layer {
  name: "res_stage_3_179_3"
  type: "Convolution"
  bottom: "res_stage_3_179_2_top"
  top: "res_stage_3_179_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_179_3"
  type: "BatchNorm"
  bottom: "res_stage_3_179_3"
  top: "res_stage_3_179_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_179_3"  
  type: "Scale"
  bottom: "res_stage_3_179_3"
  top: "res_stage_3_179_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_179"
  type: "Eltwise"
  bottom: "res_3_178"
  bottom: "res_stage_3_179_3_top"
  top: "res_3_179"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_179_relu"
  type: "ReLU"
  bottom: "res_3_179"
  top: "res_3_179"
}
layer {
  name: "res_stage_3_180_1"
  type: "Convolution"
  bottom: "res_3_179"
  top: "res_stage_3_180_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_180_1"
  type: "BatchNorm"
  bottom: "res_stage_3_180_1"
  top: "res_stage_3_180_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_180_1"  
  type: "Scale"
  bottom: "res_stage_3_180_1"
  top: "res_stage_3_180_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_180_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_180_1_top"
  top: "res_stage_3_180_1_top"
}
layer {
  name: "res_stage_3_180_2"
  type: "Convolution"
  bottom: "res_stage_3_180_1_top"
  top: "res_stage_3_180_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_180_2"
  type: "BatchNorm"
  bottom: "res_stage_3_180_2"
  top: "res_stage_3_180_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_180_2"  
  type: "Scale"
  bottom: "res_stage_3_180_2"
  top: "res_stage_3_180_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_180_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_180_2_top"
  top: "res_stage_3_180_2_top"
}
layer {
  name: "res_stage_3_180_3"
  type: "Convolution"
  bottom: "res_stage_3_180_2_top"
  top: "res_stage_3_180_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_180_3"
  type: "BatchNorm"
  bottom: "res_stage_3_180_3"
  top: "res_stage_3_180_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_180_3"  
  type: "Scale"
  bottom: "res_stage_3_180_3"
  top: "res_stage_3_180_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_180"
  type: "Eltwise"
  bottom: "res_3_179"
  bottom: "res_stage_3_180_3_top"
  top: "res_3_180"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_180_relu"
  type: "ReLU"
  bottom: "res_3_180"
  top: "res_3_180"
}
layer {
  name: "res_stage_3_181_1"
  type: "Convolution"
  bottom: "res_3_180"
  top: "res_stage_3_181_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_181_1"
  type: "BatchNorm"
  bottom: "res_stage_3_181_1"
  top: "res_stage_3_181_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_181_1"  
  type: "Scale"
  bottom: "res_stage_3_181_1"
  top: "res_stage_3_181_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_181_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_181_1_top"
  top: "res_stage_3_181_1_top"
}
layer {
  name: "res_stage_3_181_2"
  type: "Convolution"
  bottom: "res_stage_3_181_1_top"
  top: "res_stage_3_181_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_181_2"
  type: "BatchNorm"
  bottom: "res_stage_3_181_2"
  top: "res_stage_3_181_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_181_2"  
  type: "Scale"
  bottom: "res_stage_3_181_2"
  top: "res_stage_3_181_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_181_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_181_2_top"
  top: "res_stage_3_181_2_top"
}
layer {
  name: "res_stage_3_181_3"
  type: "Convolution"
  bottom: "res_stage_3_181_2_top"
  top: "res_stage_3_181_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_181_3"
  type: "BatchNorm"
  bottom: "res_stage_3_181_3"
  top: "res_stage_3_181_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_181_3"  
  type: "Scale"
  bottom: "res_stage_3_181_3"
  top: "res_stage_3_181_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_181"
  type: "Eltwise"
  bottom: "res_3_180"
  bottom: "res_stage_3_181_3_top"
  top: "res_3_181"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_181_relu"
  type: "ReLU"
  bottom: "res_3_181"
  top: "res_3_181"
}
layer {
  name: "res_stage_3_182_1"
  type: "Convolution"
  bottom: "res_3_181"
  top: "res_stage_3_182_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_182_1"
  type: "BatchNorm"
  bottom: "res_stage_3_182_1"
  top: "res_stage_3_182_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_182_1"  
  type: "Scale"
  bottom: "res_stage_3_182_1"
  top: "res_stage_3_182_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_182_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_182_1_top"
  top: "res_stage_3_182_1_top"
}
layer {
  name: "res_stage_3_182_2"
  type: "Convolution"
  bottom: "res_stage_3_182_1_top"
  top: "res_stage_3_182_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_182_2"
  type: "BatchNorm"
  bottom: "res_stage_3_182_2"
  top: "res_stage_3_182_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_182_2"  
  type: "Scale"
  bottom: "res_stage_3_182_2"
  top: "res_stage_3_182_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_182_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_182_2_top"
  top: "res_stage_3_182_2_top"
}
layer {
  name: "res_stage_3_182_3"
  type: "Convolution"
  bottom: "res_stage_3_182_2_top"
  top: "res_stage_3_182_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_182_3"
  type: "BatchNorm"
  bottom: "res_stage_3_182_3"
  top: "res_stage_3_182_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_182_3"  
  type: "Scale"
  bottom: "res_stage_3_182_3"
  top: "res_stage_3_182_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_182"
  type: "Eltwise"
  bottom: "res_3_181"
  bottom: "res_stage_3_182_3_top"
  top: "res_3_182"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_182_relu"
  type: "ReLU"
  bottom: "res_3_182"
  top: "res_3_182"
}
layer {
  name: "res_stage_3_183_1"
  type: "Convolution"
  bottom: "res_3_182"
  top: "res_stage_3_183_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_183_1"
  type: "BatchNorm"
  bottom: "res_stage_3_183_1"
  top: "res_stage_3_183_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_183_1"  
  type: "Scale"
  bottom: "res_stage_3_183_1"
  top: "res_stage_3_183_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_183_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_183_1_top"
  top: "res_stage_3_183_1_top"
}
layer {
  name: "res_stage_3_183_2"
  type: "Convolution"
  bottom: "res_stage_3_183_1_top"
  top: "res_stage_3_183_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_183_2"
  type: "BatchNorm"
  bottom: "res_stage_3_183_2"
  top: "res_stage_3_183_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_183_2"  
  type: "Scale"
  bottom: "res_stage_3_183_2"
  top: "res_stage_3_183_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_183_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_183_2_top"
  top: "res_stage_3_183_2_top"
}
layer {
  name: "res_stage_3_183_3"
  type: "Convolution"
  bottom: "res_stage_3_183_2_top"
  top: "res_stage_3_183_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_183_3"
  type: "BatchNorm"
  bottom: "res_stage_3_183_3"
  top: "res_stage_3_183_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_183_3"  
  type: "Scale"
  bottom: "res_stage_3_183_3"
  top: "res_stage_3_183_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_183"
  type: "Eltwise"
  bottom: "res_3_182"
  bottom: "res_stage_3_183_3_top"
  top: "res_3_183"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_183_relu"
  type: "ReLU"
  bottom: "res_3_183"
  top: "res_3_183"
}
layer {
  name: "res_stage_3_184_1"
  type: "Convolution"
  bottom: "res_3_183"
  top: "res_stage_3_184_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_184_1"
  type: "BatchNorm"
  bottom: "res_stage_3_184_1"
  top: "res_stage_3_184_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_184_1"  
  type: "Scale"
  bottom: "res_stage_3_184_1"
  top: "res_stage_3_184_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_184_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_184_1_top"
  top: "res_stage_3_184_1_top"
}
layer {
  name: "res_stage_3_184_2"
  type: "Convolution"
  bottom: "res_stage_3_184_1_top"
  top: "res_stage_3_184_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_184_2"
  type: "BatchNorm"
  bottom: "res_stage_3_184_2"
  top: "res_stage_3_184_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_184_2"  
  type: "Scale"
  bottom: "res_stage_3_184_2"
  top: "res_stage_3_184_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_184_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_184_2_top"
  top: "res_stage_3_184_2_top"
}
layer {
  name: "res_stage_3_184_3"
  type: "Convolution"
  bottom: "res_stage_3_184_2_top"
  top: "res_stage_3_184_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_184_3"
  type: "BatchNorm"
  bottom: "res_stage_3_184_3"
  top: "res_stage_3_184_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_184_3"  
  type: "Scale"
  bottom: "res_stage_3_184_3"
  top: "res_stage_3_184_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_184"
  type: "Eltwise"
  bottom: "res_3_183"
  bottom: "res_stage_3_184_3_top"
  top: "res_3_184"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_184_relu"
  type: "ReLU"
  bottom: "res_3_184"
  top: "res_3_184"
}
layer {
  name: "res_stage_3_185_1"
  type: "Convolution"
  bottom: "res_3_184"
  top: "res_stage_3_185_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_185_1"
  type: "BatchNorm"
  bottom: "res_stage_3_185_1"
  top: "res_stage_3_185_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_185_1"  
  type: "Scale"
  bottom: "res_stage_3_185_1"
  top: "res_stage_3_185_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_185_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_185_1_top"
  top: "res_stage_3_185_1_top"
}
layer {
  name: "res_stage_3_185_2"
  type: "Convolution"
  bottom: "res_stage_3_185_1_top"
  top: "res_stage_3_185_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_185_2"
  type: "BatchNorm"
  bottom: "res_stage_3_185_2"
  top: "res_stage_3_185_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_185_2"  
  type: "Scale"
  bottom: "res_stage_3_185_2"
  top: "res_stage_3_185_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_185_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_185_2_top"
  top: "res_stage_3_185_2_top"
}
layer {
  name: "res_stage_3_185_3"
  type: "Convolution"
  bottom: "res_stage_3_185_2_top"
  top: "res_stage_3_185_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_185_3"
  type: "BatchNorm"
  bottom: "res_stage_3_185_3"
  top: "res_stage_3_185_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_185_3"  
  type: "Scale"
  bottom: "res_stage_3_185_3"
  top: "res_stage_3_185_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_185"
  type: "Eltwise"
  bottom: "res_3_184"
  bottom: "res_stage_3_185_3_top"
  top: "res_3_185"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_185_relu"
  type: "ReLU"
  bottom: "res_3_185"
  top: "res_3_185"
}
layer {
  name: "res_stage_3_186_1"
  type: "Convolution"
  bottom: "res_3_185"
  top: "res_stage_3_186_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_186_1"
  type: "BatchNorm"
  bottom: "res_stage_3_186_1"
  top: "res_stage_3_186_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_186_1"  
  type: "Scale"
  bottom: "res_stage_3_186_1"
  top: "res_stage_3_186_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_186_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_186_1_top"
  top: "res_stage_3_186_1_top"
}
layer {
  name: "res_stage_3_186_2"
  type: "Convolution"
  bottom: "res_stage_3_186_1_top"
  top: "res_stage_3_186_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_186_2"
  type: "BatchNorm"
  bottom: "res_stage_3_186_2"
  top: "res_stage_3_186_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_186_2"  
  type: "Scale"
  bottom: "res_stage_3_186_2"
  top: "res_stage_3_186_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_186_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_186_2_top"
  top: "res_stage_3_186_2_top"
}
layer {
  name: "res_stage_3_186_3"
  type: "Convolution"
  bottom: "res_stage_3_186_2_top"
  top: "res_stage_3_186_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_186_3"
  type: "BatchNorm"
  bottom: "res_stage_3_186_3"
  top: "res_stage_3_186_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_186_3"  
  type: "Scale"
  bottom: "res_stage_3_186_3"
  top: "res_stage_3_186_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_186"
  type: "Eltwise"
  bottom: "res_3_185"
  bottom: "res_stage_3_186_3_top"
  top: "res_3_186"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_186_relu"
  type: "ReLU"
  bottom: "res_3_186"
  top: "res_3_186"
}
layer {
  name: "res_stage_3_187_1"
  type: "Convolution"
  bottom: "res_3_186"
  top: "res_stage_3_187_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_187_1"
  type: "BatchNorm"
  bottom: "res_stage_3_187_1"
  top: "res_stage_3_187_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_187_1"  
  type: "Scale"
  bottom: "res_stage_3_187_1"
  top: "res_stage_3_187_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_187_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_187_1_top"
  top: "res_stage_3_187_1_top"
}
layer {
  name: "res_stage_3_187_2"
  type: "Convolution"
  bottom: "res_stage_3_187_1_top"
  top: "res_stage_3_187_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_187_2"
  type: "BatchNorm"
  bottom: "res_stage_3_187_2"
  top: "res_stage_3_187_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_187_2"  
  type: "Scale"
  bottom: "res_stage_3_187_2"
  top: "res_stage_3_187_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_187_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_187_2_top"
  top: "res_stage_3_187_2_top"
}
layer {
  name: "res_stage_3_187_3"
  type: "Convolution"
  bottom: "res_stage_3_187_2_top"
  top: "res_stage_3_187_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_187_3"
  type: "BatchNorm"
  bottom: "res_stage_3_187_3"
  top: "res_stage_3_187_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_187_3"  
  type: "Scale"
  bottom: "res_stage_3_187_3"
  top: "res_stage_3_187_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_187"
  type: "Eltwise"
  bottom: "res_3_186"
  bottom: "res_stage_3_187_3_top"
  top: "res_3_187"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_187_relu"
  type: "ReLU"
  bottom: "res_3_187"
  top: "res_3_187"
}
layer {
  name: "res_stage_3_188_1"
  type: "Convolution"
  bottom: "res_3_187"
  top: "res_stage_3_188_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_188_1"
  type: "BatchNorm"
  bottom: "res_stage_3_188_1"
  top: "res_stage_3_188_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_188_1"  
  type: "Scale"
  bottom: "res_stage_3_188_1"
  top: "res_stage_3_188_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_188_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_188_1_top"
  top: "res_stage_3_188_1_top"
}
layer {
  name: "res_stage_3_188_2"
  type: "Convolution"
  bottom: "res_stage_3_188_1_top"
  top: "res_stage_3_188_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_188_2"
  type: "BatchNorm"
  bottom: "res_stage_3_188_2"
  top: "res_stage_3_188_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_188_2"  
  type: "Scale"
  bottom: "res_stage_3_188_2"
  top: "res_stage_3_188_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_188_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_188_2_top"
  top: "res_stage_3_188_2_top"
}
layer {
  name: "res_stage_3_188_3"
  type: "Convolution"
  bottom: "res_stage_3_188_2_top"
  top: "res_stage_3_188_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_188_3"
  type: "BatchNorm"
  bottom: "res_stage_3_188_3"
  top: "res_stage_3_188_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_188_3"  
  type: "Scale"
  bottom: "res_stage_3_188_3"
  top: "res_stage_3_188_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_188"
  type: "Eltwise"
  bottom: "res_3_187"
  bottom: "res_stage_3_188_3_top"
  top: "res_3_188"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_188_relu"
  type: "ReLU"
  bottom: "res_3_188"
  top: "res_3_188"
}
layer {
  name: "res_stage_3_189_1"
  type: "Convolution"
  bottom: "res_3_188"
  top: "res_stage_3_189_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_189_1"
  type: "BatchNorm"
  bottom: "res_stage_3_189_1"
  top: "res_stage_3_189_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_189_1"  
  type: "Scale"
  bottom: "res_stage_3_189_1"
  top: "res_stage_3_189_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_189_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_189_1_top"
  top: "res_stage_3_189_1_top"
}
layer {
  name: "res_stage_3_189_2"
  type: "Convolution"
  bottom: "res_stage_3_189_1_top"
  top: "res_stage_3_189_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_189_2"
  type: "BatchNorm"
  bottom: "res_stage_3_189_2"
  top: "res_stage_3_189_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_189_2"  
  type: "Scale"
  bottom: "res_stage_3_189_2"
  top: "res_stage_3_189_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_189_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_189_2_top"
  top: "res_stage_3_189_2_top"
}
layer {
  name: "res_stage_3_189_3"
  type: "Convolution"
  bottom: "res_stage_3_189_2_top"
  top: "res_stage_3_189_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_189_3"
  type: "BatchNorm"
  bottom: "res_stage_3_189_3"
  top: "res_stage_3_189_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_189_3"  
  type: "Scale"
  bottom: "res_stage_3_189_3"
  top: "res_stage_3_189_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_189"
  type: "Eltwise"
  bottom: "res_3_188"
  bottom: "res_stage_3_189_3_top"
  top: "res_3_189"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_189_relu"
  type: "ReLU"
  bottom: "res_3_189"
  top: "res_3_189"
}
layer {
  name: "res_stage_3_190_1"
  type: "Convolution"
  bottom: "res_3_189"
  top: "res_stage_3_190_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_190_1"
  type: "BatchNorm"
  bottom: "res_stage_3_190_1"
  top: "res_stage_3_190_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_190_1"  
  type: "Scale"
  bottom: "res_stage_3_190_1"
  top: "res_stage_3_190_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_190_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_190_1_top"
  top: "res_stage_3_190_1_top"
}
layer {
  name: "res_stage_3_190_2"
  type: "Convolution"
  bottom: "res_stage_3_190_1_top"
  top: "res_stage_3_190_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_190_2"
  type: "BatchNorm"
  bottom: "res_stage_3_190_2"
  top: "res_stage_3_190_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_190_2"  
  type: "Scale"
  bottom: "res_stage_3_190_2"
  top: "res_stage_3_190_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_190_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_190_2_top"
  top: "res_stage_3_190_2_top"
}
layer {
  name: "res_stage_3_190_3"
  type: "Convolution"
  bottom: "res_stage_3_190_2_top"
  top: "res_stage_3_190_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_190_3"
  type: "BatchNorm"
  bottom: "res_stage_3_190_3"
  top: "res_stage_3_190_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_190_3"  
  type: "Scale"
  bottom: "res_stage_3_190_3"
  top: "res_stage_3_190_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_190"
  type: "Eltwise"
  bottom: "res_3_189"
  bottom: "res_stage_3_190_3_top"
  top: "res_3_190"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_190_relu"
  type: "ReLU"
  bottom: "res_3_190"
  top: "res_3_190"
}
layer {
  name: "res_stage_3_191_1"
  type: "Convolution"
  bottom: "res_3_190"
  top: "res_stage_3_191_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_191_1"
  type: "BatchNorm"
  bottom: "res_stage_3_191_1"
  top: "res_stage_3_191_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_191_1"  
  type: "Scale"
  bottom: "res_stage_3_191_1"
  top: "res_stage_3_191_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_191_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_191_1_top"
  top: "res_stage_3_191_1_top"
}
layer {
  name: "res_stage_3_191_2"
  type: "Convolution"
  bottom: "res_stage_3_191_1_top"
  top: "res_stage_3_191_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_191_2"
  type: "BatchNorm"
  bottom: "res_stage_3_191_2"
  top: "res_stage_3_191_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_191_2"  
  type: "Scale"
  bottom: "res_stage_3_191_2"
  top: "res_stage_3_191_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_191_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_191_2_top"
  top: "res_stage_3_191_2_top"
}
layer {
  name: "res_stage_3_191_3"
  type: "Convolution"
  bottom: "res_stage_3_191_2_top"
  top: "res_stage_3_191_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_191_3"
  type: "BatchNorm"
  bottom: "res_stage_3_191_3"
  top: "res_stage_3_191_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_191_3"  
  type: "Scale"
  bottom: "res_stage_3_191_3"
  top: "res_stage_3_191_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_191"
  type: "Eltwise"
  bottom: "res_3_190"
  bottom: "res_stage_3_191_3_top"
  top: "res_3_191"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_191_relu"
  type: "ReLU"
  bottom: "res_3_191"
  top: "res_3_191"
}
layer {
  name: "res_stage_3_192_1"
  type: "Convolution"
  bottom: "res_3_191"
  top: "res_stage_3_192_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_192_1"
  type: "BatchNorm"
  bottom: "res_stage_3_192_1"
  top: "res_stage_3_192_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_192_1"  
  type: "Scale"
  bottom: "res_stage_3_192_1"
  top: "res_stage_3_192_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_192_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_192_1_top"
  top: "res_stage_3_192_1_top"
}
layer {
  name: "res_stage_3_192_2"
  type: "Convolution"
  bottom: "res_stage_3_192_1_top"
  top: "res_stage_3_192_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_192_2"
  type: "BatchNorm"
  bottom: "res_stage_3_192_2"
  top: "res_stage_3_192_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_192_2"  
  type: "Scale"
  bottom: "res_stage_3_192_2"
  top: "res_stage_3_192_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_192_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_192_2_top"
  top: "res_stage_3_192_2_top"
}
layer {
  name: "res_stage_3_192_3"
  type: "Convolution"
  bottom: "res_stage_3_192_2_top"
  top: "res_stage_3_192_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_192_3"
  type: "BatchNorm"
  bottom: "res_stage_3_192_3"
  top: "res_stage_3_192_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_192_3"  
  type: "Scale"
  bottom: "res_stage_3_192_3"
  top: "res_stage_3_192_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_192"
  type: "Eltwise"
  bottom: "res_3_191"
  bottom: "res_stage_3_192_3_top"
  top: "res_3_192"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_192_relu"
  type: "ReLU"
  bottom: "res_3_192"
  top: "res_3_192"
}
layer {
  name: "res_stage_3_193_1"
  type: "Convolution"
  bottom: "res_3_192"
  top: "res_stage_3_193_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_193_1"
  type: "BatchNorm"
  bottom: "res_stage_3_193_1"
  top: "res_stage_3_193_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_193_1"  
  type: "Scale"
  bottom: "res_stage_3_193_1"
  top: "res_stage_3_193_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_193_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_193_1_top"
  top: "res_stage_3_193_1_top"
}
layer {
  name: "res_stage_3_193_2"
  type: "Convolution"
  bottom: "res_stage_3_193_1_top"
  top: "res_stage_3_193_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_193_2"
  type: "BatchNorm"
  bottom: "res_stage_3_193_2"
  top: "res_stage_3_193_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_193_2"  
  type: "Scale"
  bottom: "res_stage_3_193_2"
  top: "res_stage_3_193_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_193_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_193_2_top"
  top: "res_stage_3_193_2_top"
}
layer {
  name: "res_stage_3_193_3"
  type: "Convolution"
  bottom: "res_stage_3_193_2_top"
  top: "res_stage_3_193_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_193_3"
  type: "BatchNorm"
  bottom: "res_stage_3_193_3"
  top: "res_stage_3_193_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_193_3"  
  type: "Scale"
  bottom: "res_stage_3_193_3"
  top: "res_stage_3_193_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_193"
  type: "Eltwise"
  bottom: "res_3_192"
  bottom: "res_stage_3_193_3_top"
  top: "res_3_193"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_193_relu"
  type: "ReLU"
  bottom: "res_3_193"
  top: "res_3_193"
}
layer {
  name: "res_stage_3_194_1"
  type: "Convolution"
  bottom: "res_3_193"
  top: "res_stage_3_194_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_194_1"
  type: "BatchNorm"
  bottom: "res_stage_3_194_1"
  top: "res_stage_3_194_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_194_1"  
  type: "Scale"
  bottom: "res_stage_3_194_1"
  top: "res_stage_3_194_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_194_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_194_1_top"
  top: "res_stage_3_194_1_top"
}
layer {
  name: "res_stage_3_194_2"
  type: "Convolution"
  bottom: "res_stage_3_194_1_top"
  top: "res_stage_3_194_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_194_2"
  type: "BatchNorm"
  bottom: "res_stage_3_194_2"
  top: "res_stage_3_194_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_194_2"  
  type: "Scale"
  bottom: "res_stage_3_194_2"
  top: "res_stage_3_194_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_194_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_194_2_top"
  top: "res_stage_3_194_2_top"
}
layer {
  name: "res_stage_3_194_3"
  type: "Convolution"
  bottom: "res_stage_3_194_2_top"
  top: "res_stage_3_194_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_194_3"
  type: "BatchNorm"
  bottom: "res_stage_3_194_3"
  top: "res_stage_3_194_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_194_3"  
  type: "Scale"
  bottom: "res_stage_3_194_3"
  top: "res_stage_3_194_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_194"
  type: "Eltwise"
  bottom: "res_3_193"
  bottom: "res_stage_3_194_3_top"
  top: "res_3_194"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_194_relu"
  type: "ReLU"
  bottom: "res_3_194"
  top: "res_3_194"
}
layer {
  name: "res_stage_3_195_1"
  type: "Convolution"
  bottom: "res_3_194"
  top: "res_stage_3_195_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_195_1"
  type: "BatchNorm"
  bottom: "res_stage_3_195_1"
  top: "res_stage_3_195_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_195_1"  
  type: "Scale"
  bottom: "res_stage_3_195_1"
  top: "res_stage_3_195_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_195_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_195_1_top"
  top: "res_stage_3_195_1_top"
}
layer {
  name: "res_stage_3_195_2"
  type: "Convolution"
  bottom: "res_stage_3_195_1_top"
  top: "res_stage_3_195_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_195_2"
  type: "BatchNorm"
  bottom: "res_stage_3_195_2"
  top: "res_stage_3_195_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_195_2"  
  type: "Scale"
  bottom: "res_stage_3_195_2"
  top: "res_stage_3_195_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_195_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_195_2_top"
  top: "res_stage_3_195_2_top"
}
layer {
  name: "res_stage_3_195_3"
  type: "Convolution"
  bottom: "res_stage_3_195_2_top"
  top: "res_stage_3_195_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_195_3"
  type: "BatchNorm"
  bottom: "res_stage_3_195_3"
  top: "res_stage_3_195_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_195_3"  
  type: "Scale"
  bottom: "res_stage_3_195_3"
  top: "res_stage_3_195_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_195"
  type: "Eltwise"
  bottom: "res_3_194"
  bottom: "res_stage_3_195_3_top"
  top: "res_3_195"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_195_relu"
  type: "ReLU"
  bottom: "res_3_195"
  top: "res_3_195"
}
layer {
  name: "res_stage_3_196_1"
  type: "Convolution"
  bottom: "res_3_195"
  top: "res_stage_3_196_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_196_1"
  type: "BatchNorm"
  bottom: "res_stage_3_196_1"
  top: "res_stage_3_196_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_196_1"  
  type: "Scale"
  bottom: "res_stage_3_196_1"
  top: "res_stage_3_196_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_196_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_196_1_top"
  top: "res_stage_3_196_1_top"
}
layer {
  name: "res_stage_3_196_2"
  type: "Convolution"
  bottom: "res_stage_3_196_1_top"
  top: "res_stage_3_196_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_196_2"
  type: "BatchNorm"
  bottom: "res_stage_3_196_2"
  top: "res_stage_3_196_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_196_2"  
  type: "Scale"
  bottom: "res_stage_3_196_2"
  top: "res_stage_3_196_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_196_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_196_2_top"
  top: "res_stage_3_196_2_top"
}
layer {
  name: "res_stage_3_196_3"
  type: "Convolution"
  bottom: "res_stage_3_196_2_top"
  top: "res_stage_3_196_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_196_3"
  type: "BatchNorm"
  bottom: "res_stage_3_196_3"
  top: "res_stage_3_196_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_196_3"  
  type: "Scale"
  bottom: "res_stage_3_196_3"
  top: "res_stage_3_196_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_196"
  type: "Eltwise"
  bottom: "res_3_195"
  bottom: "res_stage_3_196_3_top"
  top: "res_3_196"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_196_relu"
  type: "ReLU"
  bottom: "res_3_196"
  top: "res_3_196"
}
layer {
  name: "res_stage_3_197_1"
  type: "Convolution"
  bottom: "res_3_196"
  top: "res_stage_3_197_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_197_1"
  type: "BatchNorm"
  bottom: "res_stage_3_197_1"
  top: "res_stage_3_197_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_197_1"  
  type: "Scale"
  bottom: "res_stage_3_197_1"
  top: "res_stage_3_197_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_197_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_197_1_top"
  top: "res_stage_3_197_1_top"
}
layer {
  name: "res_stage_3_197_2"
  type: "Convolution"
  bottom: "res_stage_3_197_1_top"
  top: "res_stage_3_197_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_197_2"
  type: "BatchNorm"
  bottom: "res_stage_3_197_2"
  top: "res_stage_3_197_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_197_2"  
  type: "Scale"
  bottom: "res_stage_3_197_2"
  top: "res_stage_3_197_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_197_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_197_2_top"
  top: "res_stage_3_197_2_top"
}
layer {
  name: "res_stage_3_197_3"
  type: "Convolution"
  bottom: "res_stage_3_197_2_top"
  top: "res_stage_3_197_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_197_3"
  type: "BatchNorm"
  bottom: "res_stage_3_197_3"
  top: "res_stage_3_197_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_197_3"  
  type: "Scale"
  bottom: "res_stage_3_197_3"
  top: "res_stage_3_197_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_197"
  type: "Eltwise"
  bottom: "res_3_196"
  bottom: "res_stage_3_197_3_top"
  top: "res_3_197"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_197_relu"
  type: "ReLU"
  bottom: "res_3_197"
  top: "res_3_197"
}
layer {
  name: "res_stage_3_198_1"
  type: "Convolution"
  bottom: "res_3_197"
  top: "res_stage_3_198_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_198_1"
  type: "BatchNorm"
  bottom: "res_stage_3_198_1"
  top: "res_stage_3_198_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_198_1"  
  type: "Scale"
  bottom: "res_stage_3_198_1"
  top: "res_stage_3_198_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_198_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_198_1_top"
  top: "res_stage_3_198_1_top"
}
layer {
  name: "res_stage_3_198_2"
  type: "Convolution"
  bottom: "res_stage_3_198_1_top"
  top: "res_stage_3_198_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_198_2"
  type: "BatchNorm"
  bottom: "res_stage_3_198_2"
  top: "res_stage_3_198_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_198_2"  
  type: "Scale"
  bottom: "res_stage_3_198_2"
  top: "res_stage_3_198_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_198_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_198_2_top"
  top: "res_stage_3_198_2_top"
}
layer {
  name: "res_stage_3_198_3"
  type: "Convolution"
  bottom: "res_stage_3_198_2_top"
  top: "res_stage_3_198_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_198_3"
  type: "BatchNorm"
  bottom: "res_stage_3_198_3"
  top: "res_stage_3_198_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_198_3"  
  type: "Scale"
  bottom: "res_stage_3_198_3"
  top: "res_stage_3_198_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_198"
  type: "Eltwise"
  bottom: "res_3_197"
  bottom: "res_stage_3_198_3_top"
  top: "res_3_198"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_198_relu"
  type: "ReLU"
  bottom: "res_3_198"
  top: "res_3_198"
}
layer {
  name: "res_stage_3_199_1"
  type: "Convolution"
  bottom: "res_3_198"
  top: "res_stage_3_199_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_199_1"
  type: "BatchNorm"
  bottom: "res_stage_3_199_1"
  top: "res_stage_3_199_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_199_1"  
  type: "Scale"
  bottom: "res_stage_3_199_1"
  top: "res_stage_3_199_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_199_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_199_1_top"
  top: "res_stage_3_199_1_top"
}
layer {
  name: "res_stage_3_199_2"
  type: "Convolution"
  bottom: "res_stage_3_199_1_top"
  top: "res_stage_3_199_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_199_2"
  type: "BatchNorm"
  bottom: "res_stage_3_199_2"
  top: "res_stage_3_199_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_199_2"  
  type: "Scale"
  bottom: "res_stage_3_199_2"
  top: "res_stage_3_199_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_199_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_199_2_top"
  top: "res_stage_3_199_2_top"
}
layer {
  name: "res_stage_3_199_3"
  type: "Convolution"
  bottom: "res_stage_3_199_2_top"
  top: "res_stage_3_199_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_199_3"
  type: "BatchNorm"
  bottom: "res_stage_3_199_3"
  top: "res_stage_3_199_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_199_3"  
  type: "Scale"
  bottom: "res_stage_3_199_3"
  top: "res_stage_3_199_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_199"
  type: "Eltwise"
  bottom: "res_3_198"
  bottom: "res_stage_3_199_3_top"
  top: "res_3_199"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_199_relu"
  type: "ReLU"
  bottom: "res_3_199"
  top: "res_3_199"
}
layer {
  name: "res_stage_3_200_1"
  type: "Convolution"
  bottom: "res_3_199"
  top: "res_stage_3_200_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_200_1"
  type: "BatchNorm"
  bottom: "res_stage_3_200_1"
  top: "res_stage_3_200_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_200_1"  
  type: "Scale"
  bottom: "res_stage_3_200_1"
  top: "res_stage_3_200_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_200_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_200_1_top"
  top: "res_stage_3_200_1_top"
}
layer {
  name: "res_stage_3_200_2"
  type: "Convolution"
  bottom: "res_stage_3_200_1_top"
  top: "res_stage_3_200_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_200_2"
  type: "BatchNorm"
  bottom: "res_stage_3_200_2"
  top: "res_stage_3_200_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_200_2"  
  type: "Scale"
  bottom: "res_stage_3_200_2"
  top: "res_stage_3_200_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_200_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_200_2_top"
  top: "res_stage_3_200_2_top"
}
layer {
  name: "res_stage_3_200_3"
  type: "Convolution"
  bottom: "res_stage_3_200_2_top"
  top: "res_stage_3_200_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_200_3"
  type: "BatchNorm"
  bottom: "res_stage_3_200_3"
  top: "res_stage_3_200_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_200_3"  
  type: "Scale"
  bottom: "res_stage_3_200_3"
  top: "res_stage_3_200_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_200"
  type: "Eltwise"
  bottom: "res_3_199"
  bottom: "res_stage_3_200_3_top"
  top: "res_3_200"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_200_relu"
  type: "ReLU"
  bottom: "res_3_200"
  top: "res_3_200"
}
layer {
  name: "res_stage_3_201_1"
  type: "Convolution"
  bottom: "res_3_200"
  top: "res_stage_3_201_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_201_1"
  type: "BatchNorm"
  bottom: "res_stage_3_201_1"
  top: "res_stage_3_201_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_201_1"  
  type: "Scale"
  bottom: "res_stage_3_201_1"
  top: "res_stage_3_201_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_201_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_201_1_top"
  top: "res_stage_3_201_1_top"
}
layer {
  name: "res_stage_3_201_2"
  type: "Convolution"
  bottom: "res_stage_3_201_1_top"
  top: "res_stage_3_201_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_201_2"
  type: "BatchNorm"
  bottom: "res_stage_3_201_2"
  top: "res_stage_3_201_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_201_2"  
  type: "Scale"
  bottom: "res_stage_3_201_2"
  top: "res_stage_3_201_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_201_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_201_2_top"
  top: "res_stage_3_201_2_top"
}
layer {
  name: "res_stage_3_201_3"
  type: "Convolution"
  bottom: "res_stage_3_201_2_top"
  top: "res_stage_3_201_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_201_3"
  type: "BatchNorm"
  bottom: "res_stage_3_201_3"
  top: "res_stage_3_201_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_201_3"  
  type: "Scale"
  bottom: "res_stage_3_201_3"
  top: "res_stage_3_201_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_201"
  type: "Eltwise"
  bottom: "res_3_200"
  bottom: "res_stage_3_201_3_top"
  top: "res_3_201"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_201_relu"
  type: "ReLU"
  bottom: "res_3_201"
  top: "res_3_201"
}
layer {
  name: "res_stage_3_202_1"
  type: "Convolution"
  bottom: "res_3_201"
  top: "res_stage_3_202_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_202_1"
  type: "BatchNorm"
  bottom: "res_stage_3_202_1"
  top: "res_stage_3_202_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_202_1"  
  type: "Scale"
  bottom: "res_stage_3_202_1"
  top: "res_stage_3_202_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_202_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_202_1_top"
  top: "res_stage_3_202_1_top"
}
layer {
  name: "res_stage_3_202_2"
  type: "Convolution"
  bottom: "res_stage_3_202_1_top"
  top: "res_stage_3_202_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_202_2"
  type: "BatchNorm"
  bottom: "res_stage_3_202_2"
  top: "res_stage_3_202_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_202_2"  
  type: "Scale"
  bottom: "res_stage_3_202_2"
  top: "res_stage_3_202_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_202_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_202_2_top"
  top: "res_stage_3_202_2_top"
}
layer {
  name: "res_stage_3_202_3"
  type: "Convolution"
  bottom: "res_stage_3_202_2_top"
  top: "res_stage_3_202_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_202_3"
  type: "BatchNorm"
  bottom: "res_stage_3_202_3"
  top: "res_stage_3_202_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_202_3"  
  type: "Scale"
  bottom: "res_stage_3_202_3"
  top: "res_stage_3_202_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_202"
  type: "Eltwise"
  bottom: "res_3_201"
  bottom: "res_stage_3_202_3_top"
  top: "res_3_202"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_202_relu"
  type: "ReLU"
  bottom: "res_3_202"
  top: "res_3_202"
}
layer {
  name: "res_stage_3_203_1"
  type: "Convolution"
  bottom: "res_3_202"
  top: "res_stage_3_203_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_203_1"
  type: "BatchNorm"
  bottom: "res_stage_3_203_1"
  top: "res_stage_3_203_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_203_1"  
  type: "Scale"
  bottom: "res_stage_3_203_1"
  top: "res_stage_3_203_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_203_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_203_1_top"
  top: "res_stage_3_203_1_top"
}
layer {
  name: "res_stage_3_203_2"
  type: "Convolution"
  bottom: "res_stage_3_203_1_top"
  top: "res_stage_3_203_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_203_2"
  type: "BatchNorm"
  bottom: "res_stage_3_203_2"
  top: "res_stage_3_203_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_203_2"  
  type: "Scale"
  bottom: "res_stage_3_203_2"
  top: "res_stage_3_203_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_203_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_203_2_top"
  top: "res_stage_3_203_2_top"
}
layer {
  name: "res_stage_3_203_3"
  type: "Convolution"
  bottom: "res_stage_3_203_2_top"
  top: "res_stage_3_203_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_203_3"
  type: "BatchNorm"
  bottom: "res_stage_3_203_3"
  top: "res_stage_3_203_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_203_3"  
  type: "Scale"
  bottom: "res_stage_3_203_3"
  top: "res_stage_3_203_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_203"
  type: "Eltwise"
  bottom: "res_3_202"
  bottom: "res_stage_3_203_3_top"
  top: "res_3_203"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_203_relu"
  type: "ReLU"
  bottom: "res_3_203"
  top: "res_3_203"
}
layer {
  name: "res_stage_3_204_1"
  type: "Convolution"
  bottom: "res_3_203"
  top: "res_stage_3_204_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_204_1"
  type: "BatchNorm"
  bottom: "res_stage_3_204_1"
  top: "res_stage_3_204_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_204_1"  
  type: "Scale"
  bottom: "res_stage_3_204_1"
  top: "res_stage_3_204_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_204_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_204_1_top"
  top: "res_stage_3_204_1_top"
}
layer {
  name: "res_stage_3_204_2"
  type: "Convolution"
  bottom: "res_stage_3_204_1_top"
  top: "res_stage_3_204_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_204_2"
  type: "BatchNorm"
  bottom: "res_stage_3_204_2"
  top: "res_stage_3_204_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_204_2"  
  type: "Scale"
  bottom: "res_stage_3_204_2"
  top: "res_stage_3_204_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_204_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_204_2_top"
  top: "res_stage_3_204_2_top"
}
layer {
  name: "res_stage_3_204_3"
  type: "Convolution"
  bottom: "res_stage_3_204_2_top"
  top: "res_stage_3_204_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_204_3"
  type: "BatchNorm"
  bottom: "res_stage_3_204_3"
  top: "res_stage_3_204_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_204_3"  
  type: "Scale"
  bottom: "res_stage_3_204_3"
  top: "res_stage_3_204_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_204"
  type: "Eltwise"
  bottom: "res_3_203"
  bottom: "res_stage_3_204_3_top"
  top: "res_3_204"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_204_relu"
  type: "ReLU"
  bottom: "res_3_204"
  top: "res_3_204"
}
layer {
  name: "res_stage_3_205_1"
  type: "Convolution"
  bottom: "res_3_204"
  top: "res_stage_3_205_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_205_1"
  type: "BatchNorm"
  bottom: "res_stage_3_205_1"
  top: "res_stage_3_205_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_205_1"  
  type: "Scale"
  bottom: "res_stage_3_205_1"
  top: "res_stage_3_205_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_205_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_205_1_top"
  top: "res_stage_3_205_1_top"
}
layer {
  name: "res_stage_3_205_2"
  type: "Convolution"
  bottom: "res_stage_3_205_1_top"
  top: "res_stage_3_205_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_205_2"
  type: "BatchNorm"
  bottom: "res_stage_3_205_2"
  top: "res_stage_3_205_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_205_2"  
  type: "Scale"
  bottom: "res_stage_3_205_2"
  top: "res_stage_3_205_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_205_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_205_2_top"
  top: "res_stage_3_205_2_top"
}
layer {
  name: "res_stage_3_205_3"
  type: "Convolution"
  bottom: "res_stage_3_205_2_top"
  top: "res_stage_3_205_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_205_3"
  type: "BatchNorm"
  bottom: "res_stage_3_205_3"
  top: "res_stage_3_205_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_205_3"  
  type: "Scale"
  bottom: "res_stage_3_205_3"
  top: "res_stage_3_205_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_205"
  type: "Eltwise"
  bottom: "res_3_204"
  bottom: "res_stage_3_205_3_top"
  top: "res_3_205"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_205_relu"
  type: "ReLU"
  bottom: "res_3_205"
  top: "res_3_205"
}
layer {
  name: "res_stage_3_206_1"
  type: "Convolution"
  bottom: "res_3_205"
  top: "res_stage_3_206_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_206_1"
  type: "BatchNorm"
  bottom: "res_stage_3_206_1"
  top: "res_stage_3_206_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_206_1"  
  type: "Scale"
  bottom: "res_stage_3_206_1"
  top: "res_stage_3_206_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_206_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_206_1_top"
  top: "res_stage_3_206_1_top"
}
layer {
  name: "res_stage_3_206_2"
  type: "Convolution"
  bottom: "res_stage_3_206_1_top"
  top: "res_stage_3_206_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_206_2"
  type: "BatchNorm"
  bottom: "res_stage_3_206_2"
  top: "res_stage_3_206_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_206_2"  
  type: "Scale"
  bottom: "res_stage_3_206_2"
  top: "res_stage_3_206_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_206_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_206_2_top"
  top: "res_stage_3_206_2_top"
}
layer {
  name: "res_stage_3_206_3"
  type: "Convolution"
  bottom: "res_stage_3_206_2_top"
  top: "res_stage_3_206_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_206_3"
  type: "BatchNorm"
  bottom: "res_stage_3_206_3"
  top: "res_stage_3_206_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_206_3"  
  type: "Scale"
  bottom: "res_stage_3_206_3"
  top: "res_stage_3_206_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_206"
  type: "Eltwise"
  bottom: "res_3_205"
  bottom: "res_stage_3_206_3_top"
  top: "res_3_206"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_206_relu"
  type: "ReLU"
  bottom: "res_3_206"
  top: "res_3_206"
}
layer {
  name: "res_stage_3_207_1"
  type: "Convolution"
  bottom: "res_3_206"
  top: "res_stage_3_207_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_207_1"
  type: "BatchNorm"
  bottom: "res_stage_3_207_1"
  top: "res_stage_3_207_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_207_1"  
  type: "Scale"
  bottom: "res_stage_3_207_1"
  top: "res_stage_3_207_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_207_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_207_1_top"
  top: "res_stage_3_207_1_top"
}
layer {
  name: "res_stage_3_207_2"
  type: "Convolution"
  bottom: "res_stage_3_207_1_top"
  top: "res_stage_3_207_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_207_2"
  type: "BatchNorm"
  bottom: "res_stage_3_207_2"
  top: "res_stage_3_207_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_207_2"  
  type: "Scale"
  bottom: "res_stage_3_207_2"
  top: "res_stage_3_207_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_207_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_207_2_top"
  top: "res_stage_3_207_2_top"
}
layer {
  name: "res_stage_3_207_3"
  type: "Convolution"
  bottom: "res_stage_3_207_2_top"
  top: "res_stage_3_207_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_207_3"
  type: "BatchNorm"
  bottom: "res_stage_3_207_3"
  top: "res_stage_3_207_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_207_3"  
  type: "Scale"
  bottom: "res_stage_3_207_3"
  top: "res_stage_3_207_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_207"
  type: "Eltwise"
  bottom: "res_3_206"
  bottom: "res_stage_3_207_3_top"
  top: "res_3_207"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_207_relu"
  type: "ReLU"
  bottom: "res_3_207"
  top: "res_3_207"
}
layer {
  name: "res_stage_3_208_1"
  type: "Convolution"
  bottom: "res_3_207"
  top: "res_stage_3_208_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_208_1"
  type: "BatchNorm"
  bottom: "res_stage_3_208_1"
  top: "res_stage_3_208_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_208_1"  
  type: "Scale"
  bottom: "res_stage_3_208_1"
  top: "res_stage_3_208_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_208_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_208_1_top"
  top: "res_stage_3_208_1_top"
}
layer {
  name: "res_stage_3_208_2"
  type: "Convolution"
  bottom: "res_stage_3_208_1_top"
  top: "res_stage_3_208_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_208_2"
  type: "BatchNorm"
  bottom: "res_stage_3_208_2"
  top: "res_stage_3_208_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_208_2"  
  type: "Scale"
  bottom: "res_stage_3_208_2"
  top: "res_stage_3_208_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_208_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_208_2_top"
  top: "res_stage_3_208_2_top"
}
layer {
  name: "res_stage_3_208_3"
  type: "Convolution"
  bottom: "res_stage_3_208_2_top"
  top: "res_stage_3_208_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_208_3"
  type: "BatchNorm"
  bottom: "res_stage_3_208_3"
  top: "res_stage_3_208_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_208_3"  
  type: "Scale"
  bottom: "res_stage_3_208_3"
  top: "res_stage_3_208_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_208"
  type: "Eltwise"
  bottom: "res_3_207"
  bottom: "res_stage_3_208_3_top"
  top: "res_3_208"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_208_relu"
  type: "ReLU"
  bottom: "res_3_208"
  top: "res_3_208"
}
layer {
  name: "res_stage_3_209_1"
  type: "Convolution"
  bottom: "res_3_208"
  top: "res_stage_3_209_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_209_1"
  type: "BatchNorm"
  bottom: "res_stage_3_209_1"
  top: "res_stage_3_209_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_209_1"  
  type: "Scale"
  bottom: "res_stage_3_209_1"
  top: "res_stage_3_209_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_209_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_209_1_top"
  top: "res_stage_3_209_1_top"
}
layer {
  name: "res_stage_3_209_2"
  type: "Convolution"
  bottom: "res_stage_3_209_1_top"
  top: "res_stage_3_209_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_209_2"
  type: "BatchNorm"
  bottom: "res_stage_3_209_2"
  top: "res_stage_3_209_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_209_2"  
  type: "Scale"
  bottom: "res_stage_3_209_2"
  top: "res_stage_3_209_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_209_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_209_2_top"
  top: "res_stage_3_209_2_top"
}
layer {
  name: "res_stage_3_209_3"
  type: "Convolution"
  bottom: "res_stage_3_209_2_top"
  top: "res_stage_3_209_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_209_3"
  type: "BatchNorm"
  bottom: "res_stage_3_209_3"
  top: "res_stage_3_209_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_209_3"  
  type: "Scale"
  bottom: "res_stage_3_209_3"
  top: "res_stage_3_209_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_209"
  type: "Eltwise"
  bottom: "res_3_208"
  bottom: "res_stage_3_209_3_top"
  top: "res_3_209"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_209_relu"
  type: "ReLU"
  bottom: "res_3_209"
  top: "res_3_209"
}
layer {
  name: "res_stage_3_210_1"
  type: "Convolution"
  bottom: "res_3_209"
  top: "res_stage_3_210_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_210_1"
  type: "BatchNorm"
  bottom: "res_stage_3_210_1"
  top: "res_stage_3_210_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_210_1"  
  type: "Scale"
  bottom: "res_stage_3_210_1"
  top: "res_stage_3_210_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_210_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_210_1_top"
  top: "res_stage_3_210_1_top"
}
layer {
  name: "res_stage_3_210_2"
  type: "Convolution"
  bottom: "res_stage_3_210_1_top"
  top: "res_stage_3_210_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_210_2"
  type: "BatchNorm"
  bottom: "res_stage_3_210_2"
  top: "res_stage_3_210_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_210_2"  
  type: "Scale"
  bottom: "res_stage_3_210_2"
  top: "res_stage_3_210_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_210_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_210_2_top"
  top: "res_stage_3_210_2_top"
}
layer {
  name: "res_stage_3_210_3"
  type: "Convolution"
  bottom: "res_stage_3_210_2_top"
  top: "res_stage_3_210_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_210_3"
  type: "BatchNorm"
  bottom: "res_stage_3_210_3"
  top: "res_stage_3_210_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_210_3"  
  type: "Scale"
  bottom: "res_stage_3_210_3"
  top: "res_stage_3_210_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_210"
  type: "Eltwise"
  bottom: "res_3_209"
  bottom: "res_stage_3_210_3_top"
  top: "res_3_210"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_210_relu"
  type: "ReLU"
  bottom: "res_3_210"
  top: "res_3_210"
}
layer {
  name: "res_stage_3_211_1"
  type: "Convolution"
  bottom: "res_3_210"
  top: "res_stage_3_211_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_211_1"
  type: "BatchNorm"
  bottom: "res_stage_3_211_1"
  top: "res_stage_3_211_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_211_1"  
  type: "Scale"
  bottom: "res_stage_3_211_1"
  top: "res_stage_3_211_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_211_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_211_1_top"
  top: "res_stage_3_211_1_top"
}
layer {
  name: "res_stage_3_211_2"
  type: "Convolution"
  bottom: "res_stage_3_211_1_top"
  top: "res_stage_3_211_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_211_2"
  type: "BatchNorm"
  bottom: "res_stage_3_211_2"
  top: "res_stage_3_211_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_211_2"  
  type: "Scale"
  bottom: "res_stage_3_211_2"
  top: "res_stage_3_211_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_211_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_211_2_top"
  top: "res_stage_3_211_2_top"
}
layer {
  name: "res_stage_3_211_3"
  type: "Convolution"
  bottom: "res_stage_3_211_2_top"
  top: "res_stage_3_211_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_211_3"
  type: "BatchNorm"
  bottom: "res_stage_3_211_3"
  top: "res_stage_3_211_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_211_3"  
  type: "Scale"
  bottom: "res_stage_3_211_3"
  top: "res_stage_3_211_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_211"
  type: "Eltwise"
  bottom: "res_3_210"
  bottom: "res_stage_3_211_3_top"
  top: "res_3_211"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_211_relu"
  type: "ReLU"
  bottom: "res_3_211"
  top: "res_3_211"
}
layer {
  name: "res_stage_3_212_1"
  type: "Convolution"
  bottom: "res_3_211"
  top: "res_stage_3_212_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_212_1"
  type: "BatchNorm"
  bottom: "res_stage_3_212_1"
  top: "res_stage_3_212_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_212_1"  
  type: "Scale"
  bottom: "res_stage_3_212_1"
  top: "res_stage_3_212_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_212_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_212_1_top"
  top: "res_stage_3_212_1_top"
}
layer {
  name: "res_stage_3_212_2"
  type: "Convolution"
  bottom: "res_stage_3_212_1_top"
  top: "res_stage_3_212_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_212_2"
  type: "BatchNorm"
  bottom: "res_stage_3_212_2"
  top: "res_stage_3_212_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_212_2"  
  type: "Scale"
  bottom: "res_stage_3_212_2"
  top: "res_stage_3_212_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_212_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_212_2_top"
  top: "res_stage_3_212_2_top"
}
layer {
  name: "res_stage_3_212_3"
  type: "Convolution"
  bottom: "res_stage_3_212_2_top"
  top: "res_stage_3_212_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_212_3"
  type: "BatchNorm"
  bottom: "res_stage_3_212_3"
  top: "res_stage_3_212_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_212_3"  
  type: "Scale"
  bottom: "res_stage_3_212_3"
  top: "res_stage_3_212_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_212"
  type: "Eltwise"
  bottom: "res_3_211"
  bottom: "res_stage_3_212_3_top"
  top: "res_3_212"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_212_relu"
  type: "ReLU"
  bottom: "res_3_212"
  top: "res_3_212"
}
layer {
  name: "res_stage_3_213_1"
  type: "Convolution"
  bottom: "res_3_212"
  top: "res_stage_3_213_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_213_1"
  type: "BatchNorm"
  bottom: "res_stage_3_213_1"
  top: "res_stage_3_213_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_213_1"  
  type: "Scale"
  bottom: "res_stage_3_213_1"
  top: "res_stage_3_213_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_213_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_213_1_top"
  top: "res_stage_3_213_1_top"
}
layer {
  name: "res_stage_3_213_2"
  type: "Convolution"
  bottom: "res_stage_3_213_1_top"
  top: "res_stage_3_213_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_213_2"
  type: "BatchNorm"
  bottom: "res_stage_3_213_2"
  top: "res_stage_3_213_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_213_2"  
  type: "Scale"
  bottom: "res_stage_3_213_2"
  top: "res_stage_3_213_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_213_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_213_2_top"
  top: "res_stage_3_213_2_top"
}
layer {
  name: "res_stage_3_213_3"
  type: "Convolution"
  bottom: "res_stage_3_213_2_top"
  top: "res_stage_3_213_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_213_3"
  type: "BatchNorm"
  bottom: "res_stage_3_213_3"
  top: "res_stage_3_213_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_213_3"  
  type: "Scale"
  bottom: "res_stage_3_213_3"
  top: "res_stage_3_213_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_213"
  type: "Eltwise"
  bottom: "res_3_212"
  bottom: "res_stage_3_213_3_top"
  top: "res_3_213"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_213_relu"
  type: "ReLU"
  bottom: "res_3_213"
  top: "res_3_213"
}
layer {
  name: "res_stage_3_214_1"
  type: "Convolution"
  bottom: "res_3_213"
  top: "res_stage_3_214_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_214_1"
  type: "BatchNorm"
  bottom: "res_stage_3_214_1"
  top: "res_stage_3_214_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_214_1"  
  type: "Scale"
  bottom: "res_stage_3_214_1"
  top: "res_stage_3_214_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_214_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_214_1_top"
  top: "res_stage_3_214_1_top"
}
layer {
  name: "res_stage_3_214_2"
  type: "Convolution"
  bottom: "res_stage_3_214_1_top"
  top: "res_stage_3_214_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_214_2"
  type: "BatchNorm"
  bottom: "res_stage_3_214_2"
  top: "res_stage_3_214_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_214_2"  
  type: "Scale"
  bottom: "res_stage_3_214_2"
  top: "res_stage_3_214_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_214_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_214_2_top"
  top: "res_stage_3_214_2_top"
}
layer {
  name: "res_stage_3_214_3"
  type: "Convolution"
  bottom: "res_stage_3_214_2_top"
  top: "res_stage_3_214_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_214_3"
  type: "BatchNorm"
  bottom: "res_stage_3_214_3"
  top: "res_stage_3_214_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_214_3"  
  type: "Scale"
  bottom: "res_stage_3_214_3"
  top: "res_stage_3_214_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_214"
  type: "Eltwise"
  bottom: "res_3_213"
  bottom: "res_stage_3_214_3_top"
  top: "res_3_214"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_214_relu"
  type: "ReLU"
  bottom: "res_3_214"
  top: "res_3_214"
}
layer {
  name: "res_stage_3_215_1"
  type: "Convolution"
  bottom: "res_3_214"
  top: "res_stage_3_215_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_215_1"
  type: "BatchNorm"
  bottom: "res_stage_3_215_1"
  top: "res_stage_3_215_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_215_1"  
  type: "Scale"
  bottom: "res_stage_3_215_1"
  top: "res_stage_3_215_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_215_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_215_1_top"
  top: "res_stage_3_215_1_top"
}
layer {
  name: "res_stage_3_215_2"
  type: "Convolution"
  bottom: "res_stage_3_215_1_top"
  top: "res_stage_3_215_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_215_2"
  type: "BatchNorm"
  bottom: "res_stage_3_215_2"
  top: "res_stage_3_215_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_215_2"  
  type: "Scale"
  bottom: "res_stage_3_215_2"
  top: "res_stage_3_215_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_215_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_215_2_top"
  top: "res_stage_3_215_2_top"
}
layer {
  name: "res_stage_3_215_3"
  type: "Convolution"
  bottom: "res_stage_3_215_2_top"
  top: "res_stage_3_215_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_215_3"
  type: "BatchNorm"
  bottom: "res_stage_3_215_3"
  top: "res_stage_3_215_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_215_3"  
  type: "Scale"
  bottom: "res_stage_3_215_3"
  top: "res_stage_3_215_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_215"
  type: "Eltwise"
  bottom: "res_3_214"
  bottom: "res_stage_3_215_3_top"
  top: "res_3_215"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_215_relu"
  type: "ReLU"
  bottom: "res_3_215"
  top: "res_3_215"
}
layer {
  name: "res_stage_3_216_1"
  type: "Convolution"
  bottom: "res_3_215"
  top: "res_stage_3_216_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_216_1"
  type: "BatchNorm"
  bottom: "res_stage_3_216_1"
  top: "res_stage_3_216_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_216_1"  
  type: "Scale"
  bottom: "res_stage_3_216_1"
  top: "res_stage_3_216_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_216_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_216_1_top"
  top: "res_stage_3_216_1_top"
}
layer {
  name: "res_stage_3_216_2"
  type: "Convolution"
  bottom: "res_stage_3_216_1_top"
  top: "res_stage_3_216_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_216_2"
  type: "BatchNorm"
  bottom: "res_stage_3_216_2"
  top: "res_stage_3_216_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_216_2"  
  type: "Scale"
  bottom: "res_stage_3_216_2"
  top: "res_stage_3_216_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_216_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_216_2_top"
  top: "res_stage_3_216_2_top"
}
layer {
  name: "res_stage_3_216_3"
  type: "Convolution"
  bottom: "res_stage_3_216_2_top"
  top: "res_stage_3_216_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_216_3"
  type: "BatchNorm"
  bottom: "res_stage_3_216_3"
  top: "res_stage_3_216_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_216_3"  
  type: "Scale"
  bottom: "res_stage_3_216_3"
  top: "res_stage_3_216_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_216"
  type: "Eltwise"
  bottom: "res_3_215"
  bottom: "res_stage_3_216_3_top"
  top: "res_3_216"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_216_relu"
  type: "ReLU"
  bottom: "res_3_216"
  top: "res_3_216"
}
layer {
  name: "res_stage_3_217_1"
  type: "Convolution"
  bottom: "res_3_216"
  top: "res_stage_3_217_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_217_1"
  type: "BatchNorm"
  bottom: "res_stage_3_217_1"
  top: "res_stage_3_217_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_217_1"  
  type: "Scale"
  bottom: "res_stage_3_217_1"
  top: "res_stage_3_217_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_217_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_217_1_top"
  top: "res_stage_3_217_1_top"
}
layer {
  name: "res_stage_3_217_2"
  type: "Convolution"
  bottom: "res_stage_3_217_1_top"
  top: "res_stage_3_217_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_217_2"
  type: "BatchNorm"
  bottom: "res_stage_3_217_2"
  top: "res_stage_3_217_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_217_2"  
  type: "Scale"
  bottom: "res_stage_3_217_2"
  top: "res_stage_3_217_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_217_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_217_2_top"
  top: "res_stage_3_217_2_top"
}
layer {
  name: "res_stage_3_217_3"
  type: "Convolution"
  bottom: "res_stage_3_217_2_top"
  top: "res_stage_3_217_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_217_3"
  type: "BatchNorm"
  bottom: "res_stage_3_217_3"
  top: "res_stage_3_217_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_217_3"  
  type: "Scale"
  bottom: "res_stage_3_217_3"
  top: "res_stage_3_217_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_217"
  type: "Eltwise"
  bottom: "res_3_216"
  bottom: "res_stage_3_217_3_top"
  top: "res_3_217"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_217_relu"
  type: "ReLU"
  bottom: "res_3_217"
  top: "res_3_217"
}
layer {
  name: "res_stage_3_218_1"
  type: "Convolution"
  bottom: "res_3_217"
  top: "res_stage_3_218_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_218_1"
  type: "BatchNorm"
  bottom: "res_stage_3_218_1"
  top: "res_stage_3_218_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_218_1"  
  type: "Scale"
  bottom: "res_stage_3_218_1"
  top: "res_stage_3_218_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_218_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_218_1_top"
  top: "res_stage_3_218_1_top"
}
layer {
  name: "res_stage_3_218_2"
  type: "Convolution"
  bottom: "res_stage_3_218_1_top"
  top: "res_stage_3_218_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_218_2"
  type: "BatchNorm"
  bottom: "res_stage_3_218_2"
  top: "res_stage_3_218_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_218_2"  
  type: "Scale"
  bottom: "res_stage_3_218_2"
  top: "res_stage_3_218_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_218_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_218_2_top"
  top: "res_stage_3_218_2_top"
}
layer {
  name: "res_stage_3_218_3"
  type: "Convolution"
  bottom: "res_stage_3_218_2_top"
  top: "res_stage_3_218_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_218_3"
  type: "BatchNorm"
  bottom: "res_stage_3_218_3"
  top: "res_stage_3_218_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_218_3"  
  type: "Scale"
  bottom: "res_stage_3_218_3"
  top: "res_stage_3_218_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_218"
  type: "Eltwise"
  bottom: "res_3_217"
  bottom: "res_stage_3_218_3_top"
  top: "res_3_218"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_218_relu"
  type: "ReLU"
  bottom: "res_3_218"
  top: "res_3_218"
}
layer {
  name: "res_stage_3_219_1"
  type: "Convolution"
  bottom: "res_3_218"
  top: "res_stage_3_219_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_219_1"
  type: "BatchNorm"
  bottom: "res_stage_3_219_1"
  top: "res_stage_3_219_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_219_1"  
  type: "Scale"
  bottom: "res_stage_3_219_1"
  top: "res_stage_3_219_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_219_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_219_1_top"
  top: "res_stage_3_219_1_top"
}
layer {
  name: "res_stage_3_219_2"
  type: "Convolution"
  bottom: "res_stage_3_219_1_top"
  top: "res_stage_3_219_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_219_2"
  type: "BatchNorm"
  bottom: "res_stage_3_219_2"
  top: "res_stage_3_219_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_219_2"  
  type: "Scale"
  bottom: "res_stage_3_219_2"
  top: "res_stage_3_219_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_219_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_219_2_top"
  top: "res_stage_3_219_2_top"
}
layer {
  name: "res_stage_3_219_3"
  type: "Convolution"
  bottom: "res_stage_3_219_2_top"
  top: "res_stage_3_219_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_219_3"
  type: "BatchNorm"
  bottom: "res_stage_3_219_3"
  top: "res_stage_3_219_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_219_3"  
  type: "Scale"
  bottom: "res_stage_3_219_3"
  top: "res_stage_3_219_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_219"
  type: "Eltwise"
  bottom: "res_3_218"
  bottom: "res_stage_3_219_3_top"
  top: "res_3_219"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_219_relu"
  type: "ReLU"
  bottom: "res_3_219"
  top: "res_3_219"
}
layer {
  name: "res_stage_3_220_1"
  type: "Convolution"
  bottom: "res_3_219"
  top: "res_stage_3_220_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_220_1"
  type: "BatchNorm"
  bottom: "res_stage_3_220_1"
  top: "res_stage_3_220_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_220_1"  
  type: "Scale"
  bottom: "res_stage_3_220_1"
  top: "res_stage_3_220_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_220_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_220_1_top"
  top: "res_stage_3_220_1_top"
}
layer {
  name: "res_stage_3_220_2"
  type: "Convolution"
  bottom: "res_stage_3_220_1_top"
  top: "res_stage_3_220_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_220_2"
  type: "BatchNorm"
  bottom: "res_stage_3_220_2"
  top: "res_stage_3_220_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_220_2"  
  type: "Scale"
  bottom: "res_stage_3_220_2"
  top: "res_stage_3_220_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_220_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_220_2_top"
  top: "res_stage_3_220_2_top"
}
layer {
  name: "res_stage_3_220_3"
  type: "Convolution"
  bottom: "res_stage_3_220_2_top"
  top: "res_stage_3_220_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_220_3"
  type: "BatchNorm"
  bottom: "res_stage_3_220_3"
  top: "res_stage_3_220_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_220_3"  
  type: "Scale"
  bottom: "res_stage_3_220_3"
  top: "res_stage_3_220_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_220"
  type: "Eltwise"
  bottom: "res_3_219"
  bottom: "res_stage_3_220_3_top"
  top: "res_3_220"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_220_relu"
  type: "ReLU"
  bottom: "res_3_220"
  top: "res_3_220"
}
layer {
  name: "res_stage_3_221_1"
  type: "Convolution"
  bottom: "res_3_220"
  top: "res_stage_3_221_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_221_1"
  type: "BatchNorm"
  bottom: "res_stage_3_221_1"
  top: "res_stage_3_221_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_221_1"  
  type: "Scale"
  bottom: "res_stage_3_221_1"
  top: "res_stage_3_221_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_221_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_221_1_top"
  top: "res_stage_3_221_1_top"
}
layer {
  name: "res_stage_3_221_2"
  type: "Convolution"
  bottom: "res_stage_3_221_1_top"
  top: "res_stage_3_221_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_221_2"
  type: "BatchNorm"
  bottom: "res_stage_3_221_2"
  top: "res_stage_3_221_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_221_2"  
  type: "Scale"
  bottom: "res_stage_3_221_2"
  top: "res_stage_3_221_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_221_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_221_2_top"
  top: "res_stage_3_221_2_top"
}
layer {
  name: "res_stage_3_221_3"
  type: "Convolution"
  bottom: "res_stage_3_221_2_top"
  top: "res_stage_3_221_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_221_3"
  type: "BatchNorm"
  bottom: "res_stage_3_221_3"
  top: "res_stage_3_221_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_221_3"  
  type: "Scale"
  bottom: "res_stage_3_221_3"
  top: "res_stage_3_221_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_221"
  type: "Eltwise"
  bottom: "res_3_220"
  bottom: "res_stage_3_221_3_top"
  top: "res_3_221"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_221_relu"
  type: "ReLU"
  bottom: "res_3_221"
  top: "res_3_221"
}
layer {
  name: "res_stage_3_222_1"
  type: "Convolution"
  bottom: "res_3_221"
  top: "res_stage_3_222_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_222_1"
  type: "BatchNorm"
  bottom: "res_stage_3_222_1"
  top: "res_stage_3_222_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_222_1"  
  type: "Scale"
  bottom: "res_stage_3_222_1"
  top: "res_stage_3_222_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_222_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_222_1_top"
  top: "res_stage_3_222_1_top"
}
layer {
  name: "res_stage_3_222_2"
  type: "Convolution"
  bottom: "res_stage_3_222_1_top"
  top: "res_stage_3_222_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_222_2"
  type: "BatchNorm"
  bottom: "res_stage_3_222_2"
  top: "res_stage_3_222_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_222_2"  
  type: "Scale"
  bottom: "res_stage_3_222_2"
  top: "res_stage_3_222_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_222_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_222_2_top"
  top: "res_stage_3_222_2_top"
}
layer {
  name: "res_stage_3_222_3"
  type: "Convolution"
  bottom: "res_stage_3_222_2_top"
  top: "res_stage_3_222_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_222_3"
  type: "BatchNorm"
  bottom: "res_stage_3_222_3"
  top: "res_stage_3_222_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_222_3"  
  type: "Scale"
  bottom: "res_stage_3_222_3"
  top: "res_stage_3_222_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_222"
  type: "Eltwise"
  bottom: "res_3_221"
  bottom: "res_stage_3_222_3_top"
  top: "res_3_222"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_222_relu"
  type: "ReLU"
  bottom: "res_3_222"
  top: "res_3_222"
}
layer {
  name: "res_stage_3_223_1"
  type: "Convolution"
  bottom: "res_3_222"
  top: "res_stage_3_223_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_223_1"
  type: "BatchNorm"
  bottom: "res_stage_3_223_1"
  top: "res_stage_3_223_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_223_1"  
  type: "Scale"
  bottom: "res_stage_3_223_1"
  top: "res_stage_3_223_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_223_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_223_1_top"
  top: "res_stage_3_223_1_top"
}
layer {
  name: "res_stage_3_223_2"
  type: "Convolution"
  bottom: "res_stage_3_223_1_top"
  top: "res_stage_3_223_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_223_2"
  type: "BatchNorm"
  bottom: "res_stage_3_223_2"
  top: "res_stage_3_223_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_223_2"  
  type: "Scale"
  bottom: "res_stage_3_223_2"
  top: "res_stage_3_223_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_223_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_223_2_top"
  top: "res_stage_3_223_2_top"
}
layer {
  name: "res_stage_3_223_3"
  type: "Convolution"
  bottom: "res_stage_3_223_2_top"
  top: "res_stage_3_223_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_223_3"
  type: "BatchNorm"
  bottom: "res_stage_3_223_3"
  top: "res_stage_3_223_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_223_3"  
  type: "Scale"
  bottom: "res_stage_3_223_3"
  top: "res_stage_3_223_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_223"
  type: "Eltwise"
  bottom: "res_3_222"
  bottom: "res_stage_3_223_3_top"
  top: "res_3_223"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_223_relu"
  type: "ReLU"
  bottom: "res_3_223"
  top: "res_3_223"
}
layer {
  name: "res_stage_3_224_1"
  type: "Convolution"
  bottom: "res_3_223"
  top: "res_stage_3_224_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_224_1"
  type: "BatchNorm"
  bottom: "res_stage_3_224_1"
  top: "res_stage_3_224_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_224_1"  
  type: "Scale"
  bottom: "res_stage_3_224_1"
  top: "res_stage_3_224_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_224_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_224_1_top"
  top: "res_stage_3_224_1_top"
}
layer {
  name: "res_stage_3_224_2"
  type: "Convolution"
  bottom: "res_stage_3_224_1_top"
  top: "res_stage_3_224_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_224_2"
  type: "BatchNorm"
  bottom: "res_stage_3_224_2"
  top: "res_stage_3_224_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_224_2"  
  type: "Scale"
  bottom: "res_stage_3_224_2"
  top: "res_stage_3_224_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_224_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_224_2_top"
  top: "res_stage_3_224_2_top"
}
layer {
  name: "res_stage_3_224_3"
  type: "Convolution"
  bottom: "res_stage_3_224_2_top"
  top: "res_stage_3_224_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_224_3"
  type: "BatchNorm"
  bottom: "res_stage_3_224_3"
  top: "res_stage_3_224_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_224_3"  
  type: "Scale"
  bottom: "res_stage_3_224_3"
  top: "res_stage_3_224_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_224"
  type: "Eltwise"
  bottom: "res_3_223"
  bottom: "res_stage_3_224_3_top"
  top: "res_3_224"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_224_relu"
  type: "ReLU"
  bottom: "res_3_224"
  top: "res_3_224"
}
layer {
  name: "res_stage_3_225_1"
  type: "Convolution"
  bottom: "res_3_224"
  top: "res_stage_3_225_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_225_1"
  type: "BatchNorm"
  bottom: "res_stage_3_225_1"
  top: "res_stage_3_225_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_225_1"  
  type: "Scale"
  bottom: "res_stage_3_225_1"
  top: "res_stage_3_225_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_225_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_225_1_top"
  top: "res_stage_3_225_1_top"
}
layer {
  name: "res_stage_3_225_2"
  type: "Convolution"
  bottom: "res_stage_3_225_1_top"
  top: "res_stage_3_225_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_225_2"
  type: "BatchNorm"
  bottom: "res_stage_3_225_2"
  top: "res_stage_3_225_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_225_2"  
  type: "Scale"
  bottom: "res_stage_3_225_2"
  top: "res_stage_3_225_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_225_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_225_2_top"
  top: "res_stage_3_225_2_top"
}
layer {
  name: "res_stage_3_225_3"
  type: "Convolution"
  bottom: "res_stage_3_225_2_top"
  top: "res_stage_3_225_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_225_3"
  type: "BatchNorm"
  bottom: "res_stage_3_225_3"
  top: "res_stage_3_225_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_225_3"  
  type: "Scale"
  bottom: "res_stage_3_225_3"
  top: "res_stage_3_225_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_225"
  type: "Eltwise"
  bottom: "res_3_224"
  bottom: "res_stage_3_225_3_top"
  top: "res_3_225"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_225_relu"
  type: "ReLU"
  bottom: "res_3_225"
  top: "res_3_225"
}
layer {
  name: "res_stage_3_226_1"
  type: "Convolution"
  bottom: "res_3_225"
  top: "res_stage_3_226_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_226_1"
  type: "BatchNorm"
  bottom: "res_stage_3_226_1"
  top: "res_stage_3_226_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_226_1"  
  type: "Scale"
  bottom: "res_stage_3_226_1"
  top: "res_stage_3_226_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_226_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_226_1_top"
  top: "res_stage_3_226_1_top"
}
layer {
  name: "res_stage_3_226_2"
  type: "Convolution"
  bottom: "res_stage_3_226_1_top"
  top: "res_stage_3_226_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_226_2"
  type: "BatchNorm"
  bottom: "res_stage_3_226_2"
  top: "res_stage_3_226_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_226_2"  
  type: "Scale"
  bottom: "res_stage_3_226_2"
  top: "res_stage_3_226_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_226_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_226_2_top"
  top: "res_stage_3_226_2_top"
}
layer {
  name: "res_stage_3_226_3"
  type: "Convolution"
  bottom: "res_stage_3_226_2_top"
  top: "res_stage_3_226_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_226_3"
  type: "BatchNorm"
  bottom: "res_stage_3_226_3"
  top: "res_stage_3_226_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_226_3"  
  type: "Scale"
  bottom: "res_stage_3_226_3"
  top: "res_stage_3_226_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_226"
  type: "Eltwise"
  bottom: "res_3_225"
  bottom: "res_stage_3_226_3_top"
  top: "res_3_226"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_226_relu"
  type: "ReLU"
  bottom: "res_3_226"
  top: "res_3_226"
}
layer {
  name: "res_stage_3_227_1"
  type: "Convolution"
  bottom: "res_3_226"
  top: "res_stage_3_227_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_227_1"
  type: "BatchNorm"
  bottom: "res_stage_3_227_1"
  top: "res_stage_3_227_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_227_1"  
  type: "Scale"
  bottom: "res_stage_3_227_1"
  top: "res_stage_3_227_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_227_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_227_1_top"
  top: "res_stage_3_227_1_top"
}
layer {
  name: "res_stage_3_227_2"
  type: "Convolution"
  bottom: "res_stage_3_227_1_top"
  top: "res_stage_3_227_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_227_2"
  type: "BatchNorm"
  bottom: "res_stage_3_227_2"
  top: "res_stage_3_227_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_227_2"  
  type: "Scale"
  bottom: "res_stage_3_227_2"
  top: "res_stage_3_227_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_227_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_227_2_top"
  top: "res_stage_3_227_2_top"
}
layer {
  name: "res_stage_3_227_3"
  type: "Convolution"
  bottom: "res_stage_3_227_2_top"
  top: "res_stage_3_227_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_227_3"
  type: "BatchNorm"
  bottom: "res_stage_3_227_3"
  top: "res_stage_3_227_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_227_3"  
  type: "Scale"
  bottom: "res_stage_3_227_3"
  top: "res_stage_3_227_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_227"
  type: "Eltwise"
  bottom: "res_3_226"
  bottom: "res_stage_3_227_3_top"
  top: "res_3_227"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_227_relu"
  type: "ReLU"
  bottom: "res_3_227"
  top: "res_3_227"
}
layer {
  name: "res_stage_3_228_1"
  type: "Convolution"
  bottom: "res_3_227"
  top: "res_stage_3_228_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_228_1"
  type: "BatchNorm"
  bottom: "res_stage_3_228_1"
  top: "res_stage_3_228_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_228_1"  
  type: "Scale"
  bottom: "res_stage_3_228_1"
  top: "res_stage_3_228_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_228_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_228_1_top"
  top: "res_stage_3_228_1_top"
}
layer {
  name: "res_stage_3_228_2"
  type: "Convolution"
  bottom: "res_stage_3_228_1_top"
  top: "res_stage_3_228_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_228_2"
  type: "BatchNorm"
  bottom: "res_stage_3_228_2"
  top: "res_stage_3_228_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_228_2"  
  type: "Scale"
  bottom: "res_stage_3_228_2"
  top: "res_stage_3_228_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_228_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_228_2_top"
  top: "res_stage_3_228_2_top"
}
layer {
  name: "res_stage_3_228_3"
  type: "Convolution"
  bottom: "res_stage_3_228_2_top"
  top: "res_stage_3_228_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_228_3"
  type: "BatchNorm"
  bottom: "res_stage_3_228_3"
  top: "res_stage_3_228_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_228_3"  
  type: "Scale"
  bottom: "res_stage_3_228_3"
  top: "res_stage_3_228_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_228"
  type: "Eltwise"
  bottom: "res_3_227"
  bottom: "res_stage_3_228_3_top"
  top: "res_3_228"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_228_relu"
  type: "ReLU"
  bottom: "res_3_228"
  top: "res_3_228"
}
layer {
  name: "res_stage_3_229_1"
  type: "Convolution"
  bottom: "res_3_228"
  top: "res_stage_3_229_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_229_1"
  type: "BatchNorm"
  bottom: "res_stage_3_229_1"
  top: "res_stage_3_229_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_229_1"  
  type: "Scale"
  bottom: "res_stage_3_229_1"
  top: "res_stage_3_229_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_229_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_229_1_top"
  top: "res_stage_3_229_1_top"
}
layer {
  name: "res_stage_3_229_2"
  type: "Convolution"
  bottom: "res_stage_3_229_1_top"
  top: "res_stage_3_229_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_229_2"
  type: "BatchNorm"
  bottom: "res_stage_3_229_2"
  top: "res_stage_3_229_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_229_2"  
  type: "Scale"
  bottom: "res_stage_3_229_2"
  top: "res_stage_3_229_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_229_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_229_2_top"
  top: "res_stage_3_229_2_top"
}
layer {
  name: "res_stage_3_229_3"
  type: "Convolution"
  bottom: "res_stage_3_229_2_top"
  top: "res_stage_3_229_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_229_3"
  type: "BatchNorm"
  bottom: "res_stage_3_229_3"
  top: "res_stage_3_229_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_229_3"  
  type: "Scale"
  bottom: "res_stage_3_229_3"
  top: "res_stage_3_229_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_229"
  type: "Eltwise"
  bottom: "res_3_228"
  bottom: "res_stage_3_229_3_top"
  top: "res_3_229"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_229_relu"
  type: "ReLU"
  bottom: "res_3_229"
  top: "res_3_229"
}
layer {
  name: "res_stage_3_230_1"
  type: "Convolution"
  bottom: "res_3_229"
  top: "res_stage_3_230_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_230_1"
  type: "BatchNorm"
  bottom: "res_stage_3_230_1"
  top: "res_stage_3_230_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_230_1"  
  type: "Scale"
  bottom: "res_stage_3_230_1"
  top: "res_stage_3_230_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_230_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_230_1_top"
  top: "res_stage_3_230_1_top"
}
layer {
  name: "res_stage_3_230_2"
  type: "Convolution"
  bottom: "res_stage_3_230_1_top"
  top: "res_stage_3_230_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_230_2"
  type: "BatchNorm"
  bottom: "res_stage_3_230_2"
  top: "res_stage_3_230_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_230_2"  
  type: "Scale"
  bottom: "res_stage_3_230_2"
  top: "res_stage_3_230_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_230_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_230_2_top"
  top: "res_stage_3_230_2_top"
}
layer {
  name: "res_stage_3_230_3"
  type: "Convolution"
  bottom: "res_stage_3_230_2_top"
  top: "res_stage_3_230_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_230_3"
  type: "BatchNorm"
  bottom: "res_stage_3_230_3"
  top: "res_stage_3_230_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_230_3"  
  type: "Scale"
  bottom: "res_stage_3_230_3"
  top: "res_stage_3_230_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_230"
  type: "Eltwise"
  bottom: "res_3_229"
  bottom: "res_stage_3_230_3_top"
  top: "res_3_230"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_230_relu"
  type: "ReLU"
  bottom: "res_3_230"
  top: "res_3_230"
}
layer {
  name: "res_stage_3_231_1"
  type: "Convolution"
  bottom: "res_3_230"
  top: "res_stage_3_231_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_231_1"
  type: "BatchNorm"
  bottom: "res_stage_3_231_1"
  top: "res_stage_3_231_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_231_1"  
  type: "Scale"
  bottom: "res_stage_3_231_1"
  top: "res_stage_3_231_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_231_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_231_1_top"
  top: "res_stage_3_231_1_top"
}
layer {
  name: "res_stage_3_231_2"
  type: "Convolution"
  bottom: "res_stage_3_231_1_top"
  top: "res_stage_3_231_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_231_2"
  type: "BatchNorm"
  bottom: "res_stage_3_231_2"
  top: "res_stage_3_231_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_231_2"  
  type: "Scale"
  bottom: "res_stage_3_231_2"
  top: "res_stage_3_231_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_231_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_231_2_top"
  top: "res_stage_3_231_2_top"
}
layer {
  name: "res_stage_3_231_3"
  type: "Convolution"
  bottom: "res_stage_3_231_2_top"
  top: "res_stage_3_231_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_231_3"
  type: "BatchNorm"
  bottom: "res_stage_3_231_3"
  top: "res_stage_3_231_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_231_3"  
  type: "Scale"
  bottom: "res_stage_3_231_3"
  top: "res_stage_3_231_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_231"
  type: "Eltwise"
  bottom: "res_3_230"
  bottom: "res_stage_3_231_3_top"
  top: "res_3_231"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_231_relu"
  type: "ReLU"
  bottom: "res_3_231"
  top: "res_3_231"
}
layer {
  name: "res_stage_3_232_1"
  type: "Convolution"
  bottom: "res_3_231"
  top: "res_stage_3_232_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_232_1"
  type: "BatchNorm"
  bottom: "res_stage_3_232_1"
  top: "res_stage_3_232_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_232_1"  
  type: "Scale"
  bottom: "res_stage_3_232_1"
  top: "res_stage_3_232_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_232_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_232_1_top"
  top: "res_stage_3_232_1_top"
}
layer {
  name: "res_stage_3_232_2"
  type: "Convolution"
  bottom: "res_stage_3_232_1_top"
  top: "res_stage_3_232_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_232_2"
  type: "BatchNorm"
  bottom: "res_stage_3_232_2"
  top: "res_stage_3_232_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_232_2"  
  type: "Scale"
  bottom: "res_stage_3_232_2"
  top: "res_stage_3_232_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_232_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_232_2_top"
  top: "res_stage_3_232_2_top"
}
layer {
  name: "res_stage_3_232_3"
  type: "Convolution"
  bottom: "res_stage_3_232_2_top"
  top: "res_stage_3_232_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_232_3"
  type: "BatchNorm"
  bottom: "res_stage_3_232_3"
  top: "res_stage_3_232_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_232_3"  
  type: "Scale"
  bottom: "res_stage_3_232_3"
  top: "res_stage_3_232_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_232"
  type: "Eltwise"
  bottom: "res_3_231"
  bottom: "res_stage_3_232_3_top"
  top: "res_3_232"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_232_relu"
  type: "ReLU"
  bottom: "res_3_232"
  top: "res_3_232"
}
layer {
  name: "res_stage_3_233_1"
  type: "Convolution"
  bottom: "res_3_232"
  top: "res_stage_3_233_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_233_1"
  type: "BatchNorm"
  bottom: "res_stage_3_233_1"
  top: "res_stage_3_233_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_233_1"  
  type: "Scale"
  bottom: "res_stage_3_233_1"
  top: "res_stage_3_233_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_233_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_233_1_top"
  top: "res_stage_3_233_1_top"
}
layer {
  name: "res_stage_3_233_2"
  type: "Convolution"
  bottom: "res_stage_3_233_1_top"
  top: "res_stage_3_233_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_233_2"
  type: "BatchNorm"
  bottom: "res_stage_3_233_2"
  top: "res_stage_3_233_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_233_2"  
  type: "Scale"
  bottom: "res_stage_3_233_2"
  top: "res_stage_3_233_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_233_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_233_2_top"
  top: "res_stage_3_233_2_top"
}
layer {
  name: "res_stage_3_233_3"
  type: "Convolution"
  bottom: "res_stage_3_233_2_top"
  top: "res_stage_3_233_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_233_3"
  type: "BatchNorm"
  bottom: "res_stage_3_233_3"
  top: "res_stage_3_233_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_233_3"  
  type: "Scale"
  bottom: "res_stage_3_233_3"
  top: "res_stage_3_233_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_233"
  type: "Eltwise"
  bottom: "res_3_232"
  bottom: "res_stage_3_233_3_top"
  top: "res_3_233"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_233_relu"
  type: "ReLU"
  bottom: "res_3_233"
  top: "res_3_233"
}
layer {
  name: "res_stage_3_234_1"
  type: "Convolution"
  bottom: "res_3_233"
  top: "res_stage_3_234_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_234_1"
  type: "BatchNorm"
  bottom: "res_stage_3_234_1"
  top: "res_stage_3_234_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_234_1"  
  type: "Scale"
  bottom: "res_stage_3_234_1"
  top: "res_stage_3_234_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_234_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_234_1_top"
  top: "res_stage_3_234_1_top"
}
layer {
  name: "res_stage_3_234_2"
  type: "Convolution"
  bottom: "res_stage_3_234_1_top"
  top: "res_stage_3_234_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_234_2"
  type: "BatchNorm"
  bottom: "res_stage_3_234_2"
  top: "res_stage_3_234_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_234_2"  
  type: "Scale"
  bottom: "res_stage_3_234_2"
  top: "res_stage_3_234_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_234_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_234_2_top"
  top: "res_stage_3_234_2_top"
}
layer {
  name: "res_stage_3_234_3"
  type: "Convolution"
  bottom: "res_stage_3_234_2_top"
  top: "res_stage_3_234_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_234_3"
  type: "BatchNorm"
  bottom: "res_stage_3_234_3"
  top: "res_stage_3_234_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_234_3"  
  type: "Scale"
  bottom: "res_stage_3_234_3"
  top: "res_stage_3_234_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_234"
  type: "Eltwise"
  bottom: "res_3_233"
  bottom: "res_stage_3_234_3_top"
  top: "res_3_234"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_234_relu"
  type: "ReLU"
  bottom: "res_3_234"
  top: "res_3_234"
}
layer {
  name: "res_stage_3_235_1"
  type: "Convolution"
  bottom: "res_3_234"
  top: "res_stage_3_235_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_235_1"
  type: "BatchNorm"
  bottom: "res_stage_3_235_1"
  top: "res_stage_3_235_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_235_1"  
  type: "Scale"
  bottom: "res_stage_3_235_1"
  top: "res_stage_3_235_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_235_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_235_1_top"
  top: "res_stage_3_235_1_top"
}
layer {
  name: "res_stage_3_235_2"
  type: "Convolution"
  bottom: "res_stage_3_235_1_top"
  top: "res_stage_3_235_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_235_2"
  type: "BatchNorm"
  bottom: "res_stage_3_235_2"
  top: "res_stage_3_235_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_235_2"  
  type: "Scale"
  bottom: "res_stage_3_235_2"
  top: "res_stage_3_235_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_235_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_235_2_top"
  top: "res_stage_3_235_2_top"
}
layer {
  name: "res_stage_3_235_3"
  type: "Convolution"
  bottom: "res_stage_3_235_2_top"
  top: "res_stage_3_235_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_235_3"
  type: "BatchNorm"
  bottom: "res_stage_3_235_3"
  top: "res_stage_3_235_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_235_3"  
  type: "Scale"
  bottom: "res_stage_3_235_3"
  top: "res_stage_3_235_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_235"
  type: "Eltwise"
  bottom: "res_3_234"
  bottom: "res_stage_3_235_3_top"
  top: "res_3_235"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_235_relu"
  type: "ReLU"
  bottom: "res_3_235"
  top: "res_3_235"
}
layer {
  name: "res_stage_3_236_1"
  type: "Convolution"
  bottom: "res_3_235"
  top: "res_stage_3_236_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_236_1"
  type: "BatchNorm"
  bottom: "res_stage_3_236_1"
  top: "res_stage_3_236_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_236_1"  
  type: "Scale"
  bottom: "res_stage_3_236_1"
  top: "res_stage_3_236_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_236_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_236_1_top"
  top: "res_stage_3_236_1_top"
}
layer {
  name: "res_stage_3_236_2"
  type: "Convolution"
  bottom: "res_stage_3_236_1_top"
  top: "res_stage_3_236_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_236_2"
  type: "BatchNorm"
  bottom: "res_stage_3_236_2"
  top: "res_stage_3_236_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_236_2"  
  type: "Scale"
  bottom: "res_stage_3_236_2"
  top: "res_stage_3_236_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_236_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_236_2_top"
  top: "res_stage_3_236_2_top"
}
layer {
  name: "res_stage_3_236_3"
  type: "Convolution"
  bottom: "res_stage_3_236_2_top"
  top: "res_stage_3_236_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_236_3"
  type: "BatchNorm"
  bottom: "res_stage_3_236_3"
  top: "res_stage_3_236_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_236_3"  
  type: "Scale"
  bottom: "res_stage_3_236_3"
  top: "res_stage_3_236_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_236"
  type: "Eltwise"
  bottom: "res_3_235"
  bottom: "res_stage_3_236_3_top"
  top: "res_3_236"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_236_relu"
  type: "ReLU"
  bottom: "res_3_236"
  top: "res_3_236"
}
layer {
  name: "res_stage_3_237_1"
  type: "Convolution"
  bottom: "res_3_236"
  top: "res_stage_3_237_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_237_1"
  type: "BatchNorm"
  bottom: "res_stage_3_237_1"
  top: "res_stage_3_237_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_237_1"  
  type: "Scale"
  bottom: "res_stage_3_237_1"
  top: "res_stage_3_237_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_237_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_237_1_top"
  top: "res_stage_3_237_1_top"
}
layer {
  name: "res_stage_3_237_2"
  type: "Convolution"
  bottom: "res_stage_3_237_1_top"
  top: "res_stage_3_237_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_237_2"
  type: "BatchNorm"
  bottom: "res_stage_3_237_2"
  top: "res_stage_3_237_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_237_2"  
  type: "Scale"
  bottom: "res_stage_3_237_2"
  top: "res_stage_3_237_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_237_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_237_2_top"
  top: "res_stage_3_237_2_top"
}
layer {
  name: "res_stage_3_237_3"
  type: "Convolution"
  bottom: "res_stage_3_237_2_top"
  top: "res_stage_3_237_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_237_3"
  type: "BatchNorm"
  bottom: "res_stage_3_237_3"
  top: "res_stage_3_237_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_237_3"  
  type: "Scale"
  bottom: "res_stage_3_237_3"
  top: "res_stage_3_237_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_237"
  type: "Eltwise"
  bottom: "res_3_236"
  bottom: "res_stage_3_237_3_top"
  top: "res_3_237"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_237_relu"
  type: "ReLU"
  bottom: "res_3_237"
  top: "res_3_237"
}
layer {
  name: "res_stage_3_238_1"
  type: "Convolution"
  bottom: "res_3_237"
  top: "res_stage_3_238_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_238_1"
  type: "BatchNorm"
  bottom: "res_stage_3_238_1"
  top: "res_stage_3_238_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_238_1"  
  type: "Scale"
  bottom: "res_stage_3_238_1"
  top: "res_stage_3_238_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_238_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_238_1_top"
  top: "res_stage_3_238_1_top"
}
layer {
  name: "res_stage_3_238_2"
  type: "Convolution"
  bottom: "res_stage_3_238_1_top"
  top: "res_stage_3_238_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_238_2"
  type: "BatchNorm"
  bottom: "res_stage_3_238_2"
  top: "res_stage_3_238_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_238_2"  
  type: "Scale"
  bottom: "res_stage_3_238_2"
  top: "res_stage_3_238_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_238_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_238_2_top"
  top: "res_stage_3_238_2_top"
}
layer {
  name: "res_stage_3_238_3"
  type: "Convolution"
  bottom: "res_stage_3_238_2_top"
  top: "res_stage_3_238_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_238_3"
  type: "BatchNorm"
  bottom: "res_stage_3_238_3"
  top: "res_stage_3_238_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_238_3"  
  type: "Scale"
  bottom: "res_stage_3_238_3"
  top: "res_stage_3_238_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_238"
  type: "Eltwise"
  bottom: "res_3_237"
  bottom: "res_stage_3_238_3_top"
  top: "res_3_238"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_238_relu"
  type: "ReLU"
  bottom: "res_3_238"
  top: "res_3_238"
}
layer {
  name: "res_stage_3_239_1"
  type: "Convolution"
  bottom: "res_3_238"
  top: "res_stage_3_239_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_239_1"
  type: "BatchNorm"
  bottom: "res_stage_3_239_1"
  top: "res_stage_3_239_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_239_1"  
  type: "Scale"
  bottom: "res_stage_3_239_1"
  top: "res_stage_3_239_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_239_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_239_1_top"
  top: "res_stage_3_239_1_top"
}
layer {
  name: "res_stage_3_239_2"
  type: "Convolution"
  bottom: "res_stage_3_239_1_top"
  top: "res_stage_3_239_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_239_2"
  type: "BatchNorm"
  bottom: "res_stage_3_239_2"
  top: "res_stage_3_239_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_239_2"  
  type: "Scale"
  bottom: "res_stage_3_239_2"
  top: "res_stage_3_239_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_239_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_239_2_top"
  top: "res_stage_3_239_2_top"
}
layer {
  name: "res_stage_3_239_3"
  type: "Convolution"
  bottom: "res_stage_3_239_2_top"
  top: "res_stage_3_239_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_239_3"
  type: "BatchNorm"
  bottom: "res_stage_3_239_3"
  top: "res_stage_3_239_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_239_3"  
  type: "Scale"
  bottom: "res_stage_3_239_3"
  top: "res_stage_3_239_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_239"
  type: "Eltwise"
  bottom: "res_3_238"
  bottom: "res_stage_3_239_3_top"
  top: "res_3_239"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_239_relu"
  type: "ReLU"
  bottom: "res_3_239"
  top: "res_3_239"
}
layer {
  name: "res_stage_3_240_1"
  type: "Convolution"
  bottom: "res_3_239"
  top: "res_stage_3_240_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_240_1"
  type: "BatchNorm"
  bottom: "res_stage_3_240_1"
  top: "res_stage_3_240_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_240_1"  
  type: "Scale"
  bottom: "res_stage_3_240_1"
  top: "res_stage_3_240_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_240_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_240_1_top"
  top: "res_stage_3_240_1_top"
}
layer {
  name: "res_stage_3_240_2"
  type: "Convolution"
  bottom: "res_stage_3_240_1_top"
  top: "res_stage_3_240_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_240_2"
  type: "BatchNorm"
  bottom: "res_stage_3_240_2"
  top: "res_stage_3_240_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_240_2"  
  type: "Scale"
  bottom: "res_stage_3_240_2"
  top: "res_stage_3_240_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_240_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_240_2_top"
  top: "res_stage_3_240_2_top"
}
layer {
  name: "res_stage_3_240_3"
  type: "Convolution"
  bottom: "res_stage_3_240_2_top"
  top: "res_stage_3_240_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_240_3"
  type: "BatchNorm"
  bottom: "res_stage_3_240_3"
  top: "res_stage_3_240_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_240_3"  
  type: "Scale"
  bottom: "res_stage_3_240_3"
  top: "res_stage_3_240_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_240"
  type: "Eltwise"
  bottom: "res_3_239"
  bottom: "res_stage_3_240_3_top"
  top: "res_3_240"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_240_relu"
  type: "ReLU"
  bottom: "res_3_240"
  top: "res_3_240"
}
layer {
  name: "res_stage_3_241_1"
  type: "Convolution"
  bottom: "res_3_240"
  top: "res_stage_3_241_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_241_1"
  type: "BatchNorm"
  bottom: "res_stage_3_241_1"
  top: "res_stage_3_241_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_241_1"  
  type: "Scale"
  bottom: "res_stage_3_241_1"
  top: "res_stage_3_241_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_241_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_241_1_top"
  top: "res_stage_3_241_1_top"
}
layer {
  name: "res_stage_3_241_2"
  type: "Convolution"
  bottom: "res_stage_3_241_1_top"
  top: "res_stage_3_241_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_241_2"
  type: "BatchNorm"
  bottom: "res_stage_3_241_2"
  top: "res_stage_3_241_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_241_2"  
  type: "Scale"
  bottom: "res_stage_3_241_2"
  top: "res_stage_3_241_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_241_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_241_2_top"
  top: "res_stage_3_241_2_top"
}
layer {
  name: "res_stage_3_241_3"
  type: "Convolution"
  bottom: "res_stage_3_241_2_top"
  top: "res_stage_3_241_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_241_3"
  type: "BatchNorm"
  bottom: "res_stage_3_241_3"
  top: "res_stage_3_241_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_241_3"  
  type: "Scale"
  bottom: "res_stage_3_241_3"
  top: "res_stage_3_241_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_241"
  type: "Eltwise"
  bottom: "res_3_240"
  bottom: "res_stage_3_241_3_top"
  top: "res_3_241"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_241_relu"
  type: "ReLU"
  bottom: "res_3_241"
  top: "res_3_241"
}
layer {
  name: "res_stage_3_242_1"
  type: "Convolution"
  bottom: "res_3_241"
  top: "res_stage_3_242_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_242_1"
  type: "BatchNorm"
  bottom: "res_stage_3_242_1"
  top: "res_stage_3_242_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_242_1"  
  type: "Scale"
  bottom: "res_stage_3_242_1"
  top: "res_stage_3_242_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_242_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_242_1_top"
  top: "res_stage_3_242_1_top"
}
layer {
  name: "res_stage_3_242_2"
  type: "Convolution"
  bottom: "res_stage_3_242_1_top"
  top: "res_stage_3_242_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_242_2"
  type: "BatchNorm"
  bottom: "res_stage_3_242_2"
  top: "res_stage_3_242_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_242_2"  
  type: "Scale"
  bottom: "res_stage_3_242_2"
  top: "res_stage_3_242_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_242_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_242_2_top"
  top: "res_stage_3_242_2_top"
}
layer {
  name: "res_stage_3_242_3"
  type: "Convolution"
  bottom: "res_stage_3_242_2_top"
  top: "res_stage_3_242_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_242_3"
  type: "BatchNorm"
  bottom: "res_stage_3_242_3"
  top: "res_stage_3_242_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_242_3"  
  type: "Scale"
  bottom: "res_stage_3_242_3"
  top: "res_stage_3_242_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_242"
  type: "Eltwise"
  bottom: "res_3_241"
  bottom: "res_stage_3_242_3_top"
  top: "res_3_242"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_242_relu"
  type: "ReLU"
  bottom: "res_3_242"
  top: "res_3_242"
}
layer {
  name: "res_stage_3_243_1"
  type: "Convolution"
  bottom: "res_3_242"
  top: "res_stage_3_243_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_243_1"
  type: "BatchNorm"
  bottom: "res_stage_3_243_1"
  top: "res_stage_3_243_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_243_1"  
  type: "Scale"
  bottom: "res_stage_3_243_1"
  top: "res_stage_3_243_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_243_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_243_1_top"
  top: "res_stage_3_243_1_top"
}
layer {
  name: "res_stage_3_243_2"
  type: "Convolution"
  bottom: "res_stage_3_243_1_top"
  top: "res_stage_3_243_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_243_2"
  type: "BatchNorm"
  bottom: "res_stage_3_243_2"
  top: "res_stage_3_243_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_243_2"  
  type: "Scale"
  bottom: "res_stage_3_243_2"
  top: "res_stage_3_243_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_243_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_243_2_top"
  top: "res_stage_3_243_2_top"
}
layer {
  name: "res_stage_3_243_3"
  type: "Convolution"
  bottom: "res_stage_3_243_2_top"
  top: "res_stage_3_243_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_243_3"
  type: "BatchNorm"
  bottom: "res_stage_3_243_3"
  top: "res_stage_3_243_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_243_3"  
  type: "Scale"
  bottom: "res_stage_3_243_3"
  top: "res_stage_3_243_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_243"
  type: "Eltwise"
  bottom: "res_3_242"
  bottom: "res_stage_3_243_3_top"
  top: "res_3_243"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_243_relu"
  type: "ReLU"
  bottom: "res_3_243"
  top: "res_3_243"
}
layer {
  name: "res_stage_3_244_1"
  type: "Convolution"
  bottom: "res_3_243"
  top: "res_stage_3_244_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_244_1"
  type: "BatchNorm"
  bottom: "res_stage_3_244_1"
  top: "res_stage_3_244_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_244_1"  
  type: "Scale"
  bottom: "res_stage_3_244_1"
  top: "res_stage_3_244_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_244_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_244_1_top"
  top: "res_stage_3_244_1_top"
}
layer {
  name: "res_stage_3_244_2"
  type: "Convolution"
  bottom: "res_stage_3_244_1_top"
  top: "res_stage_3_244_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_244_2"
  type: "BatchNorm"
  bottom: "res_stage_3_244_2"
  top: "res_stage_3_244_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_244_2"  
  type: "Scale"
  bottom: "res_stage_3_244_2"
  top: "res_stage_3_244_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_244_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_244_2_top"
  top: "res_stage_3_244_2_top"
}
layer {
  name: "res_stage_3_244_3"
  type: "Convolution"
  bottom: "res_stage_3_244_2_top"
  top: "res_stage_3_244_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_244_3"
  type: "BatchNorm"
  bottom: "res_stage_3_244_3"
  top: "res_stage_3_244_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_244_3"  
  type: "Scale"
  bottom: "res_stage_3_244_3"
  top: "res_stage_3_244_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_244"
  type: "Eltwise"
  bottom: "res_3_243"
  bottom: "res_stage_3_244_3_top"
  top: "res_3_244"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_244_relu"
  type: "ReLU"
  bottom: "res_3_244"
  top: "res_3_244"
}
layer {
  name: "res_stage_3_245_1"
  type: "Convolution"
  bottom: "res_3_244"
  top: "res_stage_3_245_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_245_1"
  type: "BatchNorm"
  bottom: "res_stage_3_245_1"
  top: "res_stage_3_245_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_245_1"  
  type: "Scale"
  bottom: "res_stage_3_245_1"
  top: "res_stage_3_245_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_245_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_245_1_top"
  top: "res_stage_3_245_1_top"
}
layer {
  name: "res_stage_3_245_2"
  type: "Convolution"
  bottom: "res_stage_3_245_1_top"
  top: "res_stage_3_245_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_245_2"
  type: "BatchNorm"
  bottom: "res_stage_3_245_2"
  top: "res_stage_3_245_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_245_2"  
  type: "Scale"
  bottom: "res_stage_3_245_2"
  top: "res_stage_3_245_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_245_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_245_2_top"
  top: "res_stage_3_245_2_top"
}
layer {
  name: "res_stage_3_245_3"
  type: "Convolution"
  bottom: "res_stage_3_245_2_top"
  top: "res_stage_3_245_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_245_3"
  type: "BatchNorm"
  bottom: "res_stage_3_245_3"
  top: "res_stage_3_245_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_245_3"  
  type: "Scale"
  bottom: "res_stage_3_245_3"
  top: "res_stage_3_245_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_245"
  type: "Eltwise"
  bottom: "res_3_244"
  bottom: "res_stage_3_245_3_top"
  top: "res_3_245"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_245_relu"
  type: "ReLU"
  bottom: "res_3_245"
  top: "res_3_245"
}
layer {
  name: "res_stage_3_246_1"
  type: "Convolution"
  bottom: "res_3_245"
  top: "res_stage_3_246_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_246_1"
  type: "BatchNorm"
  bottom: "res_stage_3_246_1"
  top: "res_stage_3_246_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_246_1"  
  type: "Scale"
  bottom: "res_stage_3_246_1"
  top: "res_stage_3_246_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_246_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_246_1_top"
  top: "res_stage_3_246_1_top"
}
layer {
  name: "res_stage_3_246_2"
  type: "Convolution"
  bottom: "res_stage_3_246_1_top"
  top: "res_stage_3_246_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_246_2"
  type: "BatchNorm"
  bottom: "res_stage_3_246_2"
  top: "res_stage_3_246_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_246_2"  
  type: "Scale"
  bottom: "res_stage_3_246_2"
  top: "res_stage_3_246_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_246_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_246_2_top"
  top: "res_stage_3_246_2_top"
}
layer {
  name: "res_stage_3_246_3"
  type: "Convolution"
  bottom: "res_stage_3_246_2_top"
  top: "res_stage_3_246_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_246_3"
  type: "BatchNorm"
  bottom: "res_stage_3_246_3"
  top: "res_stage_3_246_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_246_3"  
  type: "Scale"
  bottom: "res_stage_3_246_3"
  top: "res_stage_3_246_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_246"
  type: "Eltwise"
  bottom: "res_3_245"
  bottom: "res_stage_3_246_3_top"
  top: "res_3_246"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_246_relu"
  type: "ReLU"
  bottom: "res_3_246"
  top: "res_3_246"
}
layer {
  name: "res_stage_3_247_1"
  type: "Convolution"
  bottom: "res_3_246"
  top: "res_stage_3_247_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_247_1"
  type: "BatchNorm"
  bottom: "res_stage_3_247_1"
  top: "res_stage_3_247_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_247_1"  
  type: "Scale"
  bottom: "res_stage_3_247_1"
  top: "res_stage_3_247_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_247_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_247_1_top"
  top: "res_stage_3_247_1_top"
}
layer {
  name: "res_stage_3_247_2"
  type: "Convolution"
  bottom: "res_stage_3_247_1_top"
  top: "res_stage_3_247_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_247_2"
  type: "BatchNorm"
  bottom: "res_stage_3_247_2"
  top: "res_stage_3_247_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_247_2"  
  type: "Scale"
  bottom: "res_stage_3_247_2"
  top: "res_stage_3_247_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_247_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_247_2_top"
  top: "res_stage_3_247_2_top"
}
layer {
  name: "res_stage_3_247_3"
  type: "Convolution"
  bottom: "res_stage_3_247_2_top"
  top: "res_stage_3_247_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_247_3"
  type: "BatchNorm"
  bottom: "res_stage_3_247_3"
  top: "res_stage_3_247_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_247_3"  
  type: "Scale"
  bottom: "res_stage_3_247_3"
  top: "res_stage_3_247_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_247"
  type: "Eltwise"
  bottom: "res_3_246"
  bottom: "res_stage_3_247_3_top"
  top: "res_3_247"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_247_relu"
  type: "ReLU"
  bottom: "res_3_247"
  top: "res_3_247"
}
layer {
  name: "res_stage_3_248_1"
  type: "Convolution"
  bottom: "res_3_247"
  top: "res_stage_3_248_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_248_1"
  type: "BatchNorm"
  bottom: "res_stage_3_248_1"
  top: "res_stage_3_248_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_248_1"  
  type: "Scale"
  bottom: "res_stage_3_248_1"
  top: "res_stage_3_248_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_248_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_248_1_top"
  top: "res_stage_3_248_1_top"
}
layer {
  name: "res_stage_3_248_2"
  type: "Convolution"
  bottom: "res_stage_3_248_1_top"
  top: "res_stage_3_248_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_248_2"
  type: "BatchNorm"
  bottom: "res_stage_3_248_2"
  top: "res_stage_3_248_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_248_2"  
  type: "Scale"
  bottom: "res_stage_3_248_2"
  top: "res_stage_3_248_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_248_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_248_2_top"
  top: "res_stage_3_248_2_top"
}
layer {
  name: "res_stage_3_248_3"
  type: "Convolution"
  bottom: "res_stage_3_248_2_top"
  top: "res_stage_3_248_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_248_3"
  type: "BatchNorm"
  bottom: "res_stage_3_248_3"
  top: "res_stage_3_248_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_248_3"  
  type: "Scale"
  bottom: "res_stage_3_248_3"
  top: "res_stage_3_248_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_248"
  type: "Eltwise"
  bottom: "res_3_247"
  bottom: "res_stage_3_248_3_top"
  top: "res_3_248"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_248_relu"
  type: "ReLU"
  bottom: "res_3_248"
  top: "res_3_248"
}
layer {
  name: "res_stage_3_249_1"
  type: "Convolution"
  bottom: "res_3_248"
  top: "res_stage_3_249_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_249_1"
  type: "BatchNorm"
  bottom: "res_stage_3_249_1"
  top: "res_stage_3_249_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_249_1"  
  type: "Scale"
  bottom: "res_stage_3_249_1"
  top: "res_stage_3_249_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_249_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_249_1_top"
  top: "res_stage_3_249_1_top"
}
layer {
  name: "res_stage_3_249_2"
  type: "Convolution"
  bottom: "res_stage_3_249_1_top"
  top: "res_stage_3_249_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_249_2"
  type: "BatchNorm"
  bottom: "res_stage_3_249_2"
  top: "res_stage_3_249_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_249_2"  
  type: "Scale"
  bottom: "res_stage_3_249_2"
  top: "res_stage_3_249_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_249_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_249_2_top"
  top: "res_stage_3_249_2_top"
}
layer {
  name: "res_stage_3_249_3"
  type: "Convolution"
  bottom: "res_stage_3_249_2_top"
  top: "res_stage_3_249_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_249_3"
  type: "BatchNorm"
  bottom: "res_stage_3_249_3"
  top: "res_stage_3_249_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_249_3"  
  type: "Scale"
  bottom: "res_stage_3_249_3"
  top: "res_stage_3_249_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_249"
  type: "Eltwise"
  bottom: "res_3_248"
  bottom: "res_stage_3_249_3_top"
  top: "res_3_249"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_249_relu"
  type: "ReLU"
  bottom: "res_3_249"
  top: "res_3_249"
}
layer {
  name: "res_stage_3_250_1"
  type: "Convolution"
  bottom: "res_3_249"
  top: "res_stage_3_250_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_250_1"
  type: "BatchNorm"
  bottom: "res_stage_3_250_1"
  top: "res_stage_3_250_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_250_1"  
  type: "Scale"
  bottom: "res_stage_3_250_1"
  top: "res_stage_3_250_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_250_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_250_1_top"
  top: "res_stage_3_250_1_top"
}
layer {
  name: "res_stage_3_250_2"
  type: "Convolution"
  bottom: "res_stage_3_250_1_top"
  top: "res_stage_3_250_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_250_2"
  type: "BatchNorm"
  bottom: "res_stage_3_250_2"
  top: "res_stage_3_250_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_250_2"  
  type: "Scale"
  bottom: "res_stage_3_250_2"
  top: "res_stage_3_250_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_250_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_250_2_top"
  top: "res_stage_3_250_2_top"
}
layer {
  name: "res_stage_3_250_3"
  type: "Convolution"
  bottom: "res_stage_3_250_2_top"
  top: "res_stage_3_250_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_250_3"
  type: "BatchNorm"
  bottom: "res_stage_3_250_3"
  top: "res_stage_3_250_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_250_3"  
  type: "Scale"
  bottom: "res_stage_3_250_3"
  top: "res_stage_3_250_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_250"
  type: "Eltwise"
  bottom: "res_3_249"
  bottom: "res_stage_3_250_3_top"
  top: "res_3_250"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_250_relu"
  type: "ReLU"
  bottom: "res_3_250"
  top: "res_3_250"
}
layer {
  name: "res_stage_3_251_1"
  type: "Convolution"
  bottom: "res_3_250"
  top: "res_stage_3_251_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_251_1"
  type: "BatchNorm"
  bottom: "res_stage_3_251_1"
  top: "res_stage_3_251_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_251_1"  
  type: "Scale"
  bottom: "res_stage_3_251_1"
  top: "res_stage_3_251_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_251_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_251_1_top"
  top: "res_stage_3_251_1_top"
}
layer {
  name: "res_stage_3_251_2"
  type: "Convolution"
  bottom: "res_stage_3_251_1_top"
  top: "res_stage_3_251_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_251_2"
  type: "BatchNorm"
  bottom: "res_stage_3_251_2"
  top: "res_stage_3_251_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_251_2"  
  type: "Scale"
  bottom: "res_stage_3_251_2"
  top: "res_stage_3_251_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_251_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_251_2_top"
  top: "res_stage_3_251_2_top"
}
layer {
  name: "res_stage_3_251_3"
  type: "Convolution"
  bottom: "res_stage_3_251_2_top"
  top: "res_stage_3_251_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_251_3"
  type: "BatchNorm"
  bottom: "res_stage_3_251_3"
  top: "res_stage_3_251_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_251_3"  
  type: "Scale"
  bottom: "res_stage_3_251_3"
  top: "res_stage_3_251_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_251"
  type: "Eltwise"
  bottom: "res_3_250"
  bottom: "res_stage_3_251_3_top"
  top: "res_3_251"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_251_relu"
  type: "ReLU"
  bottom: "res_3_251"
  top: "res_3_251"
}
layer {
  name: "res_stage_3_252_1"
  type: "Convolution"
  bottom: "res_3_251"
  top: "res_stage_3_252_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_252_1"
  type: "BatchNorm"
  bottom: "res_stage_3_252_1"
  top: "res_stage_3_252_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_252_1"  
  type: "Scale"
  bottom: "res_stage_3_252_1"
  top: "res_stage_3_252_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_252_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_252_1_top"
  top: "res_stage_3_252_1_top"
}
layer {
  name: "res_stage_3_252_2"
  type: "Convolution"
  bottom: "res_stage_3_252_1_top"
  top: "res_stage_3_252_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_252_2"
  type: "BatchNorm"
  bottom: "res_stage_3_252_2"
  top: "res_stage_3_252_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_252_2"  
  type: "Scale"
  bottom: "res_stage_3_252_2"
  top: "res_stage_3_252_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_252_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_252_2_top"
  top: "res_stage_3_252_2_top"
}
layer {
  name: "res_stage_3_252_3"
  type: "Convolution"
  bottom: "res_stage_3_252_2_top"
  top: "res_stage_3_252_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_252_3"
  type: "BatchNorm"
  bottom: "res_stage_3_252_3"
  top: "res_stage_3_252_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_252_3"  
  type: "Scale"
  bottom: "res_stage_3_252_3"
  top: "res_stage_3_252_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_252"
  type: "Eltwise"
  bottom: "res_3_251"
  bottom: "res_stage_3_252_3_top"
  top: "res_3_252"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_252_relu"
  type: "ReLU"
  bottom: "res_3_252"
  top: "res_3_252"
}
layer {
  name: "res_stage_3_253_1"
  type: "Convolution"
  bottom: "res_3_252"
  top: "res_stage_3_253_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_253_1"
  type: "BatchNorm"
  bottom: "res_stage_3_253_1"
  top: "res_stage_3_253_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_253_1"  
  type: "Scale"
  bottom: "res_stage_3_253_1"
  top: "res_stage_3_253_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_253_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_253_1_top"
  top: "res_stage_3_253_1_top"
}
layer {
  name: "res_stage_3_253_2"
  type: "Convolution"
  bottom: "res_stage_3_253_1_top"
  top: "res_stage_3_253_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_253_2"
  type: "BatchNorm"
  bottom: "res_stage_3_253_2"
  top: "res_stage_3_253_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_253_2"  
  type: "Scale"
  bottom: "res_stage_3_253_2"
  top: "res_stage_3_253_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_253_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_253_2_top"
  top: "res_stage_3_253_2_top"
}
layer {
  name: "res_stage_3_253_3"
  type: "Convolution"
  bottom: "res_stage_3_253_2_top"
  top: "res_stage_3_253_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_253_3"
  type: "BatchNorm"
  bottom: "res_stage_3_253_3"
  top: "res_stage_3_253_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_253_3"  
  type: "Scale"
  bottom: "res_stage_3_253_3"
  top: "res_stage_3_253_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_253"
  type: "Eltwise"
  bottom: "res_3_252"
  bottom: "res_stage_3_253_3_top"
  top: "res_3_253"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_253_relu"
  type: "ReLU"
  bottom: "res_3_253"
  top: "res_3_253"
}
layer {
  name: "res_stage_3_254_1"
  type: "Convolution"
  bottom: "res_3_253"
  top: "res_stage_3_254_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_254_1"
  type: "BatchNorm"
  bottom: "res_stage_3_254_1"
  top: "res_stage_3_254_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_254_1"  
  type: "Scale"
  bottom: "res_stage_3_254_1"
  top: "res_stage_3_254_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_254_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_254_1_top"
  top: "res_stage_3_254_1_top"
}
layer {
  name: "res_stage_3_254_2"
  type: "Convolution"
  bottom: "res_stage_3_254_1_top"
  top: "res_stage_3_254_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_254_2"
  type: "BatchNorm"
  bottom: "res_stage_3_254_2"
  top: "res_stage_3_254_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_254_2"  
  type: "Scale"
  bottom: "res_stage_3_254_2"
  top: "res_stage_3_254_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_254_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_254_2_top"
  top: "res_stage_3_254_2_top"
}
layer {
  name: "res_stage_3_254_3"
  type: "Convolution"
  bottom: "res_stage_3_254_2_top"
  top: "res_stage_3_254_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_254_3"
  type: "BatchNorm"
  bottom: "res_stage_3_254_3"
  top: "res_stage_3_254_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_254_3"  
  type: "Scale"
  bottom: "res_stage_3_254_3"
  top: "res_stage_3_254_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_254"
  type: "Eltwise"
  bottom: "res_3_253"
  bottom: "res_stage_3_254_3_top"
  top: "res_3_254"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_254_relu"
  type: "ReLU"
  bottom: "res_3_254"
  top: "res_3_254"
}
layer {
  name: "res_stage_3_255_1"
  type: "Convolution"
  bottom: "res_3_254"
  top: "res_stage_3_255_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_255_1"
  type: "BatchNorm"
  bottom: "res_stage_3_255_1"
  top: "res_stage_3_255_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_255_1"  
  type: "Scale"
  bottom: "res_stage_3_255_1"
  top: "res_stage_3_255_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_255_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_255_1_top"
  top: "res_stage_3_255_1_top"
}
layer {
  name: "res_stage_3_255_2"
  type: "Convolution"
  bottom: "res_stage_3_255_1_top"
  top: "res_stage_3_255_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_255_2"
  type: "BatchNorm"
  bottom: "res_stage_3_255_2"
  top: "res_stage_3_255_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_255_2"  
  type: "Scale"
  bottom: "res_stage_3_255_2"
  top: "res_stage_3_255_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_255_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_255_2_top"
  top: "res_stage_3_255_2_top"
}
layer {
  name: "res_stage_3_255_3"
  type: "Convolution"
  bottom: "res_stage_3_255_2_top"
  top: "res_stage_3_255_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_255_3"
  type: "BatchNorm"
  bottom: "res_stage_3_255_3"
  top: "res_stage_3_255_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_255_3"  
  type: "Scale"
  bottom: "res_stage_3_255_3"
  top: "res_stage_3_255_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_255"
  type: "Eltwise"
  bottom: "res_3_254"
  bottom: "res_stage_3_255_3_top"
  top: "res_3_255"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_255_relu"
  type: "ReLU"
  bottom: "res_3_255"
  top: "res_3_255"
}
layer {
  name: "res_stage_3_256_1"
  type: "Convolution"
  bottom: "res_3_255"
  top: "res_stage_3_256_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_256_1"
  type: "BatchNorm"
  bottom: "res_stage_3_256_1"
  top: "res_stage_3_256_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_256_1"  
  type: "Scale"
  bottom: "res_stage_3_256_1"
  top: "res_stage_3_256_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_256_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_256_1_top"
  top: "res_stage_3_256_1_top"
}
layer {
  name: "res_stage_3_256_2"
  type: "Convolution"
  bottom: "res_stage_3_256_1_top"
  top: "res_stage_3_256_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_256_2"
  type: "BatchNorm"
  bottom: "res_stage_3_256_2"
  top: "res_stage_3_256_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_256_2"  
  type: "Scale"
  bottom: "res_stage_3_256_2"
  top: "res_stage_3_256_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_256_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_256_2_top"
  top: "res_stage_3_256_2_top"
}
layer {
  name: "res_stage_3_256_3"
  type: "Convolution"
  bottom: "res_stage_3_256_2_top"
  top: "res_stage_3_256_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_256_3"
  type: "BatchNorm"
  bottom: "res_stage_3_256_3"
  top: "res_stage_3_256_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_256_3"  
  type: "Scale"
  bottom: "res_stage_3_256_3"
  top: "res_stage_3_256_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_256"
  type: "Eltwise"
  bottom: "res_3_255"
  bottom: "res_stage_3_256_3_top"
  top: "res_3_256"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_256_relu"
  type: "ReLU"
  bottom: "res_3_256"
  top: "res_3_256"
}
layer {
  name: "res_stage_3_257_1"
  type: "Convolution"
  bottom: "res_3_256"
  top: "res_stage_3_257_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_257_1"
  type: "BatchNorm"
  bottom: "res_stage_3_257_1"
  top: "res_stage_3_257_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_257_1"  
  type: "Scale"
  bottom: "res_stage_3_257_1"
  top: "res_stage_3_257_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_257_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_257_1_top"
  top: "res_stage_3_257_1_top"
}
layer {
  name: "res_stage_3_257_2"
  type: "Convolution"
  bottom: "res_stage_3_257_1_top"
  top: "res_stage_3_257_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_257_2"
  type: "BatchNorm"
  bottom: "res_stage_3_257_2"
  top: "res_stage_3_257_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_257_2"  
  type: "Scale"
  bottom: "res_stage_3_257_2"
  top: "res_stage_3_257_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_257_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_257_2_top"
  top: "res_stage_3_257_2_top"
}
layer {
  name: "res_stage_3_257_3"
  type: "Convolution"
  bottom: "res_stage_3_257_2_top"
  top: "res_stage_3_257_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_257_3"
  type: "BatchNorm"
  bottom: "res_stage_3_257_3"
  top: "res_stage_3_257_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_257_3"  
  type: "Scale"
  bottom: "res_stage_3_257_3"
  top: "res_stage_3_257_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_257"
  type: "Eltwise"
  bottom: "res_3_256"
  bottom: "res_stage_3_257_3_top"
  top: "res_3_257"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_257_relu"
  type: "ReLU"
  bottom: "res_3_257"
  top: "res_3_257"
}
layer {
  name: "res_stage_3_258_1"
  type: "Convolution"
  bottom: "res_3_257"
  top: "res_stage_3_258_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_258_1"
  type: "BatchNorm"
  bottom: "res_stage_3_258_1"
  top: "res_stage_3_258_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_258_1"  
  type: "Scale"
  bottom: "res_stage_3_258_1"
  top: "res_stage_3_258_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_258_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_258_1_top"
  top: "res_stage_3_258_1_top"
}
layer {
  name: "res_stage_3_258_2"
  type: "Convolution"
  bottom: "res_stage_3_258_1_top"
  top: "res_stage_3_258_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_258_2"
  type: "BatchNorm"
  bottom: "res_stage_3_258_2"
  top: "res_stage_3_258_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_258_2"  
  type: "Scale"
  bottom: "res_stage_3_258_2"
  top: "res_stage_3_258_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_258_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_258_2_top"
  top: "res_stage_3_258_2_top"
}
layer {
  name: "res_stage_3_258_3"
  type: "Convolution"
  bottom: "res_stage_3_258_2_top"
  top: "res_stage_3_258_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_258_3"
  type: "BatchNorm"
  bottom: "res_stage_3_258_3"
  top: "res_stage_3_258_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_258_3"  
  type: "Scale"
  bottom: "res_stage_3_258_3"
  top: "res_stage_3_258_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_258"
  type: "Eltwise"
  bottom: "res_3_257"
  bottom: "res_stage_3_258_3_top"
  top: "res_3_258"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_258_relu"
  type: "ReLU"
  bottom: "res_3_258"
  top: "res_3_258"
}
layer {
  name: "res_stage_3_259_1"
  type: "Convolution"
  bottom: "res_3_258"
  top: "res_stage_3_259_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_259_1"
  type: "BatchNorm"
  bottom: "res_stage_3_259_1"
  top: "res_stage_3_259_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_259_1"  
  type: "Scale"
  bottom: "res_stage_3_259_1"
  top: "res_stage_3_259_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_259_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_259_1_top"
  top: "res_stage_3_259_1_top"
}
layer {
  name: "res_stage_3_259_2"
  type: "Convolution"
  bottom: "res_stage_3_259_1_top"
  top: "res_stage_3_259_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_259_2"
  type: "BatchNorm"
  bottom: "res_stage_3_259_2"
  top: "res_stage_3_259_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_259_2"  
  type: "Scale"
  bottom: "res_stage_3_259_2"
  top: "res_stage_3_259_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_259_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_259_2_top"
  top: "res_stage_3_259_2_top"
}
layer {
  name: "res_stage_3_259_3"
  type: "Convolution"
  bottom: "res_stage_3_259_2_top"
  top: "res_stage_3_259_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_259_3"
  type: "BatchNorm"
  bottom: "res_stage_3_259_3"
  top: "res_stage_3_259_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_259_3"  
  type: "Scale"
  bottom: "res_stage_3_259_3"
  top: "res_stage_3_259_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_259"
  type: "Eltwise"
  bottom: "res_3_258"
  bottom: "res_stage_3_259_3_top"
  top: "res_3_259"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_259_relu"
  type: "ReLU"
  bottom: "res_3_259"
  top: "res_3_259"
}
layer {
  name: "res_stage_3_260_1"
  type: "Convolution"
  bottom: "res_3_259"
  top: "res_stage_3_260_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_260_1"
  type: "BatchNorm"
  bottom: "res_stage_3_260_1"
  top: "res_stage_3_260_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_260_1"  
  type: "Scale"
  bottom: "res_stage_3_260_1"
  top: "res_stage_3_260_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_260_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_260_1_top"
  top: "res_stage_3_260_1_top"
}
layer {
  name: "res_stage_3_260_2"
  type: "Convolution"
  bottom: "res_stage_3_260_1_top"
  top: "res_stage_3_260_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_260_2"
  type: "BatchNorm"
  bottom: "res_stage_3_260_2"
  top: "res_stage_3_260_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_260_2"  
  type: "Scale"
  bottom: "res_stage_3_260_2"
  top: "res_stage_3_260_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_260_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_260_2_top"
  top: "res_stage_3_260_2_top"
}
layer {
  name: "res_stage_3_260_3"
  type: "Convolution"
  bottom: "res_stage_3_260_2_top"
  top: "res_stage_3_260_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_260_3"
  type: "BatchNorm"
  bottom: "res_stage_3_260_3"
  top: "res_stage_3_260_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_260_3"  
  type: "Scale"
  bottom: "res_stage_3_260_3"
  top: "res_stage_3_260_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_260"
  type: "Eltwise"
  bottom: "res_3_259"
  bottom: "res_stage_3_260_3_top"
  top: "res_3_260"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_260_relu"
  type: "ReLU"
  bottom: "res_3_260"
  top: "res_3_260"
}
layer {
  name: "res_stage_3_261_1"
  type: "Convolution"
  bottom: "res_3_260"
  top: "res_stage_3_261_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_261_1"
  type: "BatchNorm"
  bottom: "res_stage_3_261_1"
  top: "res_stage_3_261_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_261_1"  
  type: "Scale"
  bottom: "res_stage_3_261_1"
  top: "res_stage_3_261_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_261_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_261_1_top"
  top: "res_stage_3_261_1_top"
}
layer {
  name: "res_stage_3_261_2"
  type: "Convolution"
  bottom: "res_stage_3_261_1_top"
  top: "res_stage_3_261_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_261_2"
  type: "BatchNorm"
  bottom: "res_stage_3_261_2"
  top: "res_stage_3_261_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_261_2"  
  type: "Scale"
  bottom: "res_stage_3_261_2"
  top: "res_stage_3_261_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_261_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_261_2_top"
  top: "res_stage_3_261_2_top"
}
layer {
  name: "res_stage_3_261_3"
  type: "Convolution"
  bottom: "res_stage_3_261_2_top"
  top: "res_stage_3_261_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_261_3"
  type: "BatchNorm"
  bottom: "res_stage_3_261_3"
  top: "res_stage_3_261_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_261_3"  
  type: "Scale"
  bottom: "res_stage_3_261_3"
  top: "res_stage_3_261_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_261"
  type: "Eltwise"
  bottom: "res_3_260"
  bottom: "res_stage_3_261_3_top"
  top: "res_3_261"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_261_relu"
  type: "ReLU"
  bottom: "res_3_261"
  top: "res_3_261"
}
layer {
  name: "res_stage_3_262_1"
  type: "Convolution"
  bottom: "res_3_261"
  top: "res_stage_3_262_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_262_1"
  type: "BatchNorm"
  bottom: "res_stage_3_262_1"
  top: "res_stage_3_262_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_262_1"  
  type: "Scale"
  bottom: "res_stage_3_262_1"
  top: "res_stage_3_262_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_262_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_262_1_top"
  top: "res_stage_3_262_1_top"
}
layer {
  name: "res_stage_3_262_2"
  type: "Convolution"
  bottom: "res_stage_3_262_1_top"
  top: "res_stage_3_262_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_262_2"
  type: "BatchNorm"
  bottom: "res_stage_3_262_2"
  top: "res_stage_3_262_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_262_2"  
  type: "Scale"
  bottom: "res_stage_3_262_2"
  top: "res_stage_3_262_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_262_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_262_2_top"
  top: "res_stage_3_262_2_top"
}
layer {
  name: "res_stage_3_262_3"
  type: "Convolution"
  bottom: "res_stage_3_262_2_top"
  top: "res_stage_3_262_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_262_3"
  type: "BatchNorm"
  bottom: "res_stage_3_262_3"
  top: "res_stage_3_262_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_262_3"  
  type: "Scale"
  bottom: "res_stage_3_262_3"
  top: "res_stage_3_262_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_262"
  type: "Eltwise"
  bottom: "res_3_261"
  bottom: "res_stage_3_262_3_top"
  top: "res_3_262"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_262_relu"
  type: "ReLU"
  bottom: "res_3_262"
  top: "res_3_262"
}
layer {
  name: "res_stage_3_263_1"
  type: "Convolution"
  bottom: "res_3_262"
  top: "res_stage_3_263_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_263_1"
  type: "BatchNorm"
  bottom: "res_stage_3_263_1"
  top: "res_stage_3_263_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_263_1"  
  type: "Scale"
  bottom: "res_stage_3_263_1"
  top: "res_stage_3_263_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_263_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_263_1_top"
  top: "res_stage_3_263_1_top"
}
layer {
  name: "res_stage_3_263_2"
  type: "Convolution"
  bottom: "res_stage_3_263_1_top"
  top: "res_stage_3_263_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_263_2"
  type: "BatchNorm"
  bottom: "res_stage_3_263_2"
  top: "res_stage_3_263_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_263_2"  
  type: "Scale"
  bottom: "res_stage_3_263_2"
  top: "res_stage_3_263_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_263_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_263_2_top"
  top: "res_stage_3_263_2_top"
}
layer {
  name: "res_stage_3_263_3"
  type: "Convolution"
  bottom: "res_stage_3_263_2_top"
  top: "res_stage_3_263_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_263_3"
  type: "BatchNorm"
  bottom: "res_stage_3_263_3"
  top: "res_stage_3_263_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_263_3"  
  type: "Scale"
  bottom: "res_stage_3_263_3"
  top: "res_stage_3_263_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_263"
  type: "Eltwise"
  bottom: "res_3_262"
  bottom: "res_stage_3_263_3_top"
  top: "res_3_263"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_263_relu"
  type: "ReLU"
  bottom: "res_3_263"
  top: "res_3_263"
}
layer {
  name: "res_stage_3_264_1"
  type: "Convolution"
  bottom: "res_3_263"
  top: "res_stage_3_264_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_264_1"
  type: "BatchNorm"
  bottom: "res_stage_3_264_1"
  top: "res_stage_3_264_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_264_1"  
  type: "Scale"
  bottom: "res_stage_3_264_1"
  top: "res_stage_3_264_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_264_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_264_1_top"
  top: "res_stage_3_264_1_top"
}
layer {
  name: "res_stage_3_264_2"
  type: "Convolution"
  bottom: "res_stage_3_264_1_top"
  top: "res_stage_3_264_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_264_2"
  type: "BatchNorm"
  bottom: "res_stage_3_264_2"
  top: "res_stage_3_264_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_264_2"  
  type: "Scale"
  bottom: "res_stage_3_264_2"
  top: "res_stage_3_264_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_264_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_264_2_top"
  top: "res_stage_3_264_2_top"
}
layer {
  name: "res_stage_3_264_3"
  type: "Convolution"
  bottom: "res_stage_3_264_2_top"
  top: "res_stage_3_264_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_264_3"
  type: "BatchNorm"
  bottom: "res_stage_3_264_3"
  top: "res_stage_3_264_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_264_3"  
  type: "Scale"
  bottom: "res_stage_3_264_3"
  top: "res_stage_3_264_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_264"
  type: "Eltwise"
  bottom: "res_3_263"
  bottom: "res_stage_3_264_3_top"
  top: "res_3_264"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_264_relu"
  type: "ReLU"
  bottom: "res_3_264"
  top: "res_3_264"
}
layer {
  name: "res_stage_3_265_1"
  type: "Convolution"
  bottom: "res_3_264"
  top: "res_stage_3_265_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_265_1"
  type: "BatchNorm"
  bottom: "res_stage_3_265_1"
  top: "res_stage_3_265_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_265_1"  
  type: "Scale"
  bottom: "res_stage_3_265_1"
  top: "res_stage_3_265_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_265_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_265_1_top"
  top: "res_stage_3_265_1_top"
}
layer {
  name: "res_stage_3_265_2"
  type: "Convolution"
  bottom: "res_stage_3_265_1_top"
  top: "res_stage_3_265_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_265_2"
  type: "BatchNorm"
  bottom: "res_stage_3_265_2"
  top: "res_stage_3_265_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_265_2"  
  type: "Scale"
  bottom: "res_stage_3_265_2"
  top: "res_stage_3_265_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_265_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_265_2_top"
  top: "res_stage_3_265_2_top"
}
layer {
  name: "res_stage_3_265_3"
  type: "Convolution"
  bottom: "res_stage_3_265_2_top"
  top: "res_stage_3_265_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_265_3"
  type: "BatchNorm"
  bottom: "res_stage_3_265_3"
  top: "res_stage_3_265_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_265_3"  
  type: "Scale"
  bottom: "res_stage_3_265_3"
  top: "res_stage_3_265_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_265"
  type: "Eltwise"
  bottom: "res_3_264"
  bottom: "res_stage_3_265_3_top"
  top: "res_3_265"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_265_relu"
  type: "ReLU"
  bottom: "res_3_265"
  top: "res_3_265"
}
layer {
  name: "res_stage_3_266_1"
  type: "Convolution"
  bottom: "res_3_265"
  top: "res_stage_3_266_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_266_1"
  type: "BatchNorm"
  bottom: "res_stage_3_266_1"
  top: "res_stage_3_266_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_266_1"  
  type: "Scale"
  bottom: "res_stage_3_266_1"
  top: "res_stage_3_266_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_266_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_266_1_top"
  top: "res_stage_3_266_1_top"
}
layer {
  name: "res_stage_3_266_2"
  type: "Convolution"
  bottom: "res_stage_3_266_1_top"
  top: "res_stage_3_266_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_266_2"
  type: "BatchNorm"
  bottom: "res_stage_3_266_2"
  top: "res_stage_3_266_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_266_2"  
  type: "Scale"
  bottom: "res_stage_3_266_2"
  top: "res_stage_3_266_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_266_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_266_2_top"
  top: "res_stage_3_266_2_top"
}
layer {
  name: "res_stage_3_266_3"
  type: "Convolution"
  bottom: "res_stage_3_266_2_top"
  top: "res_stage_3_266_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_266_3"
  type: "BatchNorm"
  bottom: "res_stage_3_266_3"
  top: "res_stage_3_266_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_266_3"  
  type: "Scale"
  bottom: "res_stage_3_266_3"
  top: "res_stage_3_266_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_266"
  type: "Eltwise"
  bottom: "res_3_265"
  bottom: "res_stage_3_266_3_top"
  top: "res_3_266"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_266_relu"
  type: "ReLU"
  bottom: "res_3_266"
  top: "res_3_266"
}
layer {
  name: "res_stage_3_267_1"
  type: "Convolution"
  bottom: "res_3_266"
  top: "res_stage_3_267_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_267_1"
  type: "BatchNorm"
  bottom: "res_stage_3_267_1"
  top: "res_stage_3_267_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_267_1"  
  type: "Scale"
  bottom: "res_stage_3_267_1"
  top: "res_stage_3_267_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_267_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_267_1_top"
  top: "res_stage_3_267_1_top"
}
layer {
  name: "res_stage_3_267_2"
  type: "Convolution"
  bottom: "res_stage_3_267_1_top"
  top: "res_stage_3_267_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_267_2"
  type: "BatchNorm"
  bottom: "res_stage_3_267_2"
  top: "res_stage_3_267_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_267_2"  
  type: "Scale"
  bottom: "res_stage_3_267_2"
  top: "res_stage_3_267_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_267_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_267_2_top"
  top: "res_stage_3_267_2_top"
}
layer {
  name: "res_stage_3_267_3"
  type: "Convolution"
  bottom: "res_stage_3_267_2_top"
  top: "res_stage_3_267_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_267_3"
  type: "BatchNorm"
  bottom: "res_stage_3_267_3"
  top: "res_stage_3_267_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_267_3"  
  type: "Scale"
  bottom: "res_stage_3_267_3"
  top: "res_stage_3_267_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_267"
  type: "Eltwise"
  bottom: "res_3_266"
  bottom: "res_stage_3_267_3_top"
  top: "res_3_267"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_267_relu"
  type: "ReLU"
  bottom: "res_3_267"
  top: "res_3_267"
}
layer {
  name: "res_stage_3_268_1"
  type: "Convolution"
  bottom: "res_3_267"
  top: "res_stage_3_268_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_268_1"
  type: "BatchNorm"
  bottom: "res_stage_3_268_1"
  top: "res_stage_3_268_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_268_1"  
  type: "Scale"
  bottom: "res_stage_3_268_1"
  top: "res_stage_3_268_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_268_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_268_1_top"
  top: "res_stage_3_268_1_top"
}
layer {
  name: "res_stage_3_268_2"
  type: "Convolution"
  bottom: "res_stage_3_268_1_top"
  top: "res_stage_3_268_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_268_2"
  type: "BatchNorm"
  bottom: "res_stage_3_268_2"
  top: "res_stage_3_268_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_268_2"  
  type: "Scale"
  bottom: "res_stage_3_268_2"
  top: "res_stage_3_268_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_268_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_268_2_top"
  top: "res_stage_3_268_2_top"
}
layer {
  name: "res_stage_3_268_3"
  type: "Convolution"
  bottom: "res_stage_3_268_2_top"
  top: "res_stage_3_268_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_268_3"
  type: "BatchNorm"
  bottom: "res_stage_3_268_3"
  top: "res_stage_3_268_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_268_3"  
  type: "Scale"
  bottom: "res_stage_3_268_3"
  top: "res_stage_3_268_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_268"
  type: "Eltwise"
  bottom: "res_3_267"
  bottom: "res_stage_3_268_3_top"
  top: "res_3_268"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_268_relu"
  type: "ReLU"
  bottom: "res_3_268"
  top: "res_3_268"
}
layer {
  name: "res_stage_3_269_1"
  type: "Convolution"
  bottom: "res_3_268"
  top: "res_stage_3_269_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_269_1"
  type: "BatchNorm"
  bottom: "res_stage_3_269_1"
  top: "res_stage_3_269_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_269_1"  
  type: "Scale"
  bottom: "res_stage_3_269_1"
  top: "res_stage_3_269_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_269_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_269_1_top"
  top: "res_stage_3_269_1_top"
}
layer {
  name: "res_stage_3_269_2"
  type: "Convolution"
  bottom: "res_stage_3_269_1_top"
  top: "res_stage_3_269_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_269_2"
  type: "BatchNorm"
  bottom: "res_stage_3_269_2"
  top: "res_stage_3_269_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_269_2"  
  type: "Scale"
  bottom: "res_stage_3_269_2"
  top: "res_stage_3_269_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_269_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_269_2_top"
  top: "res_stage_3_269_2_top"
}
layer {
  name: "res_stage_3_269_3"
  type: "Convolution"
  bottom: "res_stage_3_269_2_top"
  top: "res_stage_3_269_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_269_3"
  type: "BatchNorm"
  bottom: "res_stage_3_269_3"
  top: "res_stage_3_269_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_269_3"  
  type: "Scale"
  bottom: "res_stage_3_269_3"
  top: "res_stage_3_269_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_269"
  type: "Eltwise"
  bottom: "res_3_268"
  bottom: "res_stage_3_269_3_top"
  top: "res_3_269"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_269_relu"
  type: "ReLU"
  bottom: "res_3_269"
  top: "res_3_269"
}
layer {
  name: "res_stage_3_270_1"
  type: "Convolution"
  bottom: "res_3_269"
  top: "res_stage_3_270_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_270_1"
  type: "BatchNorm"
  bottom: "res_stage_3_270_1"
  top: "res_stage_3_270_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_270_1"  
  type: "Scale"
  bottom: "res_stage_3_270_1"
  top: "res_stage_3_270_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_270_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_270_1_top"
  top: "res_stage_3_270_1_top"
}
layer {
  name: "res_stage_3_270_2"
  type: "Convolution"
  bottom: "res_stage_3_270_1_top"
  top: "res_stage_3_270_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_270_2"
  type: "BatchNorm"
  bottom: "res_stage_3_270_2"
  top: "res_stage_3_270_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_270_2"  
  type: "Scale"
  bottom: "res_stage_3_270_2"
  top: "res_stage_3_270_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_270_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_270_2_top"
  top: "res_stage_3_270_2_top"
}
layer {
  name: "res_stage_3_270_3"
  type: "Convolution"
  bottom: "res_stage_3_270_2_top"
  top: "res_stage_3_270_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_270_3"
  type: "BatchNorm"
  bottom: "res_stage_3_270_3"
  top: "res_stage_3_270_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_270_3"  
  type: "Scale"
  bottom: "res_stage_3_270_3"
  top: "res_stage_3_270_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_270"
  type: "Eltwise"
  bottom: "res_3_269"
  bottom: "res_stage_3_270_3_top"
  top: "res_3_270"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_270_relu"
  type: "ReLU"
  bottom: "res_3_270"
  top: "res_3_270"
}
layer {
  name: "res_stage_3_271_1"
  type: "Convolution"
  bottom: "res_3_270"
  top: "res_stage_3_271_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_271_1"
  type: "BatchNorm"
  bottom: "res_stage_3_271_1"
  top: "res_stage_3_271_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_271_1"  
  type: "Scale"
  bottom: "res_stage_3_271_1"
  top: "res_stage_3_271_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_271_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_271_1_top"
  top: "res_stage_3_271_1_top"
}
layer {
  name: "res_stage_3_271_2"
  type: "Convolution"
  bottom: "res_stage_3_271_1_top"
  top: "res_stage_3_271_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_271_2"
  type: "BatchNorm"
  bottom: "res_stage_3_271_2"
  top: "res_stage_3_271_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_271_2"  
  type: "Scale"
  bottom: "res_stage_3_271_2"
  top: "res_stage_3_271_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_271_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_271_2_top"
  top: "res_stage_3_271_2_top"
}
layer {
  name: "res_stage_3_271_3"
  type: "Convolution"
  bottom: "res_stage_3_271_2_top"
  top: "res_stage_3_271_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_271_3"
  type: "BatchNorm"
  bottom: "res_stage_3_271_3"
  top: "res_stage_3_271_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_271_3"  
  type: "Scale"
  bottom: "res_stage_3_271_3"
  top: "res_stage_3_271_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_271"
  type: "Eltwise"
  bottom: "res_3_270"
  bottom: "res_stage_3_271_3_top"
  top: "res_3_271"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_271_relu"
  type: "ReLU"
  bottom: "res_3_271"
  top: "res_3_271"
}
layer {
  name: "res_stage_3_272_1"
  type: "Convolution"
  bottom: "res_3_271"
  top: "res_stage_3_272_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_272_1"
  type: "BatchNorm"
  bottom: "res_stage_3_272_1"
  top: "res_stage_3_272_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_272_1"  
  type: "Scale"
  bottom: "res_stage_3_272_1"
  top: "res_stage_3_272_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_272_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_272_1_top"
  top: "res_stage_3_272_1_top"
}
layer {
  name: "res_stage_3_272_2"
  type: "Convolution"
  bottom: "res_stage_3_272_1_top"
  top: "res_stage_3_272_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_272_2"
  type: "BatchNorm"
  bottom: "res_stage_3_272_2"
  top: "res_stage_3_272_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_272_2"  
  type: "Scale"
  bottom: "res_stage_3_272_2"
  top: "res_stage_3_272_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_272_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_272_2_top"
  top: "res_stage_3_272_2_top"
}
layer {
  name: "res_stage_3_272_3"
  type: "Convolution"
  bottom: "res_stage_3_272_2_top"
  top: "res_stage_3_272_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_272_3"
  type: "BatchNorm"
  bottom: "res_stage_3_272_3"
  top: "res_stage_3_272_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_272_3"  
  type: "Scale"
  bottom: "res_stage_3_272_3"
  top: "res_stage_3_272_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_272"
  type: "Eltwise"
  bottom: "res_3_271"
  bottom: "res_stage_3_272_3_top"
  top: "res_3_272"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_272_relu"
  type: "ReLU"
  bottom: "res_3_272"
  top: "res_3_272"
}
layer {
  name: "res_stage_3_273_1"
  type: "Convolution"
  bottom: "res_3_272"
  top: "res_stage_3_273_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_273_1"
  type: "BatchNorm"
  bottom: "res_stage_3_273_1"
  top: "res_stage_3_273_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_273_1"  
  type: "Scale"
  bottom: "res_stage_3_273_1"
  top: "res_stage_3_273_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_273_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_273_1_top"
  top: "res_stage_3_273_1_top"
}
layer {
  name: "res_stage_3_273_2"
  type: "Convolution"
  bottom: "res_stage_3_273_1_top"
  top: "res_stage_3_273_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_273_2"
  type: "BatchNorm"
  bottom: "res_stage_3_273_2"
  top: "res_stage_3_273_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_273_2"  
  type: "Scale"
  bottom: "res_stage_3_273_2"
  top: "res_stage_3_273_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_273_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_273_2_top"
  top: "res_stage_3_273_2_top"
}
layer {
  name: "res_stage_3_273_3"
  type: "Convolution"
  bottom: "res_stage_3_273_2_top"
  top: "res_stage_3_273_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_273_3"
  type: "BatchNorm"
  bottom: "res_stage_3_273_3"
  top: "res_stage_3_273_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_273_3"  
  type: "Scale"
  bottom: "res_stage_3_273_3"
  top: "res_stage_3_273_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_273"
  type: "Eltwise"
  bottom: "res_3_272"
  bottom: "res_stage_3_273_3_top"
  top: "res_3_273"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_273_relu"
  type: "ReLU"
  bottom: "res_3_273"
  top: "res_3_273"
}
layer {
  name: "res_stage_3_274_1"
  type: "Convolution"
  bottom: "res_3_273"
  top: "res_stage_3_274_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_274_1"
  type: "BatchNorm"
  bottom: "res_stage_3_274_1"
  top: "res_stage_3_274_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_274_1"  
  type: "Scale"
  bottom: "res_stage_3_274_1"
  top: "res_stage_3_274_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_274_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_274_1_top"
  top: "res_stage_3_274_1_top"
}
layer {
  name: "res_stage_3_274_2"
  type: "Convolution"
  bottom: "res_stage_3_274_1_top"
  top: "res_stage_3_274_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_274_2"
  type: "BatchNorm"
  bottom: "res_stage_3_274_2"
  top: "res_stage_3_274_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_274_2"  
  type: "Scale"
  bottom: "res_stage_3_274_2"
  top: "res_stage_3_274_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_274_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_274_2_top"
  top: "res_stage_3_274_2_top"
}
layer {
  name: "res_stage_3_274_3"
  type: "Convolution"
  bottom: "res_stage_3_274_2_top"
  top: "res_stage_3_274_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_274_3"
  type: "BatchNorm"
  bottom: "res_stage_3_274_3"
  top: "res_stage_3_274_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_274_3"  
  type: "Scale"
  bottom: "res_stage_3_274_3"
  top: "res_stage_3_274_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_274"
  type: "Eltwise"
  bottom: "res_3_273"
  bottom: "res_stage_3_274_3_top"
  top: "res_3_274"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_274_relu"
  type: "ReLU"
  bottom: "res_3_274"
  top: "res_3_274"
}
layer {
  name: "res_stage_3_275_1"
  type: "Convolution"
  bottom: "res_3_274"
  top: "res_stage_3_275_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_275_1"
  type: "BatchNorm"
  bottom: "res_stage_3_275_1"
  top: "res_stage_3_275_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_275_1"  
  type: "Scale"
  bottom: "res_stage_3_275_1"
  top: "res_stage_3_275_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_275_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_275_1_top"
  top: "res_stage_3_275_1_top"
}
layer {
  name: "res_stage_3_275_2"
  type: "Convolution"
  bottom: "res_stage_3_275_1_top"
  top: "res_stage_3_275_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_275_2"
  type: "BatchNorm"
  bottom: "res_stage_3_275_2"
  top: "res_stage_3_275_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_275_2"  
  type: "Scale"
  bottom: "res_stage_3_275_2"
  top: "res_stage_3_275_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_275_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_275_2_top"
  top: "res_stage_3_275_2_top"
}
layer {
  name: "res_stage_3_275_3"
  type: "Convolution"
  bottom: "res_stage_3_275_2_top"
  top: "res_stage_3_275_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_275_3"
  type: "BatchNorm"
  bottom: "res_stage_3_275_3"
  top: "res_stage_3_275_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_275_3"  
  type: "Scale"
  bottom: "res_stage_3_275_3"
  top: "res_stage_3_275_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_275"
  type: "Eltwise"
  bottom: "res_3_274"
  bottom: "res_stage_3_275_3_top"
  top: "res_3_275"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_275_relu"
  type: "ReLU"
  bottom: "res_3_275"
  top: "res_3_275"
}
layer {
  name: "res_stage_3_276_1"
  type: "Convolution"
  bottom: "res_3_275"
  top: "res_stage_3_276_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_276_1"
  type: "BatchNorm"
  bottom: "res_stage_3_276_1"
  top: "res_stage_3_276_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_276_1"  
  type: "Scale"
  bottom: "res_stage_3_276_1"
  top: "res_stage_3_276_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_276_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_276_1_top"
  top: "res_stage_3_276_1_top"
}
layer {
  name: "res_stage_3_276_2"
  type: "Convolution"
  bottom: "res_stage_3_276_1_top"
  top: "res_stage_3_276_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_276_2"
  type: "BatchNorm"
  bottom: "res_stage_3_276_2"
  top: "res_stage_3_276_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_276_2"  
  type: "Scale"
  bottom: "res_stage_3_276_2"
  top: "res_stage_3_276_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_276_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_276_2_top"
  top: "res_stage_3_276_2_top"
}
layer {
  name: "res_stage_3_276_3"
  type: "Convolution"
  bottom: "res_stage_3_276_2_top"
  top: "res_stage_3_276_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_276_3"
  type: "BatchNorm"
  bottom: "res_stage_3_276_3"
  top: "res_stage_3_276_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_276_3"  
  type: "Scale"
  bottom: "res_stage_3_276_3"
  top: "res_stage_3_276_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_276"
  type: "Eltwise"
  bottom: "res_3_275"
  bottom: "res_stage_3_276_3_top"
  top: "res_3_276"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_276_relu"
  type: "ReLU"
  bottom: "res_3_276"
  top: "res_3_276"
}
layer {
  name: "res_stage_3_277_1"
  type: "Convolution"
  bottom: "res_3_276"
  top: "res_stage_3_277_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_277_1"
  type: "BatchNorm"
  bottom: "res_stage_3_277_1"
  top: "res_stage_3_277_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_277_1"  
  type: "Scale"
  bottom: "res_stage_3_277_1"
  top: "res_stage_3_277_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_277_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_277_1_top"
  top: "res_stage_3_277_1_top"
}
layer {
  name: "res_stage_3_277_2"
  type: "Convolution"
  bottom: "res_stage_3_277_1_top"
  top: "res_stage_3_277_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_277_2"
  type: "BatchNorm"
  bottom: "res_stage_3_277_2"
  top: "res_stage_3_277_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_277_2"  
  type: "Scale"
  bottom: "res_stage_3_277_2"
  top: "res_stage_3_277_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_277_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_277_2_top"
  top: "res_stage_3_277_2_top"
}
layer {
  name: "res_stage_3_277_3"
  type: "Convolution"
  bottom: "res_stage_3_277_2_top"
  top: "res_stage_3_277_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_277_3"
  type: "BatchNorm"
  bottom: "res_stage_3_277_3"
  top: "res_stage_3_277_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_277_3"  
  type: "Scale"
  bottom: "res_stage_3_277_3"
  top: "res_stage_3_277_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_277"
  type: "Eltwise"
  bottom: "res_3_276"
  bottom: "res_stage_3_277_3_top"
  top: "res_3_277"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_277_relu"
  type: "ReLU"
  bottom: "res_3_277"
  top: "res_3_277"
}
layer {
  name: "res_stage_3_278_1"
  type: "Convolution"
  bottom: "res_3_277"
  top: "res_stage_3_278_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_278_1"
  type: "BatchNorm"
  bottom: "res_stage_3_278_1"
  top: "res_stage_3_278_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_278_1"  
  type: "Scale"
  bottom: "res_stage_3_278_1"
  top: "res_stage_3_278_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_278_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_278_1_top"
  top: "res_stage_3_278_1_top"
}
layer {
  name: "res_stage_3_278_2"
  type: "Convolution"
  bottom: "res_stage_3_278_1_top"
  top: "res_stage_3_278_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_278_2"
  type: "BatchNorm"
  bottom: "res_stage_3_278_2"
  top: "res_stage_3_278_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_278_2"  
  type: "Scale"
  bottom: "res_stage_3_278_2"
  top: "res_stage_3_278_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_278_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_278_2_top"
  top: "res_stage_3_278_2_top"
}
layer {
  name: "res_stage_3_278_3"
  type: "Convolution"
  bottom: "res_stage_3_278_2_top"
  top: "res_stage_3_278_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_278_3"
  type: "BatchNorm"
  bottom: "res_stage_3_278_3"
  top: "res_stage_3_278_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_278_3"  
  type: "Scale"
  bottom: "res_stage_3_278_3"
  top: "res_stage_3_278_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_278"
  type: "Eltwise"
  bottom: "res_3_277"
  bottom: "res_stage_3_278_3_top"
  top: "res_3_278"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_278_relu"
  type: "ReLU"
  bottom: "res_3_278"
  top: "res_3_278"
}
layer {
  name: "res_stage_3_279_1"
  type: "Convolution"
  bottom: "res_3_278"
  top: "res_stage_3_279_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_279_1"
  type: "BatchNorm"
  bottom: "res_stage_3_279_1"
  top: "res_stage_3_279_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_279_1"  
  type: "Scale"
  bottom: "res_stage_3_279_1"
  top: "res_stage_3_279_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_279_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_279_1_top"
  top: "res_stage_3_279_1_top"
}
layer {
  name: "res_stage_3_279_2"
  type: "Convolution"
  bottom: "res_stage_3_279_1_top"
  top: "res_stage_3_279_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_279_2"
  type: "BatchNorm"
  bottom: "res_stage_3_279_2"
  top: "res_stage_3_279_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_279_2"  
  type: "Scale"
  bottom: "res_stage_3_279_2"
  top: "res_stage_3_279_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_279_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_279_2_top"
  top: "res_stage_3_279_2_top"
}
layer {
  name: "res_stage_3_279_3"
  type: "Convolution"
  bottom: "res_stage_3_279_2_top"
  top: "res_stage_3_279_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_279_3"
  type: "BatchNorm"
  bottom: "res_stage_3_279_3"
  top: "res_stage_3_279_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_279_3"  
  type: "Scale"
  bottom: "res_stage_3_279_3"
  top: "res_stage_3_279_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_279"
  type: "Eltwise"
  bottom: "res_3_278"
  bottom: "res_stage_3_279_3_top"
  top: "res_3_279"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_279_relu"
  type: "ReLU"
  bottom: "res_3_279"
  top: "res_3_279"
}
layer {
  name: "res_stage_3_280_1"
  type: "Convolution"
  bottom: "res_3_279"
  top: "res_stage_3_280_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_280_1"
  type: "BatchNorm"
  bottom: "res_stage_3_280_1"
  top: "res_stage_3_280_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_280_1"  
  type: "Scale"
  bottom: "res_stage_3_280_1"
  top: "res_stage_3_280_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_280_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_280_1_top"
  top: "res_stage_3_280_1_top"
}
layer {
  name: "res_stage_3_280_2"
  type: "Convolution"
  bottom: "res_stage_3_280_1_top"
  top: "res_stage_3_280_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_280_2"
  type: "BatchNorm"
  bottom: "res_stage_3_280_2"
  top: "res_stage_3_280_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_280_2"  
  type: "Scale"
  bottom: "res_stage_3_280_2"
  top: "res_stage_3_280_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_280_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_280_2_top"
  top: "res_stage_3_280_2_top"
}
layer {
  name: "res_stage_3_280_3"
  type: "Convolution"
  bottom: "res_stage_3_280_2_top"
  top: "res_stage_3_280_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_280_3"
  type: "BatchNorm"
  bottom: "res_stage_3_280_3"
  top: "res_stage_3_280_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_280_3"  
  type: "Scale"
  bottom: "res_stage_3_280_3"
  top: "res_stage_3_280_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_280"
  type: "Eltwise"
  bottom: "res_3_279"
  bottom: "res_stage_3_280_3_top"
  top: "res_3_280"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_280_relu"
  type: "ReLU"
  bottom: "res_3_280"
  top: "res_3_280"
}
layer {
  name: "res_stage_3_281_1"
  type: "Convolution"
  bottom: "res_3_280"
  top: "res_stage_3_281_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_281_1"
  type: "BatchNorm"
  bottom: "res_stage_3_281_1"
  top: "res_stage_3_281_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_281_1"  
  type: "Scale"
  bottom: "res_stage_3_281_1"
  top: "res_stage_3_281_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_281_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_281_1_top"
  top: "res_stage_3_281_1_top"
}
layer {
  name: "res_stage_3_281_2"
  type: "Convolution"
  bottom: "res_stage_3_281_1_top"
  top: "res_stage_3_281_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_281_2"
  type: "BatchNorm"
  bottom: "res_stage_3_281_2"
  top: "res_stage_3_281_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_281_2"  
  type: "Scale"
  bottom: "res_stage_3_281_2"
  top: "res_stage_3_281_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_281_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_281_2_top"
  top: "res_stage_3_281_2_top"
}
layer {
  name: "res_stage_3_281_3"
  type: "Convolution"
  bottom: "res_stage_3_281_2_top"
  top: "res_stage_3_281_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_281_3"
  type: "BatchNorm"
  bottom: "res_stage_3_281_3"
  top: "res_stage_3_281_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_281_3"  
  type: "Scale"
  bottom: "res_stage_3_281_3"
  top: "res_stage_3_281_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_281"
  type: "Eltwise"
  bottom: "res_3_280"
  bottom: "res_stage_3_281_3_top"
  top: "res_3_281"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_281_relu"
  type: "ReLU"
  bottom: "res_3_281"
  top: "res_3_281"
}
layer {
  name: "res_stage_3_282_1"
  type: "Convolution"
  bottom: "res_3_281"
  top: "res_stage_3_282_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_282_1"
  type: "BatchNorm"
  bottom: "res_stage_3_282_1"
  top: "res_stage_3_282_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_282_1"  
  type: "Scale"
  bottom: "res_stage_3_282_1"
  top: "res_stage_3_282_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_282_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_282_1_top"
  top: "res_stage_3_282_1_top"
}
layer {
  name: "res_stage_3_282_2"
  type: "Convolution"
  bottom: "res_stage_3_282_1_top"
  top: "res_stage_3_282_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_282_2"
  type: "BatchNorm"
  bottom: "res_stage_3_282_2"
  top: "res_stage_3_282_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_282_2"  
  type: "Scale"
  bottom: "res_stage_3_282_2"
  top: "res_stage_3_282_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_282_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_282_2_top"
  top: "res_stage_3_282_2_top"
}
layer {
  name: "res_stage_3_282_3"
  type: "Convolution"
  bottom: "res_stage_3_282_2_top"
  top: "res_stage_3_282_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_282_3"
  type: "BatchNorm"
  bottom: "res_stage_3_282_3"
  top: "res_stage_3_282_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_282_3"  
  type: "Scale"
  bottom: "res_stage_3_282_3"
  top: "res_stage_3_282_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_282"
  type: "Eltwise"
  bottom: "res_3_281"
  bottom: "res_stage_3_282_3_top"
  top: "res_3_282"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_282_relu"
  type: "ReLU"
  bottom: "res_3_282"
  top: "res_3_282"
}
layer {
  name: "res_stage_3_283_1"
  type: "Convolution"
  bottom: "res_3_282"
  top: "res_stage_3_283_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_283_1"
  type: "BatchNorm"
  bottom: "res_stage_3_283_1"
  top: "res_stage_3_283_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_283_1"  
  type: "Scale"
  bottom: "res_stage_3_283_1"
  top: "res_stage_3_283_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_283_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_283_1_top"
  top: "res_stage_3_283_1_top"
}
layer {
  name: "res_stage_3_283_2"
  type: "Convolution"
  bottom: "res_stage_3_283_1_top"
  top: "res_stage_3_283_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_283_2"
  type: "BatchNorm"
  bottom: "res_stage_3_283_2"
  top: "res_stage_3_283_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_283_2"  
  type: "Scale"
  bottom: "res_stage_3_283_2"
  top: "res_stage_3_283_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_283_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_283_2_top"
  top: "res_stage_3_283_2_top"
}
layer {
  name: "res_stage_3_283_3"
  type: "Convolution"
  bottom: "res_stage_3_283_2_top"
  top: "res_stage_3_283_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_283_3"
  type: "BatchNorm"
  bottom: "res_stage_3_283_3"
  top: "res_stage_3_283_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_283_3"  
  type: "Scale"
  bottom: "res_stage_3_283_3"
  top: "res_stage_3_283_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_283"
  type: "Eltwise"
  bottom: "res_3_282"
  bottom: "res_stage_3_283_3_top"
  top: "res_3_283"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_283_relu"
  type: "ReLU"
  bottom: "res_3_283"
  top: "res_3_283"
}
layer {
  name: "res_stage_3_284_1"
  type: "Convolution"
  bottom: "res_3_283"
  top: "res_stage_3_284_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_284_1"
  type: "BatchNorm"
  bottom: "res_stage_3_284_1"
  top: "res_stage_3_284_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_284_1"  
  type: "Scale"
  bottom: "res_stage_3_284_1"
  top: "res_stage_3_284_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_284_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_284_1_top"
  top: "res_stage_3_284_1_top"
}
layer {
  name: "res_stage_3_284_2"
  type: "Convolution"
  bottom: "res_stage_3_284_1_top"
  top: "res_stage_3_284_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_284_2"
  type: "BatchNorm"
  bottom: "res_stage_3_284_2"
  top: "res_stage_3_284_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_284_2"  
  type: "Scale"
  bottom: "res_stage_3_284_2"
  top: "res_stage_3_284_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_284_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_284_2_top"
  top: "res_stage_3_284_2_top"
}
layer {
  name: "res_stage_3_284_3"
  type: "Convolution"
  bottom: "res_stage_3_284_2_top"
  top: "res_stage_3_284_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_284_3"
  type: "BatchNorm"
  bottom: "res_stage_3_284_3"
  top: "res_stage_3_284_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_284_3"  
  type: "Scale"
  bottom: "res_stage_3_284_3"
  top: "res_stage_3_284_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_284"
  type: "Eltwise"
  bottom: "res_3_283"
  bottom: "res_stage_3_284_3_top"
  top: "res_3_284"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_284_relu"
  type: "ReLU"
  bottom: "res_3_284"
  top: "res_3_284"
}
layer {
  name: "res_stage_3_285_1"
  type: "Convolution"
  bottom: "res_3_284"
  top: "res_stage_3_285_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_285_1"
  type: "BatchNorm"
  bottom: "res_stage_3_285_1"
  top: "res_stage_3_285_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_285_1"  
  type: "Scale"
  bottom: "res_stage_3_285_1"
  top: "res_stage_3_285_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_285_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_285_1_top"
  top: "res_stage_3_285_1_top"
}
layer {
  name: "res_stage_3_285_2"
  type: "Convolution"
  bottom: "res_stage_3_285_1_top"
  top: "res_stage_3_285_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_285_2"
  type: "BatchNorm"
  bottom: "res_stage_3_285_2"
  top: "res_stage_3_285_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_285_2"  
  type: "Scale"
  bottom: "res_stage_3_285_2"
  top: "res_stage_3_285_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_285_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_285_2_top"
  top: "res_stage_3_285_2_top"
}
layer {
  name: "res_stage_3_285_3"
  type: "Convolution"
  bottom: "res_stage_3_285_2_top"
  top: "res_stage_3_285_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_285_3"
  type: "BatchNorm"
  bottom: "res_stage_3_285_3"
  top: "res_stage_3_285_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_285_3"  
  type: "Scale"
  bottom: "res_stage_3_285_3"
  top: "res_stage_3_285_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_285"
  type: "Eltwise"
  bottom: "res_3_284"
  bottom: "res_stage_3_285_3_top"
  top: "res_3_285"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_285_relu"
  type: "ReLU"
  bottom: "res_3_285"
  top: "res_3_285"
}
layer {
  name: "res_stage_3_286_1"
  type: "Convolution"
  bottom: "res_3_285"
  top: "res_stage_3_286_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_286_1"
  type: "BatchNorm"
  bottom: "res_stage_3_286_1"
  top: "res_stage_3_286_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_286_1"  
  type: "Scale"
  bottom: "res_stage_3_286_1"
  top: "res_stage_3_286_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_286_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_286_1_top"
  top: "res_stage_3_286_1_top"
}
layer {
  name: "res_stage_3_286_2"
  type: "Convolution"
  bottom: "res_stage_3_286_1_top"
  top: "res_stage_3_286_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_286_2"
  type: "BatchNorm"
  bottom: "res_stage_3_286_2"
  top: "res_stage_3_286_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_286_2"  
  type: "Scale"
  bottom: "res_stage_3_286_2"
  top: "res_stage_3_286_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_286_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_286_2_top"
  top: "res_stage_3_286_2_top"
}
layer {
  name: "res_stage_3_286_3"
  type: "Convolution"
  bottom: "res_stage_3_286_2_top"
  top: "res_stage_3_286_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_286_3"
  type: "BatchNorm"
  bottom: "res_stage_3_286_3"
  top: "res_stage_3_286_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_286_3"  
  type: "Scale"
  bottom: "res_stage_3_286_3"
  top: "res_stage_3_286_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_286"
  type: "Eltwise"
  bottom: "res_3_285"
  bottom: "res_stage_3_286_3_top"
  top: "res_3_286"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_286_relu"
  type: "ReLU"
  bottom: "res_3_286"
  top: "res_3_286"
}
layer {
  name: "res_stage_3_287_1"
  type: "Convolution"
  bottom: "res_3_286"
  top: "res_stage_3_287_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_287_1"
  type: "BatchNorm"
  bottom: "res_stage_3_287_1"
  top: "res_stage_3_287_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_287_1"  
  type: "Scale"
  bottom: "res_stage_3_287_1"
  top: "res_stage_3_287_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_287_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_287_1_top"
  top: "res_stage_3_287_1_top"
}
layer {
  name: "res_stage_3_287_2"
  type: "Convolution"
  bottom: "res_stage_3_287_1_top"
  top: "res_stage_3_287_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_287_2"
  type: "BatchNorm"
  bottom: "res_stage_3_287_2"
  top: "res_stage_3_287_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_287_2"  
  type: "Scale"
  bottom: "res_stage_3_287_2"
  top: "res_stage_3_287_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_287_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_287_2_top"
  top: "res_stage_3_287_2_top"
}
layer {
  name: "res_stage_3_287_3"
  type: "Convolution"
  bottom: "res_stage_3_287_2_top"
  top: "res_stage_3_287_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_287_3"
  type: "BatchNorm"
  bottom: "res_stage_3_287_3"
  top: "res_stage_3_287_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_287_3"  
  type: "Scale"
  bottom: "res_stage_3_287_3"
  top: "res_stage_3_287_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_287"
  type: "Eltwise"
  bottom: "res_3_286"
  bottom: "res_stage_3_287_3_top"
  top: "res_3_287"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_287_relu"
  type: "ReLU"
  bottom: "res_3_287"
  top: "res_3_287"
}
layer {
  name: "res_stage_3_288_1"
  type: "Convolution"
  bottom: "res_3_287"
  top: "res_stage_3_288_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_288_1"
  type: "BatchNorm"
  bottom: "res_stage_3_288_1"
  top: "res_stage_3_288_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_288_1"  
  type: "Scale"
  bottom: "res_stage_3_288_1"
  top: "res_stage_3_288_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_288_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_288_1_top"
  top: "res_stage_3_288_1_top"
}
layer {
  name: "res_stage_3_288_2"
  type: "Convolution"
  bottom: "res_stage_3_288_1_top"
  top: "res_stage_3_288_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_288_2"
  type: "BatchNorm"
  bottom: "res_stage_3_288_2"
  top: "res_stage_3_288_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_288_2"  
  type: "Scale"
  bottom: "res_stage_3_288_2"
  top: "res_stage_3_288_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_288_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_288_2_top"
  top: "res_stage_3_288_2_top"
}
layer {
  name: "res_stage_3_288_3"
  type: "Convolution"
  bottom: "res_stage_3_288_2_top"
  top: "res_stage_3_288_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_288_3"
  type: "BatchNorm"
  bottom: "res_stage_3_288_3"
  top: "res_stage_3_288_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_288_3"  
  type: "Scale"
  bottom: "res_stage_3_288_3"
  top: "res_stage_3_288_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_288"
  type: "Eltwise"
  bottom: "res_3_287"
  bottom: "res_stage_3_288_3_top"
  top: "res_3_288"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_288_relu"
  type: "ReLU"
  bottom: "res_3_288"
  top: "res_3_288"
}
layer {
  name: "res_stage_3_289_1"
  type: "Convolution"
  bottom: "res_3_288"
  top: "res_stage_3_289_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_289_1"
  type: "BatchNorm"
  bottom: "res_stage_3_289_1"
  top: "res_stage_3_289_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_289_1"  
  type: "Scale"
  bottom: "res_stage_3_289_1"
  top: "res_stage_3_289_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_289_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_289_1_top"
  top: "res_stage_3_289_1_top"
}
layer {
  name: "res_stage_3_289_2"
  type: "Convolution"
  bottom: "res_stage_3_289_1_top"
  top: "res_stage_3_289_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_289_2"
  type: "BatchNorm"
  bottom: "res_stage_3_289_2"
  top: "res_stage_3_289_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_289_2"  
  type: "Scale"
  bottom: "res_stage_3_289_2"
  top: "res_stage_3_289_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_289_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_289_2_top"
  top: "res_stage_3_289_2_top"
}
layer {
  name: "res_stage_3_289_3"
  type: "Convolution"
  bottom: "res_stage_3_289_2_top"
  top: "res_stage_3_289_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_289_3"
  type: "BatchNorm"
  bottom: "res_stage_3_289_3"
  top: "res_stage_3_289_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_289_3"  
  type: "Scale"
  bottom: "res_stage_3_289_3"
  top: "res_stage_3_289_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_289"
  type: "Eltwise"
  bottom: "res_3_288"
  bottom: "res_stage_3_289_3_top"
  top: "res_3_289"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_289_relu"
  type: "ReLU"
  bottom: "res_3_289"
  top: "res_3_289"
}
layer {
  name: "res_stage_3_290_1"
  type: "Convolution"
  bottom: "res_3_289"
  top: "res_stage_3_290_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_290_1"
  type: "BatchNorm"
  bottom: "res_stage_3_290_1"
  top: "res_stage_3_290_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_290_1"  
  type: "Scale"
  bottom: "res_stage_3_290_1"
  top: "res_stage_3_290_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_290_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_290_1_top"
  top: "res_stage_3_290_1_top"
}
layer {
  name: "res_stage_3_290_2"
  type: "Convolution"
  bottom: "res_stage_3_290_1_top"
  top: "res_stage_3_290_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_290_2"
  type: "BatchNorm"
  bottom: "res_stage_3_290_2"
  top: "res_stage_3_290_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_290_2"  
  type: "Scale"
  bottom: "res_stage_3_290_2"
  top: "res_stage_3_290_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_290_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_290_2_top"
  top: "res_stage_3_290_2_top"
}
layer {
  name: "res_stage_3_290_3"
  type: "Convolution"
  bottom: "res_stage_3_290_2_top"
  top: "res_stage_3_290_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_290_3"
  type: "BatchNorm"
  bottom: "res_stage_3_290_3"
  top: "res_stage_3_290_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_290_3"  
  type: "Scale"
  bottom: "res_stage_3_290_3"
  top: "res_stage_3_290_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_290"
  type: "Eltwise"
  bottom: "res_3_289"
  bottom: "res_stage_3_290_3_top"
  top: "res_3_290"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_290_relu"
  type: "ReLU"
  bottom: "res_3_290"
  top: "res_3_290"
}
layer {
  name: "res_stage_3_291_1"
  type: "Convolution"
  bottom: "res_3_290"
  top: "res_stage_3_291_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_291_1"
  type: "BatchNorm"
  bottom: "res_stage_3_291_1"
  top: "res_stage_3_291_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_291_1"  
  type: "Scale"
  bottom: "res_stage_3_291_1"
  top: "res_stage_3_291_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_291_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_291_1_top"
  top: "res_stage_3_291_1_top"
}
layer {
  name: "res_stage_3_291_2"
  type: "Convolution"
  bottom: "res_stage_3_291_1_top"
  top: "res_stage_3_291_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_291_2"
  type: "BatchNorm"
  bottom: "res_stage_3_291_2"
  top: "res_stage_3_291_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_291_2"  
  type: "Scale"
  bottom: "res_stage_3_291_2"
  top: "res_stage_3_291_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_291_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_291_2_top"
  top: "res_stage_3_291_2_top"
}
layer {
  name: "res_stage_3_291_3"
  type: "Convolution"
  bottom: "res_stage_3_291_2_top"
  top: "res_stage_3_291_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_291_3"
  type: "BatchNorm"
  bottom: "res_stage_3_291_3"
  top: "res_stage_3_291_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_291_3"  
  type: "Scale"
  bottom: "res_stage_3_291_3"
  top: "res_stage_3_291_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_291"
  type: "Eltwise"
  bottom: "res_3_290"
  bottom: "res_stage_3_291_3_top"
  top: "res_3_291"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_291_relu"
  type: "ReLU"
  bottom: "res_3_291"
  top: "res_3_291"
}
layer {
  name: "res_stage_3_292_1"
  type: "Convolution"
  bottom: "res_3_291"
  top: "res_stage_3_292_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_292_1"
  type: "BatchNorm"
  bottom: "res_stage_3_292_1"
  top: "res_stage_3_292_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_292_1"  
  type: "Scale"
  bottom: "res_stage_3_292_1"
  top: "res_stage_3_292_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_292_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_292_1_top"
  top: "res_stage_3_292_1_top"
}
layer {
  name: "res_stage_3_292_2"
  type: "Convolution"
  bottom: "res_stage_3_292_1_top"
  top: "res_stage_3_292_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_292_2"
  type: "BatchNorm"
  bottom: "res_stage_3_292_2"
  top: "res_stage_3_292_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_292_2"  
  type: "Scale"
  bottom: "res_stage_3_292_2"
  top: "res_stage_3_292_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_292_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_292_2_top"
  top: "res_stage_3_292_2_top"
}
layer {
  name: "res_stage_3_292_3"
  type: "Convolution"
  bottom: "res_stage_3_292_2_top"
  top: "res_stage_3_292_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_292_3"
  type: "BatchNorm"
  bottom: "res_stage_3_292_3"
  top: "res_stage_3_292_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_292_3"  
  type: "Scale"
  bottom: "res_stage_3_292_3"
  top: "res_stage_3_292_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_292"
  type: "Eltwise"
  bottom: "res_3_291"
  bottom: "res_stage_3_292_3_top"
  top: "res_3_292"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_292_relu"
  type: "ReLU"
  bottom: "res_3_292"
  top: "res_3_292"
}
layer {
  name: "res_stage_3_293_1"
  type: "Convolution"
  bottom: "res_3_292"
  top: "res_stage_3_293_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_293_1"
  type: "BatchNorm"
  bottom: "res_stage_3_293_1"
  top: "res_stage_3_293_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_293_1"  
  type: "Scale"
  bottom: "res_stage_3_293_1"
  top: "res_stage_3_293_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_293_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_293_1_top"
  top: "res_stage_3_293_1_top"
}
layer {
  name: "res_stage_3_293_2"
  type: "Convolution"
  bottom: "res_stage_3_293_1_top"
  top: "res_stage_3_293_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_293_2"
  type: "BatchNorm"
  bottom: "res_stage_3_293_2"
  top: "res_stage_3_293_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_293_2"  
  type: "Scale"
  bottom: "res_stage_3_293_2"
  top: "res_stage_3_293_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_293_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_293_2_top"
  top: "res_stage_3_293_2_top"
}
layer {
  name: "res_stage_3_293_3"
  type: "Convolution"
  bottom: "res_stage_3_293_2_top"
  top: "res_stage_3_293_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_293_3"
  type: "BatchNorm"
  bottom: "res_stage_3_293_3"
  top: "res_stage_3_293_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_293_3"  
  type: "Scale"
  bottom: "res_stage_3_293_3"
  top: "res_stage_3_293_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_293"
  type: "Eltwise"
  bottom: "res_3_292"
  bottom: "res_stage_3_293_3_top"
  top: "res_3_293"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_293_relu"
  type: "ReLU"
  bottom: "res_3_293"
  top: "res_3_293"
}
layer {
  name: "res_stage_3_294_1"
  type: "Convolution"
  bottom: "res_3_293"
  top: "res_stage_3_294_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_294_1"
  type: "BatchNorm"
  bottom: "res_stage_3_294_1"
  top: "res_stage_3_294_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_294_1"  
  type: "Scale"
  bottom: "res_stage_3_294_1"
  top: "res_stage_3_294_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_294_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_294_1_top"
  top: "res_stage_3_294_1_top"
}
layer {
  name: "res_stage_3_294_2"
  type: "Convolution"
  bottom: "res_stage_3_294_1_top"
  top: "res_stage_3_294_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_294_2"
  type: "BatchNorm"
  bottom: "res_stage_3_294_2"
  top: "res_stage_3_294_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_294_2"  
  type: "Scale"
  bottom: "res_stage_3_294_2"
  top: "res_stage_3_294_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_294_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_294_2_top"
  top: "res_stage_3_294_2_top"
}
layer {
  name: "res_stage_3_294_3"
  type: "Convolution"
  bottom: "res_stage_3_294_2_top"
  top: "res_stage_3_294_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_294_3"
  type: "BatchNorm"
  bottom: "res_stage_3_294_3"
  top: "res_stage_3_294_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_294_3"  
  type: "Scale"
  bottom: "res_stage_3_294_3"
  top: "res_stage_3_294_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_294"
  type: "Eltwise"
  bottom: "res_3_293"
  bottom: "res_stage_3_294_3_top"
  top: "res_3_294"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_294_relu"
  type: "ReLU"
  bottom: "res_3_294"
  top: "res_3_294"
}
layer {
  name: "res_stage_3_295_1"
  type: "Convolution"
  bottom: "res_3_294"
  top: "res_stage_3_295_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_295_1"
  type: "BatchNorm"
  bottom: "res_stage_3_295_1"
  top: "res_stage_3_295_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_295_1"  
  type: "Scale"
  bottom: "res_stage_3_295_1"
  top: "res_stage_3_295_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_295_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_295_1_top"
  top: "res_stage_3_295_1_top"
}
layer {
  name: "res_stage_3_295_2"
  type: "Convolution"
  bottom: "res_stage_3_295_1_top"
  top: "res_stage_3_295_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_295_2"
  type: "BatchNorm"
  bottom: "res_stage_3_295_2"
  top: "res_stage_3_295_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_295_2"  
  type: "Scale"
  bottom: "res_stage_3_295_2"
  top: "res_stage_3_295_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_295_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_295_2_top"
  top: "res_stage_3_295_2_top"
}
layer {
  name: "res_stage_3_295_3"
  type: "Convolution"
  bottom: "res_stage_3_295_2_top"
  top: "res_stage_3_295_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_295_3"
  type: "BatchNorm"
  bottom: "res_stage_3_295_3"
  top: "res_stage_3_295_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_295_3"  
  type: "Scale"
  bottom: "res_stage_3_295_3"
  top: "res_stage_3_295_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_295"
  type: "Eltwise"
  bottom: "res_3_294"
  bottom: "res_stage_3_295_3_top"
  top: "res_3_295"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_295_relu"
  type: "ReLU"
  bottom: "res_3_295"
  top: "res_3_295"
}
layer {
  name: "res_stage_3_296_1"
  type: "Convolution"
  bottom: "res_3_295"
  top: "res_stage_3_296_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_296_1"
  type: "BatchNorm"
  bottom: "res_stage_3_296_1"
  top: "res_stage_3_296_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_296_1"  
  type: "Scale"
  bottom: "res_stage_3_296_1"
  top: "res_stage_3_296_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_296_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_296_1_top"
  top: "res_stage_3_296_1_top"
}
layer {
  name: "res_stage_3_296_2"
  type: "Convolution"
  bottom: "res_stage_3_296_1_top"
  top: "res_stage_3_296_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_296_2"
  type: "BatchNorm"
  bottom: "res_stage_3_296_2"
  top: "res_stage_3_296_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_296_2"  
  type: "Scale"
  bottom: "res_stage_3_296_2"
  top: "res_stage_3_296_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_296_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_296_2_top"
  top: "res_stage_3_296_2_top"
}
layer {
  name: "res_stage_3_296_3"
  type: "Convolution"
  bottom: "res_stage_3_296_2_top"
  top: "res_stage_3_296_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_296_3"
  type: "BatchNorm"
  bottom: "res_stage_3_296_3"
  top: "res_stage_3_296_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_296_3"  
  type: "Scale"
  bottom: "res_stage_3_296_3"
  top: "res_stage_3_296_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_296"
  type: "Eltwise"
  bottom: "res_3_295"
  bottom: "res_stage_3_296_3_top"
  top: "res_3_296"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_296_relu"
  type: "ReLU"
  bottom: "res_3_296"
  top: "res_3_296"
}
layer {
  name: "res_stage_3_297_1"
  type: "Convolution"
  bottom: "res_3_296"
  top: "res_stage_3_297_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_297_1"
  type: "BatchNorm"
  bottom: "res_stage_3_297_1"
  top: "res_stage_3_297_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_297_1"  
  type: "Scale"
  bottom: "res_stage_3_297_1"
  top: "res_stage_3_297_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_297_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_297_1_top"
  top: "res_stage_3_297_1_top"
}
layer {
  name: "res_stage_3_297_2"
  type: "Convolution"
  bottom: "res_stage_3_297_1_top"
  top: "res_stage_3_297_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_297_2"
  type: "BatchNorm"
  bottom: "res_stage_3_297_2"
  top: "res_stage_3_297_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_297_2"  
  type: "Scale"
  bottom: "res_stage_3_297_2"
  top: "res_stage_3_297_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_297_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_297_2_top"
  top: "res_stage_3_297_2_top"
}
layer {
  name: "res_stage_3_297_3"
  type: "Convolution"
  bottom: "res_stage_3_297_2_top"
  top: "res_stage_3_297_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_297_3"
  type: "BatchNorm"
  bottom: "res_stage_3_297_3"
  top: "res_stage_3_297_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_297_3"  
  type: "Scale"
  bottom: "res_stage_3_297_3"
  top: "res_stage_3_297_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_297"
  type: "Eltwise"
  bottom: "res_3_296"
  bottom: "res_stage_3_297_3_top"
  top: "res_3_297"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_297_relu"
  type: "ReLU"
  bottom: "res_3_297"
  top: "res_3_297"
}
layer {
  name: "res_stage_3_298_1"
  type: "Convolution"
  bottom: "res_3_297"
  top: "res_stage_3_298_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_298_1"
  type: "BatchNorm"
  bottom: "res_stage_3_298_1"
  top: "res_stage_3_298_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_298_1"  
  type: "Scale"
  bottom: "res_stage_3_298_1"
  top: "res_stage_3_298_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_298_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_298_1_top"
  top: "res_stage_3_298_1_top"
}
layer {
  name: "res_stage_3_298_2"
  type: "Convolution"
  bottom: "res_stage_3_298_1_top"
  top: "res_stage_3_298_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_298_2"
  type: "BatchNorm"
  bottom: "res_stage_3_298_2"
  top: "res_stage_3_298_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_298_2"  
  type: "Scale"
  bottom: "res_stage_3_298_2"
  top: "res_stage_3_298_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_298_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_298_2_top"
  top: "res_stage_3_298_2_top"
}
layer {
  name: "res_stage_3_298_3"
  type: "Convolution"
  bottom: "res_stage_3_298_2_top"
  top: "res_stage_3_298_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_298_3"
  type: "BatchNorm"
  bottom: "res_stage_3_298_3"
  top: "res_stage_3_298_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_298_3"  
  type: "Scale"
  bottom: "res_stage_3_298_3"
  top: "res_stage_3_298_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_298"
  type: "Eltwise"
  bottom: "res_3_297"
  bottom: "res_stage_3_298_3_top"
  top: "res_3_298"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_298_relu"
  type: "ReLU"
  bottom: "res_3_298"
  top: "res_3_298"
}
layer {
  name: "res_stage_3_299_1"
  type: "Convolution"
  bottom: "res_3_298"
  top: "res_stage_3_299_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_299_1"
  type: "BatchNorm"
  bottom: "res_stage_3_299_1"
  top: "res_stage_3_299_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_299_1"  
  type: "Scale"
  bottom: "res_stage_3_299_1"
  top: "res_stage_3_299_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_299_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_299_1_top"
  top: "res_stage_3_299_1_top"
}
layer {
  name: "res_stage_3_299_2"
  type: "Convolution"
  bottom: "res_stage_3_299_1_top"
  top: "res_stage_3_299_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_299_2"
  type: "BatchNorm"
  bottom: "res_stage_3_299_2"
  top: "res_stage_3_299_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_299_2"  
  type: "Scale"
  bottom: "res_stage_3_299_2"
  top: "res_stage_3_299_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_299_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_299_2_top"
  top: "res_stage_3_299_2_top"
}
layer {
  name: "res_stage_3_299_3"
  type: "Convolution"
  bottom: "res_stage_3_299_2_top"
  top: "res_stage_3_299_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_299_3"
  type: "BatchNorm"
  bottom: "res_stage_3_299_3"
  top: "res_stage_3_299_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_299_3"  
  type: "Scale"
  bottom: "res_stage_3_299_3"
  top: "res_stage_3_299_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_299"
  type: "Eltwise"
  bottom: "res_3_298"
  bottom: "res_stage_3_299_3_top"
  top: "res_3_299"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_299_relu"
  type: "ReLU"
  bottom: "res_3_299"
  top: "res_3_299"
}
layer {
  name: "res_stage_3_300_1"
  type: "Convolution"
  bottom: "res_3_299"
  top: "res_stage_3_300_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_300_1"
  type: "BatchNorm"
  bottom: "res_stage_3_300_1"
  top: "res_stage_3_300_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_300_1"  
  type: "Scale"
  bottom: "res_stage_3_300_1"
  top: "res_stage_3_300_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_300_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_300_1_top"
  top: "res_stage_3_300_1_top"
}
layer {
  name: "res_stage_3_300_2"
  type: "Convolution"
  bottom: "res_stage_3_300_1_top"
  top: "res_stage_3_300_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_300_2"
  type: "BatchNorm"
  bottom: "res_stage_3_300_2"
  top: "res_stage_3_300_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_300_2"  
  type: "Scale"
  bottom: "res_stage_3_300_2"
  top: "res_stage_3_300_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_300_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_300_2_top"
  top: "res_stage_3_300_2_top"
}
layer {
  name: "res_stage_3_300_3"
  type: "Convolution"
  bottom: "res_stage_3_300_2_top"
  top: "res_stage_3_300_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_300_3"
  type: "BatchNorm"
  bottom: "res_stage_3_300_3"
  top: "res_stage_3_300_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_300_3"  
  type: "Scale"
  bottom: "res_stage_3_300_3"
  top: "res_stage_3_300_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_300"
  type: "Eltwise"
  bottom: "res_3_299"
  bottom: "res_stage_3_300_3_top"
  top: "res_3_300"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_300_relu"
  type: "ReLU"
  bottom: "res_3_300"
  top: "res_3_300"
}
layer {
  name: "res_stage_3_301_1"
  type: "Convolution"
  bottom: "res_3_300"
  top: "res_stage_3_301_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_301_1"
  type: "BatchNorm"
  bottom: "res_stage_3_301_1"
  top: "res_stage_3_301_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_301_1"  
  type: "Scale"
  bottom: "res_stage_3_301_1"
  top: "res_stage_3_301_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_301_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_301_1_top"
  top: "res_stage_3_301_1_top"
}
layer {
  name: "res_stage_3_301_2"
  type: "Convolution"
  bottom: "res_stage_3_301_1_top"
  top: "res_stage_3_301_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_301_2"
  type: "BatchNorm"
  bottom: "res_stage_3_301_2"
  top: "res_stage_3_301_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_301_2"  
  type: "Scale"
  bottom: "res_stage_3_301_2"
  top: "res_stage_3_301_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_301_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_301_2_top"
  top: "res_stage_3_301_2_top"
}
layer {
  name: "res_stage_3_301_3"
  type: "Convolution"
  bottom: "res_stage_3_301_2_top"
  top: "res_stage_3_301_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_301_3"
  type: "BatchNorm"
  bottom: "res_stage_3_301_3"
  top: "res_stage_3_301_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_301_3"  
  type: "Scale"
  bottom: "res_stage_3_301_3"
  top: "res_stage_3_301_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_301"
  type: "Eltwise"
  bottom: "res_3_300"
  bottom: "res_stage_3_301_3_top"
  top: "res_3_301"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_301_relu"
  type: "ReLU"
  bottom: "res_3_301"
  top: "res_3_301"
}
layer {
  name: "res_stage_3_302_1"
  type: "Convolution"
  bottom: "res_3_301"
  top: "res_stage_3_302_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_302_1"
  type: "BatchNorm"
  bottom: "res_stage_3_302_1"
  top: "res_stage_3_302_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_302_1"  
  type: "Scale"
  bottom: "res_stage_3_302_1"
  top: "res_stage_3_302_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_302_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_302_1_top"
  top: "res_stage_3_302_1_top"
}
layer {
  name: "res_stage_3_302_2"
  type: "Convolution"
  bottom: "res_stage_3_302_1_top"
  top: "res_stage_3_302_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_302_2"
  type: "BatchNorm"
  bottom: "res_stage_3_302_2"
  top: "res_stage_3_302_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_302_2"  
  type: "Scale"
  bottom: "res_stage_3_302_2"
  top: "res_stage_3_302_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_302_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_302_2_top"
  top: "res_stage_3_302_2_top"
}
layer {
  name: "res_stage_3_302_3"
  type: "Convolution"
  bottom: "res_stage_3_302_2_top"
  top: "res_stage_3_302_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_302_3"
  type: "BatchNorm"
  bottom: "res_stage_3_302_3"
  top: "res_stage_3_302_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_302_3"  
  type: "Scale"
  bottom: "res_stage_3_302_3"
  top: "res_stage_3_302_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_302"
  type: "Eltwise"
  bottom: "res_3_301"
  bottom: "res_stage_3_302_3_top"
  top: "res_3_302"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_302_relu"
  type: "ReLU"
  bottom: "res_3_302"
  top: "res_3_302"
}
layer {
  name: "res_stage_3_303_1"
  type: "Convolution"
  bottom: "res_3_302"
  top: "res_stage_3_303_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_303_1"
  type: "BatchNorm"
  bottom: "res_stage_3_303_1"
  top: "res_stage_3_303_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_303_1"  
  type: "Scale"
  bottom: "res_stage_3_303_1"
  top: "res_stage_3_303_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_303_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_303_1_top"
  top: "res_stage_3_303_1_top"
}
layer {
  name: "res_stage_3_303_2"
  type: "Convolution"
  bottom: "res_stage_3_303_1_top"
  top: "res_stage_3_303_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_303_2"
  type: "BatchNorm"
  bottom: "res_stage_3_303_2"
  top: "res_stage_3_303_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_303_2"  
  type: "Scale"
  bottom: "res_stage_3_303_2"
  top: "res_stage_3_303_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_303_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_303_2_top"
  top: "res_stage_3_303_2_top"
}
layer {
  name: "res_stage_3_303_3"
  type: "Convolution"
  bottom: "res_stage_3_303_2_top"
  top: "res_stage_3_303_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_303_3"
  type: "BatchNorm"
  bottom: "res_stage_3_303_3"
  top: "res_stage_3_303_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_303_3"  
  type: "Scale"
  bottom: "res_stage_3_303_3"
  top: "res_stage_3_303_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_303"
  type: "Eltwise"
  bottom: "res_3_302"
  bottom: "res_stage_3_303_3_top"
  top: "res_3_303"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_303_relu"
  type: "ReLU"
  bottom: "res_3_303"
  top: "res_3_303"
}
layer {
  name: "res_stage_3_304_1"
  type: "Convolution"
  bottom: "res_3_303"
  top: "res_stage_3_304_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_304_1"
  type: "BatchNorm"
  bottom: "res_stage_3_304_1"
  top: "res_stage_3_304_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_304_1"  
  type: "Scale"
  bottom: "res_stage_3_304_1"
  top: "res_stage_3_304_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_304_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_304_1_top"
  top: "res_stage_3_304_1_top"
}
layer {
  name: "res_stage_3_304_2"
  type: "Convolution"
  bottom: "res_stage_3_304_1_top"
  top: "res_stage_3_304_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_304_2"
  type: "BatchNorm"
  bottom: "res_stage_3_304_2"
  top: "res_stage_3_304_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_304_2"  
  type: "Scale"
  bottom: "res_stage_3_304_2"
  top: "res_stage_3_304_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_304_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_304_2_top"
  top: "res_stage_3_304_2_top"
}
layer {
  name: "res_stage_3_304_3"
  type: "Convolution"
  bottom: "res_stage_3_304_2_top"
  top: "res_stage_3_304_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_304_3"
  type: "BatchNorm"
  bottom: "res_stage_3_304_3"
  top: "res_stage_3_304_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_304_3"  
  type: "Scale"
  bottom: "res_stage_3_304_3"
  top: "res_stage_3_304_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_304"
  type: "Eltwise"
  bottom: "res_3_303"
  bottom: "res_stage_3_304_3_top"
  top: "res_3_304"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_304_relu"
  type: "ReLU"
  bottom: "res_3_304"
  top: "res_3_304"
}
layer {
  name: "res_stage_3_305_1"
  type: "Convolution"
  bottom: "res_3_304"
  top: "res_stage_3_305_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_305_1"
  type: "BatchNorm"
  bottom: "res_stage_3_305_1"
  top: "res_stage_3_305_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_305_1"  
  type: "Scale"
  bottom: "res_stage_3_305_1"
  top: "res_stage_3_305_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_305_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_305_1_top"
  top: "res_stage_3_305_1_top"
}
layer {
  name: "res_stage_3_305_2"
  type: "Convolution"
  bottom: "res_stage_3_305_1_top"
  top: "res_stage_3_305_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_305_2"
  type: "BatchNorm"
  bottom: "res_stage_3_305_2"
  top: "res_stage_3_305_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_305_2"  
  type: "Scale"
  bottom: "res_stage_3_305_2"
  top: "res_stage_3_305_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_305_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_305_2_top"
  top: "res_stage_3_305_2_top"
}
layer {
  name: "res_stage_3_305_3"
  type: "Convolution"
  bottom: "res_stage_3_305_2_top"
  top: "res_stage_3_305_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_305_3"
  type: "BatchNorm"
  bottom: "res_stage_3_305_3"
  top: "res_stage_3_305_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_305_3"  
  type: "Scale"
  bottom: "res_stage_3_305_3"
  top: "res_stage_3_305_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_305"
  type: "Eltwise"
  bottom: "res_3_304"
  bottom: "res_stage_3_305_3_top"
  top: "res_3_305"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_305_relu"
  type: "ReLU"
  bottom: "res_3_305"
  top: "res_3_305"
}
layer {
  name: "res_stage_3_306_1"
  type: "Convolution"
  bottom: "res_3_305"
  top: "res_stage_3_306_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_306_1"
  type: "BatchNorm"
  bottom: "res_stage_3_306_1"
  top: "res_stage_3_306_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_306_1"  
  type: "Scale"
  bottom: "res_stage_3_306_1"
  top: "res_stage_3_306_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_306_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_306_1_top"
  top: "res_stage_3_306_1_top"
}
layer {
  name: "res_stage_3_306_2"
  type: "Convolution"
  bottom: "res_stage_3_306_1_top"
  top: "res_stage_3_306_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_306_2"
  type: "BatchNorm"
  bottom: "res_stage_3_306_2"
  top: "res_stage_3_306_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_306_2"  
  type: "Scale"
  bottom: "res_stage_3_306_2"
  top: "res_stage_3_306_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_306_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_306_2_top"
  top: "res_stage_3_306_2_top"
}
layer {
  name: "res_stage_3_306_3"
  type: "Convolution"
  bottom: "res_stage_3_306_2_top"
  top: "res_stage_3_306_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_306_3"
  type: "BatchNorm"
  bottom: "res_stage_3_306_3"
  top: "res_stage_3_306_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_306_3"  
  type: "Scale"
  bottom: "res_stage_3_306_3"
  top: "res_stage_3_306_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_306"
  type: "Eltwise"
  bottom: "res_3_305"
  bottom: "res_stage_3_306_3_top"
  top: "res_3_306"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_306_relu"
  type: "ReLU"
  bottom: "res_3_306"
  top: "res_3_306"
}
layer {
  name: "res_stage_3_307_1"
  type: "Convolution"
  bottom: "res_3_306"
  top: "res_stage_3_307_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_307_1"
  type: "BatchNorm"
  bottom: "res_stage_3_307_1"
  top: "res_stage_3_307_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_307_1"  
  type: "Scale"
  bottom: "res_stage_3_307_1"
  top: "res_stage_3_307_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_307_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_307_1_top"
  top: "res_stage_3_307_1_top"
}
layer {
  name: "res_stage_3_307_2"
  type: "Convolution"
  bottom: "res_stage_3_307_1_top"
  top: "res_stage_3_307_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_307_2"
  type: "BatchNorm"
  bottom: "res_stage_3_307_2"
  top: "res_stage_3_307_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_307_2"  
  type: "Scale"
  bottom: "res_stage_3_307_2"
  top: "res_stage_3_307_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_307_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_307_2_top"
  top: "res_stage_3_307_2_top"
}
layer {
  name: "res_stage_3_307_3"
  type: "Convolution"
  bottom: "res_stage_3_307_2_top"
  top: "res_stage_3_307_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_307_3"
  type: "BatchNorm"
  bottom: "res_stage_3_307_3"
  top: "res_stage_3_307_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_307_3"  
  type: "Scale"
  bottom: "res_stage_3_307_3"
  top: "res_stage_3_307_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_307"
  type: "Eltwise"
  bottom: "res_3_306"
  bottom: "res_stage_3_307_3_top"
  top: "res_3_307"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_307_relu"
  type: "ReLU"
  bottom: "res_3_307"
  top: "res_3_307"
}
layer {
  name: "res_stage_3_308_1"
  type: "Convolution"
  bottom: "res_3_307"
  top: "res_stage_3_308_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_308_1"
  type: "BatchNorm"
  bottom: "res_stage_3_308_1"
  top: "res_stage_3_308_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_308_1"  
  type: "Scale"
  bottom: "res_stage_3_308_1"
  top: "res_stage_3_308_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_308_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_308_1_top"
  top: "res_stage_3_308_1_top"
}
layer {
  name: "res_stage_3_308_2"
  type: "Convolution"
  bottom: "res_stage_3_308_1_top"
  top: "res_stage_3_308_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_308_2"
  type: "BatchNorm"
  bottom: "res_stage_3_308_2"
  top: "res_stage_3_308_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_308_2"  
  type: "Scale"
  bottom: "res_stage_3_308_2"
  top: "res_stage_3_308_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_308_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_308_2_top"
  top: "res_stage_3_308_2_top"
}
layer {
  name: "res_stage_3_308_3"
  type: "Convolution"
  bottom: "res_stage_3_308_2_top"
  top: "res_stage_3_308_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_308_3"
  type: "BatchNorm"
  bottom: "res_stage_3_308_3"
  top: "res_stage_3_308_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_308_3"  
  type: "Scale"
  bottom: "res_stage_3_308_3"
  top: "res_stage_3_308_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_308"
  type: "Eltwise"
  bottom: "res_3_307"
  bottom: "res_stage_3_308_3_top"
  top: "res_3_308"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_308_relu"
  type: "ReLU"
  bottom: "res_3_308"
  top: "res_3_308"
}
layer {
  name: "res_stage_3_309_1"
  type: "Convolution"
  bottom: "res_3_308"
  top: "res_stage_3_309_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_309_1"
  type: "BatchNorm"
  bottom: "res_stage_3_309_1"
  top: "res_stage_3_309_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_309_1"  
  type: "Scale"
  bottom: "res_stage_3_309_1"
  top: "res_stage_3_309_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_309_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_309_1_top"
  top: "res_stage_3_309_1_top"
}
layer {
  name: "res_stage_3_309_2"
  type: "Convolution"
  bottom: "res_stage_3_309_1_top"
  top: "res_stage_3_309_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_309_2"
  type: "BatchNorm"
  bottom: "res_stage_3_309_2"
  top: "res_stage_3_309_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_309_2"  
  type: "Scale"
  bottom: "res_stage_3_309_2"
  top: "res_stage_3_309_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_309_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_309_2_top"
  top: "res_stage_3_309_2_top"
}
layer {
  name: "res_stage_3_309_3"
  type: "Convolution"
  bottom: "res_stage_3_309_2_top"
  top: "res_stage_3_309_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_309_3"
  type: "BatchNorm"
  bottom: "res_stage_3_309_3"
  top: "res_stage_3_309_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_309_3"  
  type: "Scale"
  bottom: "res_stage_3_309_3"
  top: "res_stage_3_309_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_309"
  type: "Eltwise"
  bottom: "res_3_308"
  bottom: "res_stage_3_309_3_top"
  top: "res_3_309"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_309_relu"
  type: "ReLU"
  bottom: "res_3_309"
  top: "res_3_309"
}
layer {
  name: "res_stage_3_310_1"
  type: "Convolution"
  bottom: "res_3_309"
  top: "res_stage_3_310_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_310_1"
  type: "BatchNorm"
  bottom: "res_stage_3_310_1"
  top: "res_stage_3_310_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_310_1"  
  type: "Scale"
  bottom: "res_stage_3_310_1"
  top: "res_stage_3_310_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_310_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_310_1_top"
  top: "res_stage_3_310_1_top"
}
layer {
  name: "res_stage_3_310_2"
  type: "Convolution"
  bottom: "res_stage_3_310_1_top"
  top: "res_stage_3_310_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_310_2"
  type: "BatchNorm"
  bottom: "res_stage_3_310_2"
  top: "res_stage_3_310_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_310_2"  
  type: "Scale"
  bottom: "res_stage_3_310_2"
  top: "res_stage_3_310_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_310_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_310_2_top"
  top: "res_stage_3_310_2_top"
}
layer {
  name: "res_stage_3_310_3"
  type: "Convolution"
  bottom: "res_stage_3_310_2_top"
  top: "res_stage_3_310_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_310_3"
  type: "BatchNorm"
  bottom: "res_stage_3_310_3"
  top: "res_stage_3_310_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_310_3"  
  type: "Scale"
  bottom: "res_stage_3_310_3"
  top: "res_stage_3_310_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_310"
  type: "Eltwise"
  bottom: "res_3_309"
  bottom: "res_stage_3_310_3_top"
  top: "res_3_310"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_310_relu"
  type: "ReLU"
  bottom: "res_3_310"
  top: "res_3_310"
}
layer {
  name: "res_stage_3_311_1"
  type: "Convolution"
  bottom: "res_3_310"
  top: "res_stage_3_311_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_311_1"
  type: "BatchNorm"
  bottom: "res_stage_3_311_1"
  top: "res_stage_3_311_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_311_1"  
  type: "Scale"
  bottom: "res_stage_3_311_1"
  top: "res_stage_3_311_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_311_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_311_1_top"
  top: "res_stage_3_311_1_top"
}
layer {
  name: "res_stage_3_311_2"
  type: "Convolution"
  bottom: "res_stage_3_311_1_top"
  top: "res_stage_3_311_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_311_2"
  type: "BatchNorm"
  bottom: "res_stage_3_311_2"
  top: "res_stage_3_311_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_311_2"  
  type: "Scale"
  bottom: "res_stage_3_311_2"
  top: "res_stage_3_311_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_311_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_311_2_top"
  top: "res_stage_3_311_2_top"
}
layer {
  name: "res_stage_3_311_3"
  type: "Convolution"
  bottom: "res_stage_3_311_2_top"
  top: "res_stage_3_311_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_311_3"
  type: "BatchNorm"
  bottom: "res_stage_3_311_3"
  top: "res_stage_3_311_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_311_3"  
  type: "Scale"
  bottom: "res_stage_3_311_3"
  top: "res_stage_3_311_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_311"
  type: "Eltwise"
  bottom: "res_3_310"
  bottom: "res_stage_3_311_3_top"
  top: "res_3_311"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_311_relu"
  type: "ReLU"
  bottom: "res_3_311"
  top: "res_3_311"
}
layer {
  name: "res_stage_3_312_1"
  type: "Convolution"
  bottom: "res_3_311"
  top: "res_stage_3_312_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_312_1"
  type: "BatchNorm"
  bottom: "res_stage_3_312_1"
  top: "res_stage_3_312_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_312_1"  
  type: "Scale"
  bottom: "res_stage_3_312_1"
  top: "res_stage_3_312_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_312_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_312_1_top"
  top: "res_stage_3_312_1_top"
}
layer {
  name: "res_stage_3_312_2"
  type: "Convolution"
  bottom: "res_stage_3_312_1_top"
  top: "res_stage_3_312_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_312_2"
  type: "BatchNorm"
  bottom: "res_stage_3_312_2"
  top: "res_stage_3_312_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_312_2"  
  type: "Scale"
  bottom: "res_stage_3_312_2"
  top: "res_stage_3_312_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_312_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_312_2_top"
  top: "res_stage_3_312_2_top"
}
layer {
  name: "res_stage_3_312_3"
  type: "Convolution"
  bottom: "res_stage_3_312_2_top"
  top: "res_stage_3_312_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_312_3"
  type: "BatchNorm"
  bottom: "res_stage_3_312_3"
  top: "res_stage_3_312_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_312_3"  
  type: "Scale"
  bottom: "res_stage_3_312_3"
  top: "res_stage_3_312_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_312"
  type: "Eltwise"
  bottom: "res_3_311"
  bottom: "res_stage_3_312_3_top"
  top: "res_3_312"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_312_relu"
  type: "ReLU"
  bottom: "res_3_312"
  top: "res_3_312"
}
layer {
  name: "res_stage_3_313_1"
  type: "Convolution"
  bottom: "res_3_312"
  top: "res_stage_3_313_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_313_1"
  type: "BatchNorm"
  bottom: "res_stage_3_313_1"
  top: "res_stage_3_313_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_313_1"  
  type: "Scale"
  bottom: "res_stage_3_313_1"
  top: "res_stage_3_313_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_313_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_313_1_top"
  top: "res_stage_3_313_1_top"
}
layer {
  name: "res_stage_3_313_2"
  type: "Convolution"
  bottom: "res_stage_3_313_1_top"
  top: "res_stage_3_313_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_313_2"
  type: "BatchNorm"
  bottom: "res_stage_3_313_2"
  top: "res_stage_3_313_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_313_2"  
  type: "Scale"
  bottom: "res_stage_3_313_2"
  top: "res_stage_3_313_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_313_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_313_2_top"
  top: "res_stage_3_313_2_top"
}
layer {
  name: "res_stage_3_313_3"
  type: "Convolution"
  bottom: "res_stage_3_313_2_top"
  top: "res_stage_3_313_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_313_3"
  type: "BatchNorm"
  bottom: "res_stage_3_313_3"
  top: "res_stage_3_313_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_313_3"  
  type: "Scale"
  bottom: "res_stage_3_313_3"
  top: "res_stage_3_313_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_313"
  type: "Eltwise"
  bottom: "res_3_312"
  bottom: "res_stage_3_313_3_top"
  top: "res_3_313"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_313_relu"
  type: "ReLU"
  bottom: "res_3_313"
  top: "res_3_313"
}
layer {
  name: "res_stage_3_314_1"
  type: "Convolution"
  bottom: "res_3_313"
  top: "res_stage_3_314_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_314_1"
  type: "BatchNorm"
  bottom: "res_stage_3_314_1"
  top: "res_stage_3_314_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_314_1"  
  type: "Scale"
  bottom: "res_stage_3_314_1"
  top: "res_stage_3_314_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_314_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_314_1_top"
  top: "res_stage_3_314_1_top"
}
layer {
  name: "res_stage_3_314_2"
  type: "Convolution"
  bottom: "res_stage_3_314_1_top"
  top: "res_stage_3_314_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_314_2"
  type: "BatchNorm"
  bottom: "res_stage_3_314_2"
  top: "res_stage_3_314_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_314_2"  
  type: "Scale"
  bottom: "res_stage_3_314_2"
  top: "res_stage_3_314_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_314_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_314_2_top"
  top: "res_stage_3_314_2_top"
}
layer {
  name: "res_stage_3_314_3"
  type: "Convolution"
  bottom: "res_stage_3_314_2_top"
  top: "res_stage_3_314_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_314_3"
  type: "BatchNorm"
  bottom: "res_stage_3_314_3"
  top: "res_stage_3_314_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_314_3"  
  type: "Scale"
  bottom: "res_stage_3_314_3"
  top: "res_stage_3_314_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_314"
  type: "Eltwise"
  bottom: "res_3_313"
  bottom: "res_stage_3_314_3_top"
  top: "res_3_314"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_314_relu"
  type: "ReLU"
  bottom: "res_3_314"
  top: "res_3_314"
}
layer {
  name: "res_stage_3_315_1"
  type: "Convolution"
  bottom: "res_3_314"
  top: "res_stage_3_315_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_315_1"
  type: "BatchNorm"
  bottom: "res_stage_3_315_1"
  top: "res_stage_3_315_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_315_1"  
  type: "Scale"
  bottom: "res_stage_3_315_1"
  top: "res_stage_3_315_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_315_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_315_1_top"
  top: "res_stage_3_315_1_top"
}
layer {
  name: "res_stage_3_315_2"
  type: "Convolution"
  bottom: "res_stage_3_315_1_top"
  top: "res_stage_3_315_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_315_2"
  type: "BatchNorm"
  bottom: "res_stage_3_315_2"
  top: "res_stage_3_315_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_315_2"  
  type: "Scale"
  bottom: "res_stage_3_315_2"
  top: "res_stage_3_315_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_315_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_315_2_top"
  top: "res_stage_3_315_2_top"
}
layer {
  name: "res_stage_3_315_3"
  type: "Convolution"
  bottom: "res_stage_3_315_2_top"
  top: "res_stage_3_315_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_315_3"
  type: "BatchNorm"
  bottom: "res_stage_3_315_3"
  top: "res_stage_3_315_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_315_3"  
  type: "Scale"
  bottom: "res_stage_3_315_3"
  top: "res_stage_3_315_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_315"
  type: "Eltwise"
  bottom: "res_3_314"
  bottom: "res_stage_3_315_3_top"
  top: "res_3_315"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_315_relu"
  type: "ReLU"
  bottom: "res_3_315"
  top: "res_3_315"
}
layer {
  name: "res_stage_3_316_1"
  type: "Convolution"
  bottom: "res_3_315"
  top: "res_stage_3_316_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_316_1"
  type: "BatchNorm"
  bottom: "res_stage_3_316_1"
  top: "res_stage_3_316_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_316_1"  
  type: "Scale"
  bottom: "res_stage_3_316_1"
  top: "res_stage_3_316_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_316_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_316_1_top"
  top: "res_stage_3_316_1_top"
}
layer {
  name: "res_stage_3_316_2"
  type: "Convolution"
  bottom: "res_stage_3_316_1_top"
  top: "res_stage_3_316_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_316_2"
  type: "BatchNorm"
  bottom: "res_stage_3_316_2"
  top: "res_stage_3_316_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_316_2"  
  type: "Scale"
  bottom: "res_stage_3_316_2"
  top: "res_stage_3_316_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_316_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_316_2_top"
  top: "res_stage_3_316_2_top"
}
layer {
  name: "res_stage_3_316_3"
  type: "Convolution"
  bottom: "res_stage_3_316_2_top"
  top: "res_stage_3_316_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_316_3"
  type: "BatchNorm"
  bottom: "res_stage_3_316_3"
  top: "res_stage_3_316_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_316_3"  
  type: "Scale"
  bottom: "res_stage_3_316_3"
  top: "res_stage_3_316_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_316"
  type: "Eltwise"
  bottom: "res_3_315"
  bottom: "res_stage_3_316_3_top"
  top: "res_3_316"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_316_relu"
  type: "ReLU"
  bottom: "res_3_316"
  top: "res_3_316"
}
layer {
  name: "res_stage_3_317_1"
  type: "Convolution"
  bottom: "res_3_316"
  top: "res_stage_3_317_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_317_1"
  type: "BatchNorm"
  bottom: "res_stage_3_317_1"
  top: "res_stage_3_317_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_317_1"  
  type: "Scale"
  bottom: "res_stage_3_317_1"
  top: "res_stage_3_317_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_317_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_317_1_top"
  top: "res_stage_3_317_1_top"
}
layer {
  name: "res_stage_3_317_2"
  type: "Convolution"
  bottom: "res_stage_3_317_1_top"
  top: "res_stage_3_317_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_317_2"
  type: "BatchNorm"
  bottom: "res_stage_3_317_2"
  top: "res_stage_3_317_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_317_2"  
  type: "Scale"
  bottom: "res_stage_3_317_2"
  top: "res_stage_3_317_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_317_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_317_2_top"
  top: "res_stage_3_317_2_top"
}
layer {
  name: "res_stage_3_317_3"
  type: "Convolution"
  bottom: "res_stage_3_317_2_top"
  top: "res_stage_3_317_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_317_3"
  type: "BatchNorm"
  bottom: "res_stage_3_317_3"
  top: "res_stage_3_317_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_317_3"  
  type: "Scale"
  bottom: "res_stage_3_317_3"
  top: "res_stage_3_317_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_317"
  type: "Eltwise"
  bottom: "res_3_316"
  bottom: "res_stage_3_317_3_top"
  top: "res_3_317"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_317_relu"
  type: "ReLU"
  bottom: "res_3_317"
  top: "res_3_317"
}
layer {
  name: "res_stage_3_318_1"
  type: "Convolution"
  bottom: "res_3_317"
  top: "res_stage_3_318_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_318_1"
  type: "BatchNorm"
  bottom: "res_stage_3_318_1"
  top: "res_stage_3_318_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_318_1"  
  type: "Scale"
  bottom: "res_stage_3_318_1"
  top: "res_stage_3_318_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_318_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_318_1_top"
  top: "res_stage_3_318_1_top"
}
layer {
  name: "res_stage_3_318_2"
  type: "Convolution"
  bottom: "res_stage_3_318_1_top"
  top: "res_stage_3_318_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_318_2"
  type: "BatchNorm"
  bottom: "res_stage_3_318_2"
  top: "res_stage_3_318_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_318_2"  
  type: "Scale"
  bottom: "res_stage_3_318_2"
  top: "res_stage_3_318_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_318_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_318_2_top"
  top: "res_stage_3_318_2_top"
}
layer {
  name: "res_stage_3_318_3"
  type: "Convolution"
  bottom: "res_stage_3_318_2_top"
  top: "res_stage_3_318_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_318_3"
  type: "BatchNorm"
  bottom: "res_stage_3_318_3"
  top: "res_stage_3_318_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_318_3"  
  type: "Scale"
  bottom: "res_stage_3_318_3"
  top: "res_stage_3_318_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_318"
  type: "Eltwise"
  bottom: "res_3_317"
  bottom: "res_stage_3_318_3_top"
  top: "res_3_318"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_318_relu"
  type: "ReLU"
  bottom: "res_3_318"
  top: "res_3_318"
}
layer {
  name: "res_stage_3_319_1"
  type: "Convolution"
  bottom: "res_3_318"
  top: "res_stage_3_319_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_319_1"
  type: "BatchNorm"
  bottom: "res_stage_3_319_1"
  top: "res_stage_3_319_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_319_1"  
  type: "Scale"
  bottom: "res_stage_3_319_1"
  top: "res_stage_3_319_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_319_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_319_1_top"
  top: "res_stage_3_319_1_top"
}
layer {
  name: "res_stage_3_319_2"
  type: "Convolution"
  bottom: "res_stage_3_319_1_top"
  top: "res_stage_3_319_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_319_2"
  type: "BatchNorm"
  bottom: "res_stage_3_319_2"
  top: "res_stage_3_319_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_319_2"  
  type: "Scale"
  bottom: "res_stage_3_319_2"
  top: "res_stage_3_319_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_319_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_319_2_top"
  top: "res_stage_3_319_2_top"
}
layer {
  name: "res_stage_3_319_3"
  type: "Convolution"
  bottom: "res_stage_3_319_2_top"
  top: "res_stage_3_319_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_319_3"
  type: "BatchNorm"
  bottom: "res_stage_3_319_3"
  top: "res_stage_3_319_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_319_3"  
  type: "Scale"
  bottom: "res_stage_3_319_3"
  top: "res_stage_3_319_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_319"
  type: "Eltwise"
  bottom: "res_3_318"
  bottom: "res_stage_3_319_3_top"
  top: "res_3_319"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_319_relu"
  type: "ReLU"
  bottom: "res_3_319"
  top: "res_3_319"
}
layer {
  name: "res_stage_3_320_1"
  type: "Convolution"
  bottom: "res_3_319"
  top: "res_stage_3_320_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_320_1"
  type: "BatchNorm"
  bottom: "res_stage_3_320_1"
  top: "res_stage_3_320_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_320_1"  
  type: "Scale"
  bottom: "res_stage_3_320_1"
  top: "res_stage_3_320_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_320_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_320_1_top"
  top: "res_stage_3_320_1_top"
}
layer {
  name: "res_stage_3_320_2"
  type: "Convolution"
  bottom: "res_stage_3_320_1_top"
  top: "res_stage_3_320_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_320_2"
  type: "BatchNorm"
  bottom: "res_stage_3_320_2"
  top: "res_stage_3_320_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_320_2"  
  type: "Scale"
  bottom: "res_stage_3_320_2"
  top: "res_stage_3_320_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_320_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_320_2_top"
  top: "res_stage_3_320_2_top"
}
layer {
  name: "res_stage_3_320_3"
  type: "Convolution"
  bottom: "res_stage_3_320_2_top"
  top: "res_stage_3_320_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_320_3"
  type: "BatchNorm"
  bottom: "res_stage_3_320_3"
  top: "res_stage_3_320_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_320_3"  
  type: "Scale"
  bottom: "res_stage_3_320_3"
  top: "res_stage_3_320_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_320"
  type: "Eltwise"
  bottom: "res_3_319"
  bottom: "res_stage_3_320_3_top"
  top: "res_3_320"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_320_relu"
  type: "ReLU"
  bottom: "res_3_320"
  top: "res_3_320"
}
layer {
  name: "res_stage_3_321_1"
  type: "Convolution"
  bottom: "res_3_320"
  top: "res_stage_3_321_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_321_1"
  type: "BatchNorm"
  bottom: "res_stage_3_321_1"
  top: "res_stage_3_321_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_321_1"  
  type: "Scale"
  bottom: "res_stage_3_321_1"
  top: "res_stage_3_321_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_321_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_321_1_top"
  top: "res_stage_3_321_1_top"
}
layer {
  name: "res_stage_3_321_2"
  type: "Convolution"
  bottom: "res_stage_3_321_1_top"
  top: "res_stage_3_321_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_321_2"
  type: "BatchNorm"
  bottom: "res_stage_3_321_2"
  top: "res_stage_3_321_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_321_2"  
  type: "Scale"
  bottom: "res_stage_3_321_2"
  top: "res_stage_3_321_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_321_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_321_2_top"
  top: "res_stage_3_321_2_top"
}
layer {
  name: "res_stage_3_321_3"
  type: "Convolution"
  bottom: "res_stage_3_321_2_top"
  top: "res_stage_3_321_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_321_3"
  type: "BatchNorm"
  bottom: "res_stage_3_321_3"
  top: "res_stage_3_321_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_321_3"  
  type: "Scale"
  bottom: "res_stage_3_321_3"
  top: "res_stage_3_321_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_321"
  type: "Eltwise"
  bottom: "res_3_320"
  bottom: "res_stage_3_321_3_top"
  top: "res_3_321"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_321_relu"
  type: "ReLU"
  bottom: "res_3_321"
  top: "res_3_321"
}
layer {
  name: "res_stage_3_322_1"
  type: "Convolution"
  bottom: "res_3_321"
  top: "res_stage_3_322_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_322_1"
  type: "BatchNorm"
  bottom: "res_stage_3_322_1"
  top: "res_stage_3_322_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_322_1"  
  type: "Scale"
  bottom: "res_stage_3_322_1"
  top: "res_stage_3_322_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_322_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_322_1_top"
  top: "res_stage_3_322_1_top"
}
layer {
  name: "res_stage_3_322_2"
  type: "Convolution"
  bottom: "res_stage_3_322_1_top"
  top: "res_stage_3_322_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_322_2"
  type: "BatchNorm"
  bottom: "res_stage_3_322_2"
  top: "res_stage_3_322_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_322_2"  
  type: "Scale"
  bottom: "res_stage_3_322_2"
  top: "res_stage_3_322_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_322_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_322_2_top"
  top: "res_stage_3_322_2_top"
}
layer {
  name: "res_stage_3_322_3"
  type: "Convolution"
  bottom: "res_stage_3_322_2_top"
  top: "res_stage_3_322_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_322_3"
  type: "BatchNorm"
  bottom: "res_stage_3_322_3"
  top: "res_stage_3_322_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_322_3"  
  type: "Scale"
  bottom: "res_stage_3_322_3"
  top: "res_stage_3_322_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_322"
  type: "Eltwise"
  bottom: "res_3_321"
  bottom: "res_stage_3_322_3_top"
  top: "res_3_322"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_322_relu"
  type: "ReLU"
  bottom: "res_3_322"
  top: "res_3_322"
}
layer {
  name: "res_stage_3_323_1"
  type: "Convolution"
  bottom: "res_3_322"
  top: "res_stage_3_323_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_323_1"
  type: "BatchNorm"
  bottom: "res_stage_3_323_1"
  top: "res_stage_3_323_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_323_1"  
  type: "Scale"
  bottom: "res_stage_3_323_1"
  top: "res_stage_3_323_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_323_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_323_1_top"
  top: "res_stage_3_323_1_top"
}
layer {
  name: "res_stage_3_323_2"
  type: "Convolution"
  bottom: "res_stage_3_323_1_top"
  top: "res_stage_3_323_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_323_2"
  type: "BatchNorm"
  bottom: "res_stage_3_323_2"
  top: "res_stage_3_323_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_323_2"  
  type: "Scale"
  bottom: "res_stage_3_323_2"
  top: "res_stage_3_323_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_323_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_323_2_top"
  top: "res_stage_3_323_2_top"
}
layer {
  name: "res_stage_3_323_3"
  type: "Convolution"
  bottom: "res_stage_3_323_2_top"
  top: "res_stage_3_323_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_323_3"
  type: "BatchNorm"
  bottom: "res_stage_3_323_3"
  top: "res_stage_3_323_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_323_3"  
  type: "Scale"
  bottom: "res_stage_3_323_3"
  top: "res_stage_3_323_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_323"
  type: "Eltwise"
  bottom: "res_3_322"
  bottom: "res_stage_3_323_3_top"
  top: "res_3_323"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_323_relu"
  type: "ReLU"
  bottom: "res_3_323"
  top: "res_3_323"
}
layer {
  name: "res_stage_3_324_1"
  type: "Convolution"
  bottom: "res_3_323"
  top: "res_stage_3_324_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_324_1"
  type: "BatchNorm"
  bottom: "res_stage_3_324_1"
  top: "res_stage_3_324_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_324_1"  
  type: "Scale"
  bottom: "res_stage_3_324_1"
  top: "res_stage_3_324_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_324_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_324_1_top"
  top: "res_stage_3_324_1_top"
}
layer {
  name: "res_stage_3_324_2"
  type: "Convolution"
  bottom: "res_stage_3_324_1_top"
  top: "res_stage_3_324_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_324_2"
  type: "BatchNorm"
  bottom: "res_stage_3_324_2"
  top: "res_stage_3_324_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_324_2"  
  type: "Scale"
  bottom: "res_stage_3_324_2"
  top: "res_stage_3_324_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_324_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_324_2_top"
  top: "res_stage_3_324_2_top"
}
layer {
  name: "res_stage_3_324_3"
  type: "Convolution"
  bottom: "res_stage_3_324_2_top"
  top: "res_stage_3_324_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_324_3"
  type: "BatchNorm"
  bottom: "res_stage_3_324_3"
  top: "res_stage_3_324_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_324_3"  
  type: "Scale"
  bottom: "res_stage_3_324_3"
  top: "res_stage_3_324_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_324"
  type: "Eltwise"
  bottom: "res_3_323"
  bottom: "res_stage_3_324_3_top"
  top: "res_3_324"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_324_relu"
  type: "ReLU"
  bottom: "res_3_324"
  top: "res_3_324"
}
layer {
  name: "res_stage_3_325_1"
  type: "Convolution"
  bottom: "res_3_324"
  top: "res_stage_3_325_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_325_1"
  type: "BatchNorm"
  bottom: "res_stage_3_325_1"
  top: "res_stage_3_325_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_325_1"  
  type: "Scale"
  bottom: "res_stage_3_325_1"
  top: "res_stage_3_325_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_325_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_325_1_top"
  top: "res_stage_3_325_1_top"
}
layer {
  name: "res_stage_3_325_2"
  type: "Convolution"
  bottom: "res_stage_3_325_1_top"
  top: "res_stage_3_325_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_325_2"
  type: "BatchNorm"
  bottom: "res_stage_3_325_2"
  top: "res_stage_3_325_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_325_2"  
  type: "Scale"
  bottom: "res_stage_3_325_2"
  top: "res_stage_3_325_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_325_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_325_2_top"
  top: "res_stage_3_325_2_top"
}
layer {
  name: "res_stage_3_325_3"
  type: "Convolution"
  bottom: "res_stage_3_325_2_top"
  top: "res_stage_3_325_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_325_3"
  type: "BatchNorm"
  bottom: "res_stage_3_325_3"
  top: "res_stage_3_325_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_325_3"  
  type: "Scale"
  bottom: "res_stage_3_325_3"
  top: "res_stage_3_325_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_325"
  type: "Eltwise"
  bottom: "res_3_324"
  bottom: "res_stage_3_325_3_top"
  top: "res_3_325"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_325_relu"
  type: "ReLU"
  bottom: "res_3_325"
  top: "res_3_325"
}
layer {
  name: "res_stage_3_326_1"
  type: "Convolution"
  bottom: "res_3_325"
  top: "res_stage_3_326_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_326_1"
  type: "BatchNorm"
  bottom: "res_stage_3_326_1"
  top: "res_stage_3_326_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_326_1"  
  type: "Scale"
  bottom: "res_stage_3_326_1"
  top: "res_stage_3_326_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_326_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_326_1_top"
  top: "res_stage_3_326_1_top"
}
layer {
  name: "res_stage_3_326_2"
  type: "Convolution"
  bottom: "res_stage_3_326_1_top"
  top: "res_stage_3_326_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_326_2"
  type: "BatchNorm"
  bottom: "res_stage_3_326_2"
  top: "res_stage_3_326_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_326_2"  
  type: "Scale"
  bottom: "res_stage_3_326_2"
  top: "res_stage_3_326_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_326_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_326_2_top"
  top: "res_stage_3_326_2_top"
}
layer {
  name: "res_stage_3_326_3"
  type: "Convolution"
  bottom: "res_stage_3_326_2_top"
  top: "res_stage_3_326_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_326_3"
  type: "BatchNorm"
  bottom: "res_stage_3_326_3"
  top: "res_stage_3_326_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_326_3"  
  type: "Scale"
  bottom: "res_stage_3_326_3"
  top: "res_stage_3_326_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_326"
  type: "Eltwise"
  bottom: "res_3_325"
  bottom: "res_stage_3_326_3_top"
  top: "res_3_326"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_326_relu"
  type: "ReLU"
  bottom: "res_3_326"
  top: "res_3_326"
}
layer {
  name: "res_stage_3_327_1"
  type: "Convolution"
  bottom: "res_3_326"
  top: "res_stage_3_327_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_327_1"
  type: "BatchNorm"
  bottom: "res_stage_3_327_1"
  top: "res_stage_3_327_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_327_1"  
  type: "Scale"
  bottom: "res_stage_3_327_1"
  top: "res_stage_3_327_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_327_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_327_1_top"
  top: "res_stage_3_327_1_top"
}
layer {
  name: "res_stage_3_327_2"
  type: "Convolution"
  bottom: "res_stage_3_327_1_top"
  top: "res_stage_3_327_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_327_2"
  type: "BatchNorm"
  bottom: "res_stage_3_327_2"
  top: "res_stage_3_327_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_327_2"  
  type: "Scale"
  bottom: "res_stage_3_327_2"
  top: "res_stage_3_327_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_327_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_327_2_top"
  top: "res_stage_3_327_2_top"
}
layer {
  name: "res_stage_3_327_3"
  type: "Convolution"
  bottom: "res_stage_3_327_2_top"
  top: "res_stage_3_327_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_327_3"
  type: "BatchNorm"
  bottom: "res_stage_3_327_3"
  top: "res_stage_3_327_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_327_3"  
  type: "Scale"
  bottom: "res_stage_3_327_3"
  top: "res_stage_3_327_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_327"
  type: "Eltwise"
  bottom: "res_3_326"
  bottom: "res_stage_3_327_3_top"
  top: "res_3_327"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_327_relu"
  type: "ReLU"
  bottom: "res_3_327"
  top: "res_3_327"
}
layer {
  name: "res_stage_3_328_1"
  type: "Convolution"
  bottom: "res_3_327"
  top: "res_stage_3_328_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_328_1"
  type: "BatchNorm"
  bottom: "res_stage_3_328_1"
  top: "res_stage_3_328_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_328_1"  
  type: "Scale"
  bottom: "res_stage_3_328_1"
  top: "res_stage_3_328_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_328_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_328_1_top"
  top: "res_stage_3_328_1_top"
}
layer {
  name: "res_stage_3_328_2"
  type: "Convolution"
  bottom: "res_stage_3_328_1_top"
  top: "res_stage_3_328_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_328_2"
  type: "BatchNorm"
  bottom: "res_stage_3_328_2"
  top: "res_stage_3_328_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_328_2"  
  type: "Scale"
  bottom: "res_stage_3_328_2"
  top: "res_stage_3_328_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_328_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_328_2_top"
  top: "res_stage_3_328_2_top"
}
layer {
  name: "res_stage_3_328_3"
  type: "Convolution"
  bottom: "res_stage_3_328_2_top"
  top: "res_stage_3_328_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_328_3"
  type: "BatchNorm"
  bottom: "res_stage_3_328_3"
  top: "res_stage_3_328_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_328_3"  
  type: "Scale"
  bottom: "res_stage_3_328_3"
  top: "res_stage_3_328_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_328"
  type: "Eltwise"
  bottom: "res_3_327"
  bottom: "res_stage_3_328_3_top"
  top: "res_3_328"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_328_relu"
  type: "ReLU"
  bottom: "res_3_328"
  top: "res_3_328"
}
layer {
  name: "res_stage_3_329_1"
  type: "Convolution"
  bottom: "res_3_328"
  top: "res_stage_3_329_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_329_1"
  type: "BatchNorm"
  bottom: "res_stage_3_329_1"
  top: "res_stage_3_329_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_329_1"  
  type: "Scale"
  bottom: "res_stage_3_329_1"
  top: "res_stage_3_329_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_329_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_329_1_top"
  top: "res_stage_3_329_1_top"
}
layer {
  name: "res_stage_3_329_2"
  type: "Convolution"
  bottom: "res_stage_3_329_1_top"
  top: "res_stage_3_329_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_329_2"
  type: "BatchNorm"
  bottom: "res_stage_3_329_2"
  top: "res_stage_3_329_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_329_2"  
  type: "Scale"
  bottom: "res_stage_3_329_2"
  top: "res_stage_3_329_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_329_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_329_2_top"
  top: "res_stage_3_329_2_top"
}
layer {
  name: "res_stage_3_329_3"
  type: "Convolution"
  bottom: "res_stage_3_329_2_top"
  top: "res_stage_3_329_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_329_3"
  type: "BatchNorm"
  bottom: "res_stage_3_329_3"
  top: "res_stage_3_329_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_329_3"  
  type: "Scale"
  bottom: "res_stage_3_329_3"
  top: "res_stage_3_329_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_329"
  type: "Eltwise"
  bottom: "res_3_328"
  bottom: "res_stage_3_329_3_top"
  top: "res_3_329"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_329_relu"
  type: "ReLU"
  bottom: "res_3_329"
  top: "res_3_329"
}
layer {
  name: "res_stage_3_330_1"
  type: "Convolution"
  bottom: "res_3_329"
  top: "res_stage_3_330_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_330_1"
  type: "BatchNorm"
  bottom: "res_stage_3_330_1"
  top: "res_stage_3_330_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_330_1"  
  type: "Scale"
  bottom: "res_stage_3_330_1"
  top: "res_stage_3_330_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_330_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_330_1_top"
  top: "res_stage_3_330_1_top"
}
layer {
  name: "res_stage_3_330_2"
  type: "Convolution"
  bottom: "res_stage_3_330_1_top"
  top: "res_stage_3_330_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_330_2"
  type: "BatchNorm"
  bottom: "res_stage_3_330_2"
  top: "res_stage_3_330_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_330_2"  
  type: "Scale"
  bottom: "res_stage_3_330_2"
  top: "res_stage_3_330_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_330_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_330_2_top"
  top: "res_stage_3_330_2_top"
}
layer {
  name: "res_stage_3_330_3"
  type: "Convolution"
  bottom: "res_stage_3_330_2_top"
  top: "res_stage_3_330_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_330_3"
  type: "BatchNorm"
  bottom: "res_stage_3_330_3"
  top: "res_stage_3_330_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_330_3"  
  type: "Scale"
  bottom: "res_stage_3_330_3"
  top: "res_stage_3_330_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_330"
  type: "Eltwise"
  bottom: "res_3_329"
  bottom: "res_stage_3_330_3_top"
  top: "res_3_330"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_330_relu"
  type: "ReLU"
  bottom: "res_3_330"
  top: "res_3_330"
}
layer {
  name: "res_stage_3_331_1"
  type: "Convolution"
  bottom: "res_3_330"
  top: "res_stage_3_331_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_331_1"
  type: "BatchNorm"
  bottom: "res_stage_3_331_1"
  top: "res_stage_3_331_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_331_1"  
  type: "Scale"
  bottom: "res_stage_3_331_1"
  top: "res_stage_3_331_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_331_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_331_1_top"
  top: "res_stage_3_331_1_top"
}
layer {
  name: "res_stage_3_331_2"
  type: "Convolution"
  bottom: "res_stage_3_331_1_top"
  top: "res_stage_3_331_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_331_2"
  type: "BatchNorm"
  bottom: "res_stage_3_331_2"
  top: "res_stage_3_331_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_331_2"  
  type: "Scale"
  bottom: "res_stage_3_331_2"
  top: "res_stage_3_331_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_331_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_331_2_top"
  top: "res_stage_3_331_2_top"
}
layer {
  name: "res_stage_3_331_3"
  type: "Convolution"
  bottom: "res_stage_3_331_2_top"
  top: "res_stage_3_331_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_331_3"
  type: "BatchNorm"
  bottom: "res_stage_3_331_3"
  top: "res_stage_3_331_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_331_3"  
  type: "Scale"
  bottom: "res_stage_3_331_3"
  top: "res_stage_3_331_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_331"
  type: "Eltwise"
  bottom: "res_3_330"
  bottom: "res_stage_3_331_3_top"
  top: "res_3_331"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_331_relu"
  type: "ReLU"
  bottom: "res_3_331"
  top: "res_3_331"
}
layer {
  name: "res_stage_3_332_1"
  type: "Convolution"
  bottom: "res_3_331"
  top: "res_stage_3_332_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_332_1"
  type: "BatchNorm"
  bottom: "res_stage_3_332_1"
  top: "res_stage_3_332_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_332_1"  
  type: "Scale"
  bottom: "res_stage_3_332_1"
  top: "res_stage_3_332_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_332_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_332_1_top"
  top: "res_stage_3_332_1_top"
}
layer {
  name: "res_stage_3_332_2"
  type: "Convolution"
  bottom: "res_stage_3_332_1_top"
  top: "res_stage_3_332_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_332_2"
  type: "BatchNorm"
  bottom: "res_stage_3_332_2"
  top: "res_stage_3_332_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_332_2"  
  type: "Scale"
  bottom: "res_stage_3_332_2"
  top: "res_stage_3_332_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_332_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_332_2_top"
  top: "res_stage_3_332_2_top"
}
layer {
  name: "res_stage_3_332_3"
  type: "Convolution"
  bottom: "res_stage_3_332_2_top"
  top: "res_stage_3_332_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_332_3"
  type: "BatchNorm"
  bottom: "res_stage_3_332_3"
  top: "res_stage_3_332_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_332_3"  
  type: "Scale"
  bottom: "res_stage_3_332_3"
  top: "res_stage_3_332_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_332"
  type: "Eltwise"
  bottom: "res_3_331"
  bottom: "res_stage_3_332_3_top"
  top: "res_3_332"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_332_relu"
  type: "ReLU"
  bottom: "res_3_332"
  top: "res_3_332"
}
layer {
  name: "res_stage_3_333_1"
  type: "Convolution"
  bottom: "res_3_332"
  top: "res_stage_3_333_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_333_1"
  type: "BatchNorm"
  bottom: "res_stage_3_333_1"
  top: "res_stage_3_333_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_333_1"  
  type: "Scale"
  bottom: "res_stage_3_333_1"
  top: "res_stage_3_333_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_333_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_333_1_top"
  top: "res_stage_3_333_1_top"
}
layer {
  name: "res_stage_3_333_2"
  type: "Convolution"
  bottom: "res_stage_3_333_1_top"
  top: "res_stage_3_333_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_333_2"
  type: "BatchNorm"
  bottom: "res_stage_3_333_2"
  top: "res_stage_3_333_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_333_2"  
  type: "Scale"
  bottom: "res_stage_3_333_2"
  top: "res_stage_3_333_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_333_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_333_2_top"
  top: "res_stage_3_333_2_top"
}
layer {
  name: "res_stage_3_333_3"
  type: "Convolution"
  bottom: "res_stage_3_333_2_top"
  top: "res_stage_3_333_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_333_3"
  type: "BatchNorm"
  bottom: "res_stage_3_333_3"
  top: "res_stage_3_333_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_333_3"  
  type: "Scale"
  bottom: "res_stage_3_333_3"
  top: "res_stage_3_333_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_333"
  type: "Eltwise"
  bottom: "res_3_332"
  bottom: "res_stage_3_333_3_top"
  top: "res_3_333"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_333_relu"
  type: "ReLU"
  bottom: "res_3_333"
  top: "res_3_333"
}
layer {
  name: "res_stage_3_334_1"
  type: "Convolution"
  bottom: "res_3_333"
  top: "res_stage_3_334_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_334_1"
  type: "BatchNorm"
  bottom: "res_stage_3_334_1"
  top: "res_stage_3_334_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_334_1"  
  type: "Scale"
  bottom: "res_stage_3_334_1"
  top: "res_stage_3_334_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_334_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_334_1_top"
  top: "res_stage_3_334_1_top"
}
layer {
  name: "res_stage_3_334_2"
  type: "Convolution"
  bottom: "res_stage_3_334_1_top"
  top: "res_stage_3_334_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_334_2"
  type: "BatchNorm"
  bottom: "res_stage_3_334_2"
  top: "res_stage_3_334_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_334_2"  
  type: "Scale"
  bottom: "res_stage_3_334_2"
  top: "res_stage_3_334_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_334_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_334_2_top"
  top: "res_stage_3_334_2_top"
}
layer {
  name: "res_stage_3_334_3"
  type: "Convolution"
  bottom: "res_stage_3_334_2_top"
  top: "res_stage_3_334_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_334_3"
  type: "BatchNorm"
  bottom: "res_stage_3_334_3"
  top: "res_stage_3_334_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_334_3"  
  type: "Scale"
  bottom: "res_stage_3_334_3"
  top: "res_stage_3_334_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_334"
  type: "Eltwise"
  bottom: "res_3_333"
  bottom: "res_stage_3_334_3_top"
  top: "res_3_334"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_334_relu"
  type: "ReLU"
  bottom: "res_3_334"
  top: "res_3_334"
}
layer {
  name: "res_stage_3_335_1"
  type: "Convolution"
  bottom: "res_3_334"
  top: "res_stage_3_335_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_335_1"
  type: "BatchNorm"
  bottom: "res_stage_3_335_1"
  top: "res_stage_3_335_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_335_1"  
  type: "Scale"
  bottom: "res_stage_3_335_1"
  top: "res_stage_3_335_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_335_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_335_1_top"
  top: "res_stage_3_335_1_top"
}
layer {
  name: "res_stage_3_335_2"
  type: "Convolution"
  bottom: "res_stage_3_335_1_top"
  top: "res_stage_3_335_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_335_2"
  type: "BatchNorm"
  bottom: "res_stage_3_335_2"
  top: "res_stage_3_335_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_335_2"  
  type: "Scale"
  bottom: "res_stage_3_335_2"
  top: "res_stage_3_335_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_335_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_335_2_top"
  top: "res_stage_3_335_2_top"
}
layer {
  name: "res_stage_3_335_3"
  type: "Convolution"
  bottom: "res_stage_3_335_2_top"
  top: "res_stage_3_335_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_335_3"
  type: "BatchNorm"
  bottom: "res_stage_3_335_3"
  top: "res_stage_3_335_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_335_3"  
  type: "Scale"
  bottom: "res_stage_3_335_3"
  top: "res_stage_3_335_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_335"
  type: "Eltwise"
  bottom: "res_3_334"
  bottom: "res_stage_3_335_3_top"
  top: "res_3_335"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_335_relu"
  type: "ReLU"
  bottom: "res_3_335"
  top: "res_3_335"
}
layer {
  name: "res_stage_3_336_1"
  type: "Convolution"
  bottom: "res_3_335"
  top: "res_stage_3_336_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_336_1"
  type: "BatchNorm"
  bottom: "res_stage_3_336_1"
  top: "res_stage_3_336_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_336_1"  
  type: "Scale"
  bottom: "res_stage_3_336_1"
  top: "res_stage_3_336_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_336_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_336_1_top"
  top: "res_stage_3_336_1_top"
}
layer {
  name: "res_stage_3_336_2"
  type: "Convolution"
  bottom: "res_stage_3_336_1_top"
  top: "res_stage_3_336_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_336_2"
  type: "BatchNorm"
  bottom: "res_stage_3_336_2"
  top: "res_stage_3_336_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_336_2"  
  type: "Scale"
  bottom: "res_stage_3_336_2"
  top: "res_stage_3_336_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_336_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_336_2_top"
  top: "res_stage_3_336_2_top"
}
layer {
  name: "res_stage_3_336_3"
  type: "Convolution"
  bottom: "res_stage_3_336_2_top"
  top: "res_stage_3_336_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_336_3"
  type: "BatchNorm"
  bottom: "res_stage_3_336_3"
  top: "res_stage_3_336_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_336_3"  
  type: "Scale"
  bottom: "res_stage_3_336_3"
  top: "res_stage_3_336_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_336"
  type: "Eltwise"
  bottom: "res_3_335"
  bottom: "res_stage_3_336_3_top"
  top: "res_3_336"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_336_relu"
  type: "ReLU"
  bottom: "res_3_336"
  top: "res_3_336"
}
layer {
  name: "res_stage_3_337_1"
  type: "Convolution"
  bottom: "res_3_336"
  top: "res_stage_3_337_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_337_1"
  type: "BatchNorm"
  bottom: "res_stage_3_337_1"
  top: "res_stage_3_337_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_337_1"  
  type: "Scale"
  bottom: "res_stage_3_337_1"
  top: "res_stage_3_337_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_337_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_337_1_top"
  top: "res_stage_3_337_1_top"
}
layer {
  name: "res_stage_3_337_2"
  type: "Convolution"
  bottom: "res_stage_3_337_1_top"
  top: "res_stage_3_337_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_337_2"
  type: "BatchNorm"
  bottom: "res_stage_3_337_2"
  top: "res_stage_3_337_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_337_2"  
  type: "Scale"
  bottom: "res_stage_3_337_2"
  top: "res_stage_3_337_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_337_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_337_2_top"
  top: "res_stage_3_337_2_top"
}
layer {
  name: "res_stage_3_337_3"
  type: "Convolution"
  bottom: "res_stage_3_337_2_top"
  top: "res_stage_3_337_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_337_3"
  type: "BatchNorm"
  bottom: "res_stage_3_337_3"
  top: "res_stage_3_337_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_337_3"  
  type: "Scale"
  bottom: "res_stage_3_337_3"
  top: "res_stage_3_337_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_337"
  type: "Eltwise"
  bottom: "res_3_336"
  bottom: "res_stage_3_337_3_top"
  top: "res_3_337"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_337_relu"
  type: "ReLU"
  bottom: "res_3_337"
  top: "res_3_337"
}
layer {
  name: "res_stage_3_338_1"
  type: "Convolution"
  bottom: "res_3_337"
  top: "res_stage_3_338_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_338_1"
  type: "BatchNorm"
  bottom: "res_stage_3_338_1"
  top: "res_stage_3_338_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_338_1"  
  type: "Scale"
  bottom: "res_stage_3_338_1"
  top: "res_stage_3_338_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_338_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_338_1_top"
  top: "res_stage_3_338_1_top"
}
layer {
  name: "res_stage_3_338_2"
  type: "Convolution"
  bottom: "res_stage_3_338_1_top"
  top: "res_stage_3_338_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_338_2"
  type: "BatchNorm"
  bottom: "res_stage_3_338_2"
  top: "res_stage_3_338_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_338_2"  
  type: "Scale"
  bottom: "res_stage_3_338_2"
  top: "res_stage_3_338_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_338_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_338_2_top"
  top: "res_stage_3_338_2_top"
}
layer {
  name: "res_stage_3_338_3"
  type: "Convolution"
  bottom: "res_stage_3_338_2_top"
  top: "res_stage_3_338_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_338_3"
  type: "BatchNorm"
  bottom: "res_stage_3_338_3"
  top: "res_stage_3_338_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_338_3"  
  type: "Scale"
  bottom: "res_stage_3_338_3"
  top: "res_stage_3_338_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_338"
  type: "Eltwise"
  bottom: "res_3_337"
  bottom: "res_stage_3_338_3_top"
  top: "res_3_338"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_338_relu"
  type: "ReLU"
  bottom: "res_3_338"
  top: "res_3_338"
}
layer {
  name: "res_stage_3_339_1"
  type: "Convolution"
  bottom: "res_3_338"
  top: "res_stage_3_339_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_339_1"
  type: "BatchNorm"
  bottom: "res_stage_3_339_1"
  top: "res_stage_3_339_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_339_1"  
  type: "Scale"
  bottom: "res_stage_3_339_1"
  top: "res_stage_3_339_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_339_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_339_1_top"
  top: "res_stage_3_339_1_top"
}
layer {
  name: "res_stage_3_339_2"
  type: "Convolution"
  bottom: "res_stage_3_339_1_top"
  top: "res_stage_3_339_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_339_2"
  type: "BatchNorm"
  bottom: "res_stage_3_339_2"
  top: "res_stage_3_339_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_339_2"  
  type: "Scale"
  bottom: "res_stage_3_339_2"
  top: "res_stage_3_339_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_339_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_339_2_top"
  top: "res_stage_3_339_2_top"
}
layer {
  name: "res_stage_3_339_3"
  type: "Convolution"
  bottom: "res_stage_3_339_2_top"
  top: "res_stage_3_339_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_339_3"
  type: "BatchNorm"
  bottom: "res_stage_3_339_3"
  top: "res_stage_3_339_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_339_3"  
  type: "Scale"
  bottom: "res_stage_3_339_3"
  top: "res_stage_3_339_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_339"
  type: "Eltwise"
  bottom: "res_3_338"
  bottom: "res_stage_3_339_3_top"
  top: "res_3_339"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_339_relu"
  type: "ReLU"
  bottom: "res_3_339"
  top: "res_3_339"
}
layer {
  name: "res_stage_3_340_1"
  type: "Convolution"
  bottom: "res_3_339"
  top: "res_stage_3_340_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_340_1"
  type: "BatchNorm"
  bottom: "res_stage_3_340_1"
  top: "res_stage_3_340_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_340_1"  
  type: "Scale"
  bottom: "res_stage_3_340_1"
  top: "res_stage_3_340_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_340_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_340_1_top"
  top: "res_stage_3_340_1_top"
}
layer {
  name: "res_stage_3_340_2"
  type: "Convolution"
  bottom: "res_stage_3_340_1_top"
  top: "res_stage_3_340_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_340_2"
  type: "BatchNorm"
  bottom: "res_stage_3_340_2"
  top: "res_stage_3_340_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_340_2"  
  type: "Scale"
  bottom: "res_stage_3_340_2"
  top: "res_stage_3_340_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_340_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_340_2_top"
  top: "res_stage_3_340_2_top"
}
layer {
  name: "res_stage_3_340_3"
  type: "Convolution"
  bottom: "res_stage_3_340_2_top"
  top: "res_stage_3_340_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_340_3"
  type: "BatchNorm"
  bottom: "res_stage_3_340_3"
  top: "res_stage_3_340_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_340_3"  
  type: "Scale"
  bottom: "res_stage_3_340_3"
  top: "res_stage_3_340_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_340"
  type: "Eltwise"
  bottom: "res_3_339"
  bottom: "res_stage_3_340_3_top"
  top: "res_3_340"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_340_relu"
  type: "ReLU"
  bottom: "res_3_340"
  top: "res_3_340"
}
layer {
  name: "res_stage_3_341_1"
  type: "Convolution"
  bottom: "res_3_340"
  top: "res_stage_3_341_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_341_1"
  type: "BatchNorm"
  bottom: "res_stage_3_341_1"
  top: "res_stage_3_341_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_341_1"  
  type: "Scale"
  bottom: "res_stage_3_341_1"
  top: "res_stage_3_341_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_341_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_341_1_top"
  top: "res_stage_3_341_1_top"
}
layer {
  name: "res_stage_3_341_2"
  type: "Convolution"
  bottom: "res_stage_3_341_1_top"
  top: "res_stage_3_341_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_341_2"
  type: "BatchNorm"
  bottom: "res_stage_3_341_2"
  top: "res_stage_3_341_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_341_2"  
  type: "Scale"
  bottom: "res_stage_3_341_2"
  top: "res_stage_3_341_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_341_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_341_2_top"
  top: "res_stage_3_341_2_top"
}
layer {
  name: "res_stage_3_341_3"
  type: "Convolution"
  bottom: "res_stage_3_341_2_top"
  top: "res_stage_3_341_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_341_3"
  type: "BatchNorm"
  bottom: "res_stage_3_341_3"
  top: "res_stage_3_341_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_341_3"  
  type: "Scale"
  bottom: "res_stage_3_341_3"
  top: "res_stage_3_341_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_341"
  type: "Eltwise"
  bottom: "res_3_340"
  bottom: "res_stage_3_341_3_top"
  top: "res_3_341"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_341_relu"
  type: "ReLU"
  bottom: "res_3_341"
  top: "res_3_341"
}
layer {
  name: "res_stage_3_342_1"
  type: "Convolution"
  bottom: "res_3_341"
  top: "res_stage_3_342_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_342_1"
  type: "BatchNorm"
  bottom: "res_stage_3_342_1"
  top: "res_stage_3_342_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_342_1"  
  type: "Scale"
  bottom: "res_stage_3_342_1"
  top: "res_stage_3_342_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_342_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_342_1_top"
  top: "res_stage_3_342_1_top"
}
layer {
  name: "res_stage_3_342_2"
  type: "Convolution"
  bottom: "res_stage_3_342_1_top"
  top: "res_stage_3_342_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_342_2"
  type: "BatchNorm"
  bottom: "res_stage_3_342_2"
  top: "res_stage_3_342_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_342_2"  
  type: "Scale"
  bottom: "res_stage_3_342_2"
  top: "res_stage_3_342_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_342_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_342_2_top"
  top: "res_stage_3_342_2_top"
}
layer {
  name: "res_stage_3_342_3"
  type: "Convolution"
  bottom: "res_stage_3_342_2_top"
  top: "res_stage_3_342_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_342_3"
  type: "BatchNorm"
  bottom: "res_stage_3_342_3"
  top: "res_stage_3_342_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_342_3"  
  type: "Scale"
  bottom: "res_stage_3_342_3"
  top: "res_stage_3_342_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_342"
  type: "Eltwise"
  bottom: "res_3_341"
  bottom: "res_stage_3_342_3_top"
  top: "res_3_342"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_342_relu"
  type: "ReLU"
  bottom: "res_3_342"
  top: "res_3_342"
}
layer {
  name: "res_stage_3_343_1"
  type: "Convolution"
  bottom: "res_3_342"
  top: "res_stage_3_343_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_343_1"
  type: "BatchNorm"
  bottom: "res_stage_3_343_1"
  top: "res_stage_3_343_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_343_1"  
  type: "Scale"
  bottom: "res_stage_3_343_1"
  top: "res_stage_3_343_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_343_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_343_1_top"
  top: "res_stage_3_343_1_top"
}
layer {
  name: "res_stage_3_343_2"
  type: "Convolution"
  bottom: "res_stage_3_343_1_top"
  top: "res_stage_3_343_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_343_2"
  type: "BatchNorm"
  bottom: "res_stage_3_343_2"
  top: "res_stage_3_343_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_343_2"  
  type: "Scale"
  bottom: "res_stage_3_343_2"
  top: "res_stage_3_343_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_343_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_343_2_top"
  top: "res_stage_3_343_2_top"
}
layer {
  name: "res_stage_3_343_3"
  type: "Convolution"
  bottom: "res_stage_3_343_2_top"
  top: "res_stage_3_343_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_343_3"
  type: "BatchNorm"
  bottom: "res_stage_3_343_3"
  top: "res_stage_3_343_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_343_3"  
  type: "Scale"
  bottom: "res_stage_3_343_3"
  top: "res_stage_3_343_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_343"
  type: "Eltwise"
  bottom: "res_3_342"
  bottom: "res_stage_3_343_3_top"
  top: "res_3_343"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_343_relu"
  type: "ReLU"
  bottom: "res_3_343"
  top: "res_3_343"
}
layer {
  name: "res_stage_3_344_1"
  type: "Convolution"
  bottom: "res_3_343"
  top: "res_stage_3_344_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_344_1"
  type: "BatchNorm"
  bottom: "res_stage_3_344_1"
  top: "res_stage_3_344_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_344_1"  
  type: "Scale"
  bottom: "res_stage_3_344_1"
  top: "res_stage_3_344_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_344_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_344_1_top"
  top: "res_stage_3_344_1_top"
}
layer {
  name: "res_stage_3_344_2"
  type: "Convolution"
  bottom: "res_stage_3_344_1_top"
  top: "res_stage_3_344_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_344_2"
  type: "BatchNorm"
  bottom: "res_stage_3_344_2"
  top: "res_stage_3_344_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_344_2"  
  type: "Scale"
  bottom: "res_stage_3_344_2"
  top: "res_stage_3_344_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_344_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_344_2_top"
  top: "res_stage_3_344_2_top"
}
layer {
  name: "res_stage_3_344_3"
  type: "Convolution"
  bottom: "res_stage_3_344_2_top"
  top: "res_stage_3_344_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_344_3"
  type: "BatchNorm"
  bottom: "res_stage_3_344_3"
  top: "res_stage_3_344_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_344_3"  
  type: "Scale"
  bottom: "res_stage_3_344_3"
  top: "res_stage_3_344_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_344"
  type: "Eltwise"
  bottom: "res_3_343"
  bottom: "res_stage_3_344_3_top"
  top: "res_3_344"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_344_relu"
  type: "ReLU"
  bottom: "res_3_344"
  top: "res_3_344"
}
layer {
  name: "res_stage_3_345_1"
  type: "Convolution"
  bottom: "res_3_344"
  top: "res_stage_3_345_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_345_1"
  type: "BatchNorm"
  bottom: "res_stage_3_345_1"
  top: "res_stage_3_345_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_345_1"  
  type: "Scale"
  bottom: "res_stage_3_345_1"
  top: "res_stage_3_345_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_345_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_345_1_top"
  top: "res_stage_3_345_1_top"
}
layer {
  name: "res_stage_3_345_2"
  type: "Convolution"
  bottom: "res_stage_3_345_1_top"
  top: "res_stage_3_345_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_345_2"
  type: "BatchNorm"
  bottom: "res_stage_3_345_2"
  top: "res_stage_3_345_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_345_2"  
  type: "Scale"
  bottom: "res_stage_3_345_2"
  top: "res_stage_3_345_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_345_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_345_2_top"
  top: "res_stage_3_345_2_top"
}
layer {
  name: "res_stage_3_345_3"
  type: "Convolution"
  bottom: "res_stage_3_345_2_top"
  top: "res_stage_3_345_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_345_3"
  type: "BatchNorm"
  bottom: "res_stage_3_345_3"
  top: "res_stage_3_345_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_345_3"  
  type: "Scale"
  bottom: "res_stage_3_345_3"
  top: "res_stage_3_345_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_345"
  type: "Eltwise"
  bottom: "res_3_344"
  bottom: "res_stage_3_345_3_top"
  top: "res_3_345"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_345_relu"
  type: "ReLU"
  bottom: "res_3_345"
  top: "res_3_345"
}
layer {
  name: "res_stage_3_346_1"
  type: "Convolution"
  bottom: "res_3_345"
  top: "res_stage_3_346_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_346_1"
  type: "BatchNorm"
  bottom: "res_stage_3_346_1"
  top: "res_stage_3_346_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_346_1"  
  type: "Scale"
  bottom: "res_stage_3_346_1"
  top: "res_stage_3_346_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_346_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_346_1_top"
  top: "res_stage_3_346_1_top"
}
layer {
  name: "res_stage_3_346_2"
  type: "Convolution"
  bottom: "res_stage_3_346_1_top"
  top: "res_stage_3_346_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_346_2"
  type: "BatchNorm"
  bottom: "res_stage_3_346_2"
  top: "res_stage_3_346_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_346_2"  
  type: "Scale"
  bottom: "res_stage_3_346_2"
  top: "res_stage_3_346_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_346_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_346_2_top"
  top: "res_stage_3_346_2_top"
}
layer {
  name: "res_stage_3_346_3"
  type: "Convolution"
  bottom: "res_stage_3_346_2_top"
  top: "res_stage_3_346_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_346_3"
  type: "BatchNorm"
  bottom: "res_stage_3_346_3"
  top: "res_stage_3_346_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_346_3"  
  type: "Scale"
  bottom: "res_stage_3_346_3"
  top: "res_stage_3_346_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_346"
  type: "Eltwise"
  bottom: "res_3_345"
  bottom: "res_stage_3_346_3_top"
  top: "res_3_346"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_346_relu"
  type: "ReLU"
  bottom: "res_3_346"
  top: "res_3_346"
}
layer {
  name: "res_stage_3_347_1"
  type: "Convolution"
  bottom: "res_3_346"
  top: "res_stage_3_347_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_347_1"
  type: "BatchNorm"
  bottom: "res_stage_3_347_1"
  top: "res_stage_3_347_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_347_1"  
  type: "Scale"
  bottom: "res_stage_3_347_1"
  top: "res_stage_3_347_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_347_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_347_1_top"
  top: "res_stage_3_347_1_top"
}
layer {
  name: "res_stage_3_347_2"
  type: "Convolution"
  bottom: "res_stage_3_347_1_top"
  top: "res_stage_3_347_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_347_2"
  type: "BatchNorm"
  bottom: "res_stage_3_347_2"
  top: "res_stage_3_347_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_347_2"  
  type: "Scale"
  bottom: "res_stage_3_347_2"
  top: "res_stage_3_347_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_347_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_347_2_top"
  top: "res_stage_3_347_2_top"
}
layer {
  name: "res_stage_3_347_3"
  type: "Convolution"
  bottom: "res_stage_3_347_2_top"
  top: "res_stage_3_347_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_347_3"
  type: "BatchNorm"
  bottom: "res_stage_3_347_3"
  top: "res_stage_3_347_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_347_3"  
  type: "Scale"
  bottom: "res_stage_3_347_3"
  top: "res_stage_3_347_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_347"
  type: "Eltwise"
  bottom: "res_3_346"
  bottom: "res_stage_3_347_3_top"
  top: "res_3_347"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_347_relu"
  type: "ReLU"
  bottom: "res_3_347"
  top: "res_3_347"
}
layer {
  name: "res_stage_3_348_1"
  type: "Convolution"
  bottom: "res_3_347"
  top: "res_stage_3_348_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_348_1"
  type: "BatchNorm"
  bottom: "res_stage_3_348_1"
  top: "res_stage_3_348_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_348_1"  
  type: "Scale"
  bottom: "res_stage_3_348_1"
  top: "res_stage_3_348_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_348_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_348_1_top"
  top: "res_stage_3_348_1_top"
}
layer {
  name: "res_stage_3_348_2"
  type: "Convolution"
  bottom: "res_stage_3_348_1_top"
  top: "res_stage_3_348_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_348_2"
  type: "BatchNorm"
  bottom: "res_stage_3_348_2"
  top: "res_stage_3_348_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_348_2"  
  type: "Scale"
  bottom: "res_stage_3_348_2"
  top: "res_stage_3_348_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_348_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_348_2_top"
  top: "res_stage_3_348_2_top"
}
layer {
  name: "res_stage_3_348_3"
  type: "Convolution"
  bottom: "res_stage_3_348_2_top"
  top: "res_stage_3_348_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_348_3"
  type: "BatchNorm"
  bottom: "res_stage_3_348_3"
  top: "res_stage_3_348_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_348_3"  
  type: "Scale"
  bottom: "res_stage_3_348_3"
  top: "res_stage_3_348_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_348"
  type: "Eltwise"
  bottom: "res_3_347"
  bottom: "res_stage_3_348_3_top"
  top: "res_3_348"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_348_relu"
  type: "ReLU"
  bottom: "res_3_348"
  top: "res_3_348"
}
layer {
  name: "res_stage_3_349_1"
  type: "Convolution"
  bottom: "res_3_348"
  top: "res_stage_3_349_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_349_1"
  type: "BatchNorm"
  bottom: "res_stage_3_349_1"
  top: "res_stage_3_349_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_349_1"  
  type: "Scale"
  bottom: "res_stage_3_349_1"
  top: "res_stage_3_349_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_349_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_349_1_top"
  top: "res_stage_3_349_1_top"
}
layer {
  name: "res_stage_3_349_2"
  type: "Convolution"
  bottom: "res_stage_3_349_1_top"
  top: "res_stage_3_349_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_349_2"
  type: "BatchNorm"
  bottom: "res_stage_3_349_2"
  top: "res_stage_3_349_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_349_2"  
  type: "Scale"
  bottom: "res_stage_3_349_2"
  top: "res_stage_3_349_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_349_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_349_2_top"
  top: "res_stage_3_349_2_top"
}
layer {
  name: "res_stage_3_349_3"
  type: "Convolution"
  bottom: "res_stage_3_349_2_top"
  top: "res_stage_3_349_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_349_3"
  type: "BatchNorm"
  bottom: "res_stage_3_349_3"
  top: "res_stage_3_349_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_349_3"  
  type: "Scale"
  bottom: "res_stage_3_349_3"
  top: "res_stage_3_349_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_349"
  type: "Eltwise"
  bottom: "res_3_348"
  bottom: "res_stage_3_349_3_top"
  top: "res_3_349"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_349_relu"
  type: "ReLU"
  bottom: "res_3_349"
  top: "res_3_349"
}
layer {
  name: "res_stage_3_350_1"
  type: "Convolution"
  bottom: "res_3_349"
  top: "res_stage_3_350_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_350_1"
  type: "BatchNorm"
  bottom: "res_stage_3_350_1"
  top: "res_stage_3_350_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_350_1"  
  type: "Scale"
  bottom: "res_stage_3_350_1"
  top: "res_stage_3_350_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_350_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_350_1_top"
  top: "res_stage_3_350_1_top"
}
layer {
  name: "res_stage_3_350_2"
  type: "Convolution"
  bottom: "res_stage_3_350_1_top"
  top: "res_stage_3_350_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_350_2"
  type: "BatchNorm"
  bottom: "res_stage_3_350_2"
  top: "res_stage_3_350_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_350_2"  
  type: "Scale"
  bottom: "res_stage_3_350_2"
  top: "res_stage_3_350_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_350_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_350_2_top"
  top: "res_stage_3_350_2_top"
}
layer {
  name: "res_stage_3_350_3"
  type: "Convolution"
  bottom: "res_stage_3_350_2_top"
  top: "res_stage_3_350_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_350_3"
  type: "BatchNorm"
  bottom: "res_stage_3_350_3"
  top: "res_stage_3_350_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_350_3"  
  type: "Scale"
  bottom: "res_stage_3_350_3"
  top: "res_stage_3_350_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_350"
  type: "Eltwise"
  bottom: "res_3_349"
  bottom: "res_stage_3_350_3_top"
  top: "res_3_350"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_350_relu"
  type: "ReLU"
  bottom: "res_3_350"
  top: "res_3_350"
}
layer {
  name: "res_stage_3_351_1"
  type: "Convolution"
  bottom: "res_3_350"
  top: "res_stage_3_351_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_351_1"
  type: "BatchNorm"
  bottom: "res_stage_3_351_1"
  top: "res_stage_3_351_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_351_1"  
  type: "Scale"
  bottom: "res_stage_3_351_1"
  top: "res_stage_3_351_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_351_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_351_1_top"
  top: "res_stage_3_351_1_top"
}
layer {
  name: "res_stage_3_351_2"
  type: "Convolution"
  bottom: "res_stage_3_351_1_top"
  top: "res_stage_3_351_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_351_2"
  type: "BatchNorm"
  bottom: "res_stage_3_351_2"
  top: "res_stage_3_351_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_351_2"  
  type: "Scale"
  bottom: "res_stage_3_351_2"
  top: "res_stage_3_351_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_351_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_351_2_top"
  top: "res_stage_3_351_2_top"
}
layer {
  name: "res_stage_3_351_3"
  type: "Convolution"
  bottom: "res_stage_3_351_2_top"
  top: "res_stage_3_351_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_351_3"
  type: "BatchNorm"
  bottom: "res_stage_3_351_3"
  top: "res_stage_3_351_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_351_3"  
  type: "Scale"
  bottom: "res_stage_3_351_3"
  top: "res_stage_3_351_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_351"
  type: "Eltwise"
  bottom: "res_3_350"
  bottom: "res_stage_3_351_3_top"
  top: "res_3_351"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_351_relu"
  type: "ReLU"
  bottom: "res_3_351"
  top: "res_3_351"
}
layer {
  name: "res_stage_3_352_1"
  type: "Convolution"
  bottom: "res_3_351"
  top: "res_stage_3_352_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_352_1"
  type: "BatchNorm"
  bottom: "res_stage_3_352_1"
  top: "res_stage_3_352_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_352_1"  
  type: "Scale"
  bottom: "res_stage_3_352_1"
  top: "res_stage_3_352_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_352_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_352_1_top"
  top: "res_stage_3_352_1_top"
}
layer {
  name: "res_stage_3_352_2"
  type: "Convolution"
  bottom: "res_stage_3_352_1_top"
  top: "res_stage_3_352_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_352_2"
  type: "BatchNorm"
  bottom: "res_stage_3_352_2"
  top: "res_stage_3_352_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_352_2"  
  type: "Scale"
  bottom: "res_stage_3_352_2"
  top: "res_stage_3_352_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_352_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_352_2_top"
  top: "res_stage_3_352_2_top"
}
layer {
  name: "res_stage_3_352_3"
  type: "Convolution"
  bottom: "res_stage_3_352_2_top"
  top: "res_stage_3_352_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_352_3"
  type: "BatchNorm"
  bottom: "res_stage_3_352_3"
  top: "res_stage_3_352_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_352_3"  
  type: "Scale"
  bottom: "res_stage_3_352_3"
  top: "res_stage_3_352_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_352"
  type: "Eltwise"
  bottom: "res_3_351"
  bottom: "res_stage_3_352_3_top"
  top: "res_3_352"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_352_relu"
  type: "ReLU"
  bottom: "res_3_352"
  top: "res_3_352"
}
layer {
  name: "res_stage_3_353_1"
  type: "Convolution"
  bottom: "res_3_352"
  top: "res_stage_3_353_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_353_1"
  type: "BatchNorm"
  bottom: "res_stage_3_353_1"
  top: "res_stage_3_353_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_353_1"  
  type: "Scale"
  bottom: "res_stage_3_353_1"
  top: "res_stage_3_353_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_353_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_353_1_top"
  top: "res_stage_3_353_1_top"
}
layer {
  name: "res_stage_3_353_2"
  type: "Convolution"
  bottom: "res_stage_3_353_1_top"
  top: "res_stage_3_353_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_353_2"
  type: "BatchNorm"
  bottom: "res_stage_3_353_2"
  top: "res_stage_3_353_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_353_2"  
  type: "Scale"
  bottom: "res_stage_3_353_2"
  top: "res_stage_3_353_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_353_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_353_2_top"
  top: "res_stage_3_353_2_top"
}
layer {
  name: "res_stage_3_353_3"
  type: "Convolution"
  bottom: "res_stage_3_353_2_top"
  top: "res_stage_3_353_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_353_3"
  type: "BatchNorm"
  bottom: "res_stage_3_353_3"
  top: "res_stage_3_353_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_353_3"  
  type: "Scale"
  bottom: "res_stage_3_353_3"
  top: "res_stage_3_353_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_353"
  type: "Eltwise"
  bottom: "res_3_352"
  bottom: "res_stage_3_353_3_top"
  top: "res_3_353"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_353_relu"
  type: "ReLU"
  bottom: "res_3_353"
  top: "res_3_353"
}
layer {
  name: "res_stage_3_354_1"
  type: "Convolution"
  bottom: "res_3_353"
  top: "res_stage_3_354_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_354_1"
  type: "BatchNorm"
  bottom: "res_stage_3_354_1"
  top: "res_stage_3_354_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_354_1"  
  type: "Scale"
  bottom: "res_stage_3_354_1"
  top: "res_stage_3_354_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_354_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_354_1_top"
  top: "res_stage_3_354_1_top"
}
layer {
  name: "res_stage_3_354_2"
  type: "Convolution"
  bottom: "res_stage_3_354_1_top"
  top: "res_stage_3_354_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_354_2"
  type: "BatchNorm"
  bottom: "res_stage_3_354_2"
  top: "res_stage_3_354_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_354_2"  
  type: "Scale"
  bottom: "res_stage_3_354_2"
  top: "res_stage_3_354_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_354_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_354_2_top"
  top: "res_stage_3_354_2_top"
}
layer {
  name: "res_stage_3_354_3"
  type: "Convolution"
  bottom: "res_stage_3_354_2_top"
  top: "res_stage_3_354_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_354_3"
  type: "BatchNorm"
  bottom: "res_stage_3_354_3"
  top: "res_stage_3_354_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_354_3"  
  type: "Scale"
  bottom: "res_stage_3_354_3"
  top: "res_stage_3_354_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_354"
  type: "Eltwise"
  bottom: "res_3_353"
  bottom: "res_stage_3_354_3_top"
  top: "res_3_354"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_354_relu"
  type: "ReLU"
  bottom: "res_3_354"
  top: "res_3_354"
}
layer {
  name: "res_stage_3_355_1"
  type: "Convolution"
  bottom: "res_3_354"
  top: "res_stage_3_355_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_355_1"
  type: "BatchNorm"
  bottom: "res_stage_3_355_1"
  top: "res_stage_3_355_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_355_1"  
  type: "Scale"
  bottom: "res_stage_3_355_1"
  top: "res_stage_3_355_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_355_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_355_1_top"
  top: "res_stage_3_355_1_top"
}
layer {
  name: "res_stage_3_355_2"
  type: "Convolution"
  bottom: "res_stage_3_355_1_top"
  top: "res_stage_3_355_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_355_2"
  type: "BatchNorm"
  bottom: "res_stage_3_355_2"
  top: "res_stage_3_355_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_355_2"  
  type: "Scale"
  bottom: "res_stage_3_355_2"
  top: "res_stage_3_355_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_355_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_355_2_top"
  top: "res_stage_3_355_2_top"
}
layer {
  name: "res_stage_3_355_3"
  type: "Convolution"
  bottom: "res_stage_3_355_2_top"
  top: "res_stage_3_355_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_355_3"
  type: "BatchNorm"
  bottom: "res_stage_3_355_3"
  top: "res_stage_3_355_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_355_3"  
  type: "Scale"
  bottom: "res_stage_3_355_3"
  top: "res_stage_3_355_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_355"
  type: "Eltwise"
  bottom: "res_3_354"
  bottom: "res_stage_3_355_3_top"
  top: "res_3_355"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_355_relu"
  type: "ReLU"
  bottom: "res_3_355"
  top: "res_3_355"
}
layer {
  name: "res_stage_3_356_1"
  type: "Convolution"
  bottom: "res_3_355"
  top: "res_stage_3_356_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_356_1"
  type: "BatchNorm"
  bottom: "res_stage_3_356_1"
  top: "res_stage_3_356_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_356_1"  
  type: "Scale"
  bottom: "res_stage_3_356_1"
  top: "res_stage_3_356_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_356_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_356_1_top"
  top: "res_stage_3_356_1_top"
}
layer {
  name: "res_stage_3_356_2"
  type: "Convolution"
  bottom: "res_stage_3_356_1_top"
  top: "res_stage_3_356_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_356_2"
  type: "BatchNorm"
  bottom: "res_stage_3_356_2"
  top: "res_stage_3_356_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_356_2"  
  type: "Scale"
  bottom: "res_stage_3_356_2"
  top: "res_stage_3_356_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_356_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_356_2_top"
  top: "res_stage_3_356_2_top"
}
layer {
  name: "res_stage_3_356_3"
  type: "Convolution"
  bottom: "res_stage_3_356_2_top"
  top: "res_stage_3_356_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_356_3"
  type: "BatchNorm"
  bottom: "res_stage_3_356_3"
  top: "res_stage_3_356_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_356_3"  
  type: "Scale"
  bottom: "res_stage_3_356_3"
  top: "res_stage_3_356_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_356"
  type: "Eltwise"
  bottom: "res_3_355"
  bottom: "res_stage_3_356_3_top"
  top: "res_3_356"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_356_relu"
  type: "ReLU"
  bottom: "res_3_356"
  top: "res_3_356"
}
layer {
  name: "res_stage_3_357_1"
  type: "Convolution"
  bottom: "res_3_356"
  top: "res_stage_3_357_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_357_1"
  type: "BatchNorm"
  bottom: "res_stage_3_357_1"
  top: "res_stage_3_357_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_357_1"  
  type: "Scale"
  bottom: "res_stage_3_357_1"
  top: "res_stage_3_357_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_357_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_357_1_top"
  top: "res_stage_3_357_1_top"
}
layer {
  name: "res_stage_3_357_2"
  type: "Convolution"
  bottom: "res_stage_3_357_1_top"
  top: "res_stage_3_357_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_357_2"
  type: "BatchNorm"
  bottom: "res_stage_3_357_2"
  top: "res_stage_3_357_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_357_2"  
  type: "Scale"
  bottom: "res_stage_3_357_2"
  top: "res_stage_3_357_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_357_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_357_2_top"
  top: "res_stage_3_357_2_top"
}
layer {
  name: "res_stage_3_357_3"
  type: "Convolution"
  bottom: "res_stage_3_357_2_top"
  top: "res_stage_3_357_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_357_3"
  type: "BatchNorm"
  bottom: "res_stage_3_357_3"
  top: "res_stage_3_357_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_357_3"  
  type: "Scale"
  bottom: "res_stage_3_357_3"
  top: "res_stage_3_357_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_357"
  type: "Eltwise"
  bottom: "res_3_356"
  bottom: "res_stage_3_357_3_top"
  top: "res_3_357"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_357_relu"
  type: "ReLU"
  bottom: "res_3_357"
  top: "res_3_357"
}
layer {
  name: "res_stage_3_358_1"
  type: "Convolution"
  bottom: "res_3_357"
  top: "res_stage_3_358_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_358_1"
  type: "BatchNorm"
  bottom: "res_stage_3_358_1"
  top: "res_stage_3_358_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_358_1"  
  type: "Scale"
  bottom: "res_stage_3_358_1"
  top: "res_stage_3_358_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_358_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_358_1_top"
  top: "res_stage_3_358_1_top"
}
layer {
  name: "res_stage_3_358_2"
  type: "Convolution"
  bottom: "res_stage_3_358_1_top"
  top: "res_stage_3_358_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_358_2"
  type: "BatchNorm"
  bottom: "res_stage_3_358_2"
  top: "res_stage_3_358_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_358_2"  
  type: "Scale"
  bottom: "res_stage_3_358_2"
  top: "res_stage_3_358_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_358_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_358_2_top"
  top: "res_stage_3_358_2_top"
}
layer {
  name: "res_stage_3_358_3"
  type: "Convolution"
  bottom: "res_stage_3_358_2_top"
  top: "res_stage_3_358_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_358_3"
  type: "BatchNorm"
  bottom: "res_stage_3_358_3"
  top: "res_stage_3_358_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_358_3"  
  type: "Scale"
  bottom: "res_stage_3_358_3"
  top: "res_stage_3_358_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_358"
  type: "Eltwise"
  bottom: "res_3_357"
  bottom: "res_stage_3_358_3_top"
  top: "res_3_358"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_358_relu"
  type: "ReLU"
  bottom: "res_3_358"
  top: "res_3_358"
}
layer {
  name: "res_stage_3_359_1"
  type: "Convolution"
  bottom: "res_3_358"
  top: "res_stage_3_359_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_359_1"
  type: "BatchNorm"
  bottom: "res_stage_3_359_1"
  top: "res_stage_3_359_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_359_1"  
  type: "Scale"
  bottom: "res_stage_3_359_1"
  top: "res_stage_3_359_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_359_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_359_1_top"
  top: "res_stage_3_359_1_top"
}
layer {
  name: "res_stage_3_359_2"
  type: "Convolution"
  bottom: "res_stage_3_359_1_top"
  top: "res_stage_3_359_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_359_2"
  type: "BatchNorm"
  bottom: "res_stage_3_359_2"
  top: "res_stage_3_359_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_359_2"  
  type: "Scale"
  bottom: "res_stage_3_359_2"
  top: "res_stage_3_359_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_359_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_359_2_top"
  top: "res_stage_3_359_2_top"
}
layer {
  name: "res_stage_3_359_3"
  type: "Convolution"
  bottom: "res_stage_3_359_2_top"
  top: "res_stage_3_359_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_359_3"
  type: "BatchNorm"
  bottom: "res_stage_3_359_3"
  top: "res_stage_3_359_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_359_3"  
  type: "Scale"
  bottom: "res_stage_3_359_3"
  top: "res_stage_3_359_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_359"
  type: "Eltwise"
  bottom: "res_3_358"
  bottom: "res_stage_3_359_3_top"
  top: "res_3_359"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_359_relu"
  type: "ReLU"
  bottom: "res_3_359"
  top: "res_3_359"
}
layer {
  name: "res_stage_3_360_1"
  type: "Convolution"
  bottom: "res_3_359"
  top: "res_stage_3_360_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_360_1"
  type: "BatchNorm"
  bottom: "res_stage_3_360_1"
  top: "res_stage_3_360_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_360_1"  
  type: "Scale"
  bottom: "res_stage_3_360_1"
  top: "res_stage_3_360_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_360_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_360_1_top"
  top: "res_stage_3_360_1_top"
}
layer {
  name: "res_stage_3_360_2"
  type: "Convolution"
  bottom: "res_stage_3_360_1_top"
  top: "res_stage_3_360_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_360_2"
  type: "BatchNorm"
  bottom: "res_stage_3_360_2"
  top: "res_stage_3_360_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_360_2"  
  type: "Scale"
  bottom: "res_stage_3_360_2"
  top: "res_stage_3_360_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_360_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_360_2_top"
  top: "res_stage_3_360_2_top"
}
layer {
  name: "res_stage_3_360_3"
  type: "Convolution"
  bottom: "res_stage_3_360_2_top"
  top: "res_stage_3_360_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_360_3"
  type: "BatchNorm"
  bottom: "res_stage_3_360_3"
  top: "res_stage_3_360_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_360_3"  
  type: "Scale"
  bottom: "res_stage_3_360_3"
  top: "res_stage_3_360_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_360"
  type: "Eltwise"
  bottom: "res_3_359"
  bottom: "res_stage_3_360_3_top"
  top: "res_3_360"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_360_relu"
  type: "ReLU"
  bottom: "res_3_360"
  top: "res_3_360"
}
layer {
  name: "res_stage_3_361_1"
  type: "Convolution"
  bottom: "res_3_360"
  top: "res_stage_3_361_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_361_1"
  type: "BatchNorm"
  bottom: "res_stage_3_361_1"
  top: "res_stage_3_361_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_361_1"  
  type: "Scale"
  bottom: "res_stage_3_361_1"
  top: "res_stage_3_361_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_361_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_361_1_top"
  top: "res_stage_3_361_1_top"
}
layer {
  name: "res_stage_3_361_2"
  type: "Convolution"
  bottom: "res_stage_3_361_1_top"
  top: "res_stage_3_361_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_361_2"
  type: "BatchNorm"
  bottom: "res_stage_3_361_2"
  top: "res_stage_3_361_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_361_2"  
  type: "Scale"
  bottom: "res_stage_3_361_2"
  top: "res_stage_3_361_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_361_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_361_2_top"
  top: "res_stage_3_361_2_top"
}
layer {
  name: "res_stage_3_361_3"
  type: "Convolution"
  bottom: "res_stage_3_361_2_top"
  top: "res_stage_3_361_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_361_3"
  type: "BatchNorm"
  bottom: "res_stage_3_361_3"
  top: "res_stage_3_361_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_361_3"  
  type: "Scale"
  bottom: "res_stage_3_361_3"
  top: "res_stage_3_361_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_361"
  type: "Eltwise"
  bottom: "res_3_360"
  bottom: "res_stage_3_361_3_top"
  top: "res_3_361"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_361_relu"
  type: "ReLU"
  bottom: "res_3_361"
  top: "res_3_361"
}
layer {
  name: "res_stage_3_362_1"
  type: "Convolution"
  bottom: "res_3_361"
  top: "res_stage_3_362_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_362_1"
  type: "BatchNorm"
  bottom: "res_stage_3_362_1"
  top: "res_stage_3_362_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_362_1"  
  type: "Scale"
  bottom: "res_stage_3_362_1"
  top: "res_stage_3_362_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_362_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_362_1_top"
  top: "res_stage_3_362_1_top"
}
layer {
  name: "res_stage_3_362_2"
  type: "Convolution"
  bottom: "res_stage_3_362_1_top"
  top: "res_stage_3_362_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_362_2"
  type: "BatchNorm"
  bottom: "res_stage_3_362_2"
  top: "res_stage_3_362_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_362_2"  
  type: "Scale"
  bottom: "res_stage_3_362_2"
  top: "res_stage_3_362_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_362_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_362_2_top"
  top: "res_stage_3_362_2_top"
}
layer {
  name: "res_stage_3_362_3"
  type: "Convolution"
  bottom: "res_stage_3_362_2_top"
  top: "res_stage_3_362_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_362_3"
  type: "BatchNorm"
  bottom: "res_stage_3_362_3"
  top: "res_stage_3_362_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_362_3"  
  type: "Scale"
  bottom: "res_stage_3_362_3"
  top: "res_stage_3_362_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_362"
  type: "Eltwise"
  bottom: "res_3_361"
  bottom: "res_stage_3_362_3_top"
  top: "res_3_362"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_362_relu"
  type: "ReLU"
  bottom: "res_3_362"
  top: "res_3_362"
}
layer {
  name: "res_stage_3_363_1"
  type: "Convolution"
  bottom: "res_3_362"
  top: "res_stage_3_363_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_363_1"
  type: "BatchNorm"
  bottom: "res_stage_3_363_1"
  top: "res_stage_3_363_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_363_1"  
  type: "Scale"
  bottom: "res_stage_3_363_1"
  top: "res_stage_3_363_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_363_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_363_1_top"
  top: "res_stage_3_363_1_top"
}
layer {
  name: "res_stage_3_363_2"
  type: "Convolution"
  bottom: "res_stage_3_363_1_top"
  top: "res_stage_3_363_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_363_2"
  type: "BatchNorm"
  bottom: "res_stage_3_363_2"
  top: "res_stage_3_363_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_363_2"  
  type: "Scale"
  bottom: "res_stage_3_363_2"
  top: "res_stage_3_363_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_363_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_363_2_top"
  top: "res_stage_3_363_2_top"
}
layer {
  name: "res_stage_3_363_3"
  type: "Convolution"
  bottom: "res_stage_3_363_2_top"
  top: "res_stage_3_363_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_363_3"
  type: "BatchNorm"
  bottom: "res_stage_3_363_3"
  top: "res_stage_3_363_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_363_3"  
  type: "Scale"
  bottom: "res_stage_3_363_3"
  top: "res_stage_3_363_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_363"
  type: "Eltwise"
  bottom: "res_3_362"
  bottom: "res_stage_3_363_3_top"
  top: "res_3_363"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_363_relu"
  type: "ReLU"
  bottom: "res_3_363"
  top: "res_3_363"
}
layer {
  name: "res_stage_3_364_1"
  type: "Convolution"
  bottom: "res_3_363"
  top: "res_stage_3_364_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_364_1"
  type: "BatchNorm"
  bottom: "res_stage_3_364_1"
  top: "res_stage_3_364_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_364_1"  
  type: "Scale"
  bottom: "res_stage_3_364_1"
  top: "res_stage_3_364_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_364_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_364_1_top"
  top: "res_stage_3_364_1_top"
}
layer {
  name: "res_stage_3_364_2"
  type: "Convolution"
  bottom: "res_stage_3_364_1_top"
  top: "res_stage_3_364_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_364_2"
  type: "BatchNorm"
  bottom: "res_stage_3_364_2"
  top: "res_stage_3_364_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_364_2"  
  type: "Scale"
  bottom: "res_stage_3_364_2"
  top: "res_stage_3_364_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_364_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_364_2_top"
  top: "res_stage_3_364_2_top"
}
layer {
  name: "res_stage_3_364_3"
  type: "Convolution"
  bottom: "res_stage_3_364_2_top"
  top: "res_stage_3_364_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_364_3"
  type: "BatchNorm"
  bottom: "res_stage_3_364_3"
  top: "res_stage_3_364_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_364_3"  
  type: "Scale"
  bottom: "res_stage_3_364_3"
  top: "res_stage_3_364_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_364"
  type: "Eltwise"
  bottom: "res_3_363"
  bottom: "res_stage_3_364_3_top"
  top: "res_3_364"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_364_relu"
  type: "ReLU"
  bottom: "res_3_364"
  top: "res_3_364"
}
layer {
  name: "res_stage_3_365_1"
  type: "Convolution"
  bottom: "res_3_364"
  top: "res_stage_3_365_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_365_1"
  type: "BatchNorm"
  bottom: "res_stage_3_365_1"
  top: "res_stage_3_365_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_365_1"  
  type: "Scale"
  bottom: "res_stage_3_365_1"
  top: "res_stage_3_365_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_365_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_365_1_top"
  top: "res_stage_3_365_1_top"
}
layer {
  name: "res_stage_3_365_2"
  type: "Convolution"
  bottom: "res_stage_3_365_1_top"
  top: "res_stage_3_365_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_365_2"
  type: "BatchNorm"
  bottom: "res_stage_3_365_2"
  top: "res_stage_3_365_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_365_2"  
  type: "Scale"
  bottom: "res_stage_3_365_2"
  top: "res_stage_3_365_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_365_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_365_2_top"
  top: "res_stage_3_365_2_top"
}
layer {
  name: "res_stage_3_365_3"
  type: "Convolution"
  bottom: "res_stage_3_365_2_top"
  top: "res_stage_3_365_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_365_3"
  type: "BatchNorm"
  bottom: "res_stage_3_365_3"
  top: "res_stage_3_365_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_365_3"  
  type: "Scale"
  bottom: "res_stage_3_365_3"
  top: "res_stage_3_365_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_365"
  type: "Eltwise"
  bottom: "res_3_364"
  bottom: "res_stage_3_365_3_top"
  top: "res_3_365"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_365_relu"
  type: "ReLU"
  bottom: "res_3_365"
  top: "res_3_365"
}
layer {
  name: "res_stage_3_366_1"
  type: "Convolution"
  bottom: "res_3_365"
  top: "res_stage_3_366_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_366_1"
  type: "BatchNorm"
  bottom: "res_stage_3_366_1"
  top: "res_stage_3_366_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_366_1"  
  type: "Scale"
  bottom: "res_stage_3_366_1"
  top: "res_stage_3_366_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_366_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_366_1_top"
  top: "res_stage_3_366_1_top"
}
layer {
  name: "res_stage_3_366_2"
  type: "Convolution"
  bottom: "res_stage_3_366_1_top"
  top: "res_stage_3_366_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_366_2"
  type: "BatchNorm"
  bottom: "res_stage_3_366_2"
  top: "res_stage_3_366_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_366_2"  
  type: "Scale"
  bottom: "res_stage_3_366_2"
  top: "res_stage_3_366_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_366_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_366_2_top"
  top: "res_stage_3_366_2_top"
}
layer {
  name: "res_stage_3_366_3"
  type: "Convolution"
  bottom: "res_stage_3_366_2_top"
  top: "res_stage_3_366_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_366_3"
  type: "BatchNorm"
  bottom: "res_stage_3_366_3"
  top: "res_stage_3_366_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_366_3"  
  type: "Scale"
  bottom: "res_stage_3_366_3"
  top: "res_stage_3_366_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_366"
  type: "Eltwise"
  bottom: "res_3_365"
  bottom: "res_stage_3_366_3_top"
  top: "res_3_366"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_366_relu"
  type: "ReLU"
  bottom: "res_3_366"
  top: "res_3_366"
}
layer {
  name: "res_stage_3_367_1"
  type: "Convolution"
  bottom: "res_3_366"
  top: "res_stage_3_367_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_367_1"
  type: "BatchNorm"
  bottom: "res_stage_3_367_1"
  top: "res_stage_3_367_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_367_1"  
  type: "Scale"
  bottom: "res_stage_3_367_1"
  top: "res_stage_3_367_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_367_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_367_1_top"
  top: "res_stage_3_367_1_top"
}
layer {
  name: "res_stage_3_367_2"
  type: "Convolution"
  bottom: "res_stage_3_367_1_top"
  top: "res_stage_3_367_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_367_2"
  type: "BatchNorm"
  bottom: "res_stage_3_367_2"
  top: "res_stage_3_367_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_367_2"  
  type: "Scale"
  bottom: "res_stage_3_367_2"
  top: "res_stage_3_367_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_367_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_367_2_top"
  top: "res_stage_3_367_2_top"
}
layer {
  name: "res_stage_3_367_3"
  type: "Convolution"
  bottom: "res_stage_3_367_2_top"
  top: "res_stage_3_367_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_367_3"
  type: "BatchNorm"
  bottom: "res_stage_3_367_3"
  top: "res_stage_3_367_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_367_3"  
  type: "Scale"
  bottom: "res_stage_3_367_3"
  top: "res_stage_3_367_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_367"
  type: "Eltwise"
  bottom: "res_3_366"
  bottom: "res_stage_3_367_3_top"
  top: "res_3_367"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_367_relu"
  type: "ReLU"
  bottom: "res_3_367"
  top: "res_3_367"
}
layer {
  name: "res_stage_3_368_1"
  type: "Convolution"
  bottom: "res_3_367"
  top: "res_stage_3_368_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_368_1"
  type: "BatchNorm"
  bottom: "res_stage_3_368_1"
  top: "res_stage_3_368_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_368_1"  
  type: "Scale"
  bottom: "res_stage_3_368_1"
  top: "res_stage_3_368_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_368_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_368_1_top"
  top: "res_stage_3_368_1_top"
}
layer {
  name: "res_stage_3_368_2"
  type: "Convolution"
  bottom: "res_stage_3_368_1_top"
  top: "res_stage_3_368_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_368_2"
  type: "BatchNorm"
  bottom: "res_stage_3_368_2"
  top: "res_stage_3_368_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_368_2"  
  type: "Scale"
  bottom: "res_stage_3_368_2"
  top: "res_stage_3_368_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_368_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_368_2_top"
  top: "res_stage_3_368_2_top"
}
layer {
  name: "res_stage_3_368_3"
  type: "Convolution"
  bottom: "res_stage_3_368_2_top"
  top: "res_stage_3_368_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_368_3"
  type: "BatchNorm"
  bottom: "res_stage_3_368_3"
  top: "res_stage_3_368_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_368_3"  
  type: "Scale"
  bottom: "res_stage_3_368_3"
  top: "res_stage_3_368_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_368"
  type: "Eltwise"
  bottom: "res_3_367"
  bottom: "res_stage_3_368_3_top"
  top: "res_3_368"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_368_relu"
  type: "ReLU"
  bottom: "res_3_368"
  top: "res_3_368"
}
layer {
  name: "res_stage_3_369_1"
  type: "Convolution"
  bottom: "res_3_368"
  top: "res_stage_3_369_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_369_1"
  type: "BatchNorm"
  bottom: "res_stage_3_369_1"
  top: "res_stage_3_369_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_369_1"  
  type: "Scale"
  bottom: "res_stage_3_369_1"
  top: "res_stage_3_369_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_369_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_369_1_top"
  top: "res_stage_3_369_1_top"
}
layer {
  name: "res_stage_3_369_2"
  type: "Convolution"
  bottom: "res_stage_3_369_1_top"
  top: "res_stage_3_369_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_369_2"
  type: "BatchNorm"
  bottom: "res_stage_3_369_2"
  top: "res_stage_3_369_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_369_2"  
  type: "Scale"
  bottom: "res_stage_3_369_2"
  top: "res_stage_3_369_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_369_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_369_2_top"
  top: "res_stage_3_369_2_top"
}
layer {
  name: "res_stage_3_369_3"
  type: "Convolution"
  bottom: "res_stage_3_369_2_top"
  top: "res_stage_3_369_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_369_3"
  type: "BatchNorm"
  bottom: "res_stage_3_369_3"
  top: "res_stage_3_369_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_369_3"  
  type: "Scale"
  bottom: "res_stage_3_369_3"
  top: "res_stage_3_369_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_369"
  type: "Eltwise"
  bottom: "res_3_368"
  bottom: "res_stage_3_369_3_top"
  top: "res_3_369"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_369_relu"
  type: "ReLU"
  bottom: "res_3_369"
  top: "res_3_369"
}
layer {
  name: "res_stage_3_370_1"
  type: "Convolution"
  bottom: "res_3_369"
  top: "res_stage_3_370_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_370_1"
  type: "BatchNorm"
  bottom: "res_stage_3_370_1"
  top: "res_stage_3_370_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_370_1"  
  type: "Scale"
  bottom: "res_stage_3_370_1"
  top: "res_stage_3_370_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_370_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_370_1_top"
  top: "res_stage_3_370_1_top"
}
layer {
  name: "res_stage_3_370_2"
  type: "Convolution"
  bottom: "res_stage_3_370_1_top"
  top: "res_stage_3_370_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_370_2"
  type: "BatchNorm"
  bottom: "res_stage_3_370_2"
  top: "res_stage_3_370_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_370_2"  
  type: "Scale"
  bottom: "res_stage_3_370_2"
  top: "res_stage_3_370_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_370_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_370_2_top"
  top: "res_stage_3_370_2_top"
}
layer {
  name: "res_stage_3_370_3"
  type: "Convolution"
  bottom: "res_stage_3_370_2_top"
  top: "res_stage_3_370_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_370_3"
  type: "BatchNorm"
  bottom: "res_stage_3_370_3"
  top: "res_stage_3_370_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_370_3"  
  type: "Scale"
  bottom: "res_stage_3_370_3"
  top: "res_stage_3_370_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_370"
  type: "Eltwise"
  bottom: "res_3_369"
  bottom: "res_stage_3_370_3_top"
  top: "res_3_370"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_370_relu"
  type: "ReLU"
  bottom: "res_3_370"
  top: "res_3_370"
}
layer {
  name: "res_stage_3_371_1"
  type: "Convolution"
  bottom: "res_3_370"
  top: "res_stage_3_371_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_371_1"
  type: "BatchNorm"
  bottom: "res_stage_3_371_1"
  top: "res_stage_3_371_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_371_1"  
  type: "Scale"
  bottom: "res_stage_3_371_1"
  top: "res_stage_3_371_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_371_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_371_1_top"
  top: "res_stage_3_371_1_top"
}
layer {
  name: "res_stage_3_371_2"
  type: "Convolution"
  bottom: "res_stage_3_371_1_top"
  top: "res_stage_3_371_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_371_2"
  type: "BatchNorm"
  bottom: "res_stage_3_371_2"
  top: "res_stage_3_371_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_371_2"  
  type: "Scale"
  bottom: "res_stage_3_371_2"
  top: "res_stage_3_371_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_371_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_371_2_top"
  top: "res_stage_3_371_2_top"
}
layer {
  name: "res_stage_3_371_3"
  type: "Convolution"
  bottom: "res_stage_3_371_2_top"
  top: "res_stage_3_371_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_371_3"
  type: "BatchNorm"
  bottom: "res_stage_3_371_3"
  top: "res_stage_3_371_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_371_3"  
  type: "Scale"
  bottom: "res_stage_3_371_3"
  top: "res_stage_3_371_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_371"
  type: "Eltwise"
  bottom: "res_3_370"
  bottom: "res_stage_3_371_3_top"
  top: "res_3_371"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_371_relu"
  type: "ReLU"
  bottom: "res_3_371"
  top: "res_3_371"
}
layer {
  name: "res_stage_3_372_1"
  type: "Convolution"
  bottom: "res_3_371"
  top: "res_stage_3_372_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_372_1"
  type: "BatchNorm"
  bottom: "res_stage_3_372_1"
  top: "res_stage_3_372_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_372_1"  
  type: "Scale"
  bottom: "res_stage_3_372_1"
  top: "res_stage_3_372_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_372_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_372_1_top"
  top: "res_stage_3_372_1_top"
}
layer {
  name: "res_stage_3_372_2"
  type: "Convolution"
  bottom: "res_stage_3_372_1_top"
  top: "res_stage_3_372_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_372_2"
  type: "BatchNorm"
  bottom: "res_stage_3_372_2"
  top: "res_stage_3_372_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_372_2"  
  type: "Scale"
  bottom: "res_stage_3_372_2"
  top: "res_stage_3_372_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_372_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_372_2_top"
  top: "res_stage_3_372_2_top"
}
layer {
  name: "res_stage_3_372_3"
  type: "Convolution"
  bottom: "res_stage_3_372_2_top"
  top: "res_stage_3_372_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_372_3"
  type: "BatchNorm"
  bottom: "res_stage_3_372_3"
  top: "res_stage_3_372_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_372_3"  
  type: "Scale"
  bottom: "res_stage_3_372_3"
  top: "res_stage_3_372_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_372"
  type: "Eltwise"
  bottom: "res_3_371"
  bottom: "res_stage_3_372_3_top"
  top: "res_3_372"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_372_relu"
  type: "ReLU"
  bottom: "res_3_372"
  top: "res_3_372"
}
layer {
  name: "res_stage_3_373_1"
  type: "Convolution"
  bottom: "res_3_372"
  top: "res_stage_3_373_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_373_1"
  type: "BatchNorm"
  bottom: "res_stage_3_373_1"
  top: "res_stage_3_373_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_373_1"  
  type: "Scale"
  bottom: "res_stage_3_373_1"
  top: "res_stage_3_373_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_373_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_373_1_top"
  top: "res_stage_3_373_1_top"
}
layer {
  name: "res_stage_3_373_2"
  type: "Convolution"
  bottom: "res_stage_3_373_1_top"
  top: "res_stage_3_373_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_373_2"
  type: "BatchNorm"
  bottom: "res_stage_3_373_2"
  top: "res_stage_3_373_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_373_2"  
  type: "Scale"
  bottom: "res_stage_3_373_2"
  top: "res_stage_3_373_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_373_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_373_2_top"
  top: "res_stage_3_373_2_top"
}
layer {
  name: "res_stage_3_373_3"
  type: "Convolution"
  bottom: "res_stage_3_373_2_top"
  top: "res_stage_3_373_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_373_3"
  type: "BatchNorm"
  bottom: "res_stage_3_373_3"
  top: "res_stage_3_373_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_373_3"  
  type: "Scale"
  bottom: "res_stage_3_373_3"
  top: "res_stage_3_373_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_373"
  type: "Eltwise"
  bottom: "res_3_372"
  bottom: "res_stage_3_373_3_top"
  top: "res_3_373"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_373_relu"
  type: "ReLU"
  bottom: "res_3_373"
  top: "res_3_373"
}
layer {
  name: "res_stage_3_374_1"
  type: "Convolution"
  bottom: "res_3_373"
  top: "res_stage_3_374_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_374_1"
  type: "BatchNorm"
  bottom: "res_stage_3_374_1"
  top: "res_stage_3_374_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_374_1"  
  type: "Scale"
  bottom: "res_stage_3_374_1"
  top: "res_stage_3_374_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_374_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_374_1_top"
  top: "res_stage_3_374_1_top"
}
layer {
  name: "res_stage_3_374_2"
  type: "Convolution"
  bottom: "res_stage_3_374_1_top"
  top: "res_stage_3_374_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_374_2"
  type: "BatchNorm"
  bottom: "res_stage_3_374_2"
  top: "res_stage_3_374_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_374_2"  
  type: "Scale"
  bottom: "res_stage_3_374_2"
  top: "res_stage_3_374_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_374_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_374_2_top"
  top: "res_stage_3_374_2_top"
}
layer {
  name: "res_stage_3_374_3"
  type: "Convolution"
  bottom: "res_stage_3_374_2_top"
  top: "res_stage_3_374_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_374_3"
  type: "BatchNorm"
  bottom: "res_stage_3_374_3"
  top: "res_stage_3_374_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_374_3"  
  type: "Scale"
  bottom: "res_stage_3_374_3"
  top: "res_stage_3_374_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_374"
  type: "Eltwise"
  bottom: "res_3_373"
  bottom: "res_stage_3_374_3_top"
  top: "res_3_374"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_374_relu"
  type: "ReLU"
  bottom: "res_3_374"
  top: "res_3_374"
}
layer {
  name: "res_stage_3_375_1"
  type: "Convolution"
  bottom: "res_3_374"
  top: "res_stage_3_375_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_375_1"
  type: "BatchNorm"
  bottom: "res_stage_3_375_1"
  top: "res_stage_3_375_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_375_1"  
  type: "Scale"
  bottom: "res_stage_3_375_1"
  top: "res_stage_3_375_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_375_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_375_1_top"
  top: "res_stage_3_375_1_top"
}
layer {
  name: "res_stage_3_375_2"
  type: "Convolution"
  bottom: "res_stage_3_375_1_top"
  top: "res_stage_3_375_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_375_2"
  type: "BatchNorm"
  bottom: "res_stage_3_375_2"
  top: "res_stage_3_375_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_375_2"  
  type: "Scale"
  bottom: "res_stage_3_375_2"
  top: "res_stage_3_375_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_375_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_375_2_top"
  top: "res_stage_3_375_2_top"
}
layer {
  name: "res_stage_3_375_3"
  type: "Convolution"
  bottom: "res_stage_3_375_2_top"
  top: "res_stage_3_375_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_375_3"
  type: "BatchNorm"
  bottom: "res_stage_3_375_3"
  top: "res_stage_3_375_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_375_3"  
  type: "Scale"
  bottom: "res_stage_3_375_3"
  top: "res_stage_3_375_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_375"
  type: "Eltwise"
  bottom: "res_3_374"
  bottom: "res_stage_3_375_3_top"
  top: "res_3_375"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_375_relu"
  type: "ReLU"
  bottom: "res_3_375"
  top: "res_3_375"
}
layer {
  name: "res_stage_3_376_1"
  type: "Convolution"
  bottom: "res_3_375"
  top: "res_stage_3_376_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_376_1"
  type: "BatchNorm"
  bottom: "res_stage_3_376_1"
  top: "res_stage_3_376_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_376_1"  
  type: "Scale"
  bottom: "res_stage_3_376_1"
  top: "res_stage_3_376_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_376_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_376_1_top"
  top: "res_stage_3_376_1_top"
}
layer {
  name: "res_stage_3_376_2"
  type: "Convolution"
  bottom: "res_stage_3_376_1_top"
  top: "res_stage_3_376_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_376_2"
  type: "BatchNorm"
  bottom: "res_stage_3_376_2"
  top: "res_stage_3_376_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_376_2"  
  type: "Scale"
  bottom: "res_stage_3_376_2"
  top: "res_stage_3_376_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_376_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_376_2_top"
  top: "res_stage_3_376_2_top"
}
layer {
  name: "res_stage_3_376_3"
  type: "Convolution"
  bottom: "res_stage_3_376_2_top"
  top: "res_stage_3_376_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_376_3"
  type: "BatchNorm"
  bottom: "res_stage_3_376_3"
  top: "res_stage_3_376_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_376_3"  
  type: "Scale"
  bottom: "res_stage_3_376_3"
  top: "res_stage_3_376_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_376"
  type: "Eltwise"
  bottom: "res_3_375"
  bottom: "res_stage_3_376_3_top"
  top: "res_3_376"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_376_relu"
  type: "ReLU"
  bottom: "res_3_376"
  top: "res_3_376"
}
layer {
  name: "res_stage_3_377_1"
  type: "Convolution"
  bottom: "res_3_376"
  top: "res_stage_3_377_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_377_1"
  type: "BatchNorm"
  bottom: "res_stage_3_377_1"
  top: "res_stage_3_377_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_377_1"  
  type: "Scale"
  bottom: "res_stage_3_377_1"
  top: "res_stage_3_377_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_377_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_377_1_top"
  top: "res_stage_3_377_1_top"
}
layer {
  name: "res_stage_3_377_2"
  type: "Convolution"
  bottom: "res_stage_3_377_1_top"
  top: "res_stage_3_377_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_377_2"
  type: "BatchNorm"
  bottom: "res_stage_3_377_2"
  top: "res_stage_3_377_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_377_2"  
  type: "Scale"
  bottom: "res_stage_3_377_2"
  top: "res_stage_3_377_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_377_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_377_2_top"
  top: "res_stage_3_377_2_top"
}
layer {
  name: "res_stage_3_377_3"
  type: "Convolution"
  bottom: "res_stage_3_377_2_top"
  top: "res_stage_3_377_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_377_3"
  type: "BatchNorm"
  bottom: "res_stage_3_377_3"
  top: "res_stage_3_377_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_377_3"  
  type: "Scale"
  bottom: "res_stage_3_377_3"
  top: "res_stage_3_377_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_377"
  type: "Eltwise"
  bottom: "res_3_376"
  bottom: "res_stage_3_377_3_top"
  top: "res_3_377"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_377_relu"
  type: "ReLU"
  bottom: "res_3_377"
  top: "res_3_377"
}
layer {
  name: "res_stage_3_378_1"
  type: "Convolution"
  bottom: "res_3_377"
  top: "res_stage_3_378_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_378_1"
  type: "BatchNorm"
  bottom: "res_stage_3_378_1"
  top: "res_stage_3_378_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_378_1"  
  type: "Scale"
  bottom: "res_stage_3_378_1"
  top: "res_stage_3_378_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_378_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_378_1_top"
  top: "res_stage_3_378_1_top"
}
layer {
  name: "res_stage_3_378_2"
  type: "Convolution"
  bottom: "res_stage_3_378_1_top"
  top: "res_stage_3_378_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_378_2"
  type: "BatchNorm"
  bottom: "res_stage_3_378_2"
  top: "res_stage_3_378_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_378_2"  
  type: "Scale"
  bottom: "res_stage_3_378_2"
  top: "res_stage_3_378_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_378_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_378_2_top"
  top: "res_stage_3_378_2_top"
}
layer {
  name: "res_stage_3_378_3"
  type: "Convolution"
  bottom: "res_stage_3_378_2_top"
  top: "res_stage_3_378_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_378_3"
  type: "BatchNorm"
  bottom: "res_stage_3_378_3"
  top: "res_stage_3_378_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_378_3"  
  type: "Scale"
  bottom: "res_stage_3_378_3"
  top: "res_stage_3_378_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_378"
  type: "Eltwise"
  bottom: "res_3_377"
  bottom: "res_stage_3_378_3_top"
  top: "res_3_378"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_378_relu"
  type: "ReLU"
  bottom: "res_3_378"
  top: "res_3_378"
}
layer {
  name: "res_stage_3_379_1"
  type: "Convolution"
  bottom: "res_3_378"
  top: "res_stage_3_379_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_379_1"
  type: "BatchNorm"
  bottom: "res_stage_3_379_1"
  top: "res_stage_3_379_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_379_1"  
  type: "Scale"
  bottom: "res_stage_3_379_1"
  top: "res_stage_3_379_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_379_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_379_1_top"
  top: "res_stage_3_379_1_top"
}
layer {
  name: "res_stage_3_379_2"
  type: "Convolution"
  bottom: "res_stage_3_379_1_top"
  top: "res_stage_3_379_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_379_2"
  type: "BatchNorm"
  bottom: "res_stage_3_379_2"
  top: "res_stage_3_379_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_379_2"  
  type: "Scale"
  bottom: "res_stage_3_379_2"
  top: "res_stage_3_379_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_379_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_379_2_top"
  top: "res_stage_3_379_2_top"
}
layer {
  name: "res_stage_3_379_3"
  type: "Convolution"
  bottom: "res_stage_3_379_2_top"
  top: "res_stage_3_379_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_379_3"
  type: "BatchNorm"
  bottom: "res_stage_3_379_3"
  top: "res_stage_3_379_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_379_3"  
  type: "Scale"
  bottom: "res_stage_3_379_3"
  top: "res_stage_3_379_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_379"
  type: "Eltwise"
  bottom: "res_3_378"
  bottom: "res_stage_3_379_3_top"
  top: "res_3_379"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_379_relu"
  type: "ReLU"
  bottom: "res_3_379"
  top: "res_3_379"
}
layer {
  name: "res_stage_3_380_1"
  type: "Convolution"
  bottom: "res_3_379"
  top: "res_stage_3_380_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_380_1"
  type: "BatchNorm"
  bottom: "res_stage_3_380_1"
  top: "res_stage_3_380_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_380_1"  
  type: "Scale"
  bottom: "res_stage_3_380_1"
  top: "res_stage_3_380_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_380_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_380_1_top"
  top: "res_stage_3_380_1_top"
}
layer {
  name: "res_stage_3_380_2"
  type: "Convolution"
  bottom: "res_stage_3_380_1_top"
  top: "res_stage_3_380_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_380_2"
  type: "BatchNorm"
  bottom: "res_stage_3_380_2"
  top: "res_stage_3_380_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_380_2"  
  type: "Scale"
  bottom: "res_stage_3_380_2"
  top: "res_stage_3_380_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_380_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_380_2_top"
  top: "res_stage_3_380_2_top"
}
layer {
  name: "res_stage_3_380_3"
  type: "Convolution"
  bottom: "res_stage_3_380_2_top"
  top: "res_stage_3_380_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_380_3"
  type: "BatchNorm"
  bottom: "res_stage_3_380_3"
  top: "res_stage_3_380_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_380_3"  
  type: "Scale"
  bottom: "res_stage_3_380_3"
  top: "res_stage_3_380_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_380"
  type: "Eltwise"
  bottom: "res_3_379"
  bottom: "res_stage_3_380_3_top"
  top: "res_3_380"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_380_relu"
  type: "ReLU"
  bottom: "res_3_380"
  top: "res_3_380"
}
layer {
  name: "res_stage_3_381_1"
  type: "Convolution"
  bottom: "res_3_380"
  top: "res_stage_3_381_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_381_1"
  type: "BatchNorm"
  bottom: "res_stage_3_381_1"
  top: "res_stage_3_381_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_381_1"  
  type: "Scale"
  bottom: "res_stage_3_381_1"
  top: "res_stage_3_381_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_381_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_381_1_top"
  top: "res_stage_3_381_1_top"
}
layer {
  name: "res_stage_3_381_2"
  type: "Convolution"
  bottom: "res_stage_3_381_1_top"
  top: "res_stage_3_381_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_381_2"
  type: "BatchNorm"
  bottom: "res_stage_3_381_2"
  top: "res_stage_3_381_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_381_2"  
  type: "Scale"
  bottom: "res_stage_3_381_2"
  top: "res_stage_3_381_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_381_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_381_2_top"
  top: "res_stage_3_381_2_top"
}
layer {
  name: "res_stage_3_381_3"
  type: "Convolution"
  bottom: "res_stage_3_381_2_top"
  top: "res_stage_3_381_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_381_3"
  type: "BatchNorm"
  bottom: "res_stage_3_381_3"
  top: "res_stage_3_381_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_381_3"  
  type: "Scale"
  bottom: "res_stage_3_381_3"
  top: "res_stage_3_381_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_381"
  type: "Eltwise"
  bottom: "res_3_380"
  bottom: "res_stage_3_381_3_top"
  top: "res_3_381"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_381_relu"
  type: "ReLU"
  bottom: "res_3_381"
  top: "res_3_381"
}
layer {
  name: "res_stage_3_382_1"
  type: "Convolution"
  bottom: "res_3_381"
  top: "res_stage_3_382_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_382_1"
  type: "BatchNorm"
  bottom: "res_stage_3_382_1"
  top: "res_stage_3_382_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_382_1"  
  type: "Scale"
  bottom: "res_stage_3_382_1"
  top: "res_stage_3_382_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_382_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_382_1_top"
  top: "res_stage_3_382_1_top"
}
layer {
  name: "res_stage_3_382_2"
  type: "Convolution"
  bottom: "res_stage_3_382_1_top"
  top: "res_stage_3_382_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_382_2"
  type: "BatchNorm"
  bottom: "res_stage_3_382_2"
  top: "res_stage_3_382_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_382_2"  
  type: "Scale"
  bottom: "res_stage_3_382_2"
  top: "res_stage_3_382_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_382_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_382_2_top"
  top: "res_stage_3_382_2_top"
}
layer {
  name: "res_stage_3_382_3"
  type: "Convolution"
  bottom: "res_stage_3_382_2_top"
  top: "res_stage_3_382_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_382_3"
  type: "BatchNorm"
  bottom: "res_stage_3_382_3"
  top: "res_stage_3_382_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_382_3"  
  type: "Scale"
  bottom: "res_stage_3_382_3"
  top: "res_stage_3_382_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_382"
  type: "Eltwise"
  bottom: "res_3_381"
  bottom: "res_stage_3_382_3_top"
  top: "res_3_382"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_382_relu"
  type: "ReLU"
  bottom: "res_3_382"
  top: "res_3_382"
}
layer {
  name: "res_stage_3_383_1"
  type: "Convolution"
  bottom: "res_3_382"
  top: "res_stage_3_383_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_383_1"
  type: "BatchNorm"
  bottom: "res_stage_3_383_1"
  top: "res_stage_3_383_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_383_1"  
  type: "Scale"
  bottom: "res_stage_3_383_1"
  top: "res_stage_3_383_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_383_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_383_1_top"
  top: "res_stage_3_383_1_top"
}
layer {
  name: "res_stage_3_383_2"
  type: "Convolution"
  bottom: "res_stage_3_383_1_top"
  top: "res_stage_3_383_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_383_2"
  type: "BatchNorm"
  bottom: "res_stage_3_383_2"
  top: "res_stage_3_383_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_383_2"  
  type: "Scale"
  bottom: "res_stage_3_383_2"
  top: "res_stage_3_383_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_383_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_383_2_top"
  top: "res_stage_3_383_2_top"
}
layer {
  name: "res_stage_3_383_3"
  type: "Convolution"
  bottom: "res_stage_3_383_2_top"
  top: "res_stage_3_383_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_383_3"
  type: "BatchNorm"
  bottom: "res_stage_3_383_3"
  top: "res_stage_3_383_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_383_3"  
  type: "Scale"
  bottom: "res_stage_3_383_3"
  top: "res_stage_3_383_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_383"
  type: "Eltwise"
  bottom: "res_3_382"
  bottom: "res_stage_3_383_3_top"
  top: "res_3_383"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_383_relu"
  type: "ReLU"
  bottom: "res_3_383"
  top: "res_3_383"
}
layer {
  name: "res_stage_3_384_1"
  type: "Convolution"
  bottom: "res_3_383"
  top: "res_stage_3_384_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_384_1"
  type: "BatchNorm"
  bottom: "res_stage_3_384_1"
  top: "res_stage_3_384_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_384_1"  
  type: "Scale"
  bottom: "res_stage_3_384_1"
  top: "res_stage_3_384_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_384_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_384_1_top"
  top: "res_stage_3_384_1_top"
}
layer {
  name: "res_stage_3_384_2"
  type: "Convolution"
  bottom: "res_stage_3_384_1_top"
  top: "res_stage_3_384_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_384_2"
  type: "BatchNorm"
  bottom: "res_stage_3_384_2"
  top: "res_stage_3_384_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_384_2"  
  type: "Scale"
  bottom: "res_stage_3_384_2"
  top: "res_stage_3_384_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_384_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_384_2_top"
  top: "res_stage_3_384_2_top"
}
layer {
  name: "res_stage_3_384_3"
  type: "Convolution"
  bottom: "res_stage_3_384_2_top"
  top: "res_stage_3_384_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_384_3"
  type: "BatchNorm"
  bottom: "res_stage_3_384_3"
  top: "res_stage_3_384_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_384_3"  
  type: "Scale"
  bottom: "res_stage_3_384_3"
  top: "res_stage_3_384_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_384"
  type: "Eltwise"
  bottom: "res_3_383"
  bottom: "res_stage_3_384_3_top"
  top: "res_3_384"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_384_relu"
  type: "ReLU"
  bottom: "res_3_384"
  top: "res_3_384"
}
layer {
  name: "res_stage_3_385_1"
  type: "Convolution"
  bottom: "res_3_384"
  top: "res_stage_3_385_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_385_1"
  type: "BatchNorm"
  bottom: "res_stage_3_385_1"
  top: "res_stage_3_385_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_385_1"  
  type: "Scale"
  bottom: "res_stage_3_385_1"
  top: "res_stage_3_385_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_385_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_385_1_top"
  top: "res_stage_3_385_1_top"
}
layer {
  name: "res_stage_3_385_2"
  type: "Convolution"
  bottom: "res_stage_3_385_1_top"
  top: "res_stage_3_385_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_385_2"
  type: "BatchNorm"
  bottom: "res_stage_3_385_2"
  top: "res_stage_3_385_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_385_2"  
  type: "Scale"
  bottom: "res_stage_3_385_2"
  top: "res_stage_3_385_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_385_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_385_2_top"
  top: "res_stage_3_385_2_top"
}
layer {
  name: "res_stage_3_385_3"
  type: "Convolution"
  bottom: "res_stage_3_385_2_top"
  top: "res_stage_3_385_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_385_3"
  type: "BatchNorm"
  bottom: "res_stage_3_385_3"
  top: "res_stage_3_385_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_385_3"  
  type: "Scale"
  bottom: "res_stage_3_385_3"
  top: "res_stage_3_385_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_385"
  type: "Eltwise"
  bottom: "res_3_384"
  bottom: "res_stage_3_385_3_top"
  top: "res_3_385"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_385_relu"
  type: "ReLU"
  bottom: "res_3_385"
  top: "res_3_385"
}
layer {
  name: "res_stage_3_386_1"
  type: "Convolution"
  bottom: "res_3_385"
  top: "res_stage_3_386_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_386_1"
  type: "BatchNorm"
  bottom: "res_stage_3_386_1"
  top: "res_stage_3_386_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_386_1"  
  type: "Scale"
  bottom: "res_stage_3_386_1"
  top: "res_stage_3_386_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_386_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_386_1_top"
  top: "res_stage_3_386_1_top"
}
layer {
  name: "res_stage_3_386_2"
  type: "Convolution"
  bottom: "res_stage_3_386_1_top"
  top: "res_stage_3_386_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_386_2"
  type: "BatchNorm"
  bottom: "res_stage_3_386_2"
  top: "res_stage_3_386_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_386_2"  
  type: "Scale"
  bottom: "res_stage_3_386_2"
  top: "res_stage_3_386_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_386_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_386_2_top"
  top: "res_stage_3_386_2_top"
}
layer {
  name: "res_stage_3_386_3"
  type: "Convolution"
  bottom: "res_stage_3_386_2_top"
  top: "res_stage_3_386_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_386_3"
  type: "BatchNorm"
  bottom: "res_stage_3_386_3"
  top: "res_stage_3_386_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_386_3"  
  type: "Scale"
  bottom: "res_stage_3_386_3"
  top: "res_stage_3_386_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_386"
  type: "Eltwise"
  bottom: "res_3_385"
  bottom: "res_stage_3_386_3_top"
  top: "res_3_386"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_386_relu"
  type: "ReLU"
  bottom: "res_3_386"
  top: "res_3_386"
}
layer {
  name: "res_stage_3_387_1"
  type: "Convolution"
  bottom: "res_3_386"
  top: "res_stage_3_387_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_387_1"
  type: "BatchNorm"
  bottom: "res_stage_3_387_1"
  top: "res_stage_3_387_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_387_1"  
  type: "Scale"
  bottom: "res_stage_3_387_1"
  top: "res_stage_3_387_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_387_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_387_1_top"
  top: "res_stage_3_387_1_top"
}
layer {
  name: "res_stage_3_387_2"
  type: "Convolution"
  bottom: "res_stage_3_387_1_top"
  top: "res_stage_3_387_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_387_2"
  type: "BatchNorm"
  bottom: "res_stage_3_387_2"
  top: "res_stage_3_387_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_387_2"  
  type: "Scale"
  bottom: "res_stage_3_387_2"
  top: "res_stage_3_387_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_387_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_387_2_top"
  top: "res_stage_3_387_2_top"
}
layer {
  name: "res_stage_3_387_3"
  type: "Convolution"
  bottom: "res_stage_3_387_2_top"
  top: "res_stage_3_387_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_387_3"
  type: "BatchNorm"
  bottom: "res_stage_3_387_3"
  top: "res_stage_3_387_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_387_3"  
  type: "Scale"
  bottom: "res_stage_3_387_3"
  top: "res_stage_3_387_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_387"
  type: "Eltwise"
  bottom: "res_3_386"
  bottom: "res_stage_3_387_3_top"
  top: "res_3_387"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_387_relu"
  type: "ReLU"
  bottom: "res_3_387"
  top: "res_3_387"
}
layer {
  name: "res_stage_3_388_1"
  type: "Convolution"
  bottom: "res_3_387"
  top: "res_stage_3_388_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_388_1"
  type: "BatchNorm"
  bottom: "res_stage_3_388_1"
  top: "res_stage_3_388_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_388_1"  
  type: "Scale"
  bottom: "res_stage_3_388_1"
  top: "res_stage_3_388_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_388_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_388_1_top"
  top: "res_stage_3_388_1_top"
}
layer {
  name: "res_stage_3_388_2"
  type: "Convolution"
  bottom: "res_stage_3_388_1_top"
  top: "res_stage_3_388_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_388_2"
  type: "BatchNorm"
  bottom: "res_stage_3_388_2"
  top: "res_stage_3_388_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_388_2"  
  type: "Scale"
  bottom: "res_stage_3_388_2"
  top: "res_stage_3_388_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_388_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_388_2_top"
  top: "res_stage_3_388_2_top"
}
layer {
  name: "res_stage_3_388_3"
  type: "Convolution"
  bottom: "res_stage_3_388_2_top"
  top: "res_stage_3_388_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_388_3"
  type: "BatchNorm"
  bottom: "res_stage_3_388_3"
  top: "res_stage_3_388_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_388_3"  
  type: "Scale"
  bottom: "res_stage_3_388_3"
  top: "res_stage_3_388_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_388"
  type: "Eltwise"
  bottom: "res_3_387"
  bottom: "res_stage_3_388_3_top"
  top: "res_3_388"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_388_relu"
  type: "ReLU"
  bottom: "res_3_388"
  top: "res_3_388"
}
layer {
  name: "res_stage_3_389_1"
  type: "Convolution"
  bottom: "res_3_388"
  top: "res_stage_3_389_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_389_1"
  type: "BatchNorm"
  bottom: "res_stage_3_389_1"
  top: "res_stage_3_389_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_389_1"  
  type: "Scale"
  bottom: "res_stage_3_389_1"
  top: "res_stage_3_389_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_389_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_389_1_top"
  top: "res_stage_3_389_1_top"
}
layer {
  name: "res_stage_3_389_2"
  type: "Convolution"
  bottom: "res_stage_3_389_1_top"
  top: "res_stage_3_389_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_389_2"
  type: "BatchNorm"
  bottom: "res_stage_3_389_2"
  top: "res_stage_3_389_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_389_2"  
  type: "Scale"
  bottom: "res_stage_3_389_2"
  top: "res_stage_3_389_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_389_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_389_2_top"
  top: "res_stage_3_389_2_top"
}
layer {
  name: "res_stage_3_389_3"
  type: "Convolution"
  bottom: "res_stage_3_389_2_top"
  top: "res_stage_3_389_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_389_3"
  type: "BatchNorm"
  bottom: "res_stage_3_389_3"
  top: "res_stage_3_389_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_389_3"  
  type: "Scale"
  bottom: "res_stage_3_389_3"
  top: "res_stage_3_389_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_389"
  type: "Eltwise"
  bottom: "res_3_388"
  bottom: "res_stage_3_389_3_top"
  top: "res_3_389"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_389_relu"
  type: "ReLU"
  bottom: "res_3_389"
  top: "res_3_389"
}
layer {
  name: "res_stage_3_390_1"
  type: "Convolution"
  bottom: "res_3_389"
  top: "res_stage_3_390_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_390_1"
  type: "BatchNorm"
  bottom: "res_stage_3_390_1"
  top: "res_stage_3_390_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_390_1"  
  type: "Scale"
  bottom: "res_stage_3_390_1"
  top: "res_stage_3_390_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_390_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_390_1_top"
  top: "res_stage_3_390_1_top"
}
layer {
  name: "res_stage_3_390_2"
  type: "Convolution"
  bottom: "res_stage_3_390_1_top"
  top: "res_stage_3_390_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_390_2"
  type: "BatchNorm"
  bottom: "res_stage_3_390_2"
  top: "res_stage_3_390_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_390_2"  
  type: "Scale"
  bottom: "res_stage_3_390_2"
  top: "res_stage_3_390_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_390_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_390_2_top"
  top: "res_stage_3_390_2_top"
}
layer {
  name: "res_stage_3_390_3"
  type: "Convolution"
  bottom: "res_stage_3_390_2_top"
  top: "res_stage_3_390_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_390_3"
  type: "BatchNorm"
  bottom: "res_stage_3_390_3"
  top: "res_stage_3_390_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_390_3"  
  type: "Scale"
  bottom: "res_stage_3_390_3"
  top: "res_stage_3_390_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_390"
  type: "Eltwise"
  bottom: "res_3_389"
  bottom: "res_stage_3_390_3_top"
  top: "res_3_390"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_390_relu"
  type: "ReLU"
  bottom: "res_3_390"
  top: "res_3_390"
}
layer {
  name: "res_stage_3_391_1"
  type: "Convolution"
  bottom: "res_3_390"
  top: "res_stage_3_391_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_391_1"
  type: "BatchNorm"
  bottom: "res_stage_3_391_1"
  top: "res_stage_3_391_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_391_1"  
  type: "Scale"
  bottom: "res_stage_3_391_1"
  top: "res_stage_3_391_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_391_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_391_1_top"
  top: "res_stage_3_391_1_top"
}
layer {
  name: "res_stage_3_391_2"
  type: "Convolution"
  bottom: "res_stage_3_391_1_top"
  top: "res_stage_3_391_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_391_2"
  type: "BatchNorm"
  bottom: "res_stage_3_391_2"
  top: "res_stage_3_391_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_391_2"  
  type: "Scale"
  bottom: "res_stage_3_391_2"
  top: "res_stage_3_391_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_391_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_391_2_top"
  top: "res_stage_3_391_2_top"
}
layer {
  name: "res_stage_3_391_3"
  type: "Convolution"
  bottom: "res_stage_3_391_2_top"
  top: "res_stage_3_391_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_391_3"
  type: "BatchNorm"
  bottom: "res_stage_3_391_3"
  top: "res_stage_3_391_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_391_3"  
  type: "Scale"
  bottom: "res_stage_3_391_3"
  top: "res_stage_3_391_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_391"
  type: "Eltwise"
  bottom: "res_3_390"
  bottom: "res_stage_3_391_3_top"
  top: "res_3_391"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_391_relu"
  type: "ReLU"
  bottom: "res_3_391"
  top: "res_3_391"
}
layer {
  name: "res_stage_3_392_1"
  type: "Convolution"
  bottom: "res_3_391"
  top: "res_stage_3_392_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_392_1"
  type: "BatchNorm"
  bottom: "res_stage_3_392_1"
  top: "res_stage_3_392_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_392_1"  
  type: "Scale"
  bottom: "res_stage_3_392_1"
  top: "res_stage_3_392_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_392_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_392_1_top"
  top: "res_stage_3_392_1_top"
}
layer {
  name: "res_stage_3_392_2"
  type: "Convolution"
  bottom: "res_stage_3_392_1_top"
  top: "res_stage_3_392_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_392_2"
  type: "BatchNorm"
  bottom: "res_stage_3_392_2"
  top: "res_stage_3_392_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_392_2"  
  type: "Scale"
  bottom: "res_stage_3_392_2"
  top: "res_stage_3_392_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_392_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_392_2_top"
  top: "res_stage_3_392_2_top"
}
layer {
  name: "res_stage_3_392_3"
  type: "Convolution"
  bottom: "res_stage_3_392_2_top"
  top: "res_stage_3_392_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_392_3"
  type: "BatchNorm"
  bottom: "res_stage_3_392_3"
  top: "res_stage_3_392_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_392_3"  
  type: "Scale"
  bottom: "res_stage_3_392_3"
  top: "res_stage_3_392_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_392"
  type: "Eltwise"
  bottom: "res_3_391"
  bottom: "res_stage_3_392_3_top"
  top: "res_3_392"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_392_relu"
  type: "ReLU"
  bottom: "res_3_392"
  top: "res_3_392"
}
layer {
  name: "res_stage_3_393_1"
  type: "Convolution"
  bottom: "res_3_392"
  top: "res_stage_3_393_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_393_1"
  type: "BatchNorm"
  bottom: "res_stage_3_393_1"
  top: "res_stage_3_393_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_393_1"  
  type: "Scale"
  bottom: "res_stage_3_393_1"
  top: "res_stage_3_393_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_393_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_393_1_top"
  top: "res_stage_3_393_1_top"
}
layer {
  name: "res_stage_3_393_2"
  type: "Convolution"
  bottom: "res_stage_3_393_1_top"
  top: "res_stage_3_393_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_393_2"
  type: "BatchNorm"
  bottom: "res_stage_3_393_2"
  top: "res_stage_3_393_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_393_2"  
  type: "Scale"
  bottom: "res_stage_3_393_2"
  top: "res_stage_3_393_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_393_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_393_2_top"
  top: "res_stage_3_393_2_top"
}
layer {
  name: "res_stage_3_393_3"
  type: "Convolution"
  bottom: "res_stage_3_393_2_top"
  top: "res_stage_3_393_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_393_3"
  type: "BatchNorm"
  bottom: "res_stage_3_393_3"
  top: "res_stage_3_393_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_393_3"  
  type: "Scale"
  bottom: "res_stage_3_393_3"
  top: "res_stage_3_393_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_393"
  type: "Eltwise"
  bottom: "res_3_392"
  bottom: "res_stage_3_393_3_top"
  top: "res_3_393"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_393_relu"
  type: "ReLU"
  bottom: "res_3_393"
  top: "res_3_393"
}
layer {
  name: "res_stage_3_394_1"
  type: "Convolution"
  bottom: "res_3_393"
  top: "res_stage_3_394_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_394_1"
  type: "BatchNorm"
  bottom: "res_stage_3_394_1"
  top: "res_stage_3_394_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_394_1"  
  type: "Scale"
  bottom: "res_stage_3_394_1"
  top: "res_stage_3_394_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_394_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_394_1_top"
  top: "res_stage_3_394_1_top"
}
layer {
  name: "res_stage_3_394_2"
  type: "Convolution"
  bottom: "res_stage_3_394_1_top"
  top: "res_stage_3_394_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_394_2"
  type: "BatchNorm"
  bottom: "res_stage_3_394_2"
  top: "res_stage_3_394_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_394_2"  
  type: "Scale"
  bottom: "res_stage_3_394_2"
  top: "res_stage_3_394_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_394_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_394_2_top"
  top: "res_stage_3_394_2_top"
}
layer {
  name: "res_stage_3_394_3"
  type: "Convolution"
  bottom: "res_stage_3_394_2_top"
  top: "res_stage_3_394_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_394_3"
  type: "BatchNorm"
  bottom: "res_stage_3_394_3"
  top: "res_stage_3_394_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_394_3"  
  type: "Scale"
  bottom: "res_stage_3_394_3"
  top: "res_stage_3_394_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_394"
  type: "Eltwise"
  bottom: "res_3_393"
  bottom: "res_stage_3_394_3_top"
  top: "res_3_394"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_394_relu"
  type: "ReLU"
  bottom: "res_3_394"
  top: "res_3_394"
}
layer {
  name: "res_stage_3_395_1"
  type: "Convolution"
  bottom: "res_3_394"
  top: "res_stage_3_395_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_395_1"
  type: "BatchNorm"
  bottom: "res_stage_3_395_1"
  top: "res_stage_3_395_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_395_1"  
  type: "Scale"
  bottom: "res_stage_3_395_1"
  top: "res_stage_3_395_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_395_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_395_1_top"
  top: "res_stage_3_395_1_top"
}
layer {
  name: "res_stage_3_395_2"
  type: "Convolution"
  bottom: "res_stage_3_395_1_top"
  top: "res_stage_3_395_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_395_2"
  type: "BatchNorm"
  bottom: "res_stage_3_395_2"
  top: "res_stage_3_395_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_395_2"  
  type: "Scale"
  bottom: "res_stage_3_395_2"
  top: "res_stage_3_395_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_395_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_395_2_top"
  top: "res_stage_3_395_2_top"
}
layer {
  name: "res_stage_3_395_3"
  type: "Convolution"
  bottom: "res_stage_3_395_2_top"
  top: "res_stage_3_395_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_395_3"
  type: "BatchNorm"
  bottom: "res_stage_3_395_3"
  top: "res_stage_3_395_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_395_3"  
  type: "Scale"
  bottom: "res_stage_3_395_3"
  top: "res_stage_3_395_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_395"
  type: "Eltwise"
  bottom: "res_3_394"
  bottom: "res_stage_3_395_3_top"
  top: "res_3_395"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_395_relu"
  type: "ReLU"
  bottom: "res_3_395"
  top: "res_3_395"
}
layer {
  name: "res_stage_3_396_1"
  type: "Convolution"
  bottom: "res_3_395"
  top: "res_stage_3_396_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_396_1"
  type: "BatchNorm"
  bottom: "res_stage_3_396_1"
  top: "res_stage_3_396_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_396_1"  
  type: "Scale"
  bottom: "res_stage_3_396_1"
  top: "res_stage_3_396_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_396_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_396_1_top"
  top: "res_stage_3_396_1_top"
}
layer {
  name: "res_stage_3_396_2"
  type: "Convolution"
  bottom: "res_stage_3_396_1_top"
  top: "res_stage_3_396_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_396_2"
  type: "BatchNorm"
  bottom: "res_stage_3_396_2"
  top: "res_stage_3_396_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_396_2"  
  type: "Scale"
  bottom: "res_stage_3_396_2"
  top: "res_stage_3_396_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_396_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_396_2_top"
  top: "res_stage_3_396_2_top"
}
layer {
  name: "res_stage_3_396_3"
  type: "Convolution"
  bottom: "res_stage_3_396_2_top"
  top: "res_stage_3_396_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_396_3"
  type: "BatchNorm"
  bottom: "res_stage_3_396_3"
  top: "res_stage_3_396_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_396_3"  
  type: "Scale"
  bottom: "res_stage_3_396_3"
  top: "res_stage_3_396_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_396"
  type: "Eltwise"
  bottom: "res_3_395"
  bottom: "res_stage_3_396_3_top"
  top: "res_3_396"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_396_relu"
  type: "ReLU"
  bottom: "res_3_396"
  top: "res_3_396"
}
layer {
  name: "res_stage_3_397_1"
  type: "Convolution"
  bottom: "res_3_396"
  top: "res_stage_3_397_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_397_1"
  type: "BatchNorm"
  bottom: "res_stage_3_397_1"
  top: "res_stage_3_397_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_397_1"  
  type: "Scale"
  bottom: "res_stage_3_397_1"
  top: "res_stage_3_397_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_397_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_397_1_top"
  top: "res_stage_3_397_1_top"
}
layer {
  name: "res_stage_3_397_2"
  type: "Convolution"
  bottom: "res_stage_3_397_1_top"
  top: "res_stage_3_397_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_397_2"
  type: "BatchNorm"
  bottom: "res_stage_3_397_2"
  top: "res_stage_3_397_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_397_2"  
  type: "Scale"
  bottom: "res_stage_3_397_2"
  top: "res_stage_3_397_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_397_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_397_2_top"
  top: "res_stage_3_397_2_top"
}
layer {
  name: "res_stage_3_397_3"
  type: "Convolution"
  bottom: "res_stage_3_397_2_top"
  top: "res_stage_3_397_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_397_3"
  type: "BatchNorm"
  bottom: "res_stage_3_397_3"
  top: "res_stage_3_397_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_397_3"  
  type: "Scale"
  bottom: "res_stage_3_397_3"
  top: "res_stage_3_397_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_397"
  type: "Eltwise"
  bottom: "res_3_396"
  bottom: "res_stage_3_397_3_top"
  top: "res_3_397"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_397_relu"
  type: "ReLU"
  bottom: "res_3_397"
  top: "res_3_397"
}
layer {
  name: "res_stage_3_398_1"
  type: "Convolution"
  bottom: "res_3_397"
  top: "res_stage_3_398_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_398_1"
  type: "BatchNorm"
  bottom: "res_stage_3_398_1"
  top: "res_stage_3_398_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_398_1"  
  type: "Scale"
  bottom: "res_stage_3_398_1"
  top: "res_stage_3_398_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_398_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_398_1_top"
  top: "res_stage_3_398_1_top"
}
layer {
  name: "res_stage_3_398_2"
  type: "Convolution"
  bottom: "res_stage_3_398_1_top"
  top: "res_stage_3_398_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_398_2"
  type: "BatchNorm"
  bottom: "res_stage_3_398_2"
  top: "res_stage_3_398_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_398_2"  
  type: "Scale"
  bottom: "res_stage_3_398_2"
  top: "res_stage_3_398_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_398_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_398_2_top"
  top: "res_stage_3_398_2_top"
}
layer {
  name: "res_stage_3_398_3"
  type: "Convolution"
  bottom: "res_stage_3_398_2_top"
  top: "res_stage_3_398_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_398_3"
  type: "BatchNorm"
  bottom: "res_stage_3_398_3"
  top: "res_stage_3_398_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_398_3"  
  type: "Scale"
  bottom: "res_stage_3_398_3"
  top: "res_stage_3_398_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_398"
  type: "Eltwise"
  bottom: "res_3_397"
  bottom: "res_stage_3_398_3_top"
  top: "res_3_398"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_398_relu"
  type: "ReLU"
  bottom: "res_3_398"
  top: "res_3_398"
}
layer {
  name: "res_stage_3_399_1"
  type: "Convolution"
  bottom: "res_3_398"
  top: "res_stage_3_399_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_399_1"
  type: "BatchNorm"
  bottom: "res_stage_3_399_1"
  top: "res_stage_3_399_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_399_1"  
  type: "Scale"
  bottom: "res_stage_3_399_1"
  top: "res_stage_3_399_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_399_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_399_1_top"
  top: "res_stage_3_399_1_top"
}
layer {
  name: "res_stage_3_399_2"
  type: "Convolution"
  bottom: "res_stage_3_399_1_top"
  top: "res_stage_3_399_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_399_2"
  type: "BatchNorm"
  bottom: "res_stage_3_399_2"
  top: "res_stage_3_399_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_399_2"  
  type: "Scale"
  bottom: "res_stage_3_399_2"
  top: "res_stage_3_399_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_399_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_399_2_top"
  top: "res_stage_3_399_2_top"
}
layer {
  name: "res_stage_3_399_3"
  type: "Convolution"
  bottom: "res_stage_3_399_2_top"
  top: "res_stage_3_399_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_399_3"
  type: "BatchNorm"
  bottom: "res_stage_3_399_3"
  top: "res_stage_3_399_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_399_3"  
  type: "Scale"
  bottom: "res_stage_3_399_3"
  top: "res_stage_3_399_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_399"
  type: "Eltwise"
  bottom: "res_3_398"
  bottom: "res_stage_3_399_3_top"
  top: "res_3_399"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_399_relu"
  type: "ReLU"
  bottom: "res_3_399"
  top: "res_3_399"
}
layer {
  name: "res_stage_3_400_1"
  type: "Convolution"
  bottom: "res_3_399"
  top: "res_stage_3_400_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_400_1"
  type: "BatchNorm"
  bottom: "res_stage_3_400_1"
  top: "res_stage_3_400_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_400_1"  
  type: "Scale"
  bottom: "res_stage_3_400_1"
  top: "res_stage_3_400_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_400_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_400_1_top"
  top: "res_stage_3_400_1_top"
}
layer {
  name: "res_stage_3_400_2"
  type: "Convolution"
  bottom: "res_stage_3_400_1_top"
  top: "res_stage_3_400_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_400_2"
  type: "BatchNorm"
  bottom: "res_stage_3_400_2"
  top: "res_stage_3_400_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_400_2"  
  type: "Scale"
  bottom: "res_stage_3_400_2"
  top: "res_stage_3_400_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_400_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_400_2_top"
  top: "res_stage_3_400_2_top"
}
layer {
  name: "res_stage_3_400_3"
  type: "Convolution"
  bottom: "res_stage_3_400_2_top"
  top: "res_stage_3_400_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_400_3"
  type: "BatchNorm"
  bottom: "res_stage_3_400_3"
  top: "res_stage_3_400_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_400_3"  
  type: "Scale"
  bottom: "res_stage_3_400_3"
  top: "res_stage_3_400_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_400"
  type: "Eltwise"
  bottom: "res_3_399"
  bottom: "res_stage_3_400_3_top"
  top: "res_3_400"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_400_relu"
  type: "ReLU"
  bottom: "res_3_400"
  top: "res_3_400"
}
layer {
  name: "res_stage_3_401_1"
  type: "Convolution"
  bottom: "res_3_400"
  top: "res_stage_3_401_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_401_1"
  type: "BatchNorm"
  bottom: "res_stage_3_401_1"
  top: "res_stage_3_401_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_401_1"  
  type: "Scale"
  bottom: "res_stage_3_401_1"
  top: "res_stage_3_401_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_401_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_401_1_top"
  top: "res_stage_3_401_1_top"
}
layer {
  name: "res_stage_3_401_2"
  type: "Convolution"
  bottom: "res_stage_3_401_1_top"
  top: "res_stage_3_401_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_401_2"
  type: "BatchNorm"
  bottom: "res_stage_3_401_2"
  top: "res_stage_3_401_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_401_2"  
  type: "Scale"
  bottom: "res_stage_3_401_2"
  top: "res_stage_3_401_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_401_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_401_2_top"
  top: "res_stage_3_401_2_top"
}
layer {
  name: "res_stage_3_401_3"
  type: "Convolution"
  bottom: "res_stage_3_401_2_top"
  top: "res_stage_3_401_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_401_3"
  type: "BatchNorm"
  bottom: "res_stage_3_401_3"
  top: "res_stage_3_401_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_401_3"  
  type: "Scale"
  bottom: "res_stage_3_401_3"
  top: "res_stage_3_401_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_401"
  type: "Eltwise"
  bottom: "res_3_400"
  bottom: "res_stage_3_401_3_top"
  top: "res_3_401"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_401_relu"
  type: "ReLU"
  bottom: "res_3_401"
  top: "res_3_401"
}
layer {
  name: "res_stage_3_402_1"
  type: "Convolution"
  bottom: "res_3_401"
  top: "res_stage_3_402_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_402_1"
  type: "BatchNorm"
  bottom: "res_stage_3_402_1"
  top: "res_stage_3_402_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_402_1"  
  type: "Scale"
  bottom: "res_stage_3_402_1"
  top: "res_stage_3_402_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_402_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_402_1_top"
  top: "res_stage_3_402_1_top"
}
layer {
  name: "res_stage_3_402_2"
  type: "Convolution"
  bottom: "res_stage_3_402_1_top"
  top: "res_stage_3_402_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_402_2"
  type: "BatchNorm"
  bottom: "res_stage_3_402_2"
  top: "res_stage_3_402_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_402_2"  
  type: "Scale"
  bottom: "res_stage_3_402_2"
  top: "res_stage_3_402_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_402_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_402_2_top"
  top: "res_stage_3_402_2_top"
}
layer {
  name: "res_stage_3_402_3"
  type: "Convolution"
  bottom: "res_stage_3_402_2_top"
  top: "res_stage_3_402_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_402_3"
  type: "BatchNorm"
  bottom: "res_stage_3_402_3"
  top: "res_stage_3_402_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_402_3"  
  type: "Scale"
  bottom: "res_stage_3_402_3"
  top: "res_stage_3_402_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_402"
  type: "Eltwise"
  bottom: "res_3_401"
  bottom: "res_stage_3_402_3_top"
  top: "res_3_402"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_402_relu"
  type: "ReLU"
  bottom: "res_3_402"
  top: "res_3_402"
}
layer {
  name: "res_stage_3_403_1"
  type: "Convolution"
  bottom: "res_3_402"
  top: "res_stage_3_403_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_403_1"
  type: "BatchNorm"
  bottom: "res_stage_3_403_1"
  top: "res_stage_3_403_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_403_1"  
  type: "Scale"
  bottom: "res_stage_3_403_1"
  top: "res_stage_3_403_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_403_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_403_1_top"
  top: "res_stage_3_403_1_top"
}
layer {
  name: "res_stage_3_403_2"
  type: "Convolution"
  bottom: "res_stage_3_403_1_top"
  top: "res_stage_3_403_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_403_2"
  type: "BatchNorm"
  bottom: "res_stage_3_403_2"
  top: "res_stage_3_403_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_403_2"  
  type: "Scale"
  bottom: "res_stage_3_403_2"
  top: "res_stage_3_403_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_403_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_403_2_top"
  top: "res_stage_3_403_2_top"
}
layer {
  name: "res_stage_3_403_3"
  type: "Convolution"
  bottom: "res_stage_3_403_2_top"
  top: "res_stage_3_403_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_403_3"
  type: "BatchNorm"
  bottom: "res_stage_3_403_3"
  top: "res_stage_3_403_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_403_3"  
  type: "Scale"
  bottom: "res_stage_3_403_3"
  top: "res_stage_3_403_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_403"
  type: "Eltwise"
  bottom: "res_3_402"
  bottom: "res_stage_3_403_3_top"
  top: "res_3_403"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_403_relu"
  type: "ReLU"
  bottom: "res_3_403"
  top: "res_3_403"
}
layer {
  name: "res_stage_3_404_1"
  type: "Convolution"
  bottom: "res_3_403"
  top: "res_stage_3_404_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_404_1"
  type: "BatchNorm"
  bottom: "res_stage_3_404_1"
  top: "res_stage_3_404_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_404_1"  
  type: "Scale"
  bottom: "res_stage_3_404_1"
  top: "res_stage_3_404_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_404_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_404_1_top"
  top: "res_stage_3_404_1_top"
}
layer {
  name: "res_stage_3_404_2"
  type: "Convolution"
  bottom: "res_stage_3_404_1_top"
  top: "res_stage_3_404_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_404_2"
  type: "BatchNorm"
  bottom: "res_stage_3_404_2"
  top: "res_stage_3_404_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_404_2"  
  type: "Scale"
  bottom: "res_stage_3_404_2"
  top: "res_stage_3_404_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_404_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_404_2_top"
  top: "res_stage_3_404_2_top"
}
layer {
  name: "res_stage_3_404_3"
  type: "Convolution"
  bottom: "res_stage_3_404_2_top"
  top: "res_stage_3_404_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_404_3"
  type: "BatchNorm"
  bottom: "res_stage_3_404_3"
  top: "res_stage_3_404_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_404_3"  
  type: "Scale"
  bottom: "res_stage_3_404_3"
  top: "res_stage_3_404_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_404"
  type: "Eltwise"
  bottom: "res_3_403"
  bottom: "res_stage_3_404_3_top"
  top: "res_3_404"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_404_relu"
  type: "ReLU"
  bottom: "res_3_404"
  top: "res_3_404"
}
layer {
  name: "res_stage_3_405_1"
  type: "Convolution"
  bottom: "res_3_404"
  top: "res_stage_3_405_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_405_1"
  type: "BatchNorm"
  bottom: "res_stage_3_405_1"
  top: "res_stage_3_405_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_405_1"  
  type: "Scale"
  bottom: "res_stage_3_405_1"
  top: "res_stage_3_405_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_405_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_405_1_top"
  top: "res_stage_3_405_1_top"
}
layer {
  name: "res_stage_3_405_2"
  type: "Convolution"
  bottom: "res_stage_3_405_1_top"
  top: "res_stage_3_405_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_405_2"
  type: "BatchNorm"
  bottom: "res_stage_3_405_2"
  top: "res_stage_3_405_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_405_2"  
  type: "Scale"
  bottom: "res_stage_3_405_2"
  top: "res_stage_3_405_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_405_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_405_2_top"
  top: "res_stage_3_405_2_top"
}
layer {
  name: "res_stage_3_405_3"
  type: "Convolution"
  bottom: "res_stage_3_405_2_top"
  top: "res_stage_3_405_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_405_3"
  type: "BatchNorm"
  bottom: "res_stage_3_405_3"
  top: "res_stage_3_405_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_405_3"  
  type: "Scale"
  bottom: "res_stage_3_405_3"
  top: "res_stage_3_405_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_405"
  type: "Eltwise"
  bottom: "res_3_404"
  bottom: "res_stage_3_405_3_top"
  top: "res_3_405"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_405_relu"
  type: "ReLU"
  bottom: "res_3_405"
  top: "res_3_405"
}
layer {
  name: "res_stage_3_406_1"
  type: "Convolution"
  bottom: "res_3_405"
  top: "res_stage_3_406_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_406_1"
  type: "BatchNorm"
  bottom: "res_stage_3_406_1"
  top: "res_stage_3_406_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_406_1"  
  type: "Scale"
  bottom: "res_stage_3_406_1"
  top: "res_stage_3_406_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_406_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_406_1_top"
  top: "res_stage_3_406_1_top"
}
layer {
  name: "res_stage_3_406_2"
  type: "Convolution"
  bottom: "res_stage_3_406_1_top"
  top: "res_stage_3_406_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_406_2"
  type: "BatchNorm"
  bottom: "res_stage_3_406_2"
  top: "res_stage_3_406_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_406_2"  
  type: "Scale"
  bottom: "res_stage_3_406_2"
  top: "res_stage_3_406_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_406_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_406_2_top"
  top: "res_stage_3_406_2_top"
}
layer {
  name: "res_stage_3_406_3"
  type: "Convolution"
  bottom: "res_stage_3_406_2_top"
  top: "res_stage_3_406_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_406_3"
  type: "BatchNorm"
  bottom: "res_stage_3_406_3"
  top: "res_stage_3_406_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_406_3"  
  type: "Scale"
  bottom: "res_stage_3_406_3"
  top: "res_stage_3_406_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_406"
  type: "Eltwise"
  bottom: "res_3_405"
  bottom: "res_stage_3_406_3_top"
  top: "res_3_406"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_406_relu"
  type: "ReLU"
  bottom: "res_3_406"
  top: "res_3_406"
}
layer {
  name: "res_stage_3_407_1"
  type: "Convolution"
  bottom: "res_3_406"
  top: "res_stage_3_407_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_407_1"
  type: "BatchNorm"
  bottom: "res_stage_3_407_1"
  top: "res_stage_3_407_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_407_1"  
  type: "Scale"
  bottom: "res_stage_3_407_1"
  top: "res_stage_3_407_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_407_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_407_1_top"
  top: "res_stage_3_407_1_top"
}
layer {
  name: "res_stage_3_407_2"
  type: "Convolution"
  bottom: "res_stage_3_407_1_top"
  top: "res_stage_3_407_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_407_2"
  type: "BatchNorm"
  bottom: "res_stage_3_407_2"
  top: "res_stage_3_407_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_407_2"  
  type: "Scale"
  bottom: "res_stage_3_407_2"
  top: "res_stage_3_407_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_407_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_407_2_top"
  top: "res_stage_3_407_2_top"
}
layer {
  name: "res_stage_3_407_3"
  type: "Convolution"
  bottom: "res_stage_3_407_2_top"
  top: "res_stage_3_407_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_407_3"
  type: "BatchNorm"
  bottom: "res_stage_3_407_3"
  top: "res_stage_3_407_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_407_3"  
  type: "Scale"
  bottom: "res_stage_3_407_3"
  top: "res_stage_3_407_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_407"
  type: "Eltwise"
  bottom: "res_3_406"
  bottom: "res_stage_3_407_3_top"
  top: "res_3_407"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_407_relu"
  type: "ReLU"
  bottom: "res_3_407"
  top: "res_3_407"
}
layer {
  name: "res_stage_3_408_1"
  type: "Convolution"
  bottom: "res_3_407"
  top: "res_stage_3_408_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_408_1"
  type: "BatchNorm"
  bottom: "res_stage_3_408_1"
  top: "res_stage_3_408_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_408_1"  
  type: "Scale"
  bottom: "res_stage_3_408_1"
  top: "res_stage_3_408_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_408_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_408_1_top"
  top: "res_stage_3_408_1_top"
}
layer {
  name: "res_stage_3_408_2"
  type: "Convolution"
  bottom: "res_stage_3_408_1_top"
  top: "res_stage_3_408_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_408_2"
  type: "BatchNorm"
  bottom: "res_stage_3_408_2"
  top: "res_stage_3_408_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_408_2"  
  type: "Scale"
  bottom: "res_stage_3_408_2"
  top: "res_stage_3_408_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_408_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_408_2_top"
  top: "res_stage_3_408_2_top"
}
layer {
  name: "res_stage_3_408_3"
  type: "Convolution"
  bottom: "res_stage_3_408_2_top"
  top: "res_stage_3_408_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_408_3"
  type: "BatchNorm"
  bottom: "res_stage_3_408_3"
  top: "res_stage_3_408_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_408_3"  
  type: "Scale"
  bottom: "res_stage_3_408_3"
  top: "res_stage_3_408_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_408"
  type: "Eltwise"
  bottom: "res_3_407"
  bottom: "res_stage_3_408_3_top"
  top: "res_3_408"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_408_relu"
  type: "ReLU"
  bottom: "res_3_408"
  top: "res_3_408"
}
layer {
  name: "res_stage_3_409_1"
  type: "Convolution"
  bottom: "res_3_408"
  top: "res_stage_3_409_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_409_1"
  type: "BatchNorm"
  bottom: "res_stage_3_409_1"
  top: "res_stage_3_409_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_409_1"  
  type: "Scale"
  bottom: "res_stage_3_409_1"
  top: "res_stage_3_409_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_409_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_409_1_top"
  top: "res_stage_3_409_1_top"
}
layer {
  name: "res_stage_3_409_2"
  type: "Convolution"
  bottom: "res_stage_3_409_1_top"
  top: "res_stage_3_409_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_409_2"
  type: "BatchNorm"
  bottom: "res_stage_3_409_2"
  top: "res_stage_3_409_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_409_2"  
  type: "Scale"
  bottom: "res_stage_3_409_2"
  top: "res_stage_3_409_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_409_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_409_2_top"
  top: "res_stage_3_409_2_top"
}
layer {
  name: "res_stage_3_409_3"
  type: "Convolution"
  bottom: "res_stage_3_409_2_top"
  top: "res_stage_3_409_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_409_3"
  type: "BatchNorm"
  bottom: "res_stage_3_409_3"
  top: "res_stage_3_409_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_409_3"  
  type: "Scale"
  bottom: "res_stage_3_409_3"
  top: "res_stage_3_409_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_409"
  type: "Eltwise"
  bottom: "res_3_408"
  bottom: "res_stage_3_409_3_top"
  top: "res_3_409"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_409_relu"
  type: "ReLU"
  bottom: "res_3_409"
  top: "res_3_409"
}
layer {
  name: "res_stage_3_410_1"
  type: "Convolution"
  bottom: "res_3_409"
  top: "res_stage_3_410_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_410_1"
  type: "BatchNorm"
  bottom: "res_stage_3_410_1"
  top: "res_stage_3_410_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_410_1"  
  type: "Scale"
  bottom: "res_stage_3_410_1"
  top: "res_stage_3_410_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_410_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_410_1_top"
  top: "res_stage_3_410_1_top"
}
layer {
  name: "res_stage_3_410_2"
  type: "Convolution"
  bottom: "res_stage_3_410_1_top"
  top: "res_stage_3_410_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_410_2"
  type: "BatchNorm"
  bottom: "res_stage_3_410_2"
  top: "res_stage_3_410_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_410_2"  
  type: "Scale"
  bottom: "res_stage_3_410_2"
  top: "res_stage_3_410_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_410_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_410_2_top"
  top: "res_stage_3_410_2_top"
}
layer {
  name: "res_stage_3_410_3"
  type: "Convolution"
  bottom: "res_stage_3_410_2_top"
  top: "res_stage_3_410_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_410_3"
  type: "BatchNorm"
  bottom: "res_stage_3_410_3"
  top: "res_stage_3_410_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_410_3"  
  type: "Scale"
  bottom: "res_stage_3_410_3"
  top: "res_stage_3_410_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_410"
  type: "Eltwise"
  bottom: "res_3_409"
  bottom: "res_stage_3_410_3_top"
  top: "res_3_410"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_410_relu"
  type: "ReLU"
  bottom: "res_3_410"
  top: "res_3_410"
}
layer {
  name: "res_stage_3_411_1"
  type: "Convolution"
  bottom: "res_3_410"
  top: "res_stage_3_411_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_411_1"
  type: "BatchNorm"
  bottom: "res_stage_3_411_1"
  top: "res_stage_3_411_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_411_1"  
  type: "Scale"
  bottom: "res_stage_3_411_1"
  top: "res_stage_3_411_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_411_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_411_1_top"
  top: "res_stage_3_411_1_top"
}
layer {
  name: "res_stage_3_411_2"
  type: "Convolution"
  bottom: "res_stage_3_411_1_top"
  top: "res_stage_3_411_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_411_2"
  type: "BatchNorm"
  bottom: "res_stage_3_411_2"
  top: "res_stage_3_411_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_411_2"  
  type: "Scale"
  bottom: "res_stage_3_411_2"
  top: "res_stage_3_411_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_411_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_411_2_top"
  top: "res_stage_3_411_2_top"
}
layer {
  name: "res_stage_3_411_3"
  type: "Convolution"
  bottom: "res_stage_3_411_2_top"
  top: "res_stage_3_411_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_411_3"
  type: "BatchNorm"
  bottom: "res_stage_3_411_3"
  top: "res_stage_3_411_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_411_3"  
  type: "Scale"
  bottom: "res_stage_3_411_3"
  top: "res_stage_3_411_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_411"
  type: "Eltwise"
  bottom: "res_3_410"
  bottom: "res_stage_3_411_3_top"
  top: "res_3_411"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_411_relu"
  type: "ReLU"
  bottom: "res_3_411"
  top: "res_3_411"
}
layer {
  name: "res_stage_3_412_1"
  type: "Convolution"
  bottom: "res_3_411"
  top: "res_stage_3_412_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_412_1"
  type: "BatchNorm"
  bottom: "res_stage_3_412_1"
  top: "res_stage_3_412_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_412_1"  
  type: "Scale"
  bottom: "res_stage_3_412_1"
  top: "res_stage_3_412_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_412_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_412_1_top"
  top: "res_stage_3_412_1_top"
}
layer {
  name: "res_stage_3_412_2"
  type: "Convolution"
  bottom: "res_stage_3_412_1_top"
  top: "res_stage_3_412_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_412_2"
  type: "BatchNorm"
  bottom: "res_stage_3_412_2"
  top: "res_stage_3_412_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_412_2"  
  type: "Scale"
  bottom: "res_stage_3_412_2"
  top: "res_stage_3_412_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_412_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_412_2_top"
  top: "res_stage_3_412_2_top"
}
layer {
  name: "res_stage_3_412_3"
  type: "Convolution"
  bottom: "res_stage_3_412_2_top"
  top: "res_stage_3_412_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_412_3"
  type: "BatchNorm"
  bottom: "res_stage_3_412_3"
  top: "res_stage_3_412_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_412_3"  
  type: "Scale"
  bottom: "res_stage_3_412_3"
  top: "res_stage_3_412_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_412"
  type: "Eltwise"
  bottom: "res_3_411"
  bottom: "res_stage_3_412_3_top"
  top: "res_3_412"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_412_relu"
  type: "ReLU"
  bottom: "res_3_412"
  top: "res_3_412"
}
layer {
  name: "res_stage_3_413_1"
  type: "Convolution"
  bottom: "res_3_412"
  top: "res_stage_3_413_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_413_1"
  type: "BatchNorm"
  bottom: "res_stage_3_413_1"
  top: "res_stage_3_413_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_413_1"  
  type: "Scale"
  bottom: "res_stage_3_413_1"
  top: "res_stage_3_413_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_413_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_413_1_top"
  top: "res_stage_3_413_1_top"
}
layer {
  name: "res_stage_3_413_2"
  type: "Convolution"
  bottom: "res_stage_3_413_1_top"
  top: "res_stage_3_413_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_413_2"
  type: "BatchNorm"
  bottom: "res_stage_3_413_2"
  top: "res_stage_3_413_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_413_2"  
  type: "Scale"
  bottom: "res_stage_3_413_2"
  top: "res_stage_3_413_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_413_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_413_2_top"
  top: "res_stage_3_413_2_top"
}
layer {
  name: "res_stage_3_413_3"
  type: "Convolution"
  bottom: "res_stage_3_413_2_top"
  top: "res_stage_3_413_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_413_3"
  type: "BatchNorm"
  bottom: "res_stage_3_413_3"
  top: "res_stage_3_413_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_413_3"  
  type: "Scale"
  bottom: "res_stage_3_413_3"
  top: "res_stage_3_413_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_413"
  type: "Eltwise"
  bottom: "res_3_412"
  bottom: "res_stage_3_413_3_top"
  top: "res_3_413"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_413_relu"
  type: "ReLU"
  bottom: "res_3_413"
  top: "res_3_413"
}
layer {
  name: "res_stage_3_414_1"
  type: "Convolution"
  bottom: "res_3_413"
  top: "res_stage_3_414_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_414_1"
  type: "BatchNorm"
  bottom: "res_stage_3_414_1"
  top: "res_stage_3_414_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_414_1"  
  type: "Scale"
  bottom: "res_stage_3_414_1"
  top: "res_stage_3_414_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_414_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_414_1_top"
  top: "res_stage_3_414_1_top"
}
layer {
  name: "res_stage_3_414_2"
  type: "Convolution"
  bottom: "res_stage_3_414_1_top"
  top: "res_stage_3_414_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_414_2"
  type: "BatchNorm"
  bottom: "res_stage_3_414_2"
  top: "res_stage_3_414_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_414_2"  
  type: "Scale"
  bottom: "res_stage_3_414_2"
  top: "res_stage_3_414_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_414_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_414_2_top"
  top: "res_stage_3_414_2_top"
}
layer {
  name: "res_stage_3_414_3"
  type: "Convolution"
  bottom: "res_stage_3_414_2_top"
  top: "res_stage_3_414_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_414_3"
  type: "BatchNorm"
  bottom: "res_stage_3_414_3"
  top: "res_stage_3_414_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_414_3"  
  type: "Scale"
  bottom: "res_stage_3_414_3"
  top: "res_stage_3_414_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_414"
  type: "Eltwise"
  bottom: "res_3_413"
  bottom: "res_stage_3_414_3_top"
  top: "res_3_414"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_414_relu"
  type: "ReLU"
  bottom: "res_3_414"
  top: "res_3_414"
}
layer {
  name: "res_stage_3_415_1"
  type: "Convolution"
  bottom: "res_3_414"
  top: "res_stage_3_415_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_415_1"
  type: "BatchNorm"
  bottom: "res_stage_3_415_1"
  top: "res_stage_3_415_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_415_1"  
  type: "Scale"
  bottom: "res_stage_3_415_1"
  top: "res_stage_3_415_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_415_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_415_1_top"
  top: "res_stage_3_415_1_top"
}
layer {
  name: "res_stage_3_415_2"
  type: "Convolution"
  bottom: "res_stage_3_415_1_top"
  top: "res_stage_3_415_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_415_2"
  type: "BatchNorm"
  bottom: "res_stage_3_415_2"
  top: "res_stage_3_415_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_415_2"  
  type: "Scale"
  bottom: "res_stage_3_415_2"
  top: "res_stage_3_415_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_415_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_415_2_top"
  top: "res_stage_3_415_2_top"
}
layer {
  name: "res_stage_3_415_3"
  type: "Convolution"
  bottom: "res_stage_3_415_2_top"
  top: "res_stage_3_415_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_415_3"
  type: "BatchNorm"
  bottom: "res_stage_3_415_3"
  top: "res_stage_3_415_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_415_3"  
  type: "Scale"
  bottom: "res_stage_3_415_3"
  top: "res_stage_3_415_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_415"
  type: "Eltwise"
  bottom: "res_3_414"
  bottom: "res_stage_3_415_3_top"
  top: "res_3_415"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_415_relu"
  type: "ReLU"
  bottom: "res_3_415"
  top: "res_3_415"
}
layer {
  name: "res_stage_3_416_1"
  type: "Convolution"
  bottom: "res_3_415"
  top: "res_stage_3_416_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_416_1"
  type: "BatchNorm"
  bottom: "res_stage_3_416_1"
  top: "res_stage_3_416_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_416_1"  
  type: "Scale"
  bottom: "res_stage_3_416_1"
  top: "res_stage_3_416_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_416_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_416_1_top"
  top: "res_stage_3_416_1_top"
}
layer {
  name: "res_stage_3_416_2"
  type: "Convolution"
  bottom: "res_stage_3_416_1_top"
  top: "res_stage_3_416_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_416_2"
  type: "BatchNorm"
  bottom: "res_stage_3_416_2"
  top: "res_stage_3_416_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_416_2"  
  type: "Scale"
  bottom: "res_stage_3_416_2"
  top: "res_stage_3_416_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_416_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_416_2_top"
  top: "res_stage_3_416_2_top"
}
layer {
  name: "res_stage_3_416_3"
  type: "Convolution"
  bottom: "res_stage_3_416_2_top"
  top: "res_stage_3_416_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_416_3"
  type: "BatchNorm"
  bottom: "res_stage_3_416_3"
  top: "res_stage_3_416_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_416_3"  
  type: "Scale"
  bottom: "res_stage_3_416_3"
  top: "res_stage_3_416_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_416"
  type: "Eltwise"
  bottom: "res_3_415"
  bottom: "res_stage_3_416_3_top"
  top: "res_3_416"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_416_relu"
  type: "ReLU"
  bottom: "res_3_416"
  top: "res_3_416"
}
layer {
  name: "res_stage_3_417_1"
  type: "Convolution"
  bottom: "res_3_416"
  top: "res_stage_3_417_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_417_1"
  type: "BatchNorm"
  bottom: "res_stage_3_417_1"
  top: "res_stage_3_417_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_417_1"  
  type: "Scale"
  bottom: "res_stage_3_417_1"
  top: "res_stage_3_417_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_417_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_417_1_top"
  top: "res_stage_3_417_1_top"
}
layer {
  name: "res_stage_3_417_2"
  type: "Convolution"
  bottom: "res_stage_3_417_1_top"
  top: "res_stage_3_417_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_417_2"
  type: "BatchNorm"
  bottom: "res_stage_3_417_2"
  top: "res_stage_3_417_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_417_2"  
  type: "Scale"
  bottom: "res_stage_3_417_2"
  top: "res_stage_3_417_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_417_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_417_2_top"
  top: "res_stage_3_417_2_top"
}
layer {
  name: "res_stage_3_417_3"
  type: "Convolution"
  bottom: "res_stage_3_417_2_top"
  top: "res_stage_3_417_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_417_3"
  type: "BatchNorm"
  bottom: "res_stage_3_417_3"
  top: "res_stage_3_417_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_417_3"  
  type: "Scale"
  bottom: "res_stage_3_417_3"
  top: "res_stage_3_417_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_417"
  type: "Eltwise"
  bottom: "res_3_416"
  bottom: "res_stage_3_417_3_top"
  top: "res_3_417"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_417_relu"
  type: "ReLU"
  bottom: "res_3_417"
  top: "res_3_417"
}
layer {
  name: "res_stage_3_418_1"
  type: "Convolution"
  bottom: "res_3_417"
  top: "res_stage_3_418_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_418_1"
  type: "BatchNorm"
  bottom: "res_stage_3_418_1"
  top: "res_stage_3_418_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_418_1"  
  type: "Scale"
  bottom: "res_stage_3_418_1"
  top: "res_stage_3_418_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_418_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_418_1_top"
  top: "res_stage_3_418_1_top"
}
layer {
  name: "res_stage_3_418_2"
  type: "Convolution"
  bottom: "res_stage_3_418_1_top"
  top: "res_stage_3_418_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_418_2"
  type: "BatchNorm"
  bottom: "res_stage_3_418_2"
  top: "res_stage_3_418_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_418_2"  
  type: "Scale"
  bottom: "res_stage_3_418_2"
  top: "res_stage_3_418_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_418_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_418_2_top"
  top: "res_stage_3_418_2_top"
}
layer {
  name: "res_stage_3_418_3"
  type: "Convolution"
  bottom: "res_stage_3_418_2_top"
  top: "res_stage_3_418_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_418_3"
  type: "BatchNorm"
  bottom: "res_stage_3_418_3"
  top: "res_stage_3_418_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_418_3"  
  type: "Scale"
  bottom: "res_stage_3_418_3"
  top: "res_stage_3_418_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_418"
  type: "Eltwise"
  bottom: "res_3_417"
  bottom: "res_stage_3_418_3_top"
  top: "res_3_418"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_418_relu"
  type: "ReLU"
  bottom: "res_3_418"
  top: "res_3_418"
}
layer {
  name: "res_stage_3_419_1"
  type: "Convolution"
  bottom: "res_3_418"
  top: "res_stage_3_419_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_419_1"
  type: "BatchNorm"
  bottom: "res_stage_3_419_1"
  top: "res_stage_3_419_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_419_1"  
  type: "Scale"
  bottom: "res_stage_3_419_1"
  top: "res_stage_3_419_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_419_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_419_1_top"
  top: "res_stage_3_419_1_top"
}
layer {
  name: "res_stage_3_419_2"
  type: "Convolution"
  bottom: "res_stage_3_419_1_top"
  top: "res_stage_3_419_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_419_2"
  type: "BatchNorm"
  bottom: "res_stage_3_419_2"
  top: "res_stage_3_419_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_419_2"  
  type: "Scale"
  bottom: "res_stage_3_419_2"
  top: "res_stage_3_419_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_419_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_419_2_top"
  top: "res_stage_3_419_2_top"
}
layer {
  name: "res_stage_3_419_3"
  type: "Convolution"
  bottom: "res_stage_3_419_2_top"
  top: "res_stage_3_419_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_419_3"
  type: "BatchNorm"
  bottom: "res_stage_3_419_3"
  top: "res_stage_3_419_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_419_3"  
  type: "Scale"
  bottom: "res_stage_3_419_3"
  top: "res_stage_3_419_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_419"
  type: "Eltwise"
  bottom: "res_3_418"
  bottom: "res_stage_3_419_3_top"
  top: "res_3_419"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_419_relu"
  type: "ReLU"
  bottom: "res_3_419"
  top: "res_3_419"
}
layer {
  name: "res_stage_3_420_1"
  type: "Convolution"
  bottom: "res_3_419"
  top: "res_stage_3_420_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_420_1"
  type: "BatchNorm"
  bottom: "res_stage_3_420_1"
  top: "res_stage_3_420_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_420_1"  
  type: "Scale"
  bottom: "res_stage_3_420_1"
  top: "res_stage_3_420_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_420_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_420_1_top"
  top: "res_stage_3_420_1_top"
}
layer {
  name: "res_stage_3_420_2"
  type: "Convolution"
  bottom: "res_stage_3_420_1_top"
  top: "res_stage_3_420_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_420_2"
  type: "BatchNorm"
  bottom: "res_stage_3_420_2"
  top: "res_stage_3_420_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_420_2"  
  type: "Scale"
  bottom: "res_stage_3_420_2"
  top: "res_stage_3_420_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_420_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_420_2_top"
  top: "res_stage_3_420_2_top"
}
layer {
  name: "res_stage_3_420_3"
  type: "Convolution"
  bottom: "res_stage_3_420_2_top"
  top: "res_stage_3_420_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_420_3"
  type: "BatchNorm"
  bottom: "res_stage_3_420_3"
  top: "res_stage_3_420_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_420_3"  
  type: "Scale"
  bottom: "res_stage_3_420_3"
  top: "res_stage_3_420_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_420"
  type: "Eltwise"
  bottom: "res_3_419"
  bottom: "res_stage_3_420_3_top"
  top: "res_3_420"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_420_relu"
  type: "ReLU"
  bottom: "res_3_420"
  top: "res_3_420"
}
layer {
  name: "res_stage_3_421_1"
  type: "Convolution"
  bottom: "res_3_420"
  top: "res_stage_3_421_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_421_1"
  type: "BatchNorm"
  bottom: "res_stage_3_421_1"
  top: "res_stage_3_421_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_421_1"  
  type: "Scale"
  bottom: "res_stage_3_421_1"
  top: "res_stage_3_421_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_421_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_421_1_top"
  top: "res_stage_3_421_1_top"
}
layer {
  name: "res_stage_3_421_2"
  type: "Convolution"
  bottom: "res_stage_3_421_1_top"
  top: "res_stage_3_421_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_421_2"
  type: "BatchNorm"
  bottom: "res_stage_3_421_2"
  top: "res_stage_3_421_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_421_2"  
  type: "Scale"
  bottom: "res_stage_3_421_2"
  top: "res_stage_3_421_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_421_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_421_2_top"
  top: "res_stage_3_421_2_top"
}
layer {
  name: "res_stage_3_421_3"
  type: "Convolution"
  bottom: "res_stage_3_421_2_top"
  top: "res_stage_3_421_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_421_3"
  type: "BatchNorm"
  bottom: "res_stage_3_421_3"
  top: "res_stage_3_421_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_421_3"  
  type: "Scale"
  bottom: "res_stage_3_421_3"
  top: "res_stage_3_421_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_421"
  type: "Eltwise"
  bottom: "res_3_420"
  bottom: "res_stage_3_421_3_top"
  top: "res_3_421"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_421_relu"
  type: "ReLU"
  bottom: "res_3_421"
  top: "res_3_421"
}
layer {
  name: "res_stage_3_422_1"
  type: "Convolution"
  bottom: "res_3_421"
  top: "res_stage_3_422_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_422_1"
  type: "BatchNorm"
  bottom: "res_stage_3_422_1"
  top: "res_stage_3_422_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_422_1"  
  type: "Scale"
  bottom: "res_stage_3_422_1"
  top: "res_stage_3_422_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_422_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_422_1_top"
  top: "res_stage_3_422_1_top"
}
layer {
  name: "res_stage_3_422_2"
  type: "Convolution"
  bottom: "res_stage_3_422_1_top"
  top: "res_stage_3_422_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_422_2"
  type: "BatchNorm"
  bottom: "res_stage_3_422_2"
  top: "res_stage_3_422_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_422_2"  
  type: "Scale"
  bottom: "res_stage_3_422_2"
  top: "res_stage_3_422_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_422_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_422_2_top"
  top: "res_stage_3_422_2_top"
}
layer {
  name: "res_stage_3_422_3"
  type: "Convolution"
  bottom: "res_stage_3_422_2_top"
  top: "res_stage_3_422_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_422_3"
  type: "BatchNorm"
  bottom: "res_stage_3_422_3"
  top: "res_stage_3_422_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_422_3"  
  type: "Scale"
  bottom: "res_stage_3_422_3"
  top: "res_stage_3_422_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_422"
  type: "Eltwise"
  bottom: "res_3_421"
  bottom: "res_stage_3_422_3_top"
  top: "res_3_422"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_422_relu"
  type: "ReLU"
  bottom: "res_3_422"
  top: "res_3_422"
}
layer {
  name: "res_stage_3_423_1"
  type: "Convolution"
  bottom: "res_3_422"
  top: "res_stage_3_423_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_423_1"
  type: "BatchNorm"
  bottom: "res_stage_3_423_1"
  top: "res_stage_3_423_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_423_1"  
  type: "Scale"
  bottom: "res_stage_3_423_1"
  top: "res_stage_3_423_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_423_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_423_1_top"
  top: "res_stage_3_423_1_top"
}
layer {
  name: "res_stage_3_423_2"
  type: "Convolution"
  bottom: "res_stage_3_423_1_top"
  top: "res_stage_3_423_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_423_2"
  type: "BatchNorm"
  bottom: "res_stage_3_423_2"
  top: "res_stage_3_423_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_423_2"  
  type: "Scale"
  bottom: "res_stage_3_423_2"
  top: "res_stage_3_423_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_423_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_423_2_top"
  top: "res_stage_3_423_2_top"
}
layer {
  name: "res_stage_3_423_3"
  type: "Convolution"
  bottom: "res_stage_3_423_2_top"
  top: "res_stage_3_423_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_423_3"
  type: "BatchNorm"
  bottom: "res_stage_3_423_3"
  top: "res_stage_3_423_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_423_3"  
  type: "Scale"
  bottom: "res_stage_3_423_3"
  top: "res_stage_3_423_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_423"
  type: "Eltwise"
  bottom: "res_3_422"
  bottom: "res_stage_3_423_3_top"
  top: "res_3_423"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_423_relu"
  type: "ReLU"
  bottom: "res_3_423"
  top: "res_3_423"
}
layer {
  name: "res_stage_3_424_1"
  type: "Convolution"
  bottom: "res_3_423"
  top: "res_stage_3_424_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_424_1"
  type: "BatchNorm"
  bottom: "res_stage_3_424_1"
  top: "res_stage_3_424_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_424_1"  
  type: "Scale"
  bottom: "res_stage_3_424_1"
  top: "res_stage_3_424_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_424_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_424_1_top"
  top: "res_stage_3_424_1_top"
}
layer {
  name: "res_stage_3_424_2"
  type: "Convolution"
  bottom: "res_stage_3_424_1_top"
  top: "res_stage_3_424_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_424_2"
  type: "BatchNorm"
  bottom: "res_stage_3_424_2"
  top: "res_stage_3_424_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_424_2"  
  type: "Scale"
  bottom: "res_stage_3_424_2"
  top: "res_stage_3_424_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_424_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_424_2_top"
  top: "res_stage_3_424_2_top"
}
layer {
  name: "res_stage_3_424_3"
  type: "Convolution"
  bottom: "res_stage_3_424_2_top"
  top: "res_stage_3_424_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_424_3"
  type: "BatchNorm"
  bottom: "res_stage_3_424_3"
  top: "res_stage_3_424_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_424_3"  
  type: "Scale"
  bottom: "res_stage_3_424_3"
  top: "res_stage_3_424_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_424"
  type: "Eltwise"
  bottom: "res_3_423"
  bottom: "res_stage_3_424_3_top"
  top: "res_3_424"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_424_relu"
  type: "ReLU"
  bottom: "res_3_424"
  top: "res_3_424"
}
layer {
  name: "res_stage_3_425_1"
  type: "Convolution"
  bottom: "res_3_424"
  top: "res_stage_3_425_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_425_1"
  type: "BatchNorm"
  bottom: "res_stage_3_425_1"
  top: "res_stage_3_425_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_425_1"  
  type: "Scale"
  bottom: "res_stage_3_425_1"
  top: "res_stage_3_425_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_425_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_425_1_top"
  top: "res_stage_3_425_1_top"
}
layer {
  name: "res_stage_3_425_2"
  type: "Convolution"
  bottom: "res_stage_3_425_1_top"
  top: "res_stage_3_425_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_425_2"
  type: "BatchNorm"
  bottom: "res_stage_3_425_2"
  top: "res_stage_3_425_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_425_2"  
  type: "Scale"
  bottom: "res_stage_3_425_2"
  top: "res_stage_3_425_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_425_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_425_2_top"
  top: "res_stage_3_425_2_top"
}
layer {
  name: "res_stage_3_425_3"
  type: "Convolution"
  bottom: "res_stage_3_425_2_top"
  top: "res_stage_3_425_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_425_3"
  type: "BatchNorm"
  bottom: "res_stage_3_425_3"
  top: "res_stage_3_425_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_425_3"  
  type: "Scale"
  bottom: "res_stage_3_425_3"
  top: "res_stage_3_425_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_425"
  type: "Eltwise"
  bottom: "res_3_424"
  bottom: "res_stage_3_425_3_top"
  top: "res_3_425"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_425_relu"
  type: "ReLU"
  bottom: "res_3_425"
  top: "res_3_425"
}
layer {
  name: "res_stage_3_426_1"
  type: "Convolution"
  bottom: "res_3_425"
  top: "res_stage_3_426_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_426_1"
  type: "BatchNorm"
  bottom: "res_stage_3_426_1"
  top: "res_stage_3_426_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_426_1"  
  type: "Scale"
  bottom: "res_stage_3_426_1"
  top: "res_stage_3_426_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_426_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_426_1_top"
  top: "res_stage_3_426_1_top"
}
layer {
  name: "res_stage_3_426_2"
  type: "Convolution"
  bottom: "res_stage_3_426_1_top"
  top: "res_stage_3_426_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_426_2"
  type: "BatchNorm"
  bottom: "res_stage_3_426_2"
  top: "res_stage_3_426_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_426_2"  
  type: "Scale"
  bottom: "res_stage_3_426_2"
  top: "res_stage_3_426_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_426_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_426_2_top"
  top: "res_stage_3_426_2_top"
}
layer {
  name: "res_stage_3_426_3"
  type: "Convolution"
  bottom: "res_stage_3_426_2_top"
  top: "res_stage_3_426_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_426_3"
  type: "BatchNorm"
  bottom: "res_stage_3_426_3"
  top: "res_stage_3_426_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_426_3"  
  type: "Scale"
  bottom: "res_stage_3_426_3"
  top: "res_stage_3_426_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_426"
  type: "Eltwise"
  bottom: "res_3_425"
  bottom: "res_stage_3_426_3_top"
  top: "res_3_426"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_426_relu"
  type: "ReLU"
  bottom: "res_3_426"
  top: "res_3_426"
}
layer {
  name: "res_stage_3_427_1"
  type: "Convolution"
  bottom: "res_3_426"
  top: "res_stage_3_427_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_427_1"
  type: "BatchNorm"
  bottom: "res_stage_3_427_1"
  top: "res_stage_3_427_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_427_1"  
  type: "Scale"
  bottom: "res_stage_3_427_1"
  top: "res_stage_3_427_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_427_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_427_1_top"
  top: "res_stage_3_427_1_top"
}
layer {
  name: "res_stage_3_427_2"
  type: "Convolution"
  bottom: "res_stage_3_427_1_top"
  top: "res_stage_3_427_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_427_2"
  type: "BatchNorm"
  bottom: "res_stage_3_427_2"
  top: "res_stage_3_427_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_427_2"  
  type: "Scale"
  bottom: "res_stage_3_427_2"
  top: "res_stage_3_427_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_427_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_427_2_top"
  top: "res_stage_3_427_2_top"
}
layer {
  name: "res_stage_3_427_3"
  type: "Convolution"
  bottom: "res_stage_3_427_2_top"
  top: "res_stage_3_427_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_427_3"
  type: "BatchNorm"
  bottom: "res_stage_3_427_3"
  top: "res_stage_3_427_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_427_3"  
  type: "Scale"
  bottom: "res_stage_3_427_3"
  top: "res_stage_3_427_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_427"
  type: "Eltwise"
  bottom: "res_3_426"
  bottom: "res_stage_3_427_3_top"
  top: "res_3_427"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_427_relu"
  type: "ReLU"
  bottom: "res_3_427"
  top: "res_3_427"
}
layer {
  name: "res_stage_3_428_1"
  type: "Convolution"
  bottom: "res_3_427"
  top: "res_stage_3_428_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_428_1"
  type: "BatchNorm"
  bottom: "res_stage_3_428_1"
  top: "res_stage_3_428_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_428_1"  
  type: "Scale"
  bottom: "res_stage_3_428_1"
  top: "res_stage_3_428_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_428_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_428_1_top"
  top: "res_stage_3_428_1_top"
}
layer {
  name: "res_stage_3_428_2"
  type: "Convolution"
  bottom: "res_stage_3_428_1_top"
  top: "res_stage_3_428_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_428_2"
  type: "BatchNorm"
  bottom: "res_stage_3_428_2"
  top: "res_stage_3_428_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_428_2"  
  type: "Scale"
  bottom: "res_stage_3_428_2"
  top: "res_stage_3_428_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_428_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_428_2_top"
  top: "res_stage_3_428_2_top"
}
layer {
  name: "res_stage_3_428_3"
  type: "Convolution"
  bottom: "res_stage_3_428_2_top"
  top: "res_stage_3_428_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_428_3"
  type: "BatchNorm"
  bottom: "res_stage_3_428_3"
  top: "res_stage_3_428_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_428_3"  
  type: "Scale"
  bottom: "res_stage_3_428_3"
  top: "res_stage_3_428_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_428"
  type: "Eltwise"
  bottom: "res_3_427"
  bottom: "res_stage_3_428_3_top"
  top: "res_3_428"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_428_relu"
  type: "ReLU"
  bottom: "res_3_428"
  top: "res_3_428"
}
layer {
  name: "res_stage_3_429_1"
  type: "Convolution"
  bottom: "res_3_428"
  top: "res_stage_3_429_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_429_1"
  type: "BatchNorm"
  bottom: "res_stage_3_429_1"
  top: "res_stage_3_429_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_429_1"  
  type: "Scale"
  bottom: "res_stage_3_429_1"
  top: "res_stage_3_429_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_429_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_429_1_top"
  top: "res_stage_3_429_1_top"
}
layer {
  name: "res_stage_3_429_2"
  type: "Convolution"
  bottom: "res_stage_3_429_1_top"
  top: "res_stage_3_429_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_429_2"
  type: "BatchNorm"
  bottom: "res_stage_3_429_2"
  top: "res_stage_3_429_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_429_2"  
  type: "Scale"
  bottom: "res_stage_3_429_2"
  top: "res_stage_3_429_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_429_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_429_2_top"
  top: "res_stage_3_429_2_top"
}
layer {
  name: "res_stage_3_429_3"
  type: "Convolution"
  bottom: "res_stage_3_429_2_top"
  top: "res_stage_3_429_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_429_3"
  type: "BatchNorm"
  bottom: "res_stage_3_429_3"
  top: "res_stage_3_429_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_429_3"  
  type: "Scale"
  bottom: "res_stage_3_429_3"
  top: "res_stage_3_429_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_429"
  type: "Eltwise"
  bottom: "res_3_428"
  bottom: "res_stage_3_429_3_top"
  top: "res_3_429"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_429_relu"
  type: "ReLU"
  bottom: "res_3_429"
  top: "res_3_429"
}
layer {
  name: "res_stage_3_430_1"
  type: "Convolution"
  bottom: "res_3_429"
  top: "res_stage_3_430_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_430_1"
  type: "BatchNorm"
  bottom: "res_stage_3_430_1"
  top: "res_stage_3_430_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_430_1"  
  type: "Scale"
  bottom: "res_stage_3_430_1"
  top: "res_stage_3_430_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_430_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_430_1_top"
  top: "res_stage_3_430_1_top"
}
layer {
  name: "res_stage_3_430_2"
  type: "Convolution"
  bottom: "res_stage_3_430_1_top"
  top: "res_stage_3_430_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_430_2"
  type: "BatchNorm"
  bottom: "res_stage_3_430_2"
  top: "res_stage_3_430_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_430_2"  
  type: "Scale"
  bottom: "res_stage_3_430_2"
  top: "res_stage_3_430_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_430_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_430_2_top"
  top: "res_stage_3_430_2_top"
}
layer {
  name: "res_stage_3_430_3"
  type: "Convolution"
  bottom: "res_stage_3_430_2_top"
  top: "res_stage_3_430_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_430_3"
  type: "BatchNorm"
  bottom: "res_stage_3_430_3"
  top: "res_stage_3_430_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_430_3"  
  type: "Scale"
  bottom: "res_stage_3_430_3"
  top: "res_stage_3_430_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_430"
  type: "Eltwise"
  bottom: "res_3_429"
  bottom: "res_stage_3_430_3_top"
  top: "res_3_430"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_430_relu"
  type: "ReLU"
  bottom: "res_3_430"
  top: "res_3_430"
}
layer {
  name: "res_stage_3_431_1"
  type: "Convolution"
  bottom: "res_3_430"
  top: "res_stage_3_431_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_431_1"
  type: "BatchNorm"
  bottom: "res_stage_3_431_1"
  top: "res_stage_3_431_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_431_1"  
  type: "Scale"
  bottom: "res_stage_3_431_1"
  top: "res_stage_3_431_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_431_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_431_1_top"
  top: "res_stage_3_431_1_top"
}
layer {
  name: "res_stage_3_431_2"
  type: "Convolution"
  bottom: "res_stage_3_431_1_top"
  top: "res_stage_3_431_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_431_2"
  type: "BatchNorm"
  bottom: "res_stage_3_431_2"
  top: "res_stage_3_431_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_431_2"  
  type: "Scale"
  bottom: "res_stage_3_431_2"
  top: "res_stage_3_431_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_431_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_431_2_top"
  top: "res_stage_3_431_2_top"
}
layer {
  name: "res_stage_3_431_3"
  type: "Convolution"
  bottom: "res_stage_3_431_2_top"
  top: "res_stage_3_431_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_431_3"
  type: "BatchNorm"
  bottom: "res_stage_3_431_3"
  top: "res_stage_3_431_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_431_3"  
  type: "Scale"
  bottom: "res_stage_3_431_3"
  top: "res_stage_3_431_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_431"
  type: "Eltwise"
  bottom: "res_3_430"
  bottom: "res_stage_3_431_3_top"
  top: "res_3_431"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_431_relu"
  type: "ReLU"
  bottom: "res_3_431"
  top: "res_3_431"
}
layer {
  name: "res_stage_3_432_1"
  type: "Convolution"
  bottom: "res_3_431"
  top: "res_stage_3_432_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_432_1"
  type: "BatchNorm"
  bottom: "res_stage_3_432_1"
  top: "res_stage_3_432_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_432_1"  
  type: "Scale"
  bottom: "res_stage_3_432_1"
  top: "res_stage_3_432_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_432_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_432_1_top"
  top: "res_stage_3_432_1_top"
}
layer {
  name: "res_stage_3_432_2"
  type: "Convolution"
  bottom: "res_stage_3_432_1_top"
  top: "res_stage_3_432_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_432_2"
  type: "BatchNorm"
  bottom: "res_stage_3_432_2"
  top: "res_stage_3_432_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_432_2"  
  type: "Scale"
  bottom: "res_stage_3_432_2"
  top: "res_stage_3_432_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_432_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_432_2_top"
  top: "res_stage_3_432_2_top"
}
layer {
  name: "res_stage_3_432_3"
  type: "Convolution"
  bottom: "res_stage_3_432_2_top"
  top: "res_stage_3_432_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_432_3"
  type: "BatchNorm"
  bottom: "res_stage_3_432_3"
  top: "res_stage_3_432_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_432_3"  
  type: "Scale"
  bottom: "res_stage_3_432_3"
  top: "res_stage_3_432_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_432"
  type: "Eltwise"
  bottom: "res_3_431"
  bottom: "res_stage_3_432_3_top"
  top: "res_3_432"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_432_relu"
  type: "ReLU"
  bottom: "res_3_432"
  top: "res_3_432"
}
layer {
  name: "res_stage_3_433_1"
  type: "Convolution"
  bottom: "res_3_432"
  top: "res_stage_3_433_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_433_1"
  type: "BatchNorm"
  bottom: "res_stage_3_433_1"
  top: "res_stage_3_433_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_433_1"  
  type: "Scale"
  bottom: "res_stage_3_433_1"
  top: "res_stage_3_433_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_433_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_433_1_top"
  top: "res_stage_3_433_1_top"
}
layer {
  name: "res_stage_3_433_2"
  type: "Convolution"
  bottom: "res_stage_3_433_1_top"
  top: "res_stage_3_433_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_433_2"
  type: "BatchNorm"
  bottom: "res_stage_3_433_2"
  top: "res_stage_3_433_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_433_2"  
  type: "Scale"
  bottom: "res_stage_3_433_2"
  top: "res_stage_3_433_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_433_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_433_2_top"
  top: "res_stage_3_433_2_top"
}
layer {
  name: "res_stage_3_433_3"
  type: "Convolution"
  bottom: "res_stage_3_433_2_top"
  top: "res_stage_3_433_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_433_3"
  type: "BatchNorm"
  bottom: "res_stage_3_433_3"
  top: "res_stage_3_433_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_433_3"  
  type: "Scale"
  bottom: "res_stage_3_433_3"
  top: "res_stage_3_433_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_433"
  type: "Eltwise"
  bottom: "res_3_432"
  bottom: "res_stage_3_433_3_top"
  top: "res_3_433"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_433_relu"
  type: "ReLU"
  bottom: "res_3_433"
  top: "res_3_433"
}
layer {
  name: "res_stage_3_434_1"
  type: "Convolution"
  bottom: "res_3_433"
  top: "res_stage_3_434_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_434_1"
  type: "BatchNorm"
  bottom: "res_stage_3_434_1"
  top: "res_stage_3_434_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_434_1"  
  type: "Scale"
  bottom: "res_stage_3_434_1"
  top: "res_stage_3_434_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_434_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_434_1_top"
  top: "res_stage_3_434_1_top"
}
layer {
  name: "res_stage_3_434_2"
  type: "Convolution"
  bottom: "res_stage_3_434_1_top"
  top: "res_stage_3_434_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_434_2"
  type: "BatchNorm"
  bottom: "res_stage_3_434_2"
  top: "res_stage_3_434_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_434_2"  
  type: "Scale"
  bottom: "res_stage_3_434_2"
  top: "res_stage_3_434_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_434_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_434_2_top"
  top: "res_stage_3_434_2_top"
}
layer {
  name: "res_stage_3_434_3"
  type: "Convolution"
  bottom: "res_stage_3_434_2_top"
  top: "res_stage_3_434_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_434_3"
  type: "BatchNorm"
  bottom: "res_stage_3_434_3"
  top: "res_stage_3_434_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_434_3"  
  type: "Scale"
  bottom: "res_stage_3_434_3"
  top: "res_stage_3_434_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_434"
  type: "Eltwise"
  bottom: "res_3_433"
  bottom: "res_stage_3_434_3_top"
  top: "res_3_434"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_434_relu"
  type: "ReLU"
  bottom: "res_3_434"
  top: "res_3_434"
}
layer {
  name: "res_stage_3_435_1"
  type: "Convolution"
  bottom: "res_3_434"
  top: "res_stage_3_435_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_435_1"
  type: "BatchNorm"
  bottom: "res_stage_3_435_1"
  top: "res_stage_3_435_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_435_1"  
  type: "Scale"
  bottom: "res_stage_3_435_1"
  top: "res_stage_3_435_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_435_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_435_1_top"
  top: "res_stage_3_435_1_top"
}
layer {
  name: "res_stage_3_435_2"
  type: "Convolution"
  bottom: "res_stage_3_435_1_top"
  top: "res_stage_3_435_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_435_2"
  type: "BatchNorm"
  bottom: "res_stage_3_435_2"
  top: "res_stage_3_435_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_435_2"  
  type: "Scale"
  bottom: "res_stage_3_435_2"
  top: "res_stage_3_435_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_435_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_435_2_top"
  top: "res_stage_3_435_2_top"
}
layer {
  name: "res_stage_3_435_3"
  type: "Convolution"
  bottom: "res_stage_3_435_2_top"
  top: "res_stage_3_435_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_435_3"
  type: "BatchNorm"
  bottom: "res_stage_3_435_3"
  top: "res_stage_3_435_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_435_3"  
  type: "Scale"
  bottom: "res_stage_3_435_3"
  top: "res_stage_3_435_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_435"
  type: "Eltwise"
  bottom: "res_3_434"
  bottom: "res_stage_3_435_3_top"
  top: "res_3_435"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_435_relu"
  type: "ReLU"
  bottom: "res_3_435"
  top: "res_3_435"
}
layer {
  name: "res_stage_3_436_1"
  type: "Convolution"
  bottom: "res_3_435"
  top: "res_stage_3_436_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_436_1"
  type: "BatchNorm"
  bottom: "res_stage_3_436_1"
  top: "res_stage_3_436_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_436_1"  
  type: "Scale"
  bottom: "res_stage_3_436_1"
  top: "res_stage_3_436_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_436_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_436_1_top"
  top: "res_stage_3_436_1_top"
}
layer {
  name: "res_stage_3_436_2"
  type: "Convolution"
  bottom: "res_stage_3_436_1_top"
  top: "res_stage_3_436_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_436_2"
  type: "BatchNorm"
  bottom: "res_stage_3_436_2"
  top: "res_stage_3_436_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_436_2"  
  type: "Scale"
  bottom: "res_stage_3_436_2"
  top: "res_stage_3_436_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_436_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_436_2_top"
  top: "res_stage_3_436_2_top"
}
layer {
  name: "res_stage_3_436_3"
  type: "Convolution"
  bottom: "res_stage_3_436_2_top"
  top: "res_stage_3_436_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_436_3"
  type: "BatchNorm"
  bottom: "res_stage_3_436_3"
  top: "res_stage_3_436_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_436_3"  
  type: "Scale"
  bottom: "res_stage_3_436_3"
  top: "res_stage_3_436_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_436"
  type: "Eltwise"
  bottom: "res_3_435"
  bottom: "res_stage_3_436_3_top"
  top: "res_3_436"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_436_relu"
  type: "ReLU"
  bottom: "res_3_436"
  top: "res_3_436"
}
layer {
  name: "res_stage_3_437_1"
  type: "Convolution"
  bottom: "res_3_436"
  top: "res_stage_3_437_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_437_1"
  type: "BatchNorm"
  bottom: "res_stage_3_437_1"
  top: "res_stage_3_437_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_437_1"  
  type: "Scale"
  bottom: "res_stage_3_437_1"
  top: "res_stage_3_437_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_437_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_437_1_top"
  top: "res_stage_3_437_1_top"
}
layer {
  name: "res_stage_3_437_2"
  type: "Convolution"
  bottom: "res_stage_3_437_1_top"
  top: "res_stage_3_437_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_437_2"
  type: "BatchNorm"
  bottom: "res_stage_3_437_2"
  top: "res_stage_3_437_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_437_2"  
  type: "Scale"
  bottom: "res_stage_3_437_2"
  top: "res_stage_3_437_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_437_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_437_2_top"
  top: "res_stage_3_437_2_top"
}
layer {
  name: "res_stage_3_437_3"
  type: "Convolution"
  bottom: "res_stage_3_437_2_top"
  top: "res_stage_3_437_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_437_3"
  type: "BatchNorm"
  bottom: "res_stage_3_437_3"
  top: "res_stage_3_437_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_437_3"  
  type: "Scale"
  bottom: "res_stage_3_437_3"
  top: "res_stage_3_437_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_437"
  type: "Eltwise"
  bottom: "res_3_436"
  bottom: "res_stage_3_437_3_top"
  top: "res_3_437"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_437_relu"
  type: "ReLU"
  bottom: "res_3_437"
  top: "res_3_437"
}
layer {
  name: "res_stage_3_438_1"
  type: "Convolution"
  bottom: "res_3_437"
  top: "res_stage_3_438_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_438_1"
  type: "BatchNorm"
  bottom: "res_stage_3_438_1"
  top: "res_stage_3_438_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_438_1"  
  type: "Scale"
  bottom: "res_stage_3_438_1"
  top: "res_stage_3_438_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_438_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_438_1_top"
  top: "res_stage_3_438_1_top"
}
layer {
  name: "res_stage_3_438_2"
  type: "Convolution"
  bottom: "res_stage_3_438_1_top"
  top: "res_stage_3_438_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_438_2"
  type: "BatchNorm"
  bottom: "res_stage_3_438_2"
  top: "res_stage_3_438_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_438_2"  
  type: "Scale"
  bottom: "res_stage_3_438_2"
  top: "res_stage_3_438_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_438_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_438_2_top"
  top: "res_stage_3_438_2_top"
}
layer {
  name: "res_stage_3_438_3"
  type: "Convolution"
  bottom: "res_stage_3_438_2_top"
  top: "res_stage_3_438_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_438_3"
  type: "BatchNorm"
  bottom: "res_stage_3_438_3"
  top: "res_stage_3_438_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_438_3"  
  type: "Scale"
  bottom: "res_stage_3_438_3"
  top: "res_stage_3_438_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_438"
  type: "Eltwise"
  bottom: "res_3_437"
  bottom: "res_stage_3_438_3_top"
  top: "res_3_438"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_438_relu"
  type: "ReLU"
  bottom: "res_3_438"
  top: "res_3_438"
}
layer {
  name: "res_stage_3_439_1"
  type: "Convolution"
  bottom: "res_3_438"
  top: "res_stage_3_439_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_439_1"
  type: "BatchNorm"
  bottom: "res_stage_3_439_1"
  top: "res_stage_3_439_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_439_1"  
  type: "Scale"
  bottom: "res_stage_3_439_1"
  top: "res_stage_3_439_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_439_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_439_1_top"
  top: "res_stage_3_439_1_top"
}
layer {
  name: "res_stage_3_439_2"
  type: "Convolution"
  bottom: "res_stage_3_439_1_top"
  top: "res_stage_3_439_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_439_2"
  type: "BatchNorm"
  bottom: "res_stage_3_439_2"
  top: "res_stage_3_439_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_439_2"  
  type: "Scale"
  bottom: "res_stage_3_439_2"
  top: "res_stage_3_439_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_439_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_439_2_top"
  top: "res_stage_3_439_2_top"
}
layer {
  name: "res_stage_3_439_3"
  type: "Convolution"
  bottom: "res_stage_3_439_2_top"
  top: "res_stage_3_439_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_439_3"
  type: "BatchNorm"
  bottom: "res_stage_3_439_3"
  top: "res_stage_3_439_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_439_3"  
  type: "Scale"
  bottom: "res_stage_3_439_3"
  top: "res_stage_3_439_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_439"
  type: "Eltwise"
  bottom: "res_3_438"
  bottom: "res_stage_3_439_3_top"
  top: "res_3_439"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_439_relu"
  type: "ReLU"
  bottom: "res_3_439"
  top: "res_3_439"
}
layer {
  name: "res_stage_3_440_1"
  type: "Convolution"
  bottom: "res_3_439"
  top: "res_stage_3_440_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_440_1"
  type: "BatchNorm"
  bottom: "res_stage_3_440_1"
  top: "res_stage_3_440_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_440_1"  
  type: "Scale"
  bottom: "res_stage_3_440_1"
  top: "res_stage_3_440_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_440_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_440_1_top"
  top: "res_stage_3_440_1_top"
}
layer {
  name: "res_stage_3_440_2"
  type: "Convolution"
  bottom: "res_stage_3_440_1_top"
  top: "res_stage_3_440_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_440_2"
  type: "BatchNorm"
  bottom: "res_stage_3_440_2"
  top: "res_stage_3_440_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_440_2"  
  type: "Scale"
  bottom: "res_stage_3_440_2"
  top: "res_stage_3_440_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_440_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_440_2_top"
  top: "res_stage_3_440_2_top"
}
layer {
  name: "res_stage_3_440_3"
  type: "Convolution"
  bottom: "res_stage_3_440_2_top"
  top: "res_stage_3_440_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_440_3"
  type: "BatchNorm"
  bottom: "res_stage_3_440_3"
  top: "res_stage_3_440_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_440_3"  
  type: "Scale"
  bottom: "res_stage_3_440_3"
  top: "res_stage_3_440_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_440"
  type: "Eltwise"
  bottom: "res_3_439"
  bottom: "res_stage_3_440_3_top"
  top: "res_3_440"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_440_relu"
  type: "ReLU"
  bottom: "res_3_440"
  top: "res_3_440"
}
layer {
  name: "res_stage_3_441_1"
  type: "Convolution"
  bottom: "res_3_440"
  top: "res_stage_3_441_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_441_1"
  type: "BatchNorm"
  bottom: "res_stage_3_441_1"
  top: "res_stage_3_441_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_441_1"  
  type: "Scale"
  bottom: "res_stage_3_441_1"
  top: "res_stage_3_441_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_441_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_441_1_top"
  top: "res_stage_3_441_1_top"
}
layer {
  name: "res_stage_3_441_2"
  type: "Convolution"
  bottom: "res_stage_3_441_1_top"
  top: "res_stage_3_441_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_441_2"
  type: "BatchNorm"
  bottom: "res_stage_3_441_2"
  top: "res_stage_3_441_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_441_2"  
  type: "Scale"
  bottom: "res_stage_3_441_2"
  top: "res_stage_3_441_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_441_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_441_2_top"
  top: "res_stage_3_441_2_top"
}
layer {
  name: "res_stage_3_441_3"
  type: "Convolution"
  bottom: "res_stage_3_441_2_top"
  top: "res_stage_3_441_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_441_3"
  type: "BatchNorm"
  bottom: "res_stage_3_441_3"
  top: "res_stage_3_441_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_441_3"  
  type: "Scale"
  bottom: "res_stage_3_441_3"
  top: "res_stage_3_441_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_441"
  type: "Eltwise"
  bottom: "res_3_440"
  bottom: "res_stage_3_441_3_top"
  top: "res_3_441"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_441_relu"
  type: "ReLU"
  bottom: "res_3_441"
  top: "res_3_441"
}
layer {
  name: "res_stage_3_442_1"
  type: "Convolution"
  bottom: "res_3_441"
  top: "res_stage_3_442_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_442_1"
  type: "BatchNorm"
  bottom: "res_stage_3_442_1"
  top: "res_stage_3_442_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_442_1"  
  type: "Scale"
  bottom: "res_stage_3_442_1"
  top: "res_stage_3_442_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_442_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_442_1_top"
  top: "res_stage_3_442_1_top"
}
layer {
  name: "res_stage_3_442_2"
  type: "Convolution"
  bottom: "res_stage_3_442_1_top"
  top: "res_stage_3_442_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_442_2"
  type: "BatchNorm"
  bottom: "res_stage_3_442_2"
  top: "res_stage_3_442_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_442_2"  
  type: "Scale"
  bottom: "res_stage_3_442_2"
  top: "res_stage_3_442_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_442_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_442_2_top"
  top: "res_stage_3_442_2_top"
}
layer {
  name: "res_stage_3_442_3"
  type: "Convolution"
  bottom: "res_stage_3_442_2_top"
  top: "res_stage_3_442_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_442_3"
  type: "BatchNorm"
  bottom: "res_stage_3_442_3"
  top: "res_stage_3_442_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_442_3"  
  type: "Scale"
  bottom: "res_stage_3_442_3"
  top: "res_stage_3_442_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_442"
  type: "Eltwise"
  bottom: "res_3_441"
  bottom: "res_stage_3_442_3_top"
  top: "res_3_442"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_442_relu"
  type: "ReLU"
  bottom: "res_3_442"
  top: "res_3_442"
}
layer {
  name: "res_stage_3_443_1"
  type: "Convolution"
  bottom: "res_3_442"
  top: "res_stage_3_443_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_443_1"
  type: "BatchNorm"
  bottom: "res_stage_3_443_1"
  top: "res_stage_3_443_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_443_1"  
  type: "Scale"
  bottom: "res_stage_3_443_1"
  top: "res_stage_3_443_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_443_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_443_1_top"
  top: "res_stage_3_443_1_top"
}
layer {
  name: "res_stage_3_443_2"
  type: "Convolution"
  bottom: "res_stage_3_443_1_top"
  top: "res_stage_3_443_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_443_2"
  type: "BatchNorm"
  bottom: "res_stage_3_443_2"
  top: "res_stage_3_443_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_443_2"  
  type: "Scale"
  bottom: "res_stage_3_443_2"
  top: "res_stage_3_443_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_443_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_443_2_top"
  top: "res_stage_3_443_2_top"
}
layer {
  name: "res_stage_3_443_3"
  type: "Convolution"
  bottom: "res_stage_3_443_2_top"
  top: "res_stage_3_443_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_443_3"
  type: "BatchNorm"
  bottom: "res_stage_3_443_3"
  top: "res_stage_3_443_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_443_3"  
  type: "Scale"
  bottom: "res_stage_3_443_3"
  top: "res_stage_3_443_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_443"
  type: "Eltwise"
  bottom: "res_3_442"
  bottom: "res_stage_3_443_3_top"
  top: "res_3_443"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_443_relu"
  type: "ReLU"
  bottom: "res_3_443"
  top: "res_3_443"
}
layer {
  name: "res_stage_3_444_1"
  type: "Convolution"
  bottom: "res_3_443"
  top: "res_stage_3_444_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_444_1"
  type: "BatchNorm"
  bottom: "res_stage_3_444_1"
  top: "res_stage_3_444_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_444_1"  
  type: "Scale"
  bottom: "res_stage_3_444_1"
  top: "res_stage_3_444_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_444_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_444_1_top"
  top: "res_stage_3_444_1_top"
}
layer {
  name: "res_stage_3_444_2"
  type: "Convolution"
  bottom: "res_stage_3_444_1_top"
  top: "res_stage_3_444_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_444_2"
  type: "BatchNorm"
  bottom: "res_stage_3_444_2"
  top: "res_stage_3_444_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_444_2"  
  type: "Scale"
  bottom: "res_stage_3_444_2"
  top: "res_stage_3_444_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_444_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_444_2_top"
  top: "res_stage_3_444_2_top"
}
layer {
  name: "res_stage_3_444_3"
  type: "Convolution"
  bottom: "res_stage_3_444_2_top"
  top: "res_stage_3_444_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_444_3"
  type: "BatchNorm"
  bottom: "res_stage_3_444_3"
  top: "res_stage_3_444_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_444_3"  
  type: "Scale"
  bottom: "res_stage_3_444_3"
  top: "res_stage_3_444_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_444"
  type: "Eltwise"
  bottom: "res_3_443"
  bottom: "res_stage_3_444_3_top"
  top: "res_3_444"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_444_relu"
  type: "ReLU"
  bottom: "res_3_444"
  top: "res_3_444"
}
layer {
  name: "res_stage_3_445_1"
  type: "Convolution"
  bottom: "res_3_444"
  top: "res_stage_3_445_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_445_1"
  type: "BatchNorm"
  bottom: "res_stage_3_445_1"
  top: "res_stage_3_445_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_445_1"  
  type: "Scale"
  bottom: "res_stage_3_445_1"
  top: "res_stage_3_445_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_445_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_445_1_top"
  top: "res_stage_3_445_1_top"
}
layer {
  name: "res_stage_3_445_2"
  type: "Convolution"
  bottom: "res_stage_3_445_1_top"
  top: "res_stage_3_445_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_445_2"
  type: "BatchNorm"
  bottom: "res_stage_3_445_2"
  top: "res_stage_3_445_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_445_2"  
  type: "Scale"
  bottom: "res_stage_3_445_2"
  top: "res_stage_3_445_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_445_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_445_2_top"
  top: "res_stage_3_445_2_top"
}
layer {
  name: "res_stage_3_445_3"
  type: "Convolution"
  bottom: "res_stage_3_445_2_top"
  top: "res_stage_3_445_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_445_3"
  type: "BatchNorm"
  bottom: "res_stage_3_445_3"
  top: "res_stage_3_445_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_445_3"  
  type: "Scale"
  bottom: "res_stage_3_445_3"
  top: "res_stage_3_445_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_445"
  type: "Eltwise"
  bottom: "res_3_444"
  bottom: "res_stage_3_445_3_top"
  top: "res_3_445"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_445_relu"
  type: "ReLU"
  bottom: "res_3_445"
  top: "res_3_445"
}
layer {
  name: "res_stage_3_446_1"
  type: "Convolution"
  bottom: "res_3_445"
  top: "res_stage_3_446_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_446_1"
  type: "BatchNorm"
  bottom: "res_stage_3_446_1"
  top: "res_stage_3_446_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_446_1"  
  type: "Scale"
  bottom: "res_stage_3_446_1"
  top: "res_stage_3_446_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_446_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_446_1_top"
  top: "res_stage_3_446_1_top"
}
layer {
  name: "res_stage_3_446_2"
  type: "Convolution"
  bottom: "res_stage_3_446_1_top"
  top: "res_stage_3_446_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_446_2"
  type: "BatchNorm"
  bottom: "res_stage_3_446_2"
  top: "res_stage_3_446_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_446_2"  
  type: "Scale"
  bottom: "res_stage_3_446_2"
  top: "res_stage_3_446_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_446_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_446_2_top"
  top: "res_stage_3_446_2_top"
}
layer {
  name: "res_stage_3_446_3"
  type: "Convolution"
  bottom: "res_stage_3_446_2_top"
  top: "res_stage_3_446_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_446_3"
  type: "BatchNorm"
  bottom: "res_stage_3_446_3"
  top: "res_stage_3_446_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_446_3"  
  type: "Scale"
  bottom: "res_stage_3_446_3"
  top: "res_stage_3_446_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_446"
  type: "Eltwise"
  bottom: "res_3_445"
  bottom: "res_stage_3_446_3_top"
  top: "res_3_446"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_446_relu"
  type: "ReLU"
  bottom: "res_3_446"
  top: "res_3_446"
}
layer {
  name: "res_stage_3_447_1"
  type: "Convolution"
  bottom: "res_3_446"
  top: "res_stage_3_447_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_447_1"
  type: "BatchNorm"
  bottom: "res_stage_3_447_1"
  top: "res_stage_3_447_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_447_1"  
  type: "Scale"
  bottom: "res_stage_3_447_1"
  top: "res_stage_3_447_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_447_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_447_1_top"
  top: "res_stage_3_447_1_top"
}
layer {
  name: "res_stage_3_447_2"
  type: "Convolution"
  bottom: "res_stage_3_447_1_top"
  top: "res_stage_3_447_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_447_2"
  type: "BatchNorm"
  bottom: "res_stage_3_447_2"
  top: "res_stage_3_447_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_447_2"  
  type: "Scale"
  bottom: "res_stage_3_447_2"
  top: "res_stage_3_447_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_447_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_447_2_top"
  top: "res_stage_3_447_2_top"
}
layer {
  name: "res_stage_3_447_3"
  type: "Convolution"
  bottom: "res_stage_3_447_2_top"
  top: "res_stage_3_447_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_447_3"
  type: "BatchNorm"
  bottom: "res_stage_3_447_3"
  top: "res_stage_3_447_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_447_3"  
  type: "Scale"
  bottom: "res_stage_3_447_3"
  top: "res_stage_3_447_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_447"
  type: "Eltwise"
  bottom: "res_3_446"
  bottom: "res_stage_3_447_3_top"
  top: "res_3_447"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_447_relu"
  type: "ReLU"
  bottom: "res_3_447"
  top: "res_3_447"
}
layer {
  name: "res_stage_3_448_1"
  type: "Convolution"
  bottom: "res_3_447"
  top: "res_stage_3_448_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_448_1"
  type: "BatchNorm"
  bottom: "res_stage_3_448_1"
  top: "res_stage_3_448_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_448_1"  
  type: "Scale"
  bottom: "res_stage_3_448_1"
  top: "res_stage_3_448_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_448_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_448_1_top"
  top: "res_stage_3_448_1_top"
}
layer {
  name: "res_stage_3_448_2"
  type: "Convolution"
  bottom: "res_stage_3_448_1_top"
  top: "res_stage_3_448_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_448_2"
  type: "BatchNorm"
  bottom: "res_stage_3_448_2"
  top: "res_stage_3_448_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_448_2"  
  type: "Scale"
  bottom: "res_stage_3_448_2"
  top: "res_stage_3_448_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_448_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_448_2_top"
  top: "res_stage_3_448_2_top"
}
layer {
  name: "res_stage_3_448_3"
  type: "Convolution"
  bottom: "res_stage_3_448_2_top"
  top: "res_stage_3_448_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_448_3"
  type: "BatchNorm"
  bottom: "res_stage_3_448_3"
  top: "res_stage_3_448_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_448_3"  
  type: "Scale"
  bottom: "res_stage_3_448_3"
  top: "res_stage_3_448_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_448"
  type: "Eltwise"
  bottom: "res_3_447"
  bottom: "res_stage_3_448_3_top"
  top: "res_3_448"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_448_relu"
  type: "ReLU"
  bottom: "res_3_448"
  top: "res_3_448"
}
layer {
  name: "res_stage_3_449_1"
  type: "Convolution"
  bottom: "res_3_448"
  top: "res_stage_3_449_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_449_1"
  type: "BatchNorm"
  bottom: "res_stage_3_449_1"
  top: "res_stage_3_449_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_449_1"  
  type: "Scale"
  bottom: "res_stage_3_449_1"
  top: "res_stage_3_449_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_449_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_449_1_top"
  top: "res_stage_3_449_1_top"
}
layer {
  name: "res_stage_3_449_2"
  type: "Convolution"
  bottom: "res_stage_3_449_1_top"
  top: "res_stage_3_449_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_449_2"
  type: "BatchNorm"
  bottom: "res_stage_3_449_2"
  top: "res_stage_3_449_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_449_2"  
  type: "Scale"
  bottom: "res_stage_3_449_2"
  top: "res_stage_3_449_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_449_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_449_2_top"
  top: "res_stage_3_449_2_top"
}
layer {
  name: "res_stage_3_449_3"
  type: "Convolution"
  bottom: "res_stage_3_449_2_top"
  top: "res_stage_3_449_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_449_3"
  type: "BatchNorm"
  bottom: "res_stage_3_449_3"
  top: "res_stage_3_449_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_449_3"  
  type: "Scale"
  bottom: "res_stage_3_449_3"
  top: "res_stage_3_449_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_449"
  type: "Eltwise"
  bottom: "res_3_448"
  bottom: "res_stage_3_449_3_top"
  top: "res_3_449"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_449_relu"
  type: "ReLU"
  bottom: "res_3_449"
  top: "res_3_449"
}
layer {
  name: "res_stage_3_450_1"
  type: "Convolution"
  bottom: "res_3_449"
  top: "res_stage_3_450_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_450_1"
  type: "BatchNorm"
  bottom: "res_stage_3_450_1"
  top: "res_stage_3_450_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_450_1"  
  type: "Scale"
  bottom: "res_stage_3_450_1"
  top: "res_stage_3_450_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_450_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_450_1_top"
  top: "res_stage_3_450_1_top"
}
layer {
  name: "res_stage_3_450_2"
  type: "Convolution"
  bottom: "res_stage_3_450_1_top"
  top: "res_stage_3_450_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_450_2"
  type: "BatchNorm"
  bottom: "res_stage_3_450_2"
  top: "res_stage_3_450_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_450_2"  
  type: "Scale"
  bottom: "res_stage_3_450_2"
  top: "res_stage_3_450_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_450_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_450_2_top"
  top: "res_stage_3_450_2_top"
}
layer {
  name: "res_stage_3_450_3"
  type: "Convolution"
  bottom: "res_stage_3_450_2_top"
  top: "res_stage_3_450_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_450_3"
  type: "BatchNorm"
  bottom: "res_stage_3_450_3"
  top: "res_stage_3_450_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_450_3"  
  type: "Scale"
  bottom: "res_stage_3_450_3"
  top: "res_stage_3_450_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_450"
  type: "Eltwise"
  bottom: "res_3_449"
  bottom: "res_stage_3_450_3_top"
  top: "res_3_450"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_450_relu"
  type: "ReLU"
  bottom: "res_3_450"
  top: "res_3_450"
}
layer {
  name: "res_stage_3_451_1"
  type: "Convolution"
  bottom: "res_3_450"
  top: "res_stage_3_451_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_451_1"
  type: "BatchNorm"
  bottom: "res_stage_3_451_1"
  top: "res_stage_3_451_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_451_1"  
  type: "Scale"
  bottom: "res_stage_3_451_1"
  top: "res_stage_3_451_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_451_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_451_1_top"
  top: "res_stage_3_451_1_top"
}
layer {
  name: "res_stage_3_451_2"
  type: "Convolution"
  bottom: "res_stage_3_451_1_top"
  top: "res_stage_3_451_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_451_2"
  type: "BatchNorm"
  bottom: "res_stage_3_451_2"
  top: "res_stage_3_451_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_451_2"  
  type: "Scale"
  bottom: "res_stage_3_451_2"
  top: "res_stage_3_451_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_451_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_451_2_top"
  top: "res_stage_3_451_2_top"
}
layer {
  name: "res_stage_3_451_3"
  type: "Convolution"
  bottom: "res_stage_3_451_2_top"
  top: "res_stage_3_451_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_451_3"
  type: "BatchNorm"
  bottom: "res_stage_3_451_3"
  top: "res_stage_3_451_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_451_3"  
  type: "Scale"
  bottom: "res_stage_3_451_3"
  top: "res_stage_3_451_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_451"
  type: "Eltwise"
  bottom: "res_3_450"
  bottom: "res_stage_3_451_3_top"
  top: "res_3_451"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_451_relu"
  type: "ReLU"
  bottom: "res_3_451"
  top: "res_3_451"
}
layer {
  name: "res_stage_3_452_1"
  type: "Convolution"
  bottom: "res_3_451"
  top: "res_stage_3_452_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_452_1"
  type: "BatchNorm"
  bottom: "res_stage_3_452_1"
  top: "res_stage_3_452_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_452_1"  
  type: "Scale"
  bottom: "res_stage_3_452_1"
  top: "res_stage_3_452_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_452_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_452_1_top"
  top: "res_stage_3_452_1_top"
}
layer {
  name: "res_stage_3_452_2"
  type: "Convolution"
  bottom: "res_stage_3_452_1_top"
  top: "res_stage_3_452_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_452_2"
  type: "BatchNorm"
  bottom: "res_stage_3_452_2"
  top: "res_stage_3_452_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_452_2"  
  type: "Scale"
  bottom: "res_stage_3_452_2"
  top: "res_stage_3_452_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_452_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_452_2_top"
  top: "res_stage_3_452_2_top"
}
layer {
  name: "res_stage_3_452_3"
  type: "Convolution"
  bottom: "res_stage_3_452_2_top"
  top: "res_stage_3_452_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_452_3"
  type: "BatchNorm"
  bottom: "res_stage_3_452_3"
  top: "res_stage_3_452_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_452_3"  
  type: "Scale"
  bottom: "res_stage_3_452_3"
  top: "res_stage_3_452_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_452"
  type: "Eltwise"
  bottom: "res_3_451"
  bottom: "res_stage_3_452_3_top"
  top: "res_3_452"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_452_relu"
  type: "ReLU"
  bottom: "res_3_452"
  top: "res_3_452"
}
layer {
  name: "res_stage_3_453_1"
  type: "Convolution"
  bottom: "res_3_452"
  top: "res_stage_3_453_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_453_1"
  type: "BatchNorm"
  bottom: "res_stage_3_453_1"
  top: "res_stage_3_453_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_453_1"  
  type: "Scale"
  bottom: "res_stage_3_453_1"
  top: "res_stage_3_453_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_453_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_453_1_top"
  top: "res_stage_3_453_1_top"
}
layer {
  name: "res_stage_3_453_2"
  type: "Convolution"
  bottom: "res_stage_3_453_1_top"
  top: "res_stage_3_453_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_453_2"
  type: "BatchNorm"
  bottom: "res_stage_3_453_2"
  top: "res_stage_3_453_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_453_2"  
  type: "Scale"
  bottom: "res_stage_3_453_2"
  top: "res_stage_3_453_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_453_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_453_2_top"
  top: "res_stage_3_453_2_top"
}
layer {
  name: "res_stage_3_453_3"
  type: "Convolution"
  bottom: "res_stage_3_453_2_top"
  top: "res_stage_3_453_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_453_3"
  type: "BatchNorm"
  bottom: "res_stage_3_453_3"
  top: "res_stage_3_453_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_453_3"  
  type: "Scale"
  bottom: "res_stage_3_453_3"
  top: "res_stage_3_453_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_453"
  type: "Eltwise"
  bottom: "res_3_452"
  bottom: "res_stage_3_453_3_top"
  top: "res_3_453"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_453_relu"
  type: "ReLU"
  bottom: "res_3_453"
  top: "res_3_453"
}
layer {
  name: "res_stage_3_454_1"
  type: "Convolution"
  bottom: "res_3_453"
  top: "res_stage_3_454_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_454_1"
  type: "BatchNorm"
  bottom: "res_stage_3_454_1"
  top: "res_stage_3_454_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_454_1"  
  type: "Scale"
  bottom: "res_stage_3_454_1"
  top: "res_stage_3_454_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_454_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_454_1_top"
  top: "res_stage_3_454_1_top"
}
layer {
  name: "res_stage_3_454_2"
  type: "Convolution"
  bottom: "res_stage_3_454_1_top"
  top: "res_stage_3_454_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_454_2"
  type: "BatchNorm"
  bottom: "res_stage_3_454_2"
  top: "res_stage_3_454_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_454_2"  
  type: "Scale"
  bottom: "res_stage_3_454_2"
  top: "res_stage_3_454_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_454_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_454_2_top"
  top: "res_stage_3_454_2_top"
}
layer {
  name: "res_stage_3_454_3"
  type: "Convolution"
  bottom: "res_stage_3_454_2_top"
  top: "res_stage_3_454_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_454_3"
  type: "BatchNorm"
  bottom: "res_stage_3_454_3"
  top: "res_stage_3_454_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_454_3"  
  type: "Scale"
  bottom: "res_stage_3_454_3"
  top: "res_stage_3_454_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_454"
  type: "Eltwise"
  bottom: "res_3_453"
  bottom: "res_stage_3_454_3_top"
  top: "res_3_454"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_454_relu"
  type: "ReLU"
  bottom: "res_3_454"
  top: "res_3_454"
}
layer {
  name: "res_stage_3_455_1"
  type: "Convolution"
  bottom: "res_3_454"
  top: "res_stage_3_455_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_455_1"
  type: "BatchNorm"
  bottom: "res_stage_3_455_1"
  top: "res_stage_3_455_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_455_1"  
  type: "Scale"
  bottom: "res_stage_3_455_1"
  top: "res_stage_3_455_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_455_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_455_1_top"
  top: "res_stage_3_455_1_top"
}
layer {
  name: "res_stage_3_455_2"
  type: "Convolution"
  bottom: "res_stage_3_455_1_top"
  top: "res_stage_3_455_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_455_2"
  type: "BatchNorm"
  bottom: "res_stage_3_455_2"
  top: "res_stage_3_455_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_455_2"  
  type: "Scale"
  bottom: "res_stage_3_455_2"
  top: "res_stage_3_455_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_455_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_455_2_top"
  top: "res_stage_3_455_2_top"
}
layer {
  name: "res_stage_3_455_3"
  type: "Convolution"
  bottom: "res_stage_3_455_2_top"
  top: "res_stage_3_455_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_455_3"
  type: "BatchNorm"
  bottom: "res_stage_3_455_3"
  top: "res_stage_3_455_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_455_3"  
  type: "Scale"
  bottom: "res_stage_3_455_3"
  top: "res_stage_3_455_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_455"
  type: "Eltwise"
  bottom: "res_3_454"
  bottom: "res_stage_3_455_3_top"
  top: "res_3_455"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_455_relu"
  type: "ReLU"
  bottom: "res_3_455"
  top: "res_3_455"
}
layer {
  name: "res_stage_3_456_1"
  type: "Convolution"
  bottom: "res_3_455"
  top: "res_stage_3_456_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_456_1"
  type: "BatchNorm"
  bottom: "res_stage_3_456_1"
  top: "res_stage_3_456_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_456_1"  
  type: "Scale"
  bottom: "res_stage_3_456_1"
  top: "res_stage_3_456_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_456_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_456_1_top"
  top: "res_stage_3_456_1_top"
}
layer {
  name: "res_stage_3_456_2"
  type: "Convolution"
  bottom: "res_stage_3_456_1_top"
  top: "res_stage_3_456_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_456_2"
  type: "BatchNorm"
  bottom: "res_stage_3_456_2"
  top: "res_stage_3_456_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_456_2"  
  type: "Scale"
  bottom: "res_stage_3_456_2"
  top: "res_stage_3_456_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_456_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_456_2_top"
  top: "res_stage_3_456_2_top"
}
layer {
  name: "res_stage_3_456_3"
  type: "Convolution"
  bottom: "res_stage_3_456_2_top"
  top: "res_stage_3_456_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_456_3"
  type: "BatchNorm"
  bottom: "res_stage_3_456_3"
  top: "res_stage_3_456_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_456_3"  
  type: "Scale"
  bottom: "res_stage_3_456_3"
  top: "res_stage_3_456_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_456"
  type: "Eltwise"
  bottom: "res_3_455"
  bottom: "res_stage_3_456_3_top"
  top: "res_3_456"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_456_relu"
  type: "ReLU"
  bottom: "res_3_456"
  top: "res_3_456"
}
layer {
  name: "res_stage_3_457_1"
  type: "Convolution"
  bottom: "res_3_456"
  top: "res_stage_3_457_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_457_1"
  type: "BatchNorm"
  bottom: "res_stage_3_457_1"
  top: "res_stage_3_457_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_457_1"  
  type: "Scale"
  bottom: "res_stage_3_457_1"
  top: "res_stage_3_457_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_457_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_457_1_top"
  top: "res_stage_3_457_1_top"
}
layer {
  name: "res_stage_3_457_2"
  type: "Convolution"
  bottom: "res_stage_3_457_1_top"
  top: "res_stage_3_457_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_457_2"
  type: "BatchNorm"
  bottom: "res_stage_3_457_2"
  top: "res_stage_3_457_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_457_2"  
  type: "Scale"
  bottom: "res_stage_3_457_2"
  top: "res_stage_3_457_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_457_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_457_2_top"
  top: "res_stage_3_457_2_top"
}
layer {
  name: "res_stage_3_457_3"
  type: "Convolution"
  bottom: "res_stage_3_457_2_top"
  top: "res_stage_3_457_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_457_3"
  type: "BatchNorm"
  bottom: "res_stage_3_457_3"
  top: "res_stage_3_457_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_457_3"  
  type: "Scale"
  bottom: "res_stage_3_457_3"
  top: "res_stage_3_457_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_457"
  type: "Eltwise"
  bottom: "res_3_456"
  bottom: "res_stage_3_457_3_top"
  top: "res_3_457"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_457_relu"
  type: "ReLU"
  bottom: "res_3_457"
  top: "res_3_457"
}
layer {
  name: "res_stage_3_458_1"
  type: "Convolution"
  bottom: "res_3_457"
  top: "res_stage_3_458_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_458_1"
  type: "BatchNorm"
  bottom: "res_stage_3_458_1"
  top: "res_stage_3_458_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_458_1"  
  type: "Scale"
  bottom: "res_stage_3_458_1"
  top: "res_stage_3_458_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_458_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_458_1_top"
  top: "res_stage_3_458_1_top"
}
layer {
  name: "res_stage_3_458_2"
  type: "Convolution"
  bottom: "res_stage_3_458_1_top"
  top: "res_stage_3_458_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_458_2"
  type: "BatchNorm"
  bottom: "res_stage_3_458_2"
  top: "res_stage_3_458_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_458_2"  
  type: "Scale"
  bottom: "res_stage_3_458_2"
  top: "res_stage_3_458_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_458_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_458_2_top"
  top: "res_stage_3_458_2_top"
}
layer {
  name: "res_stage_3_458_3"
  type: "Convolution"
  bottom: "res_stage_3_458_2_top"
  top: "res_stage_3_458_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_458_3"
  type: "BatchNorm"
  bottom: "res_stage_3_458_3"
  top: "res_stage_3_458_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_458_3"  
  type: "Scale"
  bottom: "res_stage_3_458_3"
  top: "res_stage_3_458_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_458"
  type: "Eltwise"
  bottom: "res_3_457"
  bottom: "res_stage_3_458_3_top"
  top: "res_3_458"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_458_relu"
  type: "ReLU"
  bottom: "res_3_458"
  top: "res_3_458"
}
layer {
  name: "res_stage_3_459_1"
  type: "Convolution"
  bottom: "res_3_458"
  top: "res_stage_3_459_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_459_1"
  type: "BatchNorm"
  bottom: "res_stage_3_459_1"
  top: "res_stage_3_459_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_459_1"  
  type: "Scale"
  bottom: "res_stage_3_459_1"
  top: "res_stage_3_459_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_459_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_459_1_top"
  top: "res_stage_3_459_1_top"
}
layer {
  name: "res_stage_3_459_2"
  type: "Convolution"
  bottom: "res_stage_3_459_1_top"
  top: "res_stage_3_459_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_459_2"
  type: "BatchNorm"
  bottom: "res_stage_3_459_2"
  top: "res_stage_3_459_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_459_2"  
  type: "Scale"
  bottom: "res_stage_3_459_2"
  top: "res_stage_3_459_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_459_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_459_2_top"
  top: "res_stage_3_459_2_top"
}
layer {
  name: "res_stage_3_459_3"
  type: "Convolution"
  bottom: "res_stage_3_459_2_top"
  top: "res_stage_3_459_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_459_3"
  type: "BatchNorm"
  bottom: "res_stage_3_459_3"
  top: "res_stage_3_459_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_459_3"  
  type: "Scale"
  bottom: "res_stage_3_459_3"
  top: "res_stage_3_459_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_459"
  type: "Eltwise"
  bottom: "res_3_458"
  bottom: "res_stage_3_459_3_top"
  top: "res_3_459"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_459_relu"
  type: "ReLU"
  bottom: "res_3_459"
  top: "res_3_459"
}
layer {
  name: "res_stage_3_460_1"
  type: "Convolution"
  bottom: "res_3_459"
  top: "res_stage_3_460_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_460_1"
  type: "BatchNorm"
  bottom: "res_stage_3_460_1"
  top: "res_stage_3_460_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_460_1"  
  type: "Scale"
  bottom: "res_stage_3_460_1"
  top: "res_stage_3_460_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_460_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_460_1_top"
  top: "res_stage_3_460_1_top"
}
layer {
  name: "res_stage_3_460_2"
  type: "Convolution"
  bottom: "res_stage_3_460_1_top"
  top: "res_stage_3_460_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_460_2"
  type: "BatchNorm"
  bottom: "res_stage_3_460_2"
  top: "res_stage_3_460_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_460_2"  
  type: "Scale"
  bottom: "res_stage_3_460_2"
  top: "res_stage_3_460_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_460_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_460_2_top"
  top: "res_stage_3_460_2_top"
}
layer {
  name: "res_stage_3_460_3"
  type: "Convolution"
  bottom: "res_stage_3_460_2_top"
  top: "res_stage_3_460_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_460_3"
  type: "BatchNorm"
  bottom: "res_stage_3_460_3"
  top: "res_stage_3_460_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_460_3"  
  type: "Scale"
  bottom: "res_stage_3_460_3"
  top: "res_stage_3_460_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_460"
  type: "Eltwise"
  bottom: "res_3_459"
  bottom: "res_stage_3_460_3_top"
  top: "res_3_460"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_460_relu"
  type: "ReLU"
  bottom: "res_3_460"
  top: "res_3_460"
}
layer {
  name: "res_stage_3_461_1"
  type: "Convolution"
  bottom: "res_3_460"
  top: "res_stage_3_461_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_461_1"
  type: "BatchNorm"
  bottom: "res_stage_3_461_1"
  top: "res_stage_3_461_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_461_1"  
  type: "Scale"
  bottom: "res_stage_3_461_1"
  top: "res_stage_3_461_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_461_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_461_1_top"
  top: "res_stage_3_461_1_top"
}
layer {
  name: "res_stage_3_461_2"
  type: "Convolution"
  bottom: "res_stage_3_461_1_top"
  top: "res_stage_3_461_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_461_2"
  type: "BatchNorm"
  bottom: "res_stage_3_461_2"
  top: "res_stage_3_461_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_461_2"  
  type: "Scale"
  bottom: "res_stage_3_461_2"
  top: "res_stage_3_461_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_461_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_461_2_top"
  top: "res_stage_3_461_2_top"
}
layer {
  name: "res_stage_3_461_3"
  type: "Convolution"
  bottom: "res_stage_3_461_2_top"
  top: "res_stage_3_461_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_461_3"
  type: "BatchNorm"
  bottom: "res_stage_3_461_3"
  top: "res_stage_3_461_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_461_3"  
  type: "Scale"
  bottom: "res_stage_3_461_3"
  top: "res_stage_3_461_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_461"
  type: "Eltwise"
  bottom: "res_3_460"
  bottom: "res_stage_3_461_3_top"
  top: "res_3_461"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_461_relu"
  type: "ReLU"
  bottom: "res_3_461"
  top: "res_3_461"
}
layer {
  name: "res_stage_3_462_1"
  type: "Convolution"
  bottom: "res_3_461"
  top: "res_stage_3_462_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_462_1"
  type: "BatchNorm"
  bottom: "res_stage_3_462_1"
  top: "res_stage_3_462_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_462_1"  
  type: "Scale"
  bottom: "res_stage_3_462_1"
  top: "res_stage_3_462_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_462_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_462_1_top"
  top: "res_stage_3_462_1_top"
}
layer {
  name: "res_stage_3_462_2"
  type: "Convolution"
  bottom: "res_stage_3_462_1_top"
  top: "res_stage_3_462_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_462_2"
  type: "BatchNorm"
  bottom: "res_stage_3_462_2"
  top: "res_stage_3_462_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_462_2"  
  type: "Scale"
  bottom: "res_stage_3_462_2"
  top: "res_stage_3_462_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_462_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_462_2_top"
  top: "res_stage_3_462_2_top"
}
layer {
  name: "res_stage_3_462_3"
  type: "Convolution"
  bottom: "res_stage_3_462_2_top"
  top: "res_stage_3_462_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_462_3"
  type: "BatchNorm"
  bottom: "res_stage_3_462_3"
  top: "res_stage_3_462_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_462_3"  
  type: "Scale"
  bottom: "res_stage_3_462_3"
  top: "res_stage_3_462_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_462"
  type: "Eltwise"
  bottom: "res_3_461"
  bottom: "res_stage_3_462_3_top"
  top: "res_3_462"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_462_relu"
  type: "ReLU"
  bottom: "res_3_462"
  top: "res_3_462"
}
layer {
  name: "res_stage_3_463_1"
  type: "Convolution"
  bottom: "res_3_462"
  top: "res_stage_3_463_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_463_1"
  type: "BatchNorm"
  bottom: "res_stage_3_463_1"
  top: "res_stage_3_463_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_463_1"  
  type: "Scale"
  bottom: "res_stage_3_463_1"
  top: "res_stage_3_463_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_463_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_463_1_top"
  top: "res_stage_3_463_1_top"
}
layer {
  name: "res_stage_3_463_2"
  type: "Convolution"
  bottom: "res_stage_3_463_1_top"
  top: "res_stage_3_463_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_463_2"
  type: "BatchNorm"
  bottom: "res_stage_3_463_2"
  top: "res_stage_3_463_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_463_2"  
  type: "Scale"
  bottom: "res_stage_3_463_2"
  top: "res_stage_3_463_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_463_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_463_2_top"
  top: "res_stage_3_463_2_top"
}
layer {
  name: "res_stage_3_463_3"
  type: "Convolution"
  bottom: "res_stage_3_463_2_top"
  top: "res_stage_3_463_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_463_3"
  type: "BatchNorm"
  bottom: "res_stage_3_463_3"
  top: "res_stage_3_463_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_463_3"  
  type: "Scale"
  bottom: "res_stage_3_463_3"
  top: "res_stage_3_463_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_463"
  type: "Eltwise"
  bottom: "res_3_462"
  bottom: "res_stage_3_463_3_top"
  top: "res_3_463"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_463_relu"
  type: "ReLU"
  bottom: "res_3_463"
  top: "res_3_463"
}
layer {
  name: "res_stage_3_464_1"
  type: "Convolution"
  bottom: "res_3_463"
  top: "res_stage_3_464_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_464_1"
  type: "BatchNorm"
  bottom: "res_stage_3_464_1"
  top: "res_stage_3_464_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_464_1"  
  type: "Scale"
  bottom: "res_stage_3_464_1"
  top: "res_stage_3_464_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_464_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_464_1_top"
  top: "res_stage_3_464_1_top"
}
layer {
  name: "res_stage_3_464_2"
  type: "Convolution"
  bottom: "res_stage_3_464_1_top"
  top: "res_stage_3_464_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_464_2"
  type: "BatchNorm"
  bottom: "res_stage_3_464_2"
  top: "res_stage_3_464_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_464_2"  
  type: "Scale"
  bottom: "res_stage_3_464_2"
  top: "res_stage_3_464_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_464_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_464_2_top"
  top: "res_stage_3_464_2_top"
}
layer {
  name: "res_stage_3_464_3"
  type: "Convolution"
  bottom: "res_stage_3_464_2_top"
  top: "res_stage_3_464_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_464_3"
  type: "BatchNorm"
  bottom: "res_stage_3_464_3"
  top: "res_stage_3_464_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_464_3"  
  type: "Scale"
  bottom: "res_stage_3_464_3"
  top: "res_stage_3_464_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_464"
  type: "Eltwise"
  bottom: "res_3_463"
  bottom: "res_stage_3_464_3_top"
  top: "res_3_464"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_464_relu"
  type: "ReLU"
  bottom: "res_3_464"
  top: "res_3_464"
}
layer {
  name: "res_stage_3_465_1"
  type: "Convolution"
  bottom: "res_3_464"
  top: "res_stage_3_465_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_465_1"
  type: "BatchNorm"
  bottom: "res_stage_3_465_1"
  top: "res_stage_3_465_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_465_1"  
  type: "Scale"
  bottom: "res_stage_3_465_1"
  top: "res_stage_3_465_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_465_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_465_1_top"
  top: "res_stage_3_465_1_top"
}
layer {
  name: "res_stage_3_465_2"
  type: "Convolution"
  bottom: "res_stage_3_465_1_top"
  top: "res_stage_3_465_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_465_2"
  type: "BatchNorm"
  bottom: "res_stage_3_465_2"
  top: "res_stage_3_465_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_465_2"  
  type: "Scale"
  bottom: "res_stage_3_465_2"
  top: "res_stage_3_465_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_465_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_465_2_top"
  top: "res_stage_3_465_2_top"
}
layer {
  name: "res_stage_3_465_3"
  type: "Convolution"
  bottom: "res_stage_3_465_2_top"
  top: "res_stage_3_465_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_465_3"
  type: "BatchNorm"
  bottom: "res_stage_3_465_3"
  top: "res_stage_3_465_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_465_3"  
  type: "Scale"
  bottom: "res_stage_3_465_3"
  top: "res_stage_3_465_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_465"
  type: "Eltwise"
  bottom: "res_3_464"
  bottom: "res_stage_3_465_3_top"
  top: "res_3_465"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_465_relu"
  type: "ReLU"
  bottom: "res_3_465"
  top: "res_3_465"
}
layer {
  name: "res_stage_3_466_1"
  type: "Convolution"
  bottom: "res_3_465"
  top: "res_stage_3_466_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_466_1"
  type: "BatchNorm"
  bottom: "res_stage_3_466_1"
  top: "res_stage_3_466_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_466_1"  
  type: "Scale"
  bottom: "res_stage_3_466_1"
  top: "res_stage_3_466_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_466_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_466_1_top"
  top: "res_stage_3_466_1_top"
}
layer {
  name: "res_stage_3_466_2"
  type: "Convolution"
  bottom: "res_stage_3_466_1_top"
  top: "res_stage_3_466_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_466_2"
  type: "BatchNorm"
  bottom: "res_stage_3_466_2"
  top: "res_stage_3_466_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_466_2"  
  type: "Scale"
  bottom: "res_stage_3_466_2"
  top: "res_stage_3_466_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_466_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_466_2_top"
  top: "res_stage_3_466_2_top"
}
layer {
  name: "res_stage_3_466_3"
  type: "Convolution"
  bottom: "res_stage_3_466_2_top"
  top: "res_stage_3_466_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_466_3"
  type: "BatchNorm"
  bottom: "res_stage_3_466_3"
  top: "res_stage_3_466_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_466_3"  
  type: "Scale"
  bottom: "res_stage_3_466_3"
  top: "res_stage_3_466_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_466"
  type: "Eltwise"
  bottom: "res_3_465"
  bottom: "res_stage_3_466_3_top"
  top: "res_3_466"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_466_relu"
  type: "ReLU"
  bottom: "res_3_466"
  top: "res_3_466"
}
layer {
  name: "res_stage_3_467_1"
  type: "Convolution"
  bottom: "res_3_466"
  top: "res_stage_3_467_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_467_1"
  type: "BatchNorm"
  bottom: "res_stage_3_467_1"
  top: "res_stage_3_467_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_467_1"  
  type: "Scale"
  bottom: "res_stage_3_467_1"
  top: "res_stage_3_467_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_467_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_467_1_top"
  top: "res_stage_3_467_1_top"
}
layer {
  name: "res_stage_3_467_2"
  type: "Convolution"
  bottom: "res_stage_3_467_1_top"
  top: "res_stage_3_467_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_467_2"
  type: "BatchNorm"
  bottom: "res_stage_3_467_2"
  top: "res_stage_3_467_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_467_2"  
  type: "Scale"
  bottom: "res_stage_3_467_2"
  top: "res_stage_3_467_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_467_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_467_2_top"
  top: "res_stage_3_467_2_top"
}
layer {
  name: "res_stage_3_467_3"
  type: "Convolution"
  bottom: "res_stage_3_467_2_top"
  top: "res_stage_3_467_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_467_3"
  type: "BatchNorm"
  bottom: "res_stage_3_467_3"
  top: "res_stage_3_467_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_467_3"  
  type: "Scale"
  bottom: "res_stage_3_467_3"
  top: "res_stage_3_467_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_467"
  type: "Eltwise"
  bottom: "res_3_466"
  bottom: "res_stage_3_467_3_top"
  top: "res_3_467"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_467_relu"
  type: "ReLU"
  bottom: "res_3_467"
  top: "res_3_467"
}
layer {
  name: "res_stage_3_468_1"
  type: "Convolution"
  bottom: "res_3_467"
  top: "res_stage_3_468_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_468_1"
  type: "BatchNorm"
  bottom: "res_stage_3_468_1"
  top: "res_stage_3_468_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_468_1"  
  type: "Scale"
  bottom: "res_stage_3_468_1"
  top: "res_stage_3_468_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_468_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_468_1_top"
  top: "res_stage_3_468_1_top"
}
layer {
  name: "res_stage_3_468_2"
  type: "Convolution"
  bottom: "res_stage_3_468_1_top"
  top: "res_stage_3_468_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_468_2"
  type: "BatchNorm"
  bottom: "res_stage_3_468_2"
  top: "res_stage_3_468_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_468_2"  
  type: "Scale"
  bottom: "res_stage_3_468_2"
  top: "res_stage_3_468_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_468_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_468_2_top"
  top: "res_stage_3_468_2_top"
}
layer {
  name: "res_stage_3_468_3"
  type: "Convolution"
  bottom: "res_stage_3_468_2_top"
  top: "res_stage_3_468_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_468_3"
  type: "BatchNorm"
  bottom: "res_stage_3_468_3"
  top: "res_stage_3_468_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_468_3"  
  type: "Scale"
  bottom: "res_stage_3_468_3"
  top: "res_stage_3_468_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_468"
  type: "Eltwise"
  bottom: "res_3_467"
  bottom: "res_stage_3_468_3_top"
  top: "res_3_468"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_468_relu"
  type: "ReLU"
  bottom: "res_3_468"
  top: "res_3_468"
}
layer {
  name: "res_stage_3_469_1"
  type: "Convolution"
  bottom: "res_3_468"
  top: "res_stage_3_469_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_469_1"
  type: "BatchNorm"
  bottom: "res_stage_3_469_1"
  top: "res_stage_3_469_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_469_1"  
  type: "Scale"
  bottom: "res_stage_3_469_1"
  top: "res_stage_3_469_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_469_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_469_1_top"
  top: "res_stage_3_469_1_top"
}
layer {
  name: "res_stage_3_469_2"
  type: "Convolution"
  bottom: "res_stage_3_469_1_top"
  top: "res_stage_3_469_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_469_2"
  type: "BatchNorm"
  bottom: "res_stage_3_469_2"
  top: "res_stage_3_469_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_469_2"  
  type: "Scale"
  bottom: "res_stage_3_469_2"
  top: "res_stage_3_469_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_469_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_469_2_top"
  top: "res_stage_3_469_2_top"
}
layer {
  name: "res_stage_3_469_3"
  type: "Convolution"
  bottom: "res_stage_3_469_2_top"
  top: "res_stage_3_469_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_469_3"
  type: "BatchNorm"
  bottom: "res_stage_3_469_3"
  top: "res_stage_3_469_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_469_3"  
  type: "Scale"
  bottom: "res_stage_3_469_3"
  top: "res_stage_3_469_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_469"
  type: "Eltwise"
  bottom: "res_3_468"
  bottom: "res_stage_3_469_3_top"
  top: "res_3_469"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_469_relu"
  type: "ReLU"
  bottom: "res_3_469"
  top: "res_3_469"
}
layer {
  name: "res_stage_3_470_1"
  type: "Convolution"
  bottom: "res_3_469"
  top: "res_stage_3_470_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_470_1"
  type: "BatchNorm"
  bottom: "res_stage_3_470_1"
  top: "res_stage_3_470_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_470_1"  
  type: "Scale"
  bottom: "res_stage_3_470_1"
  top: "res_stage_3_470_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_470_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_470_1_top"
  top: "res_stage_3_470_1_top"
}
layer {
  name: "res_stage_3_470_2"
  type: "Convolution"
  bottom: "res_stage_3_470_1_top"
  top: "res_stage_3_470_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_470_2"
  type: "BatchNorm"
  bottom: "res_stage_3_470_2"
  top: "res_stage_3_470_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_470_2"  
  type: "Scale"
  bottom: "res_stage_3_470_2"
  top: "res_stage_3_470_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_470_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_470_2_top"
  top: "res_stage_3_470_2_top"
}
layer {
  name: "res_stage_3_470_3"
  type: "Convolution"
  bottom: "res_stage_3_470_2_top"
  top: "res_stage_3_470_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_470_3"
  type: "BatchNorm"
  bottom: "res_stage_3_470_3"
  top: "res_stage_3_470_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_470_3"  
  type: "Scale"
  bottom: "res_stage_3_470_3"
  top: "res_stage_3_470_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_470"
  type: "Eltwise"
  bottom: "res_3_469"
  bottom: "res_stage_3_470_3_top"
  top: "res_3_470"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_470_relu"
  type: "ReLU"
  bottom: "res_3_470"
  top: "res_3_470"
}
layer {
  name: "res_stage_3_471_1"
  type: "Convolution"
  bottom: "res_3_470"
  top: "res_stage_3_471_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_471_1"
  type: "BatchNorm"
  bottom: "res_stage_3_471_1"
  top: "res_stage_3_471_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_471_1"  
  type: "Scale"
  bottom: "res_stage_3_471_1"
  top: "res_stage_3_471_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_471_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_471_1_top"
  top: "res_stage_3_471_1_top"
}
layer {
  name: "res_stage_3_471_2"
  type: "Convolution"
  bottom: "res_stage_3_471_1_top"
  top: "res_stage_3_471_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_471_2"
  type: "BatchNorm"
  bottom: "res_stage_3_471_2"
  top: "res_stage_3_471_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_471_2"  
  type: "Scale"
  bottom: "res_stage_3_471_2"
  top: "res_stage_3_471_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_471_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_471_2_top"
  top: "res_stage_3_471_2_top"
}
layer {
  name: "res_stage_3_471_3"
  type: "Convolution"
  bottom: "res_stage_3_471_2_top"
  top: "res_stage_3_471_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_471_3"
  type: "BatchNorm"
  bottom: "res_stage_3_471_3"
  top: "res_stage_3_471_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_471_3"  
  type: "Scale"
  bottom: "res_stage_3_471_3"
  top: "res_stage_3_471_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_471"
  type: "Eltwise"
  bottom: "res_3_470"
  bottom: "res_stage_3_471_3_top"
  top: "res_3_471"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_471_relu"
  type: "ReLU"
  bottom: "res_3_471"
  top: "res_3_471"
}
layer {
  name: "res_stage_3_472_1"
  type: "Convolution"
  bottom: "res_3_471"
  top: "res_stage_3_472_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_472_1"
  type: "BatchNorm"
  bottom: "res_stage_3_472_1"
  top: "res_stage_3_472_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_472_1"  
  type: "Scale"
  bottom: "res_stage_3_472_1"
  top: "res_stage_3_472_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_472_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_472_1_top"
  top: "res_stage_3_472_1_top"
}
layer {
  name: "res_stage_3_472_2"
  type: "Convolution"
  bottom: "res_stage_3_472_1_top"
  top: "res_stage_3_472_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_472_2"
  type: "BatchNorm"
  bottom: "res_stage_3_472_2"
  top: "res_stage_3_472_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_472_2"  
  type: "Scale"
  bottom: "res_stage_3_472_2"
  top: "res_stage_3_472_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_472_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_472_2_top"
  top: "res_stage_3_472_2_top"
}
layer {
  name: "res_stage_3_472_3"
  type: "Convolution"
  bottom: "res_stage_3_472_2_top"
  top: "res_stage_3_472_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_472_3"
  type: "BatchNorm"
  bottom: "res_stage_3_472_3"
  top: "res_stage_3_472_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_472_3"  
  type: "Scale"
  bottom: "res_stage_3_472_3"
  top: "res_stage_3_472_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_472"
  type: "Eltwise"
  bottom: "res_3_471"
  bottom: "res_stage_3_472_3_top"
  top: "res_3_472"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_472_relu"
  type: "ReLU"
  bottom: "res_3_472"
  top: "res_3_472"
}
layer {
  name: "res_stage_3_473_1"
  type: "Convolution"
  bottom: "res_3_472"
  top: "res_stage_3_473_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_473_1"
  type: "BatchNorm"
  bottom: "res_stage_3_473_1"
  top: "res_stage_3_473_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_473_1"  
  type: "Scale"
  bottom: "res_stage_3_473_1"
  top: "res_stage_3_473_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_473_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_473_1_top"
  top: "res_stage_3_473_1_top"
}
layer {
  name: "res_stage_3_473_2"
  type: "Convolution"
  bottom: "res_stage_3_473_1_top"
  top: "res_stage_3_473_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_473_2"
  type: "BatchNorm"
  bottom: "res_stage_3_473_2"
  top: "res_stage_3_473_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_473_2"  
  type: "Scale"
  bottom: "res_stage_3_473_2"
  top: "res_stage_3_473_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_473_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_473_2_top"
  top: "res_stage_3_473_2_top"
}
layer {
  name: "res_stage_3_473_3"
  type: "Convolution"
  bottom: "res_stage_3_473_2_top"
  top: "res_stage_3_473_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_473_3"
  type: "BatchNorm"
  bottom: "res_stage_3_473_3"
  top: "res_stage_3_473_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_473_3"  
  type: "Scale"
  bottom: "res_stage_3_473_3"
  top: "res_stage_3_473_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_473"
  type: "Eltwise"
  bottom: "res_3_472"
  bottom: "res_stage_3_473_3_top"
  top: "res_3_473"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_473_relu"
  type: "ReLU"
  bottom: "res_3_473"
  top: "res_3_473"
}
layer {
  name: "res_stage_3_474_1"
  type: "Convolution"
  bottom: "res_3_473"
  top: "res_stage_3_474_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_474_1"
  type: "BatchNorm"
  bottom: "res_stage_3_474_1"
  top: "res_stage_3_474_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_474_1"  
  type: "Scale"
  bottom: "res_stage_3_474_1"
  top: "res_stage_3_474_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_474_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_474_1_top"
  top: "res_stage_3_474_1_top"
}
layer {
  name: "res_stage_3_474_2"
  type: "Convolution"
  bottom: "res_stage_3_474_1_top"
  top: "res_stage_3_474_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_474_2"
  type: "BatchNorm"
  bottom: "res_stage_3_474_2"
  top: "res_stage_3_474_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_474_2"  
  type: "Scale"
  bottom: "res_stage_3_474_2"
  top: "res_stage_3_474_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_474_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_474_2_top"
  top: "res_stage_3_474_2_top"
}
layer {
  name: "res_stage_3_474_3"
  type: "Convolution"
  bottom: "res_stage_3_474_2_top"
  top: "res_stage_3_474_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_474_3"
  type: "BatchNorm"
  bottom: "res_stage_3_474_3"
  top: "res_stage_3_474_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_474_3"  
  type: "Scale"
  bottom: "res_stage_3_474_3"
  top: "res_stage_3_474_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_474"
  type: "Eltwise"
  bottom: "res_3_473"
  bottom: "res_stage_3_474_3_top"
  top: "res_3_474"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_474_relu"
  type: "ReLU"
  bottom: "res_3_474"
  top: "res_3_474"
}
layer {
  name: "res_stage_3_475_1"
  type: "Convolution"
  bottom: "res_3_474"
  top: "res_stage_3_475_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_475_1"
  type: "BatchNorm"
  bottom: "res_stage_3_475_1"
  top: "res_stage_3_475_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_475_1"  
  type: "Scale"
  bottom: "res_stage_3_475_1"
  top: "res_stage_3_475_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_475_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_475_1_top"
  top: "res_stage_3_475_1_top"
}
layer {
  name: "res_stage_3_475_2"
  type: "Convolution"
  bottom: "res_stage_3_475_1_top"
  top: "res_stage_3_475_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_475_2"
  type: "BatchNorm"
  bottom: "res_stage_3_475_2"
  top: "res_stage_3_475_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_475_2"  
  type: "Scale"
  bottom: "res_stage_3_475_2"
  top: "res_stage_3_475_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_475_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_475_2_top"
  top: "res_stage_3_475_2_top"
}
layer {
  name: "res_stage_3_475_3"
  type: "Convolution"
  bottom: "res_stage_3_475_2_top"
  top: "res_stage_3_475_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_475_3"
  type: "BatchNorm"
  bottom: "res_stage_3_475_3"
  top: "res_stage_3_475_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_475_3"  
  type: "Scale"
  bottom: "res_stage_3_475_3"
  top: "res_stage_3_475_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_475"
  type: "Eltwise"
  bottom: "res_3_474"
  bottom: "res_stage_3_475_3_top"
  top: "res_3_475"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_475_relu"
  type: "ReLU"
  bottom: "res_3_475"
  top: "res_3_475"
}
layer {
  name: "res_stage_3_476_1"
  type: "Convolution"
  bottom: "res_3_475"
  top: "res_stage_3_476_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_476_1"
  type: "BatchNorm"
  bottom: "res_stage_3_476_1"
  top: "res_stage_3_476_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_476_1"  
  type: "Scale"
  bottom: "res_stage_3_476_1"
  top: "res_stage_3_476_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_476_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_476_1_top"
  top: "res_stage_3_476_1_top"
}
layer {
  name: "res_stage_3_476_2"
  type: "Convolution"
  bottom: "res_stage_3_476_1_top"
  top: "res_stage_3_476_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_476_2"
  type: "BatchNorm"
  bottom: "res_stage_3_476_2"
  top: "res_stage_3_476_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_476_2"  
  type: "Scale"
  bottom: "res_stage_3_476_2"
  top: "res_stage_3_476_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_476_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_476_2_top"
  top: "res_stage_3_476_2_top"
}
layer {
  name: "res_stage_3_476_3"
  type: "Convolution"
  bottom: "res_stage_3_476_2_top"
  top: "res_stage_3_476_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_476_3"
  type: "BatchNorm"
  bottom: "res_stage_3_476_3"
  top: "res_stage_3_476_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_476_3"  
  type: "Scale"
  bottom: "res_stage_3_476_3"
  top: "res_stage_3_476_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_476"
  type: "Eltwise"
  bottom: "res_3_475"
  bottom: "res_stage_3_476_3_top"
  top: "res_3_476"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_476_relu"
  type: "ReLU"
  bottom: "res_3_476"
  top: "res_3_476"
}
layer {
  name: "res_stage_3_477_1"
  type: "Convolution"
  bottom: "res_3_476"
  top: "res_stage_3_477_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_477_1"
  type: "BatchNorm"
  bottom: "res_stage_3_477_1"
  top: "res_stage_3_477_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_477_1"  
  type: "Scale"
  bottom: "res_stage_3_477_1"
  top: "res_stage_3_477_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_477_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_477_1_top"
  top: "res_stage_3_477_1_top"
}
layer {
  name: "res_stage_3_477_2"
  type: "Convolution"
  bottom: "res_stage_3_477_1_top"
  top: "res_stage_3_477_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_477_2"
  type: "BatchNorm"
  bottom: "res_stage_3_477_2"
  top: "res_stage_3_477_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_477_2"  
  type: "Scale"
  bottom: "res_stage_3_477_2"
  top: "res_stage_3_477_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_477_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_477_2_top"
  top: "res_stage_3_477_2_top"
}
layer {
  name: "res_stage_3_477_3"
  type: "Convolution"
  bottom: "res_stage_3_477_2_top"
  top: "res_stage_3_477_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_477_3"
  type: "BatchNorm"
  bottom: "res_stage_3_477_3"
  top: "res_stage_3_477_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_477_3"  
  type: "Scale"
  bottom: "res_stage_3_477_3"
  top: "res_stage_3_477_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_477"
  type: "Eltwise"
  bottom: "res_3_476"
  bottom: "res_stage_3_477_3_top"
  top: "res_3_477"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_477_relu"
  type: "ReLU"
  bottom: "res_3_477"
  top: "res_3_477"
}
layer {
  name: "res_stage_3_478_1"
  type: "Convolution"
  bottom: "res_3_477"
  top: "res_stage_3_478_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_478_1"
  type: "BatchNorm"
  bottom: "res_stage_3_478_1"
  top: "res_stage_3_478_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_478_1"  
  type: "Scale"
  bottom: "res_stage_3_478_1"
  top: "res_stage_3_478_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_478_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_478_1_top"
  top: "res_stage_3_478_1_top"
}
layer {
  name: "res_stage_3_478_2"
  type: "Convolution"
  bottom: "res_stage_3_478_1_top"
  top: "res_stage_3_478_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_478_2"
  type: "BatchNorm"
  bottom: "res_stage_3_478_2"
  top: "res_stage_3_478_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_478_2"  
  type: "Scale"
  bottom: "res_stage_3_478_2"
  top: "res_stage_3_478_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_478_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_478_2_top"
  top: "res_stage_3_478_2_top"
}
layer {
  name: "res_stage_3_478_3"
  type: "Convolution"
  bottom: "res_stage_3_478_2_top"
  top: "res_stage_3_478_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_478_3"
  type: "BatchNorm"
  bottom: "res_stage_3_478_3"
  top: "res_stage_3_478_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_478_3"  
  type: "Scale"
  bottom: "res_stage_3_478_3"
  top: "res_stage_3_478_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_478"
  type: "Eltwise"
  bottom: "res_3_477"
  bottom: "res_stage_3_478_3_top"
  top: "res_3_478"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_478_relu"
  type: "ReLU"
  bottom: "res_3_478"
  top: "res_3_478"
}
layer {
  name: "res_stage_3_479_1"
  type: "Convolution"
  bottom: "res_3_478"
  top: "res_stage_3_479_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_479_1"
  type: "BatchNorm"
  bottom: "res_stage_3_479_1"
  top: "res_stage_3_479_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_479_1"  
  type: "Scale"
  bottom: "res_stage_3_479_1"
  top: "res_stage_3_479_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_479_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_479_1_top"
  top: "res_stage_3_479_1_top"
}
layer {
  name: "res_stage_3_479_2"
  type: "Convolution"
  bottom: "res_stage_3_479_1_top"
  top: "res_stage_3_479_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_479_2"
  type: "BatchNorm"
  bottom: "res_stage_3_479_2"
  top: "res_stage_3_479_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_479_2"  
  type: "Scale"
  bottom: "res_stage_3_479_2"
  top: "res_stage_3_479_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_479_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_479_2_top"
  top: "res_stage_3_479_2_top"
}
layer {
  name: "res_stage_3_479_3"
  type: "Convolution"
  bottom: "res_stage_3_479_2_top"
  top: "res_stage_3_479_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_479_3"
  type: "BatchNorm"
  bottom: "res_stage_3_479_3"
  top: "res_stage_3_479_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_479_3"  
  type: "Scale"
  bottom: "res_stage_3_479_3"
  top: "res_stage_3_479_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_479"
  type: "Eltwise"
  bottom: "res_3_478"
  bottom: "res_stage_3_479_3_top"
  top: "res_3_479"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_479_relu"
  type: "ReLU"
  bottom: "res_3_479"
  top: "res_3_479"
}
layer {
  name: "res_stage_3_480_1"
  type: "Convolution"
  bottom: "res_3_479"
  top: "res_stage_3_480_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_480_1"
  type: "BatchNorm"
  bottom: "res_stage_3_480_1"
  top: "res_stage_3_480_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_480_1"  
  type: "Scale"
  bottom: "res_stage_3_480_1"
  top: "res_stage_3_480_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_480_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_480_1_top"
  top: "res_stage_3_480_1_top"
}
layer {
  name: "res_stage_3_480_2"
  type: "Convolution"
  bottom: "res_stage_3_480_1_top"
  top: "res_stage_3_480_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_480_2"
  type: "BatchNorm"
  bottom: "res_stage_3_480_2"
  top: "res_stage_3_480_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_480_2"  
  type: "Scale"
  bottom: "res_stage_3_480_2"
  top: "res_stage_3_480_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_480_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_480_2_top"
  top: "res_stage_3_480_2_top"
}
layer {
  name: "res_stage_3_480_3"
  type: "Convolution"
  bottom: "res_stage_3_480_2_top"
  top: "res_stage_3_480_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_480_3"
  type: "BatchNorm"
  bottom: "res_stage_3_480_3"
  top: "res_stage_3_480_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_480_3"  
  type: "Scale"
  bottom: "res_stage_3_480_3"
  top: "res_stage_3_480_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_480"
  type: "Eltwise"
  bottom: "res_3_479"
  bottom: "res_stage_3_480_3_top"
  top: "res_3_480"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_480_relu"
  type: "ReLU"
  bottom: "res_3_480"
  top: "res_3_480"
}
layer {
  name: "res_stage_3_481_1"
  type: "Convolution"
  bottom: "res_3_480"
  top: "res_stage_3_481_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_481_1"
  type: "BatchNorm"
  bottom: "res_stage_3_481_1"
  top: "res_stage_3_481_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_481_1"  
  type: "Scale"
  bottom: "res_stage_3_481_1"
  top: "res_stage_3_481_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_481_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_481_1_top"
  top: "res_stage_3_481_1_top"
}
layer {
  name: "res_stage_3_481_2"
  type: "Convolution"
  bottom: "res_stage_3_481_1_top"
  top: "res_stage_3_481_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_481_2"
  type: "BatchNorm"
  bottom: "res_stage_3_481_2"
  top: "res_stage_3_481_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_481_2"  
  type: "Scale"
  bottom: "res_stage_3_481_2"
  top: "res_stage_3_481_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_481_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_481_2_top"
  top: "res_stage_3_481_2_top"
}
layer {
  name: "res_stage_3_481_3"
  type: "Convolution"
  bottom: "res_stage_3_481_2_top"
  top: "res_stage_3_481_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_481_3"
  type: "BatchNorm"
  bottom: "res_stage_3_481_3"
  top: "res_stage_3_481_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_481_3"  
  type: "Scale"
  bottom: "res_stage_3_481_3"
  top: "res_stage_3_481_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_481"
  type: "Eltwise"
  bottom: "res_3_480"
  bottom: "res_stage_3_481_3_top"
  top: "res_3_481"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_481_relu"
  type: "ReLU"
  bottom: "res_3_481"
  top: "res_3_481"
}
layer {
  name: "res_stage_3_482_1"
  type: "Convolution"
  bottom: "res_3_481"
  top: "res_stage_3_482_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_482_1"
  type: "BatchNorm"
  bottom: "res_stage_3_482_1"
  top: "res_stage_3_482_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_482_1"  
  type: "Scale"
  bottom: "res_stage_3_482_1"
  top: "res_stage_3_482_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_482_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_482_1_top"
  top: "res_stage_3_482_1_top"
}
layer {
  name: "res_stage_3_482_2"
  type: "Convolution"
  bottom: "res_stage_3_482_1_top"
  top: "res_stage_3_482_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_482_2"
  type: "BatchNorm"
  bottom: "res_stage_3_482_2"
  top: "res_stage_3_482_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_482_2"  
  type: "Scale"
  bottom: "res_stage_3_482_2"
  top: "res_stage_3_482_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_482_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_482_2_top"
  top: "res_stage_3_482_2_top"
}
layer {
  name: "res_stage_3_482_3"
  type: "Convolution"
  bottom: "res_stage_3_482_2_top"
  top: "res_stage_3_482_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_482_3"
  type: "BatchNorm"
  bottom: "res_stage_3_482_3"
  top: "res_stage_3_482_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_482_3"  
  type: "Scale"
  bottom: "res_stage_3_482_3"
  top: "res_stage_3_482_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_482"
  type: "Eltwise"
  bottom: "res_3_481"
  bottom: "res_stage_3_482_3_top"
  top: "res_3_482"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_482_relu"
  type: "ReLU"
  bottom: "res_3_482"
  top: "res_3_482"
}
layer {
  name: "res_stage_3_483_1"
  type: "Convolution"
  bottom: "res_3_482"
  top: "res_stage_3_483_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_483_1"
  type: "BatchNorm"
  bottom: "res_stage_3_483_1"
  top: "res_stage_3_483_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_483_1"  
  type: "Scale"
  bottom: "res_stage_3_483_1"
  top: "res_stage_3_483_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_483_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_483_1_top"
  top: "res_stage_3_483_1_top"
}
layer {
  name: "res_stage_3_483_2"
  type: "Convolution"
  bottom: "res_stage_3_483_1_top"
  top: "res_stage_3_483_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_483_2"
  type: "BatchNorm"
  bottom: "res_stage_3_483_2"
  top: "res_stage_3_483_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_483_2"  
  type: "Scale"
  bottom: "res_stage_3_483_2"
  top: "res_stage_3_483_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_483_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_483_2_top"
  top: "res_stage_3_483_2_top"
}
layer {
  name: "res_stage_3_483_3"
  type: "Convolution"
  bottom: "res_stage_3_483_2_top"
  top: "res_stage_3_483_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_483_3"
  type: "BatchNorm"
  bottom: "res_stage_3_483_3"
  top: "res_stage_3_483_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_483_3"  
  type: "Scale"
  bottom: "res_stage_3_483_3"
  top: "res_stage_3_483_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_483"
  type: "Eltwise"
  bottom: "res_3_482"
  bottom: "res_stage_3_483_3_top"
  top: "res_3_483"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_483_relu"
  type: "ReLU"
  bottom: "res_3_483"
  top: "res_3_483"
}
layer {
  name: "res_stage_3_484_1"
  type: "Convolution"
  bottom: "res_3_483"
  top: "res_stage_3_484_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_484_1"
  type: "BatchNorm"
  bottom: "res_stage_3_484_1"
  top: "res_stage_3_484_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_484_1"  
  type: "Scale"
  bottom: "res_stage_3_484_1"
  top: "res_stage_3_484_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_484_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_484_1_top"
  top: "res_stage_3_484_1_top"
}
layer {
  name: "res_stage_3_484_2"
  type: "Convolution"
  bottom: "res_stage_3_484_1_top"
  top: "res_stage_3_484_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_484_2"
  type: "BatchNorm"
  bottom: "res_stage_3_484_2"
  top: "res_stage_3_484_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_484_2"  
  type: "Scale"
  bottom: "res_stage_3_484_2"
  top: "res_stage_3_484_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_484_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_484_2_top"
  top: "res_stage_3_484_2_top"
}
layer {
  name: "res_stage_3_484_3"
  type: "Convolution"
  bottom: "res_stage_3_484_2_top"
  top: "res_stage_3_484_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_484_3"
  type: "BatchNorm"
  bottom: "res_stage_3_484_3"
  top: "res_stage_3_484_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_484_3"  
  type: "Scale"
  bottom: "res_stage_3_484_3"
  top: "res_stage_3_484_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_484"
  type: "Eltwise"
  bottom: "res_3_483"
  bottom: "res_stage_3_484_3_top"
  top: "res_3_484"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_484_relu"
  type: "ReLU"
  bottom: "res_3_484"
  top: "res_3_484"
}
layer {
  name: "res_stage_3_485_1"
  type: "Convolution"
  bottom: "res_3_484"
  top: "res_stage_3_485_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_485_1"
  type: "BatchNorm"
  bottom: "res_stage_3_485_1"
  top: "res_stage_3_485_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_485_1"  
  type: "Scale"
  bottom: "res_stage_3_485_1"
  top: "res_stage_3_485_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_485_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_485_1_top"
  top: "res_stage_3_485_1_top"
}
layer {
  name: "res_stage_3_485_2"
  type: "Convolution"
  bottom: "res_stage_3_485_1_top"
  top: "res_stage_3_485_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_485_2"
  type: "BatchNorm"
  bottom: "res_stage_3_485_2"
  top: "res_stage_3_485_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_485_2"  
  type: "Scale"
  bottom: "res_stage_3_485_2"
  top: "res_stage_3_485_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_485_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_485_2_top"
  top: "res_stage_3_485_2_top"
}
layer {
  name: "res_stage_3_485_3"
  type: "Convolution"
  bottom: "res_stage_3_485_2_top"
  top: "res_stage_3_485_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_485_3"
  type: "BatchNorm"
  bottom: "res_stage_3_485_3"
  top: "res_stage_3_485_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_485_3"  
  type: "Scale"
  bottom: "res_stage_3_485_3"
  top: "res_stage_3_485_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_485"
  type: "Eltwise"
  bottom: "res_3_484"
  bottom: "res_stage_3_485_3_top"
  top: "res_3_485"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_485_relu"
  type: "ReLU"
  bottom: "res_3_485"
  top: "res_3_485"
}
layer {
  name: "res_stage_3_486_1"
  type: "Convolution"
  bottom: "res_3_485"
  top: "res_stage_3_486_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_486_1"
  type: "BatchNorm"
  bottom: "res_stage_3_486_1"
  top: "res_stage_3_486_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_486_1"  
  type: "Scale"
  bottom: "res_stage_3_486_1"
  top: "res_stage_3_486_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_486_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_486_1_top"
  top: "res_stage_3_486_1_top"
}
layer {
  name: "res_stage_3_486_2"
  type: "Convolution"
  bottom: "res_stage_3_486_1_top"
  top: "res_stage_3_486_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_486_2"
  type: "BatchNorm"
  bottom: "res_stage_3_486_2"
  top: "res_stage_3_486_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_486_2"  
  type: "Scale"
  bottom: "res_stage_3_486_2"
  top: "res_stage_3_486_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_486_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_486_2_top"
  top: "res_stage_3_486_2_top"
}
layer {
  name: "res_stage_3_486_3"
  type: "Convolution"
  bottom: "res_stage_3_486_2_top"
  top: "res_stage_3_486_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_486_3"
  type: "BatchNorm"
  bottom: "res_stage_3_486_3"
  top: "res_stage_3_486_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_486_3"  
  type: "Scale"
  bottom: "res_stage_3_486_3"
  top: "res_stage_3_486_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_486"
  type: "Eltwise"
  bottom: "res_3_485"
  bottom: "res_stage_3_486_3_top"
  top: "res_3_486"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_486_relu"
  type: "ReLU"
  bottom: "res_3_486"
  top: "res_3_486"
}
layer {
  name: "res_stage_3_487_1"
  type: "Convolution"
  bottom: "res_3_486"
  top: "res_stage_3_487_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_487_1"
  type: "BatchNorm"
  bottom: "res_stage_3_487_1"
  top: "res_stage_3_487_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_487_1"  
  type: "Scale"
  bottom: "res_stage_3_487_1"
  top: "res_stage_3_487_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_487_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_487_1_top"
  top: "res_stage_3_487_1_top"
}
layer {
  name: "res_stage_3_487_2"
  type: "Convolution"
  bottom: "res_stage_3_487_1_top"
  top: "res_stage_3_487_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_487_2"
  type: "BatchNorm"
  bottom: "res_stage_3_487_2"
  top: "res_stage_3_487_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_487_2"  
  type: "Scale"
  bottom: "res_stage_3_487_2"
  top: "res_stage_3_487_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_487_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_487_2_top"
  top: "res_stage_3_487_2_top"
}
layer {
  name: "res_stage_3_487_3"
  type: "Convolution"
  bottom: "res_stage_3_487_2_top"
  top: "res_stage_3_487_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_487_3"
  type: "BatchNorm"
  bottom: "res_stage_3_487_3"
  top: "res_stage_3_487_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_487_3"  
  type: "Scale"
  bottom: "res_stage_3_487_3"
  top: "res_stage_3_487_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_487"
  type: "Eltwise"
  bottom: "res_3_486"
  bottom: "res_stage_3_487_3_top"
  top: "res_3_487"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_487_relu"
  type: "ReLU"
  bottom: "res_3_487"
  top: "res_3_487"
}
layer {
  name: "res_stage_3_488_1"
  type: "Convolution"
  bottom: "res_3_487"
  top: "res_stage_3_488_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_488_1"
  type: "BatchNorm"
  bottom: "res_stage_3_488_1"
  top: "res_stage_3_488_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_488_1"  
  type: "Scale"
  bottom: "res_stage_3_488_1"
  top: "res_stage_3_488_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_488_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_488_1_top"
  top: "res_stage_3_488_1_top"
}
layer {
  name: "res_stage_3_488_2"
  type: "Convolution"
  bottom: "res_stage_3_488_1_top"
  top: "res_stage_3_488_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_488_2"
  type: "BatchNorm"
  bottom: "res_stage_3_488_2"
  top: "res_stage_3_488_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_488_2"  
  type: "Scale"
  bottom: "res_stage_3_488_2"
  top: "res_stage_3_488_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_488_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_488_2_top"
  top: "res_stage_3_488_2_top"
}
layer {
  name: "res_stage_3_488_3"
  type: "Convolution"
  bottom: "res_stage_3_488_2_top"
  top: "res_stage_3_488_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_488_3"
  type: "BatchNorm"
  bottom: "res_stage_3_488_3"
  top: "res_stage_3_488_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_488_3"  
  type: "Scale"
  bottom: "res_stage_3_488_3"
  top: "res_stage_3_488_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_488"
  type: "Eltwise"
  bottom: "res_3_487"
  bottom: "res_stage_3_488_3_top"
  top: "res_3_488"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_488_relu"
  type: "ReLU"
  bottom: "res_3_488"
  top: "res_3_488"
}
layer {
  name: "res_stage_3_489_1"
  type: "Convolution"
  bottom: "res_3_488"
  top: "res_stage_3_489_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_489_1"
  type: "BatchNorm"
  bottom: "res_stage_3_489_1"
  top: "res_stage_3_489_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_489_1"  
  type: "Scale"
  bottom: "res_stage_3_489_1"
  top: "res_stage_3_489_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_489_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_489_1_top"
  top: "res_stage_3_489_1_top"
}
layer {
  name: "res_stage_3_489_2"
  type: "Convolution"
  bottom: "res_stage_3_489_1_top"
  top: "res_stage_3_489_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_489_2"
  type: "BatchNorm"
  bottom: "res_stage_3_489_2"
  top: "res_stage_3_489_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_489_2"  
  type: "Scale"
  bottom: "res_stage_3_489_2"
  top: "res_stage_3_489_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_489_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_489_2_top"
  top: "res_stage_3_489_2_top"
}
layer {
  name: "res_stage_3_489_3"
  type: "Convolution"
  bottom: "res_stage_3_489_2_top"
  top: "res_stage_3_489_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_489_3"
  type: "BatchNorm"
  bottom: "res_stage_3_489_3"
  top: "res_stage_3_489_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_489_3"  
  type: "Scale"
  bottom: "res_stage_3_489_3"
  top: "res_stage_3_489_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_489"
  type: "Eltwise"
  bottom: "res_3_488"
  bottom: "res_stage_3_489_3_top"
  top: "res_3_489"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_489_relu"
  type: "ReLU"
  bottom: "res_3_489"
  top: "res_3_489"
}
layer {
  name: "res_stage_3_490_1"
  type: "Convolution"
  bottom: "res_3_489"
  top: "res_stage_3_490_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_490_1"
  type: "BatchNorm"
  bottom: "res_stage_3_490_1"
  top: "res_stage_3_490_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_490_1"  
  type: "Scale"
  bottom: "res_stage_3_490_1"
  top: "res_stage_3_490_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_490_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_490_1_top"
  top: "res_stage_3_490_1_top"
}
layer {
  name: "res_stage_3_490_2"
  type: "Convolution"
  bottom: "res_stage_3_490_1_top"
  top: "res_stage_3_490_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_490_2"
  type: "BatchNorm"
  bottom: "res_stage_3_490_2"
  top: "res_stage_3_490_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_490_2"  
  type: "Scale"
  bottom: "res_stage_3_490_2"
  top: "res_stage_3_490_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_490_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_490_2_top"
  top: "res_stage_3_490_2_top"
}
layer {
  name: "res_stage_3_490_3"
  type: "Convolution"
  bottom: "res_stage_3_490_2_top"
  top: "res_stage_3_490_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_490_3"
  type: "BatchNorm"
  bottom: "res_stage_3_490_3"
  top: "res_stage_3_490_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_490_3"  
  type: "Scale"
  bottom: "res_stage_3_490_3"
  top: "res_stage_3_490_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_490"
  type: "Eltwise"
  bottom: "res_3_489"
  bottom: "res_stage_3_490_3_top"
  top: "res_3_490"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_490_relu"
  type: "ReLU"
  bottom: "res_3_490"
  top: "res_3_490"
}
layer {
  name: "res_stage_3_491_1"
  type: "Convolution"
  bottom: "res_3_490"
  top: "res_stage_3_491_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_491_1"
  type: "BatchNorm"
  bottom: "res_stage_3_491_1"
  top: "res_stage_3_491_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_491_1"  
  type: "Scale"
  bottom: "res_stage_3_491_1"
  top: "res_stage_3_491_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_491_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_491_1_top"
  top: "res_stage_3_491_1_top"
}
layer {
  name: "res_stage_3_491_2"
  type: "Convolution"
  bottom: "res_stage_3_491_1_top"
  top: "res_stage_3_491_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_491_2"
  type: "BatchNorm"
  bottom: "res_stage_3_491_2"
  top: "res_stage_3_491_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_491_2"  
  type: "Scale"
  bottom: "res_stage_3_491_2"
  top: "res_stage_3_491_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_491_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_491_2_top"
  top: "res_stage_3_491_2_top"
}
layer {
  name: "res_stage_3_491_3"
  type: "Convolution"
  bottom: "res_stage_3_491_2_top"
  top: "res_stage_3_491_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_491_3"
  type: "BatchNorm"
  bottom: "res_stage_3_491_3"
  top: "res_stage_3_491_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_491_3"  
  type: "Scale"
  bottom: "res_stage_3_491_3"
  top: "res_stage_3_491_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_491"
  type: "Eltwise"
  bottom: "res_3_490"
  bottom: "res_stage_3_491_3_top"
  top: "res_3_491"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_491_relu"
  type: "ReLU"
  bottom: "res_3_491"
  top: "res_3_491"
}
layer {
  name: "res_stage_3_492_1"
  type: "Convolution"
  bottom: "res_3_491"
  top: "res_stage_3_492_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_492_1"
  type: "BatchNorm"
  bottom: "res_stage_3_492_1"
  top: "res_stage_3_492_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_492_1"  
  type: "Scale"
  bottom: "res_stage_3_492_1"
  top: "res_stage_3_492_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_492_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_492_1_top"
  top: "res_stage_3_492_1_top"
}
layer {
  name: "res_stage_3_492_2"
  type: "Convolution"
  bottom: "res_stage_3_492_1_top"
  top: "res_stage_3_492_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_492_2"
  type: "BatchNorm"
  bottom: "res_stage_3_492_2"
  top: "res_stage_3_492_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_492_2"  
  type: "Scale"
  bottom: "res_stage_3_492_2"
  top: "res_stage_3_492_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_492_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_492_2_top"
  top: "res_stage_3_492_2_top"
}
layer {
  name: "res_stage_3_492_3"
  type: "Convolution"
  bottom: "res_stage_3_492_2_top"
  top: "res_stage_3_492_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_492_3"
  type: "BatchNorm"
  bottom: "res_stage_3_492_3"
  top: "res_stage_3_492_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_492_3"  
  type: "Scale"
  bottom: "res_stage_3_492_3"
  top: "res_stage_3_492_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_492"
  type: "Eltwise"
  bottom: "res_3_491"
  bottom: "res_stage_3_492_3_top"
  top: "res_3_492"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_492_relu"
  type: "ReLU"
  bottom: "res_3_492"
  top: "res_3_492"
}
layer {
  name: "res_stage_3_493_1"
  type: "Convolution"
  bottom: "res_3_492"
  top: "res_stage_3_493_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_493_1"
  type: "BatchNorm"
  bottom: "res_stage_3_493_1"
  top: "res_stage_3_493_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_493_1"  
  type: "Scale"
  bottom: "res_stage_3_493_1"
  top: "res_stage_3_493_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_493_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_493_1_top"
  top: "res_stage_3_493_1_top"
}
layer {
  name: "res_stage_3_493_2"
  type: "Convolution"
  bottom: "res_stage_3_493_1_top"
  top: "res_stage_3_493_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_493_2"
  type: "BatchNorm"
  bottom: "res_stage_3_493_2"
  top: "res_stage_3_493_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_493_2"  
  type: "Scale"
  bottom: "res_stage_3_493_2"
  top: "res_stage_3_493_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_493_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_493_2_top"
  top: "res_stage_3_493_2_top"
}
layer {
  name: "res_stage_3_493_3"
  type: "Convolution"
  bottom: "res_stage_3_493_2_top"
  top: "res_stage_3_493_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_493_3"
  type: "BatchNorm"
  bottom: "res_stage_3_493_3"
  top: "res_stage_3_493_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_493_3"  
  type: "Scale"
  bottom: "res_stage_3_493_3"
  top: "res_stage_3_493_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_493"
  type: "Eltwise"
  bottom: "res_3_492"
  bottom: "res_stage_3_493_3_top"
  top: "res_3_493"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_493_relu"
  type: "ReLU"
  bottom: "res_3_493"
  top: "res_3_493"
}
layer {
  name: "res_stage_3_494_1"
  type: "Convolution"
  bottom: "res_3_493"
  top: "res_stage_3_494_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_494_1"
  type: "BatchNorm"
  bottom: "res_stage_3_494_1"
  top: "res_stage_3_494_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_494_1"  
  type: "Scale"
  bottom: "res_stage_3_494_1"
  top: "res_stage_3_494_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_494_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_494_1_top"
  top: "res_stage_3_494_1_top"
}
layer {
  name: "res_stage_3_494_2"
  type: "Convolution"
  bottom: "res_stage_3_494_1_top"
  top: "res_stage_3_494_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_494_2"
  type: "BatchNorm"
  bottom: "res_stage_3_494_2"
  top: "res_stage_3_494_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_494_2"  
  type: "Scale"
  bottom: "res_stage_3_494_2"
  top: "res_stage_3_494_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_494_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_494_2_top"
  top: "res_stage_3_494_2_top"
}
layer {
  name: "res_stage_3_494_3"
  type: "Convolution"
  bottom: "res_stage_3_494_2_top"
  top: "res_stage_3_494_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_494_3"
  type: "BatchNorm"
  bottom: "res_stage_3_494_3"
  top: "res_stage_3_494_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_494_3"  
  type: "Scale"
  bottom: "res_stage_3_494_3"
  top: "res_stage_3_494_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_494"
  type: "Eltwise"
  bottom: "res_3_493"
  bottom: "res_stage_3_494_3_top"
  top: "res_3_494"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_494_relu"
  type: "ReLU"
  bottom: "res_3_494"
  top: "res_3_494"
}
layer {
  name: "res_stage_3_495_1"
  type: "Convolution"
  bottom: "res_3_494"
  top: "res_stage_3_495_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_495_1"
  type: "BatchNorm"
  bottom: "res_stage_3_495_1"
  top: "res_stage_3_495_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_495_1"  
  type: "Scale"
  bottom: "res_stage_3_495_1"
  top: "res_stage_3_495_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_495_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_495_1_top"
  top: "res_stage_3_495_1_top"
}
layer {
  name: "res_stage_3_495_2"
  type: "Convolution"
  bottom: "res_stage_3_495_1_top"
  top: "res_stage_3_495_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_495_2"
  type: "BatchNorm"
  bottom: "res_stage_3_495_2"
  top: "res_stage_3_495_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_495_2"  
  type: "Scale"
  bottom: "res_stage_3_495_2"
  top: "res_stage_3_495_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_495_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_495_2_top"
  top: "res_stage_3_495_2_top"
}
layer {
  name: "res_stage_3_495_3"
  type: "Convolution"
  bottom: "res_stage_3_495_2_top"
  top: "res_stage_3_495_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_495_3"
  type: "BatchNorm"
  bottom: "res_stage_3_495_3"
  top: "res_stage_3_495_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_495_3"  
  type: "Scale"
  bottom: "res_stage_3_495_3"
  top: "res_stage_3_495_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_495"
  type: "Eltwise"
  bottom: "res_3_494"
  bottom: "res_stage_3_495_3_top"
  top: "res_3_495"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_495_relu"
  type: "ReLU"
  bottom: "res_3_495"
  top: "res_3_495"
}
layer {
  name: "res_stage_3_496_1"
  type: "Convolution"
  bottom: "res_3_495"
  top: "res_stage_3_496_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_496_1"
  type: "BatchNorm"
  bottom: "res_stage_3_496_1"
  top: "res_stage_3_496_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_496_1"  
  type: "Scale"
  bottom: "res_stage_3_496_1"
  top: "res_stage_3_496_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_496_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_496_1_top"
  top: "res_stage_3_496_1_top"
}
layer {
  name: "res_stage_3_496_2"
  type: "Convolution"
  bottom: "res_stage_3_496_1_top"
  top: "res_stage_3_496_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_496_2"
  type: "BatchNorm"
  bottom: "res_stage_3_496_2"
  top: "res_stage_3_496_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_496_2"  
  type: "Scale"
  bottom: "res_stage_3_496_2"
  top: "res_stage_3_496_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_496_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_496_2_top"
  top: "res_stage_3_496_2_top"
}
layer {
  name: "res_stage_3_496_3"
  type: "Convolution"
  bottom: "res_stage_3_496_2_top"
  top: "res_stage_3_496_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_496_3"
  type: "BatchNorm"
  bottom: "res_stage_3_496_3"
  top: "res_stage_3_496_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_496_3"  
  type: "Scale"
  bottom: "res_stage_3_496_3"
  top: "res_stage_3_496_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_496"
  type: "Eltwise"
  bottom: "res_3_495"
  bottom: "res_stage_3_496_3_top"
  top: "res_3_496"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_496_relu"
  type: "ReLU"
  bottom: "res_3_496"
  top: "res_3_496"
}
layer {
  name: "res_stage_3_497_1"
  type: "Convolution"
  bottom: "res_3_496"
  top: "res_stage_3_497_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_497_1"
  type: "BatchNorm"
  bottom: "res_stage_3_497_1"
  top: "res_stage_3_497_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_497_1"  
  type: "Scale"
  bottom: "res_stage_3_497_1"
  top: "res_stage_3_497_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_497_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_497_1_top"
  top: "res_stage_3_497_1_top"
}
layer {
  name: "res_stage_3_497_2"
  type: "Convolution"
  bottom: "res_stage_3_497_1_top"
  top: "res_stage_3_497_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_497_2"
  type: "BatchNorm"
  bottom: "res_stage_3_497_2"
  top: "res_stage_3_497_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_497_2"  
  type: "Scale"
  bottom: "res_stage_3_497_2"
  top: "res_stage_3_497_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_497_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_497_2_top"
  top: "res_stage_3_497_2_top"
}
layer {
  name: "res_stage_3_497_3"
  type: "Convolution"
  bottom: "res_stage_3_497_2_top"
  top: "res_stage_3_497_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_497_3"
  type: "BatchNorm"
  bottom: "res_stage_3_497_3"
  top: "res_stage_3_497_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_497_3"  
  type: "Scale"
  bottom: "res_stage_3_497_3"
  top: "res_stage_3_497_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_497"
  type: "Eltwise"
  bottom: "res_3_496"
  bottom: "res_stage_3_497_3_top"
  top: "res_3_497"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_497_relu"
  type: "ReLU"
  bottom: "res_3_497"
  top: "res_3_497"
}
layer {
  name: "res_stage_3_498_1"
  type: "Convolution"
  bottom: "res_3_497"
  top: "res_stage_3_498_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_498_1"
  type: "BatchNorm"
  bottom: "res_stage_3_498_1"
  top: "res_stage_3_498_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_498_1"  
  type: "Scale"
  bottom: "res_stage_3_498_1"
  top: "res_stage_3_498_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_498_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_498_1_top"
  top: "res_stage_3_498_1_top"
}
layer {
  name: "res_stage_3_498_2"
  type: "Convolution"
  bottom: "res_stage_3_498_1_top"
  top: "res_stage_3_498_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_498_2"
  type: "BatchNorm"
  bottom: "res_stage_3_498_2"
  top: "res_stage_3_498_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_498_2"  
  type: "Scale"
  bottom: "res_stage_3_498_2"
  top: "res_stage_3_498_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_498_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_498_2_top"
  top: "res_stage_3_498_2_top"
}
layer {
  name: "res_stage_3_498_3"
  type: "Convolution"
  bottom: "res_stage_3_498_2_top"
  top: "res_stage_3_498_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_498_3"
  type: "BatchNorm"
  bottom: "res_stage_3_498_3"
  top: "res_stage_3_498_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_498_3"  
  type: "Scale"
  bottom: "res_stage_3_498_3"
  top: "res_stage_3_498_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_498"
  type: "Eltwise"
  bottom: "res_3_497"
  bottom: "res_stage_3_498_3_top"
  top: "res_3_498"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_498_relu"
  type: "ReLU"
  bottom: "res_3_498"
  top: "res_3_498"
}
layer {
  name: "res_stage_3_499_1"
  type: "Convolution"
  bottom: "res_3_498"
  top: "res_stage_3_499_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_499_1"
  type: "BatchNorm"
  bottom: "res_stage_3_499_1"
  top: "res_stage_3_499_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_499_1"  
  type: "Scale"
  bottom: "res_stage_3_499_1"
  top: "res_stage_3_499_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_499_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_499_1_top"
  top: "res_stage_3_499_1_top"
}
layer {
  name: "res_stage_3_499_2"
  type: "Convolution"
  bottom: "res_stage_3_499_1_top"
  top: "res_stage_3_499_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_499_2"
  type: "BatchNorm"
  bottom: "res_stage_3_499_2"
  top: "res_stage_3_499_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_499_2"  
  type: "Scale"
  bottom: "res_stage_3_499_2"
  top: "res_stage_3_499_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_499_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_499_2_top"
  top: "res_stage_3_499_2_top"
}
layer {
  name: "res_stage_3_499_3"
  type: "Convolution"
  bottom: "res_stage_3_499_2_top"
  top: "res_stage_3_499_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_499_3"
  type: "BatchNorm"
  bottom: "res_stage_3_499_3"
  top: "res_stage_3_499_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_499_3"  
  type: "Scale"
  bottom: "res_stage_3_499_3"
  top: "res_stage_3_499_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_499"
  type: "Eltwise"
  bottom: "res_3_498"
  bottom: "res_stage_3_499_3_top"
  top: "res_3_499"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_499_relu"
  type: "ReLU"
  bottom: "res_3_499"
  top: "res_3_499"
}
layer {
  name: "res_stage_3_500_1"
  type: "Convolution"
  bottom: "res_3_499"
  top: "res_stage_3_500_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_500_1"
  type: "BatchNorm"
  bottom: "res_stage_3_500_1"
  top: "res_stage_3_500_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_500_1"  
  type: "Scale"
  bottom: "res_stage_3_500_1"
  top: "res_stage_3_500_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_500_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_500_1_top"
  top: "res_stage_3_500_1_top"
}
layer {
  name: "res_stage_3_500_2"
  type: "Convolution"
  bottom: "res_stage_3_500_1_top"
  top: "res_stage_3_500_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_500_2"
  type: "BatchNorm"
  bottom: "res_stage_3_500_2"
  top: "res_stage_3_500_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_500_2"  
  type: "Scale"
  bottom: "res_stage_3_500_2"
  top: "res_stage_3_500_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_500_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_500_2_top"
  top: "res_stage_3_500_2_top"
}
layer {
  name: "res_stage_3_500_3"
  type: "Convolution"
  bottom: "res_stage_3_500_2_top"
  top: "res_stage_3_500_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_500_3"
  type: "BatchNorm"
  bottom: "res_stage_3_500_3"
  top: "res_stage_3_500_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_500_3"  
  type: "Scale"
  bottom: "res_stage_3_500_3"
  top: "res_stage_3_500_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_500"
  type: "Eltwise"
  bottom: "res_3_499"
  bottom: "res_stage_3_500_3_top"
  top: "res_3_500"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_500_relu"
  type: "ReLU"
  bottom: "res_3_500"
  top: "res_3_500"
}
layer {
  name: "res_stage_3_501_1"
  type: "Convolution"
  bottom: "res_3_500"
  top: "res_stage_3_501_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_501_1"
  type: "BatchNorm"
  bottom: "res_stage_3_501_1"
  top: "res_stage_3_501_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_501_1"  
  type: "Scale"
  bottom: "res_stage_3_501_1"
  top: "res_stage_3_501_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_501_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_501_1_top"
  top: "res_stage_3_501_1_top"
}
layer {
  name: "res_stage_3_501_2"
  type: "Convolution"
  bottom: "res_stage_3_501_1_top"
  top: "res_stage_3_501_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_501_2"
  type: "BatchNorm"
  bottom: "res_stage_3_501_2"
  top: "res_stage_3_501_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_501_2"  
  type: "Scale"
  bottom: "res_stage_3_501_2"
  top: "res_stage_3_501_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_501_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_501_2_top"
  top: "res_stage_3_501_2_top"
}
layer {
  name: "res_stage_3_501_3"
  type: "Convolution"
  bottom: "res_stage_3_501_2_top"
  top: "res_stage_3_501_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_501_3"
  type: "BatchNorm"
  bottom: "res_stage_3_501_3"
  top: "res_stage_3_501_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_501_3"  
  type: "Scale"
  bottom: "res_stage_3_501_3"
  top: "res_stage_3_501_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_501"
  type: "Eltwise"
  bottom: "res_3_500"
  bottom: "res_stage_3_501_3_top"
  top: "res_3_501"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_501_relu"
  type: "ReLU"
  bottom: "res_3_501"
  top: "res_3_501"
}
layer {
  name: "res_stage_3_502_1"
  type: "Convolution"
  bottom: "res_3_501"
  top: "res_stage_3_502_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_502_1"
  type: "BatchNorm"
  bottom: "res_stage_3_502_1"
  top: "res_stage_3_502_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_502_1"  
  type: "Scale"
  bottom: "res_stage_3_502_1"
  top: "res_stage_3_502_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_502_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_502_1_top"
  top: "res_stage_3_502_1_top"
}
layer {
  name: "res_stage_3_502_2"
  type: "Convolution"
  bottom: "res_stage_3_502_1_top"
  top: "res_stage_3_502_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_502_2"
  type: "BatchNorm"
  bottom: "res_stage_3_502_2"
  top: "res_stage_3_502_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_502_2"  
  type: "Scale"
  bottom: "res_stage_3_502_2"
  top: "res_stage_3_502_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_502_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_502_2_top"
  top: "res_stage_3_502_2_top"
}
layer {
  name: "res_stage_3_502_3"
  type: "Convolution"
  bottom: "res_stage_3_502_2_top"
  top: "res_stage_3_502_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_502_3"
  type: "BatchNorm"
  bottom: "res_stage_3_502_3"
  top: "res_stage_3_502_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_502_3"  
  type: "Scale"
  bottom: "res_stage_3_502_3"
  top: "res_stage_3_502_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_502"
  type: "Eltwise"
  bottom: "res_3_501"
  bottom: "res_stage_3_502_3_top"
  top: "res_3_502"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_502_relu"
  type: "ReLU"
  bottom: "res_3_502"
  top: "res_3_502"
}
layer {
  name: "res_stage_3_503_1"
  type: "Convolution"
  bottom: "res_3_502"
  top: "res_stage_3_503_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_503_1"
  type: "BatchNorm"
  bottom: "res_stage_3_503_1"
  top: "res_stage_3_503_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_503_1"  
  type: "Scale"
  bottom: "res_stage_3_503_1"
  top: "res_stage_3_503_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_503_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_503_1_top"
  top: "res_stage_3_503_1_top"
}
layer {
  name: "res_stage_3_503_2"
  type: "Convolution"
  bottom: "res_stage_3_503_1_top"
  top: "res_stage_3_503_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_503_2"
  type: "BatchNorm"
  bottom: "res_stage_3_503_2"
  top: "res_stage_3_503_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_503_2"  
  type: "Scale"
  bottom: "res_stage_3_503_2"
  top: "res_stage_3_503_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_503_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_503_2_top"
  top: "res_stage_3_503_2_top"
}
layer {
  name: "res_stage_3_503_3"
  type: "Convolution"
  bottom: "res_stage_3_503_2_top"
  top: "res_stage_3_503_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_503_3"
  type: "BatchNorm"
  bottom: "res_stage_3_503_3"
  top: "res_stage_3_503_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_503_3"  
  type: "Scale"
  bottom: "res_stage_3_503_3"
  top: "res_stage_3_503_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_503"
  type: "Eltwise"
  bottom: "res_3_502"
  bottom: "res_stage_3_503_3_top"
  top: "res_3_503"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_503_relu"
  type: "ReLU"
  bottom: "res_3_503"
  top: "res_3_503"
}
layer {
  name: "res_stage_3_504_1"
  type: "Convolution"
  bottom: "res_3_503"
  top: "res_stage_3_504_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_504_1"
  type: "BatchNorm"
  bottom: "res_stage_3_504_1"
  top: "res_stage_3_504_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_504_1"  
  type: "Scale"
  bottom: "res_stage_3_504_1"
  top: "res_stage_3_504_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_504_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_504_1_top"
  top: "res_stage_3_504_1_top"
}
layer {
  name: "res_stage_3_504_2"
  type: "Convolution"
  bottom: "res_stage_3_504_1_top"
  top: "res_stage_3_504_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_504_2"
  type: "BatchNorm"
  bottom: "res_stage_3_504_2"
  top: "res_stage_3_504_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_504_2"  
  type: "Scale"
  bottom: "res_stage_3_504_2"
  top: "res_stage_3_504_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_504_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_504_2_top"
  top: "res_stage_3_504_2_top"
}
layer {
  name: "res_stage_3_504_3"
  type: "Convolution"
  bottom: "res_stage_3_504_2_top"
  top: "res_stage_3_504_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_504_3"
  type: "BatchNorm"
  bottom: "res_stage_3_504_3"
  top: "res_stage_3_504_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_504_3"  
  type: "Scale"
  bottom: "res_stage_3_504_3"
  top: "res_stage_3_504_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_504"
  type: "Eltwise"
  bottom: "res_3_503"
  bottom: "res_stage_3_504_3_top"
  top: "res_3_504"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_504_relu"
  type: "ReLU"
  bottom: "res_3_504"
  top: "res_3_504"
}
layer {
  name: "res_stage_3_505_1"
  type: "Convolution"
  bottom: "res_3_504"
  top: "res_stage_3_505_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_505_1"
  type: "BatchNorm"
  bottom: "res_stage_3_505_1"
  top: "res_stage_3_505_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_505_1"  
  type: "Scale"
  bottom: "res_stage_3_505_1"
  top: "res_stage_3_505_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_505_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_505_1_top"
  top: "res_stage_3_505_1_top"
}
layer {
  name: "res_stage_3_505_2"
  type: "Convolution"
  bottom: "res_stage_3_505_1_top"
  top: "res_stage_3_505_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_505_2"
  type: "BatchNorm"
  bottom: "res_stage_3_505_2"
  top: "res_stage_3_505_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_505_2"  
  type: "Scale"
  bottom: "res_stage_3_505_2"
  top: "res_stage_3_505_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_505_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_505_2_top"
  top: "res_stage_3_505_2_top"
}
layer {
  name: "res_stage_3_505_3"
  type: "Convolution"
  bottom: "res_stage_3_505_2_top"
  top: "res_stage_3_505_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_505_3"
  type: "BatchNorm"
  bottom: "res_stage_3_505_3"
  top: "res_stage_3_505_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_505_3"  
  type: "Scale"
  bottom: "res_stage_3_505_3"
  top: "res_stage_3_505_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_505"
  type: "Eltwise"
  bottom: "res_3_504"
  bottom: "res_stage_3_505_3_top"
  top: "res_3_505"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_505_relu"
  type: "ReLU"
  bottom: "res_3_505"
  top: "res_3_505"
}
layer {
  name: "res_stage_3_506_1"
  type: "Convolution"
  bottom: "res_3_505"
  top: "res_stage_3_506_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_506_1"
  type: "BatchNorm"
  bottom: "res_stage_3_506_1"
  top: "res_stage_3_506_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_506_1"  
  type: "Scale"
  bottom: "res_stage_3_506_1"
  top: "res_stage_3_506_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_506_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_506_1_top"
  top: "res_stage_3_506_1_top"
}
layer {
  name: "res_stage_3_506_2"
  type: "Convolution"
  bottom: "res_stage_3_506_1_top"
  top: "res_stage_3_506_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_506_2"
  type: "BatchNorm"
  bottom: "res_stage_3_506_2"
  top: "res_stage_3_506_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_506_2"  
  type: "Scale"
  bottom: "res_stage_3_506_2"
  top: "res_stage_3_506_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_506_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_506_2_top"
  top: "res_stage_3_506_2_top"
}
layer {
  name: "res_stage_3_506_3"
  type: "Convolution"
  bottom: "res_stage_3_506_2_top"
  top: "res_stage_3_506_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_506_3"
  type: "BatchNorm"
  bottom: "res_stage_3_506_3"
  top: "res_stage_3_506_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_506_3"  
  type: "Scale"
  bottom: "res_stage_3_506_3"
  top: "res_stage_3_506_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_506"
  type: "Eltwise"
  bottom: "res_3_505"
  bottom: "res_stage_3_506_3_top"
  top: "res_3_506"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_506_relu"
  type: "ReLU"
  bottom: "res_3_506"
  top: "res_3_506"
}
layer {
  name: "res_stage_3_507_1"
  type: "Convolution"
  bottom: "res_3_506"
  top: "res_stage_3_507_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_507_1"
  type: "BatchNorm"
  bottom: "res_stage_3_507_1"
  top: "res_stage_3_507_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_507_1"  
  type: "Scale"
  bottom: "res_stage_3_507_1"
  top: "res_stage_3_507_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_507_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_507_1_top"
  top: "res_stage_3_507_1_top"
}
layer {
  name: "res_stage_3_507_2"
  type: "Convolution"
  bottom: "res_stage_3_507_1_top"
  top: "res_stage_3_507_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_507_2"
  type: "BatchNorm"
  bottom: "res_stage_3_507_2"
  top: "res_stage_3_507_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_507_2"  
  type: "Scale"
  bottom: "res_stage_3_507_2"
  top: "res_stage_3_507_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_507_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_507_2_top"
  top: "res_stage_3_507_2_top"
}
layer {
  name: "res_stage_3_507_3"
  type: "Convolution"
  bottom: "res_stage_3_507_2_top"
  top: "res_stage_3_507_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_507_3"
  type: "BatchNorm"
  bottom: "res_stage_3_507_3"
  top: "res_stage_3_507_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_507_3"  
  type: "Scale"
  bottom: "res_stage_3_507_3"
  top: "res_stage_3_507_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_507"
  type: "Eltwise"
  bottom: "res_3_506"
  bottom: "res_stage_3_507_3_top"
  top: "res_3_507"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_507_relu"
  type: "ReLU"
  bottom: "res_3_507"
  top: "res_3_507"
}
layer {
  name: "res_stage_3_508_1"
  type: "Convolution"
  bottom: "res_3_507"
  top: "res_stage_3_508_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_508_1"
  type: "BatchNorm"
  bottom: "res_stage_3_508_1"
  top: "res_stage_3_508_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_508_1"  
  type: "Scale"
  bottom: "res_stage_3_508_1"
  top: "res_stage_3_508_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_508_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_508_1_top"
  top: "res_stage_3_508_1_top"
}
layer {
  name: "res_stage_3_508_2"
  type: "Convolution"
  bottom: "res_stage_3_508_1_top"
  top: "res_stage_3_508_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_508_2"
  type: "BatchNorm"
  bottom: "res_stage_3_508_2"
  top: "res_stage_3_508_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_508_2"  
  type: "Scale"
  bottom: "res_stage_3_508_2"
  top: "res_stage_3_508_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_508_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_508_2_top"
  top: "res_stage_3_508_2_top"
}
layer {
  name: "res_stage_3_508_3"
  type: "Convolution"
  bottom: "res_stage_3_508_2_top"
  top: "res_stage_3_508_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_508_3"
  type: "BatchNorm"
  bottom: "res_stage_3_508_3"
  top: "res_stage_3_508_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_508_3"  
  type: "Scale"
  bottom: "res_stage_3_508_3"
  top: "res_stage_3_508_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_508"
  type: "Eltwise"
  bottom: "res_3_507"
  bottom: "res_stage_3_508_3_top"
  top: "res_3_508"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_508_relu"
  type: "ReLU"
  bottom: "res_3_508"
  top: "res_3_508"
}
layer {
  name: "res_stage_3_509_1"
  type: "Convolution"
  bottom: "res_3_508"
  top: "res_stage_3_509_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_509_1"
  type: "BatchNorm"
  bottom: "res_stage_3_509_1"
  top: "res_stage_3_509_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_509_1"  
  type: "Scale"
  bottom: "res_stage_3_509_1"
  top: "res_stage_3_509_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_509_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_509_1_top"
  top: "res_stage_3_509_1_top"
}
layer {
  name: "res_stage_3_509_2"
  type: "Convolution"
  bottom: "res_stage_3_509_1_top"
  top: "res_stage_3_509_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_509_2"
  type: "BatchNorm"
  bottom: "res_stage_3_509_2"
  top: "res_stage_3_509_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_509_2"  
  type: "Scale"
  bottom: "res_stage_3_509_2"
  top: "res_stage_3_509_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_509_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_509_2_top"
  top: "res_stage_3_509_2_top"
}
layer {
  name: "res_stage_3_509_3"
  type: "Convolution"
  bottom: "res_stage_3_509_2_top"
  top: "res_stage_3_509_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_509_3"
  type: "BatchNorm"
  bottom: "res_stage_3_509_3"
  top: "res_stage_3_509_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_509_3"  
  type: "Scale"
  bottom: "res_stage_3_509_3"
  top: "res_stage_3_509_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_509"
  type: "Eltwise"
  bottom: "res_3_508"
  bottom: "res_stage_3_509_3_top"
  top: "res_3_509"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_509_relu"
  type: "ReLU"
  bottom: "res_3_509"
  top: "res_3_509"
}
layer {
  name: "res_stage_3_510_1"
  type: "Convolution"
  bottom: "res_3_509"
  top: "res_stage_3_510_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_510_1"
  type: "BatchNorm"
  bottom: "res_stage_3_510_1"
  top: "res_stage_3_510_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_510_1"  
  type: "Scale"
  bottom: "res_stage_3_510_1"
  top: "res_stage_3_510_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_510_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_510_1_top"
  top: "res_stage_3_510_1_top"
}
layer {
  name: "res_stage_3_510_2"
  type: "Convolution"
  bottom: "res_stage_3_510_1_top"
  top: "res_stage_3_510_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_510_2"
  type: "BatchNorm"
  bottom: "res_stage_3_510_2"
  top: "res_stage_3_510_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_510_2"  
  type: "Scale"
  bottom: "res_stage_3_510_2"
  top: "res_stage_3_510_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_510_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_510_2_top"
  top: "res_stage_3_510_2_top"
}
layer {
  name: "res_stage_3_510_3"
  type: "Convolution"
  bottom: "res_stage_3_510_2_top"
  top: "res_stage_3_510_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_510_3"
  type: "BatchNorm"
  bottom: "res_stage_3_510_3"
  top: "res_stage_3_510_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_510_3"  
  type: "Scale"
  bottom: "res_stage_3_510_3"
  top: "res_stage_3_510_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_510"
  type: "Eltwise"
  bottom: "res_3_509"
  bottom: "res_stage_3_510_3_top"
  top: "res_3_510"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_510_relu"
  type: "ReLU"
  bottom: "res_3_510"
  top: "res_3_510"
}
layer {
  name: "res_stage_3_511_1"
  type: "Convolution"
  bottom: "res_3_510"
  top: "res_stage_3_511_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_511_1"
  type: "BatchNorm"
  bottom: "res_stage_3_511_1"
  top: "res_stage_3_511_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_511_1"  
  type: "Scale"
  bottom: "res_stage_3_511_1"
  top: "res_stage_3_511_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_511_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_511_1_top"
  top: "res_stage_3_511_1_top"
}
layer {
  name: "res_stage_3_511_2"
  type: "Convolution"
  bottom: "res_stage_3_511_1_top"
  top: "res_stage_3_511_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_511_2"
  type: "BatchNorm"
  bottom: "res_stage_3_511_2"
  top: "res_stage_3_511_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_511_2"  
  type: "Scale"
  bottom: "res_stage_3_511_2"
  top: "res_stage_3_511_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_511_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_511_2_top"
  top: "res_stage_3_511_2_top"
}
layer {
  name: "res_stage_3_511_3"
  type: "Convolution"
  bottom: "res_stage_3_511_2_top"
  top: "res_stage_3_511_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_511_3"
  type: "BatchNorm"
  bottom: "res_stage_3_511_3"
  top: "res_stage_3_511_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_511_3"  
  type: "Scale"
  bottom: "res_stage_3_511_3"
  top: "res_stage_3_511_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_511"
  type: "Eltwise"
  bottom: "res_3_510"
  bottom: "res_stage_3_511_3_top"
  top: "res_3_511"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_511_relu"
  type: "ReLU"
  bottom: "res_3_511"
  top: "res_3_511"
}
layer {
  name: "res_stage_3_512_1"
  type: "Convolution"
  bottom: "res_3_511"
  top: "res_stage_3_512_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_512_1"
  type: "BatchNorm"
  bottom: "res_stage_3_512_1"
  top: "res_stage_3_512_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_512_1"  
  type: "Scale"
  bottom: "res_stage_3_512_1"
  top: "res_stage_3_512_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_512_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_512_1_top"
  top: "res_stage_3_512_1_top"
}
layer {
  name: "res_stage_3_512_2"
  type: "Convolution"
  bottom: "res_stage_3_512_1_top"
  top: "res_stage_3_512_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_512_2"
  type: "BatchNorm"
  bottom: "res_stage_3_512_2"
  top: "res_stage_3_512_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_512_2"  
  type: "Scale"
  bottom: "res_stage_3_512_2"
  top: "res_stage_3_512_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_512_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_512_2_top"
  top: "res_stage_3_512_2_top"
}
layer {
  name: "res_stage_3_512_3"
  type: "Convolution"
  bottom: "res_stage_3_512_2_top"
  top: "res_stage_3_512_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_512_3"
  type: "BatchNorm"
  bottom: "res_stage_3_512_3"
  top: "res_stage_3_512_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_512_3"  
  type: "Scale"
  bottom: "res_stage_3_512_3"
  top: "res_stage_3_512_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_512"
  type: "Eltwise"
  bottom: "res_3_511"
  bottom: "res_stage_3_512_3_top"
  top: "res_3_512"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_512_relu"
  type: "ReLU"
  bottom: "res_3_512"
  top: "res_3_512"
}
layer {
  name: "res_stage_3_513_1"
  type: "Convolution"
  bottom: "res_3_512"
  top: "res_stage_3_513_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_513_1"
  type: "BatchNorm"
  bottom: "res_stage_3_513_1"
  top: "res_stage_3_513_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_513_1"  
  type: "Scale"
  bottom: "res_stage_3_513_1"
  top: "res_stage_3_513_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_513_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_513_1_top"
  top: "res_stage_3_513_1_top"
}
layer {
  name: "res_stage_3_513_2"
  type: "Convolution"
  bottom: "res_stage_3_513_1_top"
  top: "res_stage_3_513_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_513_2"
  type: "BatchNorm"
  bottom: "res_stage_3_513_2"
  top: "res_stage_3_513_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_513_2"  
  type: "Scale"
  bottom: "res_stage_3_513_2"
  top: "res_stage_3_513_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_513_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_513_2_top"
  top: "res_stage_3_513_2_top"
}
layer {
  name: "res_stage_3_513_3"
  type: "Convolution"
  bottom: "res_stage_3_513_2_top"
  top: "res_stage_3_513_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_513_3"
  type: "BatchNorm"
  bottom: "res_stage_3_513_3"
  top: "res_stage_3_513_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_513_3"  
  type: "Scale"
  bottom: "res_stage_3_513_3"
  top: "res_stage_3_513_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_513"
  type: "Eltwise"
  bottom: "res_3_512"
  bottom: "res_stage_3_513_3_top"
  top: "res_3_513"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_513_relu"
  type: "ReLU"
  bottom: "res_3_513"
  top: "res_3_513"
}
layer {
  name: "res_stage_3_514_1"
  type: "Convolution"
  bottom: "res_3_513"
  top: "res_stage_3_514_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_514_1"
  type: "BatchNorm"
  bottom: "res_stage_3_514_1"
  top: "res_stage_3_514_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_514_1"  
  type: "Scale"
  bottom: "res_stage_3_514_1"
  top: "res_stage_3_514_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_514_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_514_1_top"
  top: "res_stage_3_514_1_top"
}
layer {
  name: "res_stage_3_514_2"
  type: "Convolution"
  bottom: "res_stage_3_514_1_top"
  top: "res_stage_3_514_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_514_2"
  type: "BatchNorm"
  bottom: "res_stage_3_514_2"
  top: "res_stage_3_514_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_514_2"  
  type: "Scale"
  bottom: "res_stage_3_514_2"
  top: "res_stage_3_514_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_514_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_514_2_top"
  top: "res_stage_3_514_2_top"
}
layer {
  name: "res_stage_3_514_3"
  type: "Convolution"
  bottom: "res_stage_3_514_2_top"
  top: "res_stage_3_514_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_514_3"
  type: "BatchNorm"
  bottom: "res_stage_3_514_3"
  top: "res_stage_3_514_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_514_3"  
  type: "Scale"
  bottom: "res_stage_3_514_3"
  top: "res_stage_3_514_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_514"
  type: "Eltwise"
  bottom: "res_3_513"
  bottom: "res_stage_3_514_3_top"
  top: "res_3_514"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_514_relu"
  type: "ReLU"
  bottom: "res_3_514"
  top: "res_3_514"
}
layer {
  name: "res_stage_3_515_1"
  type: "Convolution"
  bottom: "res_3_514"
  top: "res_stage_3_515_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_515_1"
  type: "BatchNorm"
  bottom: "res_stage_3_515_1"
  top: "res_stage_3_515_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_515_1"  
  type: "Scale"
  bottom: "res_stage_3_515_1"
  top: "res_stage_3_515_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_515_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_515_1_top"
  top: "res_stage_3_515_1_top"
}
layer {
  name: "res_stage_3_515_2"
  type: "Convolution"
  bottom: "res_stage_3_515_1_top"
  top: "res_stage_3_515_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_515_2"
  type: "BatchNorm"
  bottom: "res_stage_3_515_2"
  top: "res_stage_3_515_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_515_2"  
  type: "Scale"
  bottom: "res_stage_3_515_2"
  top: "res_stage_3_515_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_515_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_515_2_top"
  top: "res_stage_3_515_2_top"
}
layer {
  name: "res_stage_3_515_3"
  type: "Convolution"
  bottom: "res_stage_3_515_2_top"
  top: "res_stage_3_515_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_515_3"
  type: "BatchNorm"
  bottom: "res_stage_3_515_3"
  top: "res_stage_3_515_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_515_3"  
  type: "Scale"
  bottom: "res_stage_3_515_3"
  top: "res_stage_3_515_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_515"
  type: "Eltwise"
  bottom: "res_3_514"
  bottom: "res_stage_3_515_3_top"
  top: "res_3_515"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_515_relu"
  type: "ReLU"
  bottom: "res_3_515"
  top: "res_3_515"
}
layer {
  name: "res_stage_3_516_1"
  type: "Convolution"
  bottom: "res_3_515"
  top: "res_stage_3_516_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_516_1"
  type: "BatchNorm"
  bottom: "res_stage_3_516_1"
  top: "res_stage_3_516_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_516_1"  
  type: "Scale"
  bottom: "res_stage_3_516_1"
  top: "res_stage_3_516_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_516_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_516_1_top"
  top: "res_stage_3_516_1_top"
}
layer {
  name: "res_stage_3_516_2"
  type: "Convolution"
  bottom: "res_stage_3_516_1_top"
  top: "res_stage_3_516_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_516_2"
  type: "BatchNorm"
  bottom: "res_stage_3_516_2"
  top: "res_stage_3_516_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_516_2"  
  type: "Scale"
  bottom: "res_stage_3_516_2"
  top: "res_stage_3_516_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_516_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_516_2_top"
  top: "res_stage_3_516_2_top"
}
layer {
  name: "res_stage_3_516_3"
  type: "Convolution"
  bottom: "res_stage_3_516_2_top"
  top: "res_stage_3_516_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_516_3"
  type: "BatchNorm"
  bottom: "res_stage_3_516_3"
  top: "res_stage_3_516_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_516_3"  
  type: "Scale"
  bottom: "res_stage_3_516_3"
  top: "res_stage_3_516_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_516"
  type: "Eltwise"
  bottom: "res_3_515"
  bottom: "res_stage_3_516_3_top"
  top: "res_3_516"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_516_relu"
  type: "ReLU"
  bottom: "res_3_516"
  top: "res_3_516"
}
layer {
  name: "res_stage_3_517_1"
  type: "Convolution"
  bottom: "res_3_516"
  top: "res_stage_3_517_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_517_1"
  type: "BatchNorm"
  bottom: "res_stage_3_517_1"
  top: "res_stage_3_517_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_517_1"  
  type: "Scale"
  bottom: "res_stage_3_517_1"
  top: "res_stage_3_517_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_517_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_517_1_top"
  top: "res_stage_3_517_1_top"
}
layer {
  name: "res_stage_3_517_2"
  type: "Convolution"
  bottom: "res_stage_3_517_1_top"
  top: "res_stage_3_517_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_517_2"
  type: "BatchNorm"
  bottom: "res_stage_3_517_2"
  top: "res_stage_3_517_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_517_2"  
  type: "Scale"
  bottom: "res_stage_3_517_2"
  top: "res_stage_3_517_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_517_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_517_2_top"
  top: "res_stage_3_517_2_top"
}
layer {
  name: "res_stage_3_517_3"
  type: "Convolution"
  bottom: "res_stage_3_517_2_top"
  top: "res_stage_3_517_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_517_3"
  type: "BatchNorm"
  bottom: "res_stage_3_517_3"
  top: "res_stage_3_517_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_517_3"  
  type: "Scale"
  bottom: "res_stage_3_517_3"
  top: "res_stage_3_517_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_517"
  type: "Eltwise"
  bottom: "res_3_516"
  bottom: "res_stage_3_517_3_top"
  top: "res_3_517"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_517_relu"
  type: "ReLU"
  bottom: "res_3_517"
  top: "res_3_517"
}
layer {
  name: "res_stage_3_518_1"
  type: "Convolution"
  bottom: "res_3_517"
  top: "res_stage_3_518_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_518_1"
  type: "BatchNorm"
  bottom: "res_stage_3_518_1"
  top: "res_stage_3_518_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_518_1"  
  type: "Scale"
  bottom: "res_stage_3_518_1"
  top: "res_stage_3_518_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_518_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_518_1_top"
  top: "res_stage_3_518_1_top"
}
layer {
  name: "res_stage_3_518_2"
  type: "Convolution"
  bottom: "res_stage_3_518_1_top"
  top: "res_stage_3_518_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_518_2"
  type: "BatchNorm"
  bottom: "res_stage_3_518_2"
  top: "res_stage_3_518_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_518_2"  
  type: "Scale"
  bottom: "res_stage_3_518_2"
  top: "res_stage_3_518_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_518_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_518_2_top"
  top: "res_stage_3_518_2_top"
}
layer {
  name: "res_stage_3_518_3"
  type: "Convolution"
  bottom: "res_stage_3_518_2_top"
  top: "res_stage_3_518_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_518_3"
  type: "BatchNorm"
  bottom: "res_stage_3_518_3"
  top: "res_stage_3_518_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_518_3"  
  type: "Scale"
  bottom: "res_stage_3_518_3"
  top: "res_stage_3_518_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_518"
  type: "Eltwise"
  bottom: "res_3_517"
  bottom: "res_stage_3_518_3_top"
  top: "res_3_518"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_518_relu"
  type: "ReLU"
  bottom: "res_3_518"
  top: "res_3_518"
}
layer {
  name: "res_stage_3_519_1"
  type: "Convolution"
  bottom: "res_3_518"
  top: "res_stage_3_519_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_519_1"
  type: "BatchNorm"
  bottom: "res_stage_3_519_1"
  top: "res_stage_3_519_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_519_1"  
  type: "Scale"
  bottom: "res_stage_3_519_1"
  top: "res_stage_3_519_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_519_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_519_1_top"
  top: "res_stage_3_519_1_top"
}
layer {
  name: "res_stage_3_519_2"
  type: "Convolution"
  bottom: "res_stage_3_519_1_top"
  top: "res_stage_3_519_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_519_2"
  type: "BatchNorm"
  bottom: "res_stage_3_519_2"
  top: "res_stage_3_519_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_519_2"  
  type: "Scale"
  bottom: "res_stage_3_519_2"
  top: "res_stage_3_519_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_519_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_519_2_top"
  top: "res_stage_3_519_2_top"
}
layer {
  name: "res_stage_3_519_3"
  type: "Convolution"
  bottom: "res_stage_3_519_2_top"
  top: "res_stage_3_519_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_519_3"
  type: "BatchNorm"
  bottom: "res_stage_3_519_3"
  top: "res_stage_3_519_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_519_3"  
  type: "Scale"
  bottom: "res_stage_3_519_3"
  top: "res_stage_3_519_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_519"
  type: "Eltwise"
  bottom: "res_3_518"
  bottom: "res_stage_3_519_3_top"
  top: "res_3_519"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_519_relu"
  type: "ReLU"
  bottom: "res_3_519"
  top: "res_3_519"
}
layer {
  name: "res_stage_3_520_1"
  type: "Convolution"
  bottom: "res_3_519"
  top: "res_stage_3_520_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_520_1"
  type: "BatchNorm"
  bottom: "res_stage_3_520_1"
  top: "res_stage_3_520_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_520_1"  
  type: "Scale"
  bottom: "res_stage_3_520_1"
  top: "res_stage_3_520_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_520_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_520_1_top"
  top: "res_stage_3_520_1_top"
}
layer {
  name: "res_stage_3_520_2"
  type: "Convolution"
  bottom: "res_stage_3_520_1_top"
  top: "res_stage_3_520_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_520_2"
  type: "BatchNorm"
  bottom: "res_stage_3_520_2"
  top: "res_stage_3_520_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_520_2"  
  type: "Scale"
  bottom: "res_stage_3_520_2"
  top: "res_stage_3_520_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_520_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_520_2_top"
  top: "res_stage_3_520_2_top"
}
layer {
  name: "res_stage_3_520_3"
  type: "Convolution"
  bottom: "res_stage_3_520_2_top"
  top: "res_stage_3_520_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_520_3"
  type: "BatchNorm"
  bottom: "res_stage_3_520_3"
  top: "res_stage_3_520_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_520_3"  
  type: "Scale"
  bottom: "res_stage_3_520_3"
  top: "res_stage_3_520_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_520"
  type: "Eltwise"
  bottom: "res_3_519"
  bottom: "res_stage_3_520_3_top"
  top: "res_3_520"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_520_relu"
  type: "ReLU"
  bottom: "res_3_520"
  top: "res_3_520"
}
layer {
  name: "res_stage_3_521_1"
  type: "Convolution"
  bottom: "res_3_520"
  top: "res_stage_3_521_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_521_1"
  type: "BatchNorm"
  bottom: "res_stage_3_521_1"
  top: "res_stage_3_521_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_521_1"  
  type: "Scale"
  bottom: "res_stage_3_521_1"
  top: "res_stage_3_521_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_521_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_521_1_top"
  top: "res_stage_3_521_1_top"
}
layer {
  name: "res_stage_3_521_2"
  type: "Convolution"
  bottom: "res_stage_3_521_1_top"
  top: "res_stage_3_521_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_521_2"
  type: "BatchNorm"
  bottom: "res_stage_3_521_2"
  top: "res_stage_3_521_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_521_2"  
  type: "Scale"
  bottom: "res_stage_3_521_2"
  top: "res_stage_3_521_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_521_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_521_2_top"
  top: "res_stage_3_521_2_top"
}
layer {
  name: "res_stage_3_521_3"
  type: "Convolution"
  bottom: "res_stage_3_521_2_top"
  top: "res_stage_3_521_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_521_3"
  type: "BatchNorm"
  bottom: "res_stage_3_521_3"
  top: "res_stage_3_521_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_521_3"  
  type: "Scale"
  bottom: "res_stage_3_521_3"
  top: "res_stage_3_521_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_521"
  type: "Eltwise"
  bottom: "res_3_520"
  bottom: "res_stage_3_521_3_top"
  top: "res_3_521"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_521_relu"
  type: "ReLU"
  bottom: "res_3_521"
  top: "res_3_521"
}
layer {
  name: "res_stage_3_522_1"
  type: "Convolution"
  bottom: "res_3_521"
  top: "res_stage_3_522_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_522_1"
  type: "BatchNorm"
  bottom: "res_stage_3_522_1"
  top: "res_stage_3_522_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_522_1"  
  type: "Scale"
  bottom: "res_stage_3_522_1"
  top: "res_stage_3_522_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_522_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_522_1_top"
  top: "res_stage_3_522_1_top"
}
layer {
  name: "res_stage_3_522_2"
  type: "Convolution"
  bottom: "res_stage_3_522_1_top"
  top: "res_stage_3_522_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_522_2"
  type: "BatchNorm"
  bottom: "res_stage_3_522_2"
  top: "res_stage_3_522_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_522_2"  
  type: "Scale"
  bottom: "res_stage_3_522_2"
  top: "res_stage_3_522_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_522_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_522_2_top"
  top: "res_stage_3_522_2_top"
}
layer {
  name: "res_stage_3_522_3"
  type: "Convolution"
  bottom: "res_stage_3_522_2_top"
  top: "res_stage_3_522_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_522_3"
  type: "BatchNorm"
  bottom: "res_stage_3_522_3"
  top: "res_stage_3_522_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_522_3"  
  type: "Scale"
  bottom: "res_stage_3_522_3"
  top: "res_stage_3_522_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_522"
  type: "Eltwise"
  bottom: "res_3_521"
  bottom: "res_stage_3_522_3_top"
  top: "res_3_522"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_522_relu"
  type: "ReLU"
  bottom: "res_3_522"
  top: "res_3_522"
}
layer {
  name: "res_stage_3_523_1"
  type: "Convolution"
  bottom: "res_3_522"
  top: "res_stage_3_523_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_523_1"
  type: "BatchNorm"
  bottom: "res_stage_3_523_1"
  top: "res_stage_3_523_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_523_1"  
  type: "Scale"
  bottom: "res_stage_3_523_1"
  top: "res_stage_3_523_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_523_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_523_1_top"
  top: "res_stage_3_523_1_top"
}
layer {
  name: "res_stage_3_523_2"
  type: "Convolution"
  bottom: "res_stage_3_523_1_top"
  top: "res_stage_3_523_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_523_2"
  type: "BatchNorm"
  bottom: "res_stage_3_523_2"
  top: "res_stage_3_523_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_523_2"  
  type: "Scale"
  bottom: "res_stage_3_523_2"
  top: "res_stage_3_523_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_523_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_523_2_top"
  top: "res_stage_3_523_2_top"
}
layer {
  name: "res_stage_3_523_3"
  type: "Convolution"
  bottom: "res_stage_3_523_2_top"
  top: "res_stage_3_523_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_523_3"
  type: "BatchNorm"
  bottom: "res_stage_3_523_3"
  top: "res_stage_3_523_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_523_3"  
  type: "Scale"
  bottom: "res_stage_3_523_3"
  top: "res_stage_3_523_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_523"
  type: "Eltwise"
  bottom: "res_3_522"
  bottom: "res_stage_3_523_3_top"
  top: "res_3_523"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_523_relu"
  type: "ReLU"
  bottom: "res_3_523"
  top: "res_3_523"
}
layer {
  name: "res_stage_3_524_1"
  type: "Convolution"
  bottom: "res_3_523"
  top: "res_stage_3_524_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_524_1"
  type: "BatchNorm"
  bottom: "res_stage_3_524_1"
  top: "res_stage_3_524_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_524_1"  
  type: "Scale"
  bottom: "res_stage_3_524_1"
  top: "res_stage_3_524_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_524_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_524_1_top"
  top: "res_stage_3_524_1_top"
}
layer {
  name: "res_stage_3_524_2"
  type: "Convolution"
  bottom: "res_stage_3_524_1_top"
  top: "res_stage_3_524_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_524_2"
  type: "BatchNorm"
  bottom: "res_stage_3_524_2"
  top: "res_stage_3_524_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_524_2"  
  type: "Scale"
  bottom: "res_stage_3_524_2"
  top: "res_stage_3_524_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_524_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_524_2_top"
  top: "res_stage_3_524_2_top"
}
layer {
  name: "res_stage_3_524_3"
  type: "Convolution"
  bottom: "res_stage_3_524_2_top"
  top: "res_stage_3_524_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_524_3"
  type: "BatchNorm"
  bottom: "res_stage_3_524_3"
  top: "res_stage_3_524_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_524_3"  
  type: "Scale"
  bottom: "res_stage_3_524_3"
  top: "res_stage_3_524_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_524"
  type: "Eltwise"
  bottom: "res_3_523"
  bottom: "res_stage_3_524_3_top"
  top: "res_3_524"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_524_relu"
  type: "ReLU"
  bottom: "res_3_524"
  top: "res_3_524"
}
layer {
  name: "res_stage_3_525_1"
  type: "Convolution"
  bottom: "res_3_524"
  top: "res_stage_3_525_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_525_1"
  type: "BatchNorm"
  bottom: "res_stage_3_525_1"
  top: "res_stage_3_525_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_525_1"  
  type: "Scale"
  bottom: "res_stage_3_525_1"
  top: "res_stage_3_525_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_525_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_525_1_top"
  top: "res_stage_3_525_1_top"
}
layer {
  name: "res_stage_3_525_2"
  type: "Convolution"
  bottom: "res_stage_3_525_1_top"
  top: "res_stage_3_525_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_525_2"
  type: "BatchNorm"
  bottom: "res_stage_3_525_2"
  top: "res_stage_3_525_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_525_2"  
  type: "Scale"
  bottom: "res_stage_3_525_2"
  top: "res_stage_3_525_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_525_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_525_2_top"
  top: "res_stage_3_525_2_top"
}
layer {
  name: "res_stage_3_525_3"
  type: "Convolution"
  bottom: "res_stage_3_525_2_top"
  top: "res_stage_3_525_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_525_3"
  type: "BatchNorm"
  bottom: "res_stage_3_525_3"
  top: "res_stage_3_525_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_525_3"  
  type: "Scale"
  bottom: "res_stage_3_525_3"
  top: "res_stage_3_525_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_525"
  type: "Eltwise"
  bottom: "res_3_524"
  bottom: "res_stage_3_525_3_top"
  top: "res_3_525"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_525_relu"
  type: "ReLU"
  bottom: "res_3_525"
  top: "res_3_525"
}
layer {
  name: "res_stage_3_526_1"
  type: "Convolution"
  bottom: "res_3_525"
  top: "res_stage_3_526_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_526_1"
  type: "BatchNorm"
  bottom: "res_stage_3_526_1"
  top: "res_stage_3_526_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_526_1"  
  type: "Scale"
  bottom: "res_stage_3_526_1"
  top: "res_stage_3_526_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_526_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_526_1_top"
  top: "res_stage_3_526_1_top"
}
layer {
  name: "res_stage_3_526_2"
  type: "Convolution"
  bottom: "res_stage_3_526_1_top"
  top: "res_stage_3_526_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_526_2"
  type: "BatchNorm"
  bottom: "res_stage_3_526_2"
  top: "res_stage_3_526_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_526_2"  
  type: "Scale"
  bottom: "res_stage_3_526_2"
  top: "res_stage_3_526_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_526_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_526_2_top"
  top: "res_stage_3_526_2_top"
}
layer {
  name: "res_stage_3_526_3"
  type: "Convolution"
  bottom: "res_stage_3_526_2_top"
  top: "res_stage_3_526_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_526_3"
  type: "BatchNorm"
  bottom: "res_stage_3_526_3"
  top: "res_stage_3_526_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_526_3"  
  type: "Scale"
  bottom: "res_stage_3_526_3"
  top: "res_stage_3_526_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_526"
  type: "Eltwise"
  bottom: "res_3_525"
  bottom: "res_stage_3_526_3_top"
  top: "res_3_526"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_526_relu"
  type: "ReLU"
  bottom: "res_3_526"
  top: "res_3_526"
}
layer {
  name: "res_stage_3_527_1"
  type: "Convolution"
  bottom: "res_3_526"
  top: "res_stage_3_527_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_527_1"
  type: "BatchNorm"
  bottom: "res_stage_3_527_1"
  top: "res_stage_3_527_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_527_1"  
  type: "Scale"
  bottom: "res_stage_3_527_1"
  top: "res_stage_3_527_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_527_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_527_1_top"
  top: "res_stage_3_527_1_top"
}
layer {
  name: "res_stage_3_527_2"
  type: "Convolution"
  bottom: "res_stage_3_527_1_top"
  top: "res_stage_3_527_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_527_2"
  type: "BatchNorm"
  bottom: "res_stage_3_527_2"
  top: "res_stage_3_527_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_527_2"  
  type: "Scale"
  bottom: "res_stage_3_527_2"
  top: "res_stage_3_527_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_527_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_527_2_top"
  top: "res_stage_3_527_2_top"
}
layer {
  name: "res_stage_3_527_3"
  type: "Convolution"
  bottom: "res_stage_3_527_2_top"
  top: "res_stage_3_527_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_527_3"
  type: "BatchNorm"
  bottom: "res_stage_3_527_3"
  top: "res_stage_3_527_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_527_3"  
  type: "Scale"
  bottom: "res_stage_3_527_3"
  top: "res_stage_3_527_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_527"
  type: "Eltwise"
  bottom: "res_3_526"
  bottom: "res_stage_3_527_3_top"
  top: "res_3_527"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_527_relu"
  type: "ReLU"
  bottom: "res_3_527"
  top: "res_3_527"
}
layer {
  name: "res_stage_3_528_1"
  type: "Convolution"
  bottom: "res_3_527"
  top: "res_stage_3_528_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_528_1"
  type: "BatchNorm"
  bottom: "res_stage_3_528_1"
  top: "res_stage_3_528_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_528_1"  
  type: "Scale"
  bottom: "res_stage_3_528_1"
  top: "res_stage_3_528_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_528_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_528_1_top"
  top: "res_stage_3_528_1_top"
}
layer {
  name: "res_stage_3_528_2"
  type: "Convolution"
  bottom: "res_stage_3_528_1_top"
  top: "res_stage_3_528_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_528_2"
  type: "BatchNorm"
  bottom: "res_stage_3_528_2"
  top: "res_stage_3_528_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_528_2"  
  type: "Scale"
  bottom: "res_stage_3_528_2"
  top: "res_stage_3_528_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_528_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_528_2_top"
  top: "res_stage_3_528_2_top"
}
layer {
  name: "res_stage_3_528_3"
  type: "Convolution"
  bottom: "res_stage_3_528_2_top"
  top: "res_stage_3_528_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_528_3"
  type: "BatchNorm"
  bottom: "res_stage_3_528_3"
  top: "res_stage_3_528_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_528_3"  
  type: "Scale"
  bottom: "res_stage_3_528_3"
  top: "res_stage_3_528_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_528"
  type: "Eltwise"
  bottom: "res_3_527"
  bottom: "res_stage_3_528_3_top"
  top: "res_3_528"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_528_relu"
  type: "ReLU"
  bottom: "res_3_528"
  top: "res_3_528"
}
layer {
  name: "res_stage_3_529_1"
  type: "Convolution"
  bottom: "res_3_528"
  top: "res_stage_3_529_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_529_1"
  type: "BatchNorm"
  bottom: "res_stage_3_529_1"
  top: "res_stage_3_529_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_529_1"  
  type: "Scale"
  bottom: "res_stage_3_529_1"
  top: "res_stage_3_529_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_529_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_529_1_top"
  top: "res_stage_3_529_1_top"
}
layer {
  name: "res_stage_3_529_2"
  type: "Convolution"
  bottom: "res_stage_3_529_1_top"
  top: "res_stage_3_529_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_529_2"
  type: "BatchNorm"
  bottom: "res_stage_3_529_2"
  top: "res_stage_3_529_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_529_2"  
  type: "Scale"
  bottom: "res_stage_3_529_2"
  top: "res_stage_3_529_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_529_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_529_2_top"
  top: "res_stage_3_529_2_top"
}
layer {
  name: "res_stage_3_529_3"
  type: "Convolution"
  bottom: "res_stage_3_529_2_top"
  top: "res_stage_3_529_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_529_3"
  type: "BatchNorm"
  bottom: "res_stage_3_529_3"
  top: "res_stage_3_529_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_529_3"  
  type: "Scale"
  bottom: "res_stage_3_529_3"
  top: "res_stage_3_529_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_529"
  type: "Eltwise"
  bottom: "res_3_528"
  bottom: "res_stage_3_529_3_top"
  top: "res_3_529"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_529_relu"
  type: "ReLU"
  bottom: "res_3_529"
  top: "res_3_529"
}
layer {
  name: "res_stage_3_530_1"
  type: "Convolution"
  bottom: "res_3_529"
  top: "res_stage_3_530_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_530_1"
  type: "BatchNorm"
  bottom: "res_stage_3_530_1"
  top: "res_stage_3_530_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_530_1"  
  type: "Scale"
  bottom: "res_stage_3_530_1"
  top: "res_stage_3_530_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_530_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_530_1_top"
  top: "res_stage_3_530_1_top"
}
layer {
  name: "res_stage_3_530_2"
  type: "Convolution"
  bottom: "res_stage_3_530_1_top"
  top: "res_stage_3_530_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_530_2"
  type: "BatchNorm"
  bottom: "res_stage_3_530_2"
  top: "res_stage_3_530_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_530_2"  
  type: "Scale"
  bottom: "res_stage_3_530_2"
  top: "res_stage_3_530_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_530_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_530_2_top"
  top: "res_stage_3_530_2_top"
}
layer {
  name: "res_stage_3_530_3"
  type: "Convolution"
  bottom: "res_stage_3_530_2_top"
  top: "res_stage_3_530_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_530_3"
  type: "BatchNorm"
  bottom: "res_stage_3_530_3"
  top: "res_stage_3_530_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_530_3"  
  type: "Scale"
  bottom: "res_stage_3_530_3"
  top: "res_stage_3_530_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_530"
  type: "Eltwise"
  bottom: "res_3_529"
  bottom: "res_stage_3_530_3_top"
  top: "res_3_530"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_530_relu"
  type: "ReLU"
  bottom: "res_3_530"
  top: "res_3_530"
}
layer {
  name: "res_stage_3_531_1"
  type: "Convolution"
  bottom: "res_3_530"
  top: "res_stage_3_531_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_531_1"
  type: "BatchNorm"
  bottom: "res_stage_3_531_1"
  top: "res_stage_3_531_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_531_1"  
  type: "Scale"
  bottom: "res_stage_3_531_1"
  top: "res_stage_3_531_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_531_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_531_1_top"
  top: "res_stage_3_531_1_top"
}
layer {
  name: "res_stage_3_531_2"
  type: "Convolution"
  bottom: "res_stage_3_531_1_top"
  top: "res_stage_3_531_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_531_2"
  type: "BatchNorm"
  bottom: "res_stage_3_531_2"
  top: "res_stage_3_531_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_531_2"  
  type: "Scale"
  bottom: "res_stage_3_531_2"
  top: "res_stage_3_531_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_531_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_531_2_top"
  top: "res_stage_3_531_2_top"
}
layer {
  name: "res_stage_3_531_3"
  type: "Convolution"
  bottom: "res_stage_3_531_2_top"
  top: "res_stage_3_531_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_531_3"
  type: "BatchNorm"
  bottom: "res_stage_3_531_3"
  top: "res_stage_3_531_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_531_3"  
  type: "Scale"
  bottom: "res_stage_3_531_3"
  top: "res_stage_3_531_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_531"
  type: "Eltwise"
  bottom: "res_3_530"
  bottom: "res_stage_3_531_3_top"
  top: "res_3_531"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_531_relu"
  type: "ReLU"
  bottom: "res_3_531"
  top: "res_3_531"
}
layer {
  name: "res_stage_3_532_1"
  type: "Convolution"
  bottom: "res_3_531"
  top: "res_stage_3_532_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_532_1"
  type: "BatchNorm"
  bottom: "res_stage_3_532_1"
  top: "res_stage_3_532_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_532_1"  
  type: "Scale"
  bottom: "res_stage_3_532_1"
  top: "res_stage_3_532_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_532_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_532_1_top"
  top: "res_stage_3_532_1_top"
}
layer {
  name: "res_stage_3_532_2"
  type: "Convolution"
  bottom: "res_stage_3_532_1_top"
  top: "res_stage_3_532_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_532_2"
  type: "BatchNorm"
  bottom: "res_stage_3_532_2"
  top: "res_stage_3_532_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_532_2"  
  type: "Scale"
  bottom: "res_stage_3_532_2"
  top: "res_stage_3_532_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_532_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_532_2_top"
  top: "res_stage_3_532_2_top"
}
layer {
  name: "res_stage_3_532_3"
  type: "Convolution"
  bottom: "res_stage_3_532_2_top"
  top: "res_stage_3_532_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_532_3"
  type: "BatchNorm"
  bottom: "res_stage_3_532_3"
  top: "res_stage_3_532_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_532_3"  
  type: "Scale"
  bottom: "res_stage_3_532_3"
  top: "res_stage_3_532_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_532"
  type: "Eltwise"
  bottom: "res_3_531"
  bottom: "res_stage_3_532_3_top"
  top: "res_3_532"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_532_relu"
  type: "ReLU"
  bottom: "res_3_532"
  top: "res_3_532"
}
layer {
  name: "res_stage_3_533_1"
  type: "Convolution"
  bottom: "res_3_532"
  top: "res_stage_3_533_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_533_1"
  type: "BatchNorm"
  bottom: "res_stage_3_533_1"
  top: "res_stage_3_533_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_533_1"  
  type: "Scale"
  bottom: "res_stage_3_533_1"
  top: "res_stage_3_533_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_533_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_533_1_top"
  top: "res_stage_3_533_1_top"
}
layer {
  name: "res_stage_3_533_2"
  type: "Convolution"
  bottom: "res_stage_3_533_1_top"
  top: "res_stage_3_533_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_533_2"
  type: "BatchNorm"
  bottom: "res_stage_3_533_2"
  top: "res_stage_3_533_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_533_2"  
  type: "Scale"
  bottom: "res_stage_3_533_2"
  top: "res_stage_3_533_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_533_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_533_2_top"
  top: "res_stage_3_533_2_top"
}
layer {
  name: "res_stage_3_533_3"
  type: "Convolution"
  bottom: "res_stage_3_533_2_top"
  top: "res_stage_3_533_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_533_3"
  type: "BatchNorm"
  bottom: "res_stage_3_533_3"
  top: "res_stage_3_533_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_533_3"  
  type: "Scale"
  bottom: "res_stage_3_533_3"
  top: "res_stage_3_533_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_533"
  type: "Eltwise"
  bottom: "res_3_532"
  bottom: "res_stage_3_533_3_top"
  top: "res_3_533"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_533_relu"
  type: "ReLU"
  bottom: "res_3_533"
  top: "res_3_533"
}
layer {
  name: "res_stage_3_534_1"
  type: "Convolution"
  bottom: "res_3_533"
  top: "res_stage_3_534_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_534_1"
  type: "BatchNorm"
  bottom: "res_stage_3_534_1"
  top: "res_stage_3_534_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_534_1"  
  type: "Scale"
  bottom: "res_stage_3_534_1"
  top: "res_stage_3_534_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_534_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_534_1_top"
  top: "res_stage_3_534_1_top"
}
layer {
  name: "res_stage_3_534_2"
  type: "Convolution"
  bottom: "res_stage_3_534_1_top"
  top: "res_stage_3_534_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_534_2"
  type: "BatchNorm"
  bottom: "res_stage_3_534_2"
  top: "res_stage_3_534_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_534_2"  
  type: "Scale"
  bottom: "res_stage_3_534_2"
  top: "res_stage_3_534_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_534_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_534_2_top"
  top: "res_stage_3_534_2_top"
}
layer {
  name: "res_stage_3_534_3"
  type: "Convolution"
  bottom: "res_stage_3_534_2_top"
  top: "res_stage_3_534_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_534_3"
  type: "BatchNorm"
  bottom: "res_stage_3_534_3"
  top: "res_stage_3_534_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_534_3"  
  type: "Scale"
  bottom: "res_stage_3_534_3"
  top: "res_stage_3_534_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_534"
  type: "Eltwise"
  bottom: "res_3_533"
  bottom: "res_stage_3_534_3_top"
  top: "res_3_534"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_534_relu"
  type: "ReLU"
  bottom: "res_3_534"
  top: "res_3_534"
}
layer {
  name: "res_stage_3_535_1"
  type: "Convolution"
  bottom: "res_3_534"
  top: "res_stage_3_535_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_535_1"
  type: "BatchNorm"
  bottom: "res_stage_3_535_1"
  top: "res_stage_3_535_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_535_1"  
  type: "Scale"
  bottom: "res_stage_3_535_1"
  top: "res_stage_3_535_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_535_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_535_1_top"
  top: "res_stage_3_535_1_top"
}
layer {
  name: "res_stage_3_535_2"
  type: "Convolution"
  bottom: "res_stage_3_535_1_top"
  top: "res_stage_3_535_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_535_2"
  type: "BatchNorm"
  bottom: "res_stage_3_535_2"
  top: "res_stage_3_535_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_535_2"  
  type: "Scale"
  bottom: "res_stage_3_535_2"
  top: "res_stage_3_535_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_535_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_535_2_top"
  top: "res_stage_3_535_2_top"
}
layer {
  name: "res_stage_3_535_3"
  type: "Convolution"
  bottom: "res_stage_3_535_2_top"
  top: "res_stage_3_535_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_535_3"
  type: "BatchNorm"
  bottom: "res_stage_3_535_3"
  top: "res_stage_3_535_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_535_3"  
  type: "Scale"
  bottom: "res_stage_3_535_3"
  top: "res_stage_3_535_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_535"
  type: "Eltwise"
  bottom: "res_3_534"
  bottom: "res_stage_3_535_3_top"
  top: "res_3_535"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_535_relu"
  type: "ReLU"
  bottom: "res_3_535"
  top: "res_3_535"
}
layer {
  name: "res_stage_3_536_1"
  type: "Convolution"
  bottom: "res_3_535"
  top: "res_stage_3_536_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_536_1"
  type: "BatchNorm"
  bottom: "res_stage_3_536_1"
  top: "res_stage_3_536_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_536_1"  
  type: "Scale"
  bottom: "res_stage_3_536_1"
  top: "res_stage_3_536_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_536_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_536_1_top"
  top: "res_stage_3_536_1_top"
}
layer {
  name: "res_stage_3_536_2"
  type: "Convolution"
  bottom: "res_stage_3_536_1_top"
  top: "res_stage_3_536_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_536_2"
  type: "BatchNorm"
  bottom: "res_stage_3_536_2"
  top: "res_stage_3_536_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_536_2"  
  type: "Scale"
  bottom: "res_stage_3_536_2"
  top: "res_stage_3_536_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_536_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_536_2_top"
  top: "res_stage_3_536_2_top"
}
layer {
  name: "res_stage_3_536_3"
  type: "Convolution"
  bottom: "res_stage_3_536_2_top"
  top: "res_stage_3_536_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_536_3"
  type: "BatchNorm"
  bottom: "res_stage_3_536_3"
  top: "res_stage_3_536_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_536_3"  
  type: "Scale"
  bottom: "res_stage_3_536_3"
  top: "res_stage_3_536_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_536"
  type: "Eltwise"
  bottom: "res_3_535"
  bottom: "res_stage_3_536_3_top"
  top: "res_3_536"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_536_relu"
  type: "ReLU"
  bottom: "res_3_536"
  top: "res_3_536"
}
layer {
  name: "res_stage_3_537_1"
  type: "Convolution"
  bottom: "res_3_536"
  top: "res_stage_3_537_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_537_1"
  type: "BatchNorm"
  bottom: "res_stage_3_537_1"
  top: "res_stage_3_537_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_537_1"  
  type: "Scale"
  bottom: "res_stage_3_537_1"
  top: "res_stage_3_537_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_537_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_537_1_top"
  top: "res_stage_3_537_1_top"
}
layer {
  name: "res_stage_3_537_2"
  type: "Convolution"
  bottom: "res_stage_3_537_1_top"
  top: "res_stage_3_537_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_537_2"
  type: "BatchNorm"
  bottom: "res_stage_3_537_2"
  top: "res_stage_3_537_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_537_2"  
  type: "Scale"
  bottom: "res_stage_3_537_2"
  top: "res_stage_3_537_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_537_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_537_2_top"
  top: "res_stage_3_537_2_top"
}
layer {
  name: "res_stage_3_537_3"
  type: "Convolution"
  bottom: "res_stage_3_537_2_top"
  top: "res_stage_3_537_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_537_3"
  type: "BatchNorm"
  bottom: "res_stage_3_537_3"
  top: "res_stage_3_537_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_537_3"  
  type: "Scale"
  bottom: "res_stage_3_537_3"
  top: "res_stage_3_537_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_537"
  type: "Eltwise"
  bottom: "res_3_536"
  bottom: "res_stage_3_537_3_top"
  top: "res_3_537"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_537_relu"
  type: "ReLU"
  bottom: "res_3_537"
  top: "res_3_537"
}
layer {
  name: "res_stage_3_538_1"
  type: "Convolution"
  bottom: "res_3_537"
  top: "res_stage_3_538_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_538_1"
  type: "BatchNorm"
  bottom: "res_stage_3_538_1"
  top: "res_stage_3_538_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_538_1"  
  type: "Scale"
  bottom: "res_stage_3_538_1"
  top: "res_stage_3_538_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_538_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_538_1_top"
  top: "res_stage_3_538_1_top"
}
layer {
  name: "res_stage_3_538_2"
  type: "Convolution"
  bottom: "res_stage_3_538_1_top"
  top: "res_stage_3_538_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_538_2"
  type: "BatchNorm"
  bottom: "res_stage_3_538_2"
  top: "res_stage_3_538_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_538_2"  
  type: "Scale"
  bottom: "res_stage_3_538_2"
  top: "res_stage_3_538_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_538_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_538_2_top"
  top: "res_stage_3_538_2_top"
}
layer {
  name: "res_stage_3_538_3"
  type: "Convolution"
  bottom: "res_stage_3_538_2_top"
  top: "res_stage_3_538_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_538_3"
  type: "BatchNorm"
  bottom: "res_stage_3_538_3"
  top: "res_stage_3_538_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_538_3"  
  type: "Scale"
  bottom: "res_stage_3_538_3"
  top: "res_stage_3_538_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_538"
  type: "Eltwise"
  bottom: "res_3_537"
  bottom: "res_stage_3_538_3_top"
  top: "res_3_538"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_538_relu"
  type: "ReLU"
  bottom: "res_3_538"
  top: "res_3_538"
}
layer {
  name: "res_stage_3_539_1"
  type: "Convolution"
  bottom: "res_3_538"
  top: "res_stage_3_539_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_539_1"
  type: "BatchNorm"
  bottom: "res_stage_3_539_1"
  top: "res_stage_3_539_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_539_1"  
  type: "Scale"
  bottom: "res_stage_3_539_1"
  top: "res_stage_3_539_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_539_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_539_1_top"
  top: "res_stage_3_539_1_top"
}
layer {
  name: "res_stage_3_539_2"
  type: "Convolution"
  bottom: "res_stage_3_539_1_top"
  top: "res_stage_3_539_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_539_2"
  type: "BatchNorm"
  bottom: "res_stage_3_539_2"
  top: "res_stage_3_539_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_539_2"  
  type: "Scale"
  bottom: "res_stage_3_539_2"
  top: "res_stage_3_539_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_539_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_539_2_top"
  top: "res_stage_3_539_2_top"
}
layer {
  name: "res_stage_3_539_3"
  type: "Convolution"
  bottom: "res_stage_3_539_2_top"
  top: "res_stage_3_539_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_539_3"
  type: "BatchNorm"
  bottom: "res_stage_3_539_3"
  top: "res_stage_3_539_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_539_3"  
  type: "Scale"
  bottom: "res_stage_3_539_3"
  top: "res_stage_3_539_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_539"
  type: "Eltwise"
  bottom: "res_3_538"
  bottom: "res_stage_3_539_3_top"
  top: "res_3_539"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_539_relu"
  type: "ReLU"
  bottom: "res_3_539"
  top: "res_3_539"
}
layer {
  name: "res_stage_3_540_1"
  type: "Convolution"
  bottom: "res_3_539"
  top: "res_stage_3_540_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_540_1"
  type: "BatchNorm"
  bottom: "res_stage_3_540_1"
  top: "res_stage_3_540_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_540_1"  
  type: "Scale"
  bottom: "res_stage_3_540_1"
  top: "res_stage_3_540_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_540_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_540_1_top"
  top: "res_stage_3_540_1_top"
}
layer {
  name: "res_stage_3_540_2"
  type: "Convolution"
  bottom: "res_stage_3_540_1_top"
  top: "res_stage_3_540_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_540_2"
  type: "BatchNorm"
  bottom: "res_stage_3_540_2"
  top: "res_stage_3_540_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_540_2"  
  type: "Scale"
  bottom: "res_stage_3_540_2"
  top: "res_stage_3_540_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_540_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_540_2_top"
  top: "res_stage_3_540_2_top"
}
layer {
  name: "res_stage_3_540_3"
  type: "Convolution"
  bottom: "res_stage_3_540_2_top"
  top: "res_stage_3_540_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_540_3"
  type: "BatchNorm"
  bottom: "res_stage_3_540_3"
  top: "res_stage_3_540_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_540_3"  
  type: "Scale"
  bottom: "res_stage_3_540_3"
  top: "res_stage_3_540_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_540"
  type: "Eltwise"
  bottom: "res_3_539"
  bottom: "res_stage_3_540_3_top"
  top: "res_3_540"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_540_relu"
  type: "ReLU"
  bottom: "res_3_540"
  top: "res_3_540"
}
layer {
  name: "res_stage_3_541_1"
  type: "Convolution"
  bottom: "res_3_540"
  top: "res_stage_3_541_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_541_1"
  type: "BatchNorm"
  bottom: "res_stage_3_541_1"
  top: "res_stage_3_541_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_541_1"  
  type: "Scale"
  bottom: "res_stage_3_541_1"
  top: "res_stage_3_541_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_541_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_541_1_top"
  top: "res_stage_3_541_1_top"
}
layer {
  name: "res_stage_3_541_2"
  type: "Convolution"
  bottom: "res_stage_3_541_1_top"
  top: "res_stage_3_541_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_541_2"
  type: "BatchNorm"
  bottom: "res_stage_3_541_2"
  top: "res_stage_3_541_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_541_2"  
  type: "Scale"
  bottom: "res_stage_3_541_2"
  top: "res_stage_3_541_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_541_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_541_2_top"
  top: "res_stage_3_541_2_top"
}
layer {
  name: "res_stage_3_541_3"
  type: "Convolution"
  bottom: "res_stage_3_541_2_top"
  top: "res_stage_3_541_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_541_3"
  type: "BatchNorm"
  bottom: "res_stage_3_541_3"
  top: "res_stage_3_541_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_541_3"  
  type: "Scale"
  bottom: "res_stage_3_541_3"
  top: "res_stage_3_541_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_541"
  type: "Eltwise"
  bottom: "res_3_540"
  bottom: "res_stage_3_541_3_top"
  top: "res_3_541"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_541_relu"
  type: "ReLU"
  bottom: "res_3_541"
  top: "res_3_541"
}
layer {
  name: "res_stage_3_542_1"
  type: "Convolution"
  bottom: "res_3_541"
  top: "res_stage_3_542_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_542_1"
  type: "BatchNorm"
  bottom: "res_stage_3_542_1"
  top: "res_stage_3_542_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_542_1"  
  type: "Scale"
  bottom: "res_stage_3_542_1"
  top: "res_stage_3_542_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_542_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_542_1_top"
  top: "res_stage_3_542_1_top"
}
layer {
  name: "res_stage_3_542_2"
  type: "Convolution"
  bottom: "res_stage_3_542_1_top"
  top: "res_stage_3_542_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_542_2"
  type: "BatchNorm"
  bottom: "res_stage_3_542_2"
  top: "res_stage_3_542_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_542_2"  
  type: "Scale"
  bottom: "res_stage_3_542_2"
  top: "res_stage_3_542_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_542_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_542_2_top"
  top: "res_stage_3_542_2_top"
}
layer {
  name: "res_stage_3_542_3"
  type: "Convolution"
  bottom: "res_stage_3_542_2_top"
  top: "res_stage_3_542_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_542_3"
  type: "BatchNorm"
  bottom: "res_stage_3_542_3"
  top: "res_stage_3_542_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_542_3"  
  type: "Scale"
  bottom: "res_stage_3_542_3"
  top: "res_stage_3_542_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_542"
  type: "Eltwise"
  bottom: "res_3_541"
  bottom: "res_stage_3_542_3_top"
  top: "res_3_542"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_542_relu"
  type: "ReLU"
  bottom: "res_3_542"
  top: "res_3_542"
}
layer {
  name: "res_stage_3_543_1"
  type: "Convolution"
  bottom: "res_3_542"
  top: "res_stage_3_543_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_543_1"
  type: "BatchNorm"
  bottom: "res_stage_3_543_1"
  top: "res_stage_3_543_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_543_1"  
  type: "Scale"
  bottom: "res_stage_3_543_1"
  top: "res_stage_3_543_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_543_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_543_1_top"
  top: "res_stage_3_543_1_top"
}
layer {
  name: "res_stage_3_543_2"
  type: "Convolution"
  bottom: "res_stage_3_543_1_top"
  top: "res_stage_3_543_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_543_2"
  type: "BatchNorm"
  bottom: "res_stage_3_543_2"
  top: "res_stage_3_543_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_543_2"  
  type: "Scale"
  bottom: "res_stage_3_543_2"
  top: "res_stage_3_543_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_543_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_543_2_top"
  top: "res_stage_3_543_2_top"
}
layer {
  name: "res_stage_3_543_3"
  type: "Convolution"
  bottom: "res_stage_3_543_2_top"
  top: "res_stage_3_543_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_543_3"
  type: "BatchNorm"
  bottom: "res_stage_3_543_3"
  top: "res_stage_3_543_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_543_3"  
  type: "Scale"
  bottom: "res_stage_3_543_3"
  top: "res_stage_3_543_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_543"
  type: "Eltwise"
  bottom: "res_3_542"
  bottom: "res_stage_3_543_3_top"
  top: "res_3_543"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_543_relu"
  type: "ReLU"
  bottom: "res_3_543"
  top: "res_3_543"
}
layer {
  name: "res_stage_3_544_1"
  type: "Convolution"
  bottom: "res_3_543"
  top: "res_stage_3_544_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_544_1"
  type: "BatchNorm"
  bottom: "res_stage_3_544_1"
  top: "res_stage_3_544_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_544_1"  
  type: "Scale"
  bottom: "res_stage_3_544_1"
  top: "res_stage_3_544_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_544_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_544_1_top"
  top: "res_stage_3_544_1_top"
}
layer {
  name: "res_stage_3_544_2"
  type: "Convolution"
  bottom: "res_stage_3_544_1_top"
  top: "res_stage_3_544_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_544_2"
  type: "BatchNorm"
  bottom: "res_stage_3_544_2"
  top: "res_stage_3_544_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_544_2"  
  type: "Scale"
  bottom: "res_stage_3_544_2"
  top: "res_stage_3_544_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_544_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_544_2_top"
  top: "res_stage_3_544_2_top"
}
layer {
  name: "res_stage_3_544_3"
  type: "Convolution"
  bottom: "res_stage_3_544_2_top"
  top: "res_stage_3_544_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_544_3"
  type: "BatchNorm"
  bottom: "res_stage_3_544_3"
  top: "res_stage_3_544_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_544_3"  
  type: "Scale"
  bottom: "res_stage_3_544_3"
  top: "res_stage_3_544_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_544"
  type: "Eltwise"
  bottom: "res_3_543"
  bottom: "res_stage_3_544_3_top"
  top: "res_3_544"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_544_relu"
  type: "ReLU"
  bottom: "res_3_544"
  top: "res_3_544"
}
layer {
  name: "res_stage_3_545_1"
  type: "Convolution"
  bottom: "res_3_544"
  top: "res_stage_3_545_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_545_1"
  type: "BatchNorm"
  bottom: "res_stage_3_545_1"
  top: "res_stage_3_545_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_545_1"  
  type: "Scale"
  bottom: "res_stage_3_545_1"
  top: "res_stage_3_545_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_545_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_545_1_top"
  top: "res_stage_3_545_1_top"
}
layer {
  name: "res_stage_3_545_2"
  type: "Convolution"
  bottom: "res_stage_3_545_1_top"
  top: "res_stage_3_545_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_545_2"
  type: "BatchNorm"
  bottom: "res_stage_3_545_2"
  top: "res_stage_3_545_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_545_2"  
  type: "Scale"
  bottom: "res_stage_3_545_2"
  top: "res_stage_3_545_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_545_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_545_2_top"
  top: "res_stage_3_545_2_top"
}
layer {
  name: "res_stage_3_545_3"
  type: "Convolution"
  bottom: "res_stage_3_545_2_top"
  top: "res_stage_3_545_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_545_3"
  type: "BatchNorm"
  bottom: "res_stage_3_545_3"
  top: "res_stage_3_545_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_545_3"  
  type: "Scale"
  bottom: "res_stage_3_545_3"
  top: "res_stage_3_545_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_545"
  type: "Eltwise"
  bottom: "res_3_544"
  bottom: "res_stage_3_545_3_top"
  top: "res_3_545"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_545_relu"
  type: "ReLU"
  bottom: "res_3_545"
  top: "res_3_545"
}
layer {
  name: "res_stage_3_546_1"
  type: "Convolution"
  bottom: "res_3_545"
  top: "res_stage_3_546_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_546_1"
  type: "BatchNorm"
  bottom: "res_stage_3_546_1"
  top: "res_stage_3_546_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_546_1"  
  type: "Scale"
  bottom: "res_stage_3_546_1"
  top: "res_stage_3_546_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_546_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_546_1_top"
  top: "res_stage_3_546_1_top"
}
layer {
  name: "res_stage_3_546_2"
  type: "Convolution"
  bottom: "res_stage_3_546_1_top"
  top: "res_stage_3_546_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_546_2"
  type: "BatchNorm"
  bottom: "res_stage_3_546_2"
  top: "res_stage_3_546_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_546_2"  
  type: "Scale"
  bottom: "res_stage_3_546_2"
  top: "res_stage_3_546_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_546_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_546_2_top"
  top: "res_stage_3_546_2_top"
}
layer {
  name: "res_stage_3_546_3"
  type: "Convolution"
  bottom: "res_stage_3_546_2_top"
  top: "res_stage_3_546_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_546_3"
  type: "BatchNorm"
  bottom: "res_stage_3_546_3"
  top: "res_stage_3_546_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_546_3"  
  type: "Scale"
  bottom: "res_stage_3_546_3"
  top: "res_stage_3_546_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_546"
  type: "Eltwise"
  bottom: "res_3_545"
  bottom: "res_stage_3_546_3_top"
  top: "res_3_546"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_546_relu"
  type: "ReLU"
  bottom: "res_3_546"
  top: "res_3_546"
}
layer {
  name: "res_stage_3_547_1"
  type: "Convolution"
  bottom: "res_3_546"
  top: "res_stage_3_547_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_547_1"
  type: "BatchNorm"
  bottom: "res_stage_3_547_1"
  top: "res_stage_3_547_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_547_1"  
  type: "Scale"
  bottom: "res_stage_3_547_1"
  top: "res_stage_3_547_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_547_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_547_1_top"
  top: "res_stage_3_547_1_top"
}
layer {
  name: "res_stage_3_547_2"
  type: "Convolution"
  bottom: "res_stage_3_547_1_top"
  top: "res_stage_3_547_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_547_2"
  type: "BatchNorm"
  bottom: "res_stage_3_547_2"
  top: "res_stage_3_547_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_547_2"  
  type: "Scale"
  bottom: "res_stage_3_547_2"
  top: "res_stage_3_547_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_547_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_547_2_top"
  top: "res_stage_3_547_2_top"
}
layer {
  name: "res_stage_3_547_3"
  type: "Convolution"
  bottom: "res_stage_3_547_2_top"
  top: "res_stage_3_547_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_547_3"
  type: "BatchNorm"
  bottom: "res_stage_3_547_3"
  top: "res_stage_3_547_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_547_3"  
  type: "Scale"
  bottom: "res_stage_3_547_3"
  top: "res_stage_3_547_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_547"
  type: "Eltwise"
  bottom: "res_3_546"
  bottom: "res_stage_3_547_3_top"
  top: "res_3_547"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_547_relu"
  type: "ReLU"
  bottom: "res_3_547"
  top: "res_3_547"
}
layer {
  name: "res_stage_3_548_1"
  type: "Convolution"
  bottom: "res_3_547"
  top: "res_stage_3_548_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_548_1"
  type: "BatchNorm"
  bottom: "res_stage_3_548_1"
  top: "res_stage_3_548_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_548_1"  
  type: "Scale"
  bottom: "res_stage_3_548_1"
  top: "res_stage_3_548_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_548_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_548_1_top"
  top: "res_stage_3_548_1_top"
}
layer {
  name: "res_stage_3_548_2"
  type: "Convolution"
  bottom: "res_stage_3_548_1_top"
  top: "res_stage_3_548_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_548_2"
  type: "BatchNorm"
  bottom: "res_stage_3_548_2"
  top: "res_stage_3_548_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_548_2"  
  type: "Scale"
  bottom: "res_stage_3_548_2"
  top: "res_stage_3_548_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_548_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_548_2_top"
  top: "res_stage_3_548_2_top"
}
layer {
  name: "res_stage_3_548_3"
  type: "Convolution"
  bottom: "res_stage_3_548_2_top"
  top: "res_stage_3_548_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_548_3"
  type: "BatchNorm"
  bottom: "res_stage_3_548_3"
  top: "res_stage_3_548_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_548_3"  
  type: "Scale"
  bottom: "res_stage_3_548_3"
  top: "res_stage_3_548_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_548"
  type: "Eltwise"
  bottom: "res_3_547"
  bottom: "res_stage_3_548_3_top"
  top: "res_3_548"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_548_relu"
  type: "ReLU"
  bottom: "res_3_548"
  top: "res_3_548"
}
layer {
  name: "res_stage_3_549_1"
  type: "Convolution"
  bottom: "res_3_548"
  top: "res_stage_3_549_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_549_1"
  type: "BatchNorm"
  bottom: "res_stage_3_549_1"
  top: "res_stage_3_549_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_549_1"  
  type: "Scale"
  bottom: "res_stage_3_549_1"
  top: "res_stage_3_549_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_549_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_549_1_top"
  top: "res_stage_3_549_1_top"
}
layer {
  name: "res_stage_3_549_2"
  type: "Convolution"
  bottom: "res_stage_3_549_1_top"
  top: "res_stage_3_549_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_549_2"
  type: "BatchNorm"
  bottom: "res_stage_3_549_2"
  top: "res_stage_3_549_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_549_2"  
  type: "Scale"
  bottom: "res_stage_3_549_2"
  top: "res_stage_3_549_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_549_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_549_2_top"
  top: "res_stage_3_549_2_top"
}
layer {
  name: "res_stage_3_549_3"
  type: "Convolution"
  bottom: "res_stage_3_549_2_top"
  top: "res_stage_3_549_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_549_3"
  type: "BatchNorm"
  bottom: "res_stage_3_549_3"
  top: "res_stage_3_549_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_549_3"  
  type: "Scale"
  bottom: "res_stage_3_549_3"
  top: "res_stage_3_549_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_549"
  type: "Eltwise"
  bottom: "res_3_548"
  bottom: "res_stage_3_549_3_top"
  top: "res_3_549"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_549_relu"
  type: "ReLU"
  bottom: "res_3_549"
  top: "res_3_549"
}
layer {
  name: "res_stage_3_550_1"
  type: "Convolution"
  bottom: "res_3_549"
  top: "res_stage_3_550_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_550_1"
  type: "BatchNorm"
  bottom: "res_stage_3_550_1"
  top: "res_stage_3_550_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_550_1"  
  type: "Scale"
  bottom: "res_stage_3_550_1"
  top: "res_stage_3_550_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_550_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_550_1_top"
  top: "res_stage_3_550_1_top"
}
layer {
  name: "res_stage_3_550_2"
  type: "Convolution"
  bottom: "res_stage_3_550_1_top"
  top: "res_stage_3_550_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_550_2"
  type: "BatchNorm"
  bottom: "res_stage_3_550_2"
  top: "res_stage_3_550_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_550_2"  
  type: "Scale"
  bottom: "res_stage_3_550_2"
  top: "res_stage_3_550_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_550_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_550_2_top"
  top: "res_stage_3_550_2_top"
}
layer {
  name: "res_stage_3_550_3"
  type: "Convolution"
  bottom: "res_stage_3_550_2_top"
  top: "res_stage_3_550_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_550_3"
  type: "BatchNorm"
  bottom: "res_stage_3_550_3"
  top: "res_stage_3_550_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_550_3"  
  type: "Scale"
  bottom: "res_stage_3_550_3"
  top: "res_stage_3_550_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_550"
  type: "Eltwise"
  bottom: "res_3_549"
  bottom: "res_stage_3_550_3_top"
  top: "res_3_550"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_550_relu"
  type: "ReLU"
  bottom: "res_3_550"
  top: "res_3_550"
}
layer {
  name: "res_stage_3_551_1"
  type: "Convolution"
  bottom: "res_3_550"
  top: "res_stage_3_551_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_551_1"
  type: "BatchNorm"
  bottom: "res_stage_3_551_1"
  top: "res_stage_3_551_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_551_1"  
  type: "Scale"
  bottom: "res_stage_3_551_1"
  top: "res_stage_3_551_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_551_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_551_1_top"
  top: "res_stage_3_551_1_top"
}
layer {
  name: "res_stage_3_551_2"
  type: "Convolution"
  bottom: "res_stage_3_551_1_top"
  top: "res_stage_3_551_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_551_2"
  type: "BatchNorm"
  bottom: "res_stage_3_551_2"
  top: "res_stage_3_551_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_551_2"  
  type: "Scale"
  bottom: "res_stage_3_551_2"
  top: "res_stage_3_551_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_551_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_551_2_top"
  top: "res_stage_3_551_2_top"
}
layer {
  name: "res_stage_3_551_3"
  type: "Convolution"
  bottom: "res_stage_3_551_2_top"
  top: "res_stage_3_551_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_551_3"
  type: "BatchNorm"
  bottom: "res_stage_3_551_3"
  top: "res_stage_3_551_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_551_3"  
  type: "Scale"
  bottom: "res_stage_3_551_3"
  top: "res_stage_3_551_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_551"
  type: "Eltwise"
  bottom: "res_3_550"
  bottom: "res_stage_3_551_3_top"
  top: "res_3_551"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_551_relu"
  type: "ReLU"
  bottom: "res_3_551"
  top: "res_3_551"
}
layer {
  name: "res_stage_3_552_1"
  type: "Convolution"
  bottom: "res_3_551"
  top: "res_stage_3_552_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_552_1"
  type: "BatchNorm"
  bottom: "res_stage_3_552_1"
  top: "res_stage_3_552_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_552_1"  
  type: "Scale"
  bottom: "res_stage_3_552_1"
  top: "res_stage_3_552_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_552_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_552_1_top"
  top: "res_stage_3_552_1_top"
}
layer {
  name: "res_stage_3_552_2"
  type: "Convolution"
  bottom: "res_stage_3_552_1_top"
  top: "res_stage_3_552_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_552_2"
  type: "BatchNorm"
  bottom: "res_stage_3_552_2"
  top: "res_stage_3_552_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_552_2"  
  type: "Scale"
  bottom: "res_stage_3_552_2"
  top: "res_stage_3_552_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_552_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_552_2_top"
  top: "res_stage_3_552_2_top"
}
layer {
  name: "res_stage_3_552_3"
  type: "Convolution"
  bottom: "res_stage_3_552_2_top"
  top: "res_stage_3_552_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_552_3"
  type: "BatchNorm"
  bottom: "res_stage_3_552_3"
  top: "res_stage_3_552_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_552_3"  
  type: "Scale"
  bottom: "res_stage_3_552_3"
  top: "res_stage_3_552_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_552"
  type: "Eltwise"
  bottom: "res_3_551"
  bottom: "res_stage_3_552_3_top"
  top: "res_3_552"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_552_relu"
  type: "ReLU"
  bottom: "res_3_552"
  top: "res_3_552"
}
layer {
  name: "res_stage_3_553_1"
  type: "Convolution"
  bottom: "res_3_552"
  top: "res_stage_3_553_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_553_1"
  type: "BatchNorm"
  bottom: "res_stage_3_553_1"
  top: "res_stage_3_553_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_553_1"  
  type: "Scale"
  bottom: "res_stage_3_553_1"
  top: "res_stage_3_553_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_553_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_553_1_top"
  top: "res_stage_3_553_1_top"
}
layer {
  name: "res_stage_3_553_2"
  type: "Convolution"
  bottom: "res_stage_3_553_1_top"
  top: "res_stage_3_553_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_553_2"
  type: "BatchNorm"
  bottom: "res_stage_3_553_2"
  top: "res_stage_3_553_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_553_2"  
  type: "Scale"
  bottom: "res_stage_3_553_2"
  top: "res_stage_3_553_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_553_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_553_2_top"
  top: "res_stage_3_553_2_top"
}
layer {
  name: "res_stage_3_553_3"
  type: "Convolution"
  bottom: "res_stage_3_553_2_top"
  top: "res_stage_3_553_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_553_3"
  type: "BatchNorm"
  bottom: "res_stage_3_553_3"
  top: "res_stage_3_553_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_553_3"  
  type: "Scale"
  bottom: "res_stage_3_553_3"
  top: "res_stage_3_553_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_553"
  type: "Eltwise"
  bottom: "res_3_552"
  bottom: "res_stage_3_553_3_top"
  top: "res_3_553"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_553_relu"
  type: "ReLU"
  bottom: "res_3_553"
  top: "res_3_553"
}
layer {
  name: "res_stage_3_554_1"
  type: "Convolution"
  bottom: "res_3_553"
  top: "res_stage_3_554_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_554_1"
  type: "BatchNorm"
  bottom: "res_stage_3_554_1"
  top: "res_stage_3_554_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_554_1"  
  type: "Scale"
  bottom: "res_stage_3_554_1"
  top: "res_stage_3_554_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_554_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_554_1_top"
  top: "res_stage_3_554_1_top"
}
layer {
  name: "res_stage_3_554_2"
  type: "Convolution"
  bottom: "res_stage_3_554_1_top"
  top: "res_stage_3_554_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_554_2"
  type: "BatchNorm"
  bottom: "res_stage_3_554_2"
  top: "res_stage_3_554_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_554_2"  
  type: "Scale"
  bottom: "res_stage_3_554_2"
  top: "res_stage_3_554_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_554_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_554_2_top"
  top: "res_stage_3_554_2_top"
}
layer {
  name: "res_stage_3_554_3"
  type: "Convolution"
  bottom: "res_stage_3_554_2_top"
  top: "res_stage_3_554_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_554_3"
  type: "BatchNorm"
  bottom: "res_stage_3_554_3"
  top: "res_stage_3_554_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_554_3"  
  type: "Scale"
  bottom: "res_stage_3_554_3"
  top: "res_stage_3_554_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_554"
  type: "Eltwise"
  bottom: "res_3_553"
  bottom: "res_stage_3_554_3_top"
  top: "res_3_554"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_554_relu"
  type: "ReLU"
  bottom: "res_3_554"
  top: "res_3_554"
}
layer {
  name: "res_stage_3_555_1"
  type: "Convolution"
  bottom: "res_3_554"
  top: "res_stage_3_555_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_555_1"
  type: "BatchNorm"
  bottom: "res_stage_3_555_1"
  top: "res_stage_3_555_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_555_1"  
  type: "Scale"
  bottom: "res_stage_3_555_1"
  top: "res_stage_3_555_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_555_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_555_1_top"
  top: "res_stage_3_555_1_top"
}
layer {
  name: "res_stage_3_555_2"
  type: "Convolution"
  bottom: "res_stage_3_555_1_top"
  top: "res_stage_3_555_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_555_2"
  type: "BatchNorm"
  bottom: "res_stage_3_555_2"
  top: "res_stage_3_555_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_555_2"  
  type: "Scale"
  bottom: "res_stage_3_555_2"
  top: "res_stage_3_555_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_555_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_555_2_top"
  top: "res_stage_3_555_2_top"
}
layer {
  name: "res_stage_3_555_3"
  type: "Convolution"
  bottom: "res_stage_3_555_2_top"
  top: "res_stage_3_555_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_555_3"
  type: "BatchNorm"
  bottom: "res_stage_3_555_3"
  top: "res_stage_3_555_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_555_3"  
  type: "Scale"
  bottom: "res_stage_3_555_3"
  top: "res_stage_3_555_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_555"
  type: "Eltwise"
  bottom: "res_3_554"
  bottom: "res_stage_3_555_3_top"
  top: "res_3_555"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_555_relu"
  type: "ReLU"
  bottom: "res_3_555"
  top: "res_3_555"
}
layer {
  name: "res_stage_3_556_1"
  type: "Convolution"
  bottom: "res_3_555"
  top: "res_stage_3_556_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_556_1"
  type: "BatchNorm"
  bottom: "res_stage_3_556_1"
  top: "res_stage_3_556_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_556_1"  
  type: "Scale"
  bottom: "res_stage_3_556_1"
  top: "res_stage_3_556_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_556_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_556_1_top"
  top: "res_stage_3_556_1_top"
}
layer {
  name: "res_stage_3_556_2"
  type: "Convolution"
  bottom: "res_stage_3_556_1_top"
  top: "res_stage_3_556_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_556_2"
  type: "BatchNorm"
  bottom: "res_stage_3_556_2"
  top: "res_stage_3_556_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_556_2"  
  type: "Scale"
  bottom: "res_stage_3_556_2"
  top: "res_stage_3_556_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_556_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_556_2_top"
  top: "res_stage_3_556_2_top"
}
layer {
  name: "res_stage_3_556_3"
  type: "Convolution"
  bottom: "res_stage_3_556_2_top"
  top: "res_stage_3_556_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_556_3"
  type: "BatchNorm"
  bottom: "res_stage_3_556_3"
  top: "res_stage_3_556_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_556_3"  
  type: "Scale"
  bottom: "res_stage_3_556_3"
  top: "res_stage_3_556_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_556"
  type: "Eltwise"
  bottom: "res_3_555"
  bottom: "res_stage_3_556_3_top"
  top: "res_3_556"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_556_relu"
  type: "ReLU"
  bottom: "res_3_556"
  top: "res_3_556"
}
layer {
  name: "res_stage_3_557_1"
  type: "Convolution"
  bottom: "res_3_556"
  top: "res_stage_3_557_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_557_1"
  type: "BatchNorm"
  bottom: "res_stage_3_557_1"
  top: "res_stage_3_557_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_557_1"  
  type: "Scale"
  bottom: "res_stage_3_557_1"
  top: "res_stage_3_557_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_557_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_557_1_top"
  top: "res_stage_3_557_1_top"
}
layer {
  name: "res_stage_3_557_2"
  type: "Convolution"
  bottom: "res_stage_3_557_1_top"
  top: "res_stage_3_557_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_557_2"
  type: "BatchNorm"
  bottom: "res_stage_3_557_2"
  top: "res_stage_3_557_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_557_2"  
  type: "Scale"
  bottom: "res_stage_3_557_2"
  top: "res_stage_3_557_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_557_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_557_2_top"
  top: "res_stage_3_557_2_top"
}
layer {
  name: "res_stage_3_557_3"
  type: "Convolution"
  bottom: "res_stage_3_557_2_top"
  top: "res_stage_3_557_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_557_3"
  type: "BatchNorm"
  bottom: "res_stage_3_557_3"
  top: "res_stage_3_557_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_557_3"  
  type: "Scale"
  bottom: "res_stage_3_557_3"
  top: "res_stage_3_557_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_557"
  type: "Eltwise"
  bottom: "res_3_556"
  bottom: "res_stage_3_557_3_top"
  top: "res_3_557"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_557_relu"
  type: "ReLU"
  bottom: "res_3_557"
  top: "res_3_557"
}
layer {
  name: "res_stage_3_558_1"
  type: "Convolution"
  bottom: "res_3_557"
  top: "res_stage_3_558_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_558_1"
  type: "BatchNorm"
  bottom: "res_stage_3_558_1"
  top: "res_stage_3_558_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_558_1"  
  type: "Scale"
  bottom: "res_stage_3_558_1"
  top: "res_stage_3_558_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_558_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_558_1_top"
  top: "res_stage_3_558_1_top"
}
layer {
  name: "res_stage_3_558_2"
  type: "Convolution"
  bottom: "res_stage_3_558_1_top"
  top: "res_stage_3_558_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_558_2"
  type: "BatchNorm"
  bottom: "res_stage_3_558_2"
  top: "res_stage_3_558_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_558_2"  
  type: "Scale"
  bottom: "res_stage_3_558_2"
  top: "res_stage_3_558_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_558_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_558_2_top"
  top: "res_stage_3_558_2_top"
}
layer {
  name: "res_stage_3_558_3"
  type: "Convolution"
  bottom: "res_stage_3_558_2_top"
  top: "res_stage_3_558_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_558_3"
  type: "BatchNorm"
  bottom: "res_stage_3_558_3"
  top: "res_stage_3_558_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_558_3"  
  type: "Scale"
  bottom: "res_stage_3_558_3"
  top: "res_stage_3_558_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_558"
  type: "Eltwise"
  bottom: "res_3_557"
  bottom: "res_stage_3_558_3_top"
  top: "res_3_558"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_558_relu"
  type: "ReLU"
  bottom: "res_3_558"
  top: "res_3_558"
}
layer {
  name: "res_stage_3_559_1"
  type: "Convolution"
  bottom: "res_3_558"
  top: "res_stage_3_559_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_559_1"
  type: "BatchNorm"
  bottom: "res_stage_3_559_1"
  top: "res_stage_3_559_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_559_1"  
  type: "Scale"
  bottom: "res_stage_3_559_1"
  top: "res_stage_3_559_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_559_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_559_1_top"
  top: "res_stage_3_559_1_top"
}
layer {
  name: "res_stage_3_559_2"
  type: "Convolution"
  bottom: "res_stage_3_559_1_top"
  top: "res_stage_3_559_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_559_2"
  type: "BatchNorm"
  bottom: "res_stage_3_559_2"
  top: "res_stage_3_559_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_559_2"  
  type: "Scale"
  bottom: "res_stage_3_559_2"
  top: "res_stage_3_559_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_559_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_559_2_top"
  top: "res_stage_3_559_2_top"
}
layer {
  name: "res_stage_3_559_3"
  type: "Convolution"
  bottom: "res_stage_3_559_2_top"
  top: "res_stage_3_559_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_559_3"
  type: "BatchNorm"
  bottom: "res_stage_3_559_3"
  top: "res_stage_3_559_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_559_3"  
  type: "Scale"
  bottom: "res_stage_3_559_3"
  top: "res_stage_3_559_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_559"
  type: "Eltwise"
  bottom: "res_3_558"
  bottom: "res_stage_3_559_3_top"
  top: "res_3_559"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_559_relu"
  type: "ReLU"
  bottom: "res_3_559"
  top: "res_3_559"
}
layer {
  name: "res_stage_3_560_1"
  type: "Convolution"
  bottom: "res_3_559"
  top: "res_stage_3_560_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_560_1"
  type: "BatchNorm"
  bottom: "res_stage_3_560_1"
  top: "res_stage_3_560_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_560_1"  
  type: "Scale"
  bottom: "res_stage_3_560_1"
  top: "res_stage_3_560_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_560_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_560_1_top"
  top: "res_stage_3_560_1_top"
}
layer {
  name: "res_stage_3_560_2"
  type: "Convolution"
  bottom: "res_stage_3_560_1_top"
  top: "res_stage_3_560_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_560_2"
  type: "BatchNorm"
  bottom: "res_stage_3_560_2"
  top: "res_stage_3_560_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_560_2"  
  type: "Scale"
  bottom: "res_stage_3_560_2"
  top: "res_stage_3_560_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_560_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_560_2_top"
  top: "res_stage_3_560_2_top"
}
layer {
  name: "res_stage_3_560_3"
  type: "Convolution"
  bottom: "res_stage_3_560_2_top"
  top: "res_stage_3_560_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_560_3"
  type: "BatchNorm"
  bottom: "res_stage_3_560_3"
  top: "res_stage_3_560_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_560_3"  
  type: "Scale"
  bottom: "res_stage_3_560_3"
  top: "res_stage_3_560_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_560"
  type: "Eltwise"
  bottom: "res_3_559"
  bottom: "res_stage_3_560_3_top"
  top: "res_3_560"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_560_relu"
  type: "ReLU"
  bottom: "res_3_560"
  top: "res_3_560"
}
layer {
  name: "res_stage_3_561_1"
  type: "Convolution"
  bottom: "res_3_560"
  top: "res_stage_3_561_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_561_1"
  type: "BatchNorm"
  bottom: "res_stage_3_561_1"
  top: "res_stage_3_561_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_561_1"  
  type: "Scale"
  bottom: "res_stage_3_561_1"
  top: "res_stage_3_561_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_561_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_561_1_top"
  top: "res_stage_3_561_1_top"
}
layer {
  name: "res_stage_3_561_2"
  type: "Convolution"
  bottom: "res_stage_3_561_1_top"
  top: "res_stage_3_561_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_561_2"
  type: "BatchNorm"
  bottom: "res_stage_3_561_2"
  top: "res_stage_3_561_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_561_2"  
  type: "Scale"
  bottom: "res_stage_3_561_2"
  top: "res_stage_3_561_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_561_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_561_2_top"
  top: "res_stage_3_561_2_top"
}
layer {
  name: "res_stage_3_561_3"
  type: "Convolution"
  bottom: "res_stage_3_561_2_top"
  top: "res_stage_3_561_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_561_3"
  type: "BatchNorm"
  bottom: "res_stage_3_561_3"
  top: "res_stage_3_561_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_561_3"  
  type: "Scale"
  bottom: "res_stage_3_561_3"
  top: "res_stage_3_561_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_561"
  type: "Eltwise"
  bottom: "res_3_560"
  bottom: "res_stage_3_561_3_top"
  top: "res_3_561"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_561_relu"
  type: "ReLU"
  bottom: "res_3_561"
  top: "res_3_561"
}
layer {
  name: "res_stage_3_562_1"
  type: "Convolution"
  bottom: "res_3_561"
  top: "res_stage_3_562_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_562_1"
  type: "BatchNorm"
  bottom: "res_stage_3_562_1"
  top: "res_stage_3_562_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_562_1"  
  type: "Scale"
  bottom: "res_stage_3_562_1"
  top: "res_stage_3_562_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_562_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_562_1_top"
  top: "res_stage_3_562_1_top"
}
layer {
  name: "res_stage_3_562_2"
  type: "Convolution"
  bottom: "res_stage_3_562_1_top"
  top: "res_stage_3_562_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_562_2"
  type: "BatchNorm"
  bottom: "res_stage_3_562_2"
  top: "res_stage_3_562_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_562_2"  
  type: "Scale"
  bottom: "res_stage_3_562_2"
  top: "res_stage_3_562_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_562_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_562_2_top"
  top: "res_stage_3_562_2_top"
}
layer {
  name: "res_stage_3_562_3"
  type: "Convolution"
  bottom: "res_stage_3_562_2_top"
  top: "res_stage_3_562_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_562_3"
  type: "BatchNorm"
  bottom: "res_stage_3_562_3"
  top: "res_stage_3_562_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_562_3"  
  type: "Scale"
  bottom: "res_stage_3_562_3"
  top: "res_stage_3_562_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_562"
  type: "Eltwise"
  bottom: "res_3_561"
  bottom: "res_stage_3_562_3_top"
  top: "res_3_562"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_562_relu"
  type: "ReLU"
  bottom: "res_3_562"
  top: "res_3_562"
}
layer {
  name: "res_stage_3_563_1"
  type: "Convolution"
  bottom: "res_3_562"
  top: "res_stage_3_563_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_563_1"
  type: "BatchNorm"
  bottom: "res_stage_3_563_1"
  top: "res_stage_3_563_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_563_1"  
  type: "Scale"
  bottom: "res_stage_3_563_1"
  top: "res_stage_3_563_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_563_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_563_1_top"
  top: "res_stage_3_563_1_top"
}
layer {
  name: "res_stage_3_563_2"
  type: "Convolution"
  bottom: "res_stage_3_563_1_top"
  top: "res_stage_3_563_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_563_2"
  type: "BatchNorm"
  bottom: "res_stage_3_563_2"
  top: "res_stage_3_563_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_563_2"  
  type: "Scale"
  bottom: "res_stage_3_563_2"
  top: "res_stage_3_563_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_563_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_563_2_top"
  top: "res_stage_3_563_2_top"
}
layer {
  name: "res_stage_3_563_3"
  type: "Convolution"
  bottom: "res_stage_3_563_2_top"
  top: "res_stage_3_563_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_563_3"
  type: "BatchNorm"
  bottom: "res_stage_3_563_3"
  top: "res_stage_3_563_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_563_3"  
  type: "Scale"
  bottom: "res_stage_3_563_3"
  top: "res_stage_3_563_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_563"
  type: "Eltwise"
  bottom: "res_3_562"
  bottom: "res_stage_3_563_3_top"
  top: "res_3_563"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_563_relu"
  type: "ReLU"
  bottom: "res_3_563"
  top: "res_3_563"
}
layer {
  name: "res_stage_3_564_1"
  type: "Convolution"
  bottom: "res_3_563"
  top: "res_stage_3_564_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_564_1"
  type: "BatchNorm"
  bottom: "res_stage_3_564_1"
  top: "res_stage_3_564_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_564_1"  
  type: "Scale"
  bottom: "res_stage_3_564_1"
  top: "res_stage_3_564_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_564_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_564_1_top"
  top: "res_stage_3_564_1_top"
}
layer {
  name: "res_stage_3_564_2"
  type: "Convolution"
  bottom: "res_stage_3_564_1_top"
  top: "res_stage_3_564_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_564_2"
  type: "BatchNorm"
  bottom: "res_stage_3_564_2"
  top: "res_stage_3_564_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_564_2"  
  type: "Scale"
  bottom: "res_stage_3_564_2"
  top: "res_stage_3_564_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_564_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_564_2_top"
  top: "res_stage_3_564_2_top"
}
layer {
  name: "res_stage_3_564_3"
  type: "Convolution"
  bottom: "res_stage_3_564_2_top"
  top: "res_stage_3_564_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_564_3"
  type: "BatchNorm"
  bottom: "res_stage_3_564_3"
  top: "res_stage_3_564_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_564_3"  
  type: "Scale"
  bottom: "res_stage_3_564_3"
  top: "res_stage_3_564_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_564"
  type: "Eltwise"
  bottom: "res_3_563"
  bottom: "res_stage_3_564_3_top"
  top: "res_3_564"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_564_relu"
  type: "ReLU"
  bottom: "res_3_564"
  top: "res_3_564"
}
layer {
  name: "res_stage_3_565_1"
  type: "Convolution"
  bottom: "res_3_564"
  top: "res_stage_3_565_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_565_1"
  type: "BatchNorm"
  bottom: "res_stage_3_565_1"
  top: "res_stage_3_565_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_565_1"  
  type: "Scale"
  bottom: "res_stage_3_565_1"
  top: "res_stage_3_565_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_565_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_565_1_top"
  top: "res_stage_3_565_1_top"
}
layer {
  name: "res_stage_3_565_2"
  type: "Convolution"
  bottom: "res_stage_3_565_1_top"
  top: "res_stage_3_565_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_565_2"
  type: "BatchNorm"
  bottom: "res_stage_3_565_2"
  top: "res_stage_3_565_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_565_2"  
  type: "Scale"
  bottom: "res_stage_3_565_2"
  top: "res_stage_3_565_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_565_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_565_2_top"
  top: "res_stage_3_565_2_top"
}
layer {
  name: "res_stage_3_565_3"
  type: "Convolution"
  bottom: "res_stage_3_565_2_top"
  top: "res_stage_3_565_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_565_3"
  type: "BatchNorm"
  bottom: "res_stage_3_565_3"
  top: "res_stage_3_565_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_565_3"  
  type: "Scale"
  bottom: "res_stage_3_565_3"
  top: "res_stage_3_565_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_565"
  type: "Eltwise"
  bottom: "res_3_564"
  bottom: "res_stage_3_565_3_top"
  top: "res_3_565"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_565_relu"
  type: "ReLU"
  bottom: "res_3_565"
  top: "res_3_565"
}
layer {
  name: "res_stage_3_566_1"
  type: "Convolution"
  bottom: "res_3_565"
  top: "res_stage_3_566_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_566_1"
  type: "BatchNorm"
  bottom: "res_stage_3_566_1"
  top: "res_stage_3_566_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_566_1"  
  type: "Scale"
  bottom: "res_stage_3_566_1"
  top: "res_stage_3_566_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_566_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_566_1_top"
  top: "res_stage_3_566_1_top"
}
layer {
  name: "res_stage_3_566_2"
  type: "Convolution"
  bottom: "res_stage_3_566_1_top"
  top: "res_stage_3_566_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_566_2"
  type: "BatchNorm"
  bottom: "res_stage_3_566_2"
  top: "res_stage_3_566_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_566_2"  
  type: "Scale"
  bottom: "res_stage_3_566_2"
  top: "res_stage_3_566_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_566_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_566_2_top"
  top: "res_stage_3_566_2_top"
}
layer {
  name: "res_stage_3_566_3"
  type: "Convolution"
  bottom: "res_stage_3_566_2_top"
  top: "res_stage_3_566_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_566_3"
  type: "BatchNorm"
  bottom: "res_stage_3_566_3"
  top: "res_stage_3_566_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_566_3"  
  type: "Scale"
  bottom: "res_stage_3_566_3"
  top: "res_stage_3_566_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_566"
  type: "Eltwise"
  bottom: "res_3_565"
  bottom: "res_stage_3_566_3_top"
  top: "res_3_566"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_566_relu"
  type: "ReLU"
  bottom: "res_3_566"
  top: "res_3_566"
}
layer {
  name: "res_stage_3_567_1"
  type: "Convolution"
  bottom: "res_3_566"
  top: "res_stage_3_567_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_567_1"
  type: "BatchNorm"
  bottom: "res_stage_3_567_1"
  top: "res_stage_3_567_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_567_1"  
  type: "Scale"
  bottom: "res_stage_3_567_1"
  top: "res_stage_3_567_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_567_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_567_1_top"
  top: "res_stage_3_567_1_top"
}
layer {
  name: "res_stage_3_567_2"
  type: "Convolution"
  bottom: "res_stage_3_567_1_top"
  top: "res_stage_3_567_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_567_2"
  type: "BatchNorm"
  bottom: "res_stage_3_567_2"
  top: "res_stage_3_567_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_567_2"  
  type: "Scale"
  bottom: "res_stage_3_567_2"
  top: "res_stage_3_567_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_567_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_567_2_top"
  top: "res_stage_3_567_2_top"
}
layer {
  name: "res_stage_3_567_3"
  type: "Convolution"
  bottom: "res_stage_3_567_2_top"
  top: "res_stage_3_567_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_567_3"
  type: "BatchNorm"
  bottom: "res_stage_3_567_3"
  top: "res_stage_3_567_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_567_3"  
  type: "Scale"
  bottom: "res_stage_3_567_3"
  top: "res_stage_3_567_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_567"
  type: "Eltwise"
  bottom: "res_3_566"
  bottom: "res_stage_3_567_3_top"
  top: "res_3_567"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_567_relu"
  type: "ReLU"
  bottom: "res_3_567"
  top: "res_3_567"
}
layer {
  name: "res_stage_3_568_1"
  type: "Convolution"
  bottom: "res_3_567"
  top: "res_stage_3_568_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_568_1"
  type: "BatchNorm"
  bottom: "res_stage_3_568_1"
  top: "res_stage_3_568_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_568_1"  
  type: "Scale"
  bottom: "res_stage_3_568_1"
  top: "res_stage_3_568_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_568_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_568_1_top"
  top: "res_stage_3_568_1_top"
}
layer {
  name: "res_stage_3_568_2"
  type: "Convolution"
  bottom: "res_stage_3_568_1_top"
  top: "res_stage_3_568_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_568_2"
  type: "BatchNorm"
  bottom: "res_stage_3_568_2"
  top: "res_stage_3_568_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_568_2"  
  type: "Scale"
  bottom: "res_stage_3_568_2"
  top: "res_stage_3_568_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_568_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_568_2_top"
  top: "res_stage_3_568_2_top"
}
layer {
  name: "res_stage_3_568_3"
  type: "Convolution"
  bottom: "res_stage_3_568_2_top"
  top: "res_stage_3_568_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_568_3"
  type: "BatchNorm"
  bottom: "res_stage_3_568_3"
  top: "res_stage_3_568_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_568_3"  
  type: "Scale"
  bottom: "res_stage_3_568_3"
  top: "res_stage_3_568_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_568"
  type: "Eltwise"
  bottom: "res_3_567"
  bottom: "res_stage_3_568_3_top"
  top: "res_3_568"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_568_relu"
  type: "ReLU"
  bottom: "res_3_568"
  top: "res_3_568"
}
layer {
  name: "res_stage_3_569_1"
  type: "Convolution"
  bottom: "res_3_568"
  top: "res_stage_3_569_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_569_1"
  type: "BatchNorm"
  bottom: "res_stage_3_569_1"
  top: "res_stage_3_569_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_569_1"  
  type: "Scale"
  bottom: "res_stage_3_569_1"
  top: "res_stage_3_569_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_569_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_569_1_top"
  top: "res_stage_3_569_1_top"
}
layer {
  name: "res_stage_3_569_2"
  type: "Convolution"
  bottom: "res_stage_3_569_1_top"
  top: "res_stage_3_569_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_569_2"
  type: "BatchNorm"
  bottom: "res_stage_3_569_2"
  top: "res_stage_3_569_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_569_2"  
  type: "Scale"
  bottom: "res_stage_3_569_2"
  top: "res_stage_3_569_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_569_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_569_2_top"
  top: "res_stage_3_569_2_top"
}
layer {
  name: "res_stage_3_569_3"
  type: "Convolution"
  bottom: "res_stage_3_569_2_top"
  top: "res_stage_3_569_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_569_3"
  type: "BatchNorm"
  bottom: "res_stage_3_569_3"
  top: "res_stage_3_569_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_569_3"  
  type: "Scale"
  bottom: "res_stage_3_569_3"
  top: "res_stage_3_569_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_569"
  type: "Eltwise"
  bottom: "res_3_568"
  bottom: "res_stage_3_569_3_top"
  top: "res_3_569"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_569_relu"
  type: "ReLU"
  bottom: "res_3_569"
  top: "res_3_569"
}
layer {
  name: "res_stage_3_570_1"
  type: "Convolution"
  bottom: "res_3_569"
  top: "res_stage_3_570_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_570_1"
  type: "BatchNorm"
  bottom: "res_stage_3_570_1"
  top: "res_stage_3_570_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_570_1"  
  type: "Scale"
  bottom: "res_stage_3_570_1"
  top: "res_stage_3_570_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_570_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_570_1_top"
  top: "res_stage_3_570_1_top"
}
layer {
  name: "res_stage_3_570_2"
  type: "Convolution"
  bottom: "res_stage_3_570_1_top"
  top: "res_stage_3_570_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_570_2"
  type: "BatchNorm"
  bottom: "res_stage_3_570_2"
  top: "res_stage_3_570_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_570_2"  
  type: "Scale"
  bottom: "res_stage_3_570_2"
  top: "res_stage_3_570_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_570_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_570_2_top"
  top: "res_stage_3_570_2_top"
}
layer {
  name: "res_stage_3_570_3"
  type: "Convolution"
  bottom: "res_stage_3_570_2_top"
  top: "res_stage_3_570_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_570_3"
  type: "BatchNorm"
  bottom: "res_stage_3_570_3"
  top: "res_stage_3_570_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_570_3"  
  type: "Scale"
  bottom: "res_stage_3_570_3"
  top: "res_stage_3_570_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_570"
  type: "Eltwise"
  bottom: "res_3_569"
  bottom: "res_stage_3_570_3_top"
  top: "res_3_570"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_570_relu"
  type: "ReLU"
  bottom: "res_3_570"
  top: "res_3_570"
}
layer {
  name: "res_stage_3_571_1"
  type: "Convolution"
  bottom: "res_3_570"
  top: "res_stage_3_571_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_571_1"
  type: "BatchNorm"
  bottom: "res_stage_3_571_1"
  top: "res_stage_3_571_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_571_1"  
  type: "Scale"
  bottom: "res_stage_3_571_1"
  top: "res_stage_3_571_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_571_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_571_1_top"
  top: "res_stage_3_571_1_top"
}
layer {
  name: "res_stage_3_571_2"
  type: "Convolution"
  bottom: "res_stage_3_571_1_top"
  top: "res_stage_3_571_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_571_2"
  type: "BatchNorm"
  bottom: "res_stage_3_571_2"
  top: "res_stage_3_571_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_571_2"  
  type: "Scale"
  bottom: "res_stage_3_571_2"
  top: "res_stage_3_571_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_571_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_571_2_top"
  top: "res_stage_3_571_2_top"
}
layer {
  name: "res_stage_3_571_3"
  type: "Convolution"
  bottom: "res_stage_3_571_2_top"
  top: "res_stage_3_571_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_571_3"
  type: "BatchNorm"
  bottom: "res_stage_3_571_3"
  top: "res_stage_3_571_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_571_3"  
  type: "Scale"
  bottom: "res_stage_3_571_3"
  top: "res_stage_3_571_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_571"
  type: "Eltwise"
  bottom: "res_3_570"
  bottom: "res_stage_3_571_3_top"
  top: "res_3_571"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_571_relu"
  type: "ReLU"
  bottom: "res_3_571"
  top: "res_3_571"
}
layer {
  name: "res_stage_3_572_1"
  type: "Convolution"
  bottom: "res_3_571"
  top: "res_stage_3_572_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_572_1"
  type: "BatchNorm"
  bottom: "res_stage_3_572_1"
  top: "res_stage_3_572_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_572_1"  
  type: "Scale"
  bottom: "res_stage_3_572_1"
  top: "res_stage_3_572_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_572_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_572_1_top"
  top: "res_stage_3_572_1_top"
}
layer {
  name: "res_stage_3_572_2"
  type: "Convolution"
  bottom: "res_stage_3_572_1_top"
  top: "res_stage_3_572_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_572_2"
  type: "BatchNorm"
  bottom: "res_stage_3_572_2"
  top: "res_stage_3_572_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_572_2"  
  type: "Scale"
  bottom: "res_stage_3_572_2"
  top: "res_stage_3_572_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_572_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_572_2_top"
  top: "res_stage_3_572_2_top"
}
layer {
  name: "res_stage_3_572_3"
  type: "Convolution"
  bottom: "res_stage_3_572_2_top"
  top: "res_stage_3_572_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_572_3"
  type: "BatchNorm"
  bottom: "res_stage_3_572_3"
  top: "res_stage_3_572_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_572_3"  
  type: "Scale"
  bottom: "res_stage_3_572_3"
  top: "res_stage_3_572_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_572"
  type: "Eltwise"
  bottom: "res_3_571"
  bottom: "res_stage_3_572_3_top"
  top: "res_3_572"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_572_relu"
  type: "ReLU"
  bottom: "res_3_572"
  top: "res_3_572"
}
layer {
  name: "res_stage_3_573_1"
  type: "Convolution"
  bottom: "res_3_572"
  top: "res_stage_3_573_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_573_1"
  type: "BatchNorm"
  bottom: "res_stage_3_573_1"
  top: "res_stage_3_573_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_573_1"  
  type: "Scale"
  bottom: "res_stage_3_573_1"
  top: "res_stage_3_573_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_573_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_573_1_top"
  top: "res_stage_3_573_1_top"
}
layer {
  name: "res_stage_3_573_2"
  type: "Convolution"
  bottom: "res_stage_3_573_1_top"
  top: "res_stage_3_573_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_573_2"
  type: "BatchNorm"
  bottom: "res_stage_3_573_2"
  top: "res_stage_3_573_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_573_2"  
  type: "Scale"
  bottom: "res_stage_3_573_2"
  top: "res_stage_3_573_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_573_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_573_2_top"
  top: "res_stage_3_573_2_top"
}
layer {
  name: "res_stage_3_573_3"
  type: "Convolution"
  bottom: "res_stage_3_573_2_top"
  top: "res_stage_3_573_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_573_3"
  type: "BatchNorm"
  bottom: "res_stage_3_573_3"
  top: "res_stage_3_573_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_573_3"  
  type: "Scale"
  bottom: "res_stage_3_573_3"
  top: "res_stage_3_573_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_573"
  type: "Eltwise"
  bottom: "res_3_572"
  bottom: "res_stage_3_573_3_top"
  top: "res_3_573"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_573_relu"
  type: "ReLU"
  bottom: "res_3_573"
  top: "res_3_573"
}
layer {
  name: "res_stage_3_574_1"
  type: "Convolution"
  bottom: "res_3_573"
  top: "res_stage_3_574_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_574_1"
  type: "BatchNorm"
  bottom: "res_stage_3_574_1"
  top: "res_stage_3_574_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_574_1"  
  type: "Scale"
  bottom: "res_stage_3_574_1"
  top: "res_stage_3_574_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_574_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_574_1_top"
  top: "res_stage_3_574_1_top"
}
layer {
  name: "res_stage_3_574_2"
  type: "Convolution"
  bottom: "res_stage_3_574_1_top"
  top: "res_stage_3_574_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_574_2"
  type: "BatchNorm"
  bottom: "res_stage_3_574_2"
  top: "res_stage_3_574_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_574_2"  
  type: "Scale"
  bottom: "res_stage_3_574_2"
  top: "res_stage_3_574_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_574_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_574_2_top"
  top: "res_stage_3_574_2_top"
}
layer {
  name: "res_stage_3_574_3"
  type: "Convolution"
  bottom: "res_stage_3_574_2_top"
  top: "res_stage_3_574_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_574_3"
  type: "BatchNorm"
  bottom: "res_stage_3_574_3"
  top: "res_stage_3_574_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_574_3"  
  type: "Scale"
  bottom: "res_stage_3_574_3"
  top: "res_stage_3_574_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_574"
  type: "Eltwise"
  bottom: "res_3_573"
  bottom: "res_stage_3_574_3_top"
  top: "res_3_574"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_574_relu"
  type: "ReLU"
  bottom: "res_3_574"
  top: "res_3_574"
}
layer {
  name: "res_stage_3_575_1"
  type: "Convolution"
  bottom: "res_3_574"
  top: "res_stage_3_575_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_575_1"
  type: "BatchNorm"
  bottom: "res_stage_3_575_1"
  top: "res_stage_3_575_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_575_1"  
  type: "Scale"
  bottom: "res_stage_3_575_1"
  top: "res_stage_3_575_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_575_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_575_1_top"
  top: "res_stage_3_575_1_top"
}
layer {
  name: "res_stage_3_575_2"
  type: "Convolution"
  bottom: "res_stage_3_575_1_top"
  top: "res_stage_3_575_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_575_2"
  type: "BatchNorm"
  bottom: "res_stage_3_575_2"
  top: "res_stage_3_575_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_575_2"  
  type: "Scale"
  bottom: "res_stage_3_575_2"
  top: "res_stage_3_575_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_575_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_575_2_top"
  top: "res_stage_3_575_2_top"
}
layer {
  name: "res_stage_3_575_3"
  type: "Convolution"
  bottom: "res_stage_3_575_2_top"
  top: "res_stage_3_575_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_575_3"
  type: "BatchNorm"
  bottom: "res_stage_3_575_3"
  top: "res_stage_3_575_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_575_3"  
  type: "Scale"
  bottom: "res_stage_3_575_3"
  top: "res_stage_3_575_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_575"
  type: "Eltwise"
  bottom: "res_3_574"
  bottom: "res_stage_3_575_3_top"
  top: "res_3_575"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_575_relu"
  type: "ReLU"
  bottom: "res_3_575"
  top: "res_3_575"
}
layer {
  name: "res_stage_3_576_1"
  type: "Convolution"
  bottom: "res_3_575"
  top: "res_stage_3_576_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_576_1"
  type: "BatchNorm"
  bottom: "res_stage_3_576_1"
  top: "res_stage_3_576_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_576_1"  
  type: "Scale"
  bottom: "res_stage_3_576_1"
  top: "res_stage_3_576_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_576_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_576_1_top"
  top: "res_stage_3_576_1_top"
}
layer {
  name: "res_stage_3_576_2"
  type: "Convolution"
  bottom: "res_stage_3_576_1_top"
  top: "res_stage_3_576_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_576_2"
  type: "BatchNorm"
  bottom: "res_stage_3_576_2"
  top: "res_stage_3_576_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_576_2"  
  type: "Scale"
  bottom: "res_stage_3_576_2"
  top: "res_stage_3_576_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_576_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_576_2_top"
  top: "res_stage_3_576_2_top"
}
layer {
  name: "res_stage_3_576_3"
  type: "Convolution"
  bottom: "res_stage_3_576_2_top"
  top: "res_stage_3_576_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_576_3"
  type: "BatchNorm"
  bottom: "res_stage_3_576_3"
  top: "res_stage_3_576_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_576_3"  
  type: "Scale"
  bottom: "res_stage_3_576_3"
  top: "res_stage_3_576_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_576"
  type: "Eltwise"
  bottom: "res_3_575"
  bottom: "res_stage_3_576_3_top"
  top: "res_3_576"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_576_relu"
  type: "ReLU"
  bottom: "res_3_576"
  top: "res_3_576"
}
layer {
  name: "res_stage_3_577_1"
  type: "Convolution"
  bottom: "res_3_576"
  top: "res_stage_3_577_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_577_1"
  type: "BatchNorm"
  bottom: "res_stage_3_577_1"
  top: "res_stage_3_577_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_577_1"  
  type: "Scale"
  bottom: "res_stage_3_577_1"
  top: "res_stage_3_577_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_577_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_577_1_top"
  top: "res_stage_3_577_1_top"
}
layer {
  name: "res_stage_3_577_2"
  type: "Convolution"
  bottom: "res_stage_3_577_1_top"
  top: "res_stage_3_577_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_577_2"
  type: "BatchNorm"
  bottom: "res_stage_3_577_2"
  top: "res_stage_3_577_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_577_2"  
  type: "Scale"
  bottom: "res_stage_3_577_2"
  top: "res_stage_3_577_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_577_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_577_2_top"
  top: "res_stage_3_577_2_top"
}
layer {
  name: "res_stage_3_577_3"
  type: "Convolution"
  bottom: "res_stage_3_577_2_top"
  top: "res_stage_3_577_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_577_3"
  type: "BatchNorm"
  bottom: "res_stage_3_577_3"
  top: "res_stage_3_577_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_577_3"  
  type: "Scale"
  bottom: "res_stage_3_577_3"
  top: "res_stage_3_577_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_577"
  type: "Eltwise"
  bottom: "res_3_576"
  bottom: "res_stage_3_577_3_top"
  top: "res_3_577"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_577_relu"
  type: "ReLU"
  bottom: "res_3_577"
  top: "res_3_577"
}
layer {
  name: "res_stage_3_578_1"
  type: "Convolution"
  bottom: "res_3_577"
  top: "res_stage_3_578_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_578_1"
  type: "BatchNorm"
  bottom: "res_stage_3_578_1"
  top: "res_stage_3_578_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_578_1"  
  type: "Scale"
  bottom: "res_stage_3_578_1"
  top: "res_stage_3_578_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_578_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_578_1_top"
  top: "res_stage_3_578_1_top"
}
layer {
  name: "res_stage_3_578_2"
  type: "Convolution"
  bottom: "res_stage_3_578_1_top"
  top: "res_stage_3_578_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_578_2"
  type: "BatchNorm"
  bottom: "res_stage_3_578_2"
  top: "res_stage_3_578_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_578_2"  
  type: "Scale"
  bottom: "res_stage_3_578_2"
  top: "res_stage_3_578_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_578_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_578_2_top"
  top: "res_stage_3_578_2_top"
}
layer {
  name: "res_stage_3_578_3"
  type: "Convolution"
  bottom: "res_stage_3_578_2_top"
  top: "res_stage_3_578_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_578_3"
  type: "BatchNorm"
  bottom: "res_stage_3_578_3"
  top: "res_stage_3_578_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_578_3"  
  type: "Scale"
  bottom: "res_stage_3_578_3"
  top: "res_stage_3_578_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_578"
  type: "Eltwise"
  bottom: "res_3_577"
  bottom: "res_stage_3_578_3_top"
  top: "res_3_578"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_578_relu"
  type: "ReLU"
  bottom: "res_3_578"
  top: "res_3_578"
}
layer {
  name: "res_stage_3_579_1"
  type: "Convolution"
  bottom: "res_3_578"
  top: "res_stage_3_579_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_579_1"
  type: "BatchNorm"
  bottom: "res_stage_3_579_1"
  top: "res_stage_3_579_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_579_1"  
  type: "Scale"
  bottom: "res_stage_3_579_1"
  top: "res_stage_3_579_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_579_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_579_1_top"
  top: "res_stage_3_579_1_top"
}
layer {
  name: "res_stage_3_579_2"
  type: "Convolution"
  bottom: "res_stage_3_579_1_top"
  top: "res_stage_3_579_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_579_2"
  type: "BatchNorm"
  bottom: "res_stage_3_579_2"
  top: "res_stage_3_579_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_579_2"  
  type: "Scale"
  bottom: "res_stage_3_579_2"
  top: "res_stage_3_579_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_579_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_579_2_top"
  top: "res_stage_3_579_2_top"
}
layer {
  name: "res_stage_3_579_3"
  type: "Convolution"
  bottom: "res_stage_3_579_2_top"
  top: "res_stage_3_579_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_579_3"
  type: "BatchNorm"
  bottom: "res_stage_3_579_3"
  top: "res_stage_3_579_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_579_3"  
  type: "Scale"
  bottom: "res_stage_3_579_3"
  top: "res_stage_3_579_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_579"
  type: "Eltwise"
  bottom: "res_3_578"
  bottom: "res_stage_3_579_3_top"
  top: "res_3_579"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_579_relu"
  type: "ReLU"
  bottom: "res_3_579"
  top: "res_3_579"
}
layer {
  name: "res_stage_3_580_1"
  type: "Convolution"
  bottom: "res_3_579"
  top: "res_stage_3_580_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_580_1"
  type: "BatchNorm"
  bottom: "res_stage_3_580_1"
  top: "res_stage_3_580_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_580_1"  
  type: "Scale"
  bottom: "res_stage_3_580_1"
  top: "res_stage_3_580_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_580_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_580_1_top"
  top: "res_stage_3_580_1_top"
}
layer {
  name: "res_stage_3_580_2"
  type: "Convolution"
  bottom: "res_stage_3_580_1_top"
  top: "res_stage_3_580_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_580_2"
  type: "BatchNorm"
  bottom: "res_stage_3_580_2"
  top: "res_stage_3_580_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_580_2"  
  type: "Scale"
  bottom: "res_stage_3_580_2"
  top: "res_stage_3_580_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_580_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_580_2_top"
  top: "res_stage_3_580_2_top"
}
layer {
  name: "res_stage_3_580_3"
  type: "Convolution"
  bottom: "res_stage_3_580_2_top"
  top: "res_stage_3_580_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_580_3"
  type: "BatchNorm"
  bottom: "res_stage_3_580_3"
  top: "res_stage_3_580_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_580_3"  
  type: "Scale"
  bottom: "res_stage_3_580_3"
  top: "res_stage_3_580_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_580"
  type: "Eltwise"
  bottom: "res_3_579"
  bottom: "res_stage_3_580_3_top"
  top: "res_3_580"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_580_relu"
  type: "ReLU"
  bottom: "res_3_580"
  top: "res_3_580"
}
layer {
  name: "res_stage_3_581_1"
  type: "Convolution"
  bottom: "res_3_580"
  top: "res_stage_3_581_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_581_1"
  type: "BatchNorm"
  bottom: "res_stage_3_581_1"
  top: "res_stage_3_581_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_581_1"  
  type: "Scale"
  bottom: "res_stage_3_581_1"
  top: "res_stage_3_581_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_581_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_581_1_top"
  top: "res_stage_3_581_1_top"
}
layer {
  name: "res_stage_3_581_2"
  type: "Convolution"
  bottom: "res_stage_3_581_1_top"
  top: "res_stage_3_581_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_581_2"
  type: "BatchNorm"
  bottom: "res_stage_3_581_2"
  top: "res_stage_3_581_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_581_2"  
  type: "Scale"
  bottom: "res_stage_3_581_2"
  top: "res_stage_3_581_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_581_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_581_2_top"
  top: "res_stage_3_581_2_top"
}
layer {
  name: "res_stage_3_581_3"
  type: "Convolution"
  bottom: "res_stage_3_581_2_top"
  top: "res_stage_3_581_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_581_3"
  type: "BatchNorm"
  bottom: "res_stage_3_581_3"
  top: "res_stage_3_581_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_581_3"  
  type: "Scale"
  bottom: "res_stage_3_581_3"
  top: "res_stage_3_581_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_581"
  type: "Eltwise"
  bottom: "res_3_580"
  bottom: "res_stage_3_581_3_top"
  top: "res_3_581"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_581_relu"
  type: "ReLU"
  bottom: "res_3_581"
  top: "res_3_581"
}
layer {
  name: "res_stage_3_582_1"
  type: "Convolution"
  bottom: "res_3_581"
  top: "res_stage_3_582_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_582_1"
  type: "BatchNorm"
  bottom: "res_stage_3_582_1"
  top: "res_stage_3_582_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_582_1"  
  type: "Scale"
  bottom: "res_stage_3_582_1"
  top: "res_stage_3_582_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_582_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_582_1_top"
  top: "res_stage_3_582_1_top"
}
layer {
  name: "res_stage_3_582_2"
  type: "Convolution"
  bottom: "res_stage_3_582_1_top"
  top: "res_stage_3_582_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_582_2"
  type: "BatchNorm"
  bottom: "res_stage_3_582_2"
  top: "res_stage_3_582_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_582_2"  
  type: "Scale"
  bottom: "res_stage_3_582_2"
  top: "res_stage_3_582_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_582_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_582_2_top"
  top: "res_stage_3_582_2_top"
}
layer {
  name: "res_stage_3_582_3"
  type: "Convolution"
  bottom: "res_stage_3_582_2_top"
  top: "res_stage_3_582_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_582_3"
  type: "BatchNorm"
  bottom: "res_stage_3_582_3"
  top: "res_stage_3_582_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_582_3"  
  type: "Scale"
  bottom: "res_stage_3_582_3"
  top: "res_stage_3_582_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_582"
  type: "Eltwise"
  bottom: "res_3_581"
  bottom: "res_stage_3_582_3_top"
  top: "res_3_582"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_582_relu"
  type: "ReLU"
  bottom: "res_3_582"
  top: "res_3_582"
}
layer {
  name: "res_stage_3_583_1"
  type: "Convolution"
  bottom: "res_3_582"
  top: "res_stage_3_583_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_583_1"
  type: "BatchNorm"
  bottom: "res_stage_3_583_1"
  top: "res_stage_3_583_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_583_1"  
  type: "Scale"
  bottom: "res_stage_3_583_1"
  top: "res_stage_3_583_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_583_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_583_1_top"
  top: "res_stage_3_583_1_top"
}
layer {
  name: "res_stage_3_583_2"
  type: "Convolution"
  bottom: "res_stage_3_583_1_top"
  top: "res_stage_3_583_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_583_2"
  type: "BatchNorm"
  bottom: "res_stage_3_583_2"
  top: "res_stage_3_583_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_583_2"  
  type: "Scale"
  bottom: "res_stage_3_583_2"
  top: "res_stage_3_583_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_583_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_583_2_top"
  top: "res_stage_3_583_2_top"
}
layer {
  name: "res_stage_3_583_3"
  type: "Convolution"
  bottom: "res_stage_3_583_2_top"
  top: "res_stage_3_583_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_583_3"
  type: "BatchNorm"
  bottom: "res_stage_3_583_3"
  top: "res_stage_3_583_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_583_3"  
  type: "Scale"
  bottom: "res_stage_3_583_3"
  top: "res_stage_3_583_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_583"
  type: "Eltwise"
  bottom: "res_3_582"
  bottom: "res_stage_3_583_3_top"
  top: "res_3_583"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_583_relu"
  type: "ReLU"
  bottom: "res_3_583"
  top: "res_3_583"
}
layer {
  name: "res_stage_3_584_1"
  type: "Convolution"
  bottom: "res_3_583"
  top: "res_stage_3_584_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_584_1"
  type: "BatchNorm"
  bottom: "res_stage_3_584_1"
  top: "res_stage_3_584_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_584_1"  
  type: "Scale"
  bottom: "res_stage_3_584_1"
  top: "res_stage_3_584_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_584_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_584_1_top"
  top: "res_stage_3_584_1_top"
}
layer {
  name: "res_stage_3_584_2"
  type: "Convolution"
  bottom: "res_stage_3_584_1_top"
  top: "res_stage_3_584_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_584_2"
  type: "BatchNorm"
  bottom: "res_stage_3_584_2"
  top: "res_stage_3_584_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_584_2"  
  type: "Scale"
  bottom: "res_stage_3_584_2"
  top: "res_stage_3_584_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_584_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_584_2_top"
  top: "res_stage_3_584_2_top"
}
layer {
  name: "res_stage_3_584_3"
  type: "Convolution"
  bottom: "res_stage_3_584_2_top"
  top: "res_stage_3_584_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_584_3"
  type: "BatchNorm"
  bottom: "res_stage_3_584_3"
  top: "res_stage_3_584_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_584_3"  
  type: "Scale"
  bottom: "res_stage_3_584_3"
  top: "res_stage_3_584_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_584"
  type: "Eltwise"
  bottom: "res_3_583"
  bottom: "res_stage_3_584_3_top"
  top: "res_3_584"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_584_relu"
  type: "ReLU"
  bottom: "res_3_584"
  top: "res_3_584"
}
layer {
  name: "res_stage_3_585_1"
  type: "Convolution"
  bottom: "res_3_584"
  top: "res_stage_3_585_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_585_1"
  type: "BatchNorm"
  bottom: "res_stage_3_585_1"
  top: "res_stage_3_585_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_585_1"  
  type: "Scale"
  bottom: "res_stage_3_585_1"
  top: "res_stage_3_585_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_585_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_585_1_top"
  top: "res_stage_3_585_1_top"
}
layer {
  name: "res_stage_3_585_2"
  type: "Convolution"
  bottom: "res_stage_3_585_1_top"
  top: "res_stage_3_585_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_585_2"
  type: "BatchNorm"
  bottom: "res_stage_3_585_2"
  top: "res_stage_3_585_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_585_2"  
  type: "Scale"
  bottom: "res_stage_3_585_2"
  top: "res_stage_3_585_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_585_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_585_2_top"
  top: "res_stage_3_585_2_top"
}
layer {
  name: "res_stage_3_585_3"
  type: "Convolution"
  bottom: "res_stage_3_585_2_top"
  top: "res_stage_3_585_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_585_3"
  type: "BatchNorm"
  bottom: "res_stage_3_585_3"
  top: "res_stage_3_585_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_585_3"  
  type: "Scale"
  bottom: "res_stage_3_585_3"
  top: "res_stage_3_585_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_585"
  type: "Eltwise"
  bottom: "res_3_584"
  bottom: "res_stage_3_585_3_top"
  top: "res_3_585"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_585_relu"
  type: "ReLU"
  bottom: "res_3_585"
  top: "res_3_585"
}
layer {
  name: "res_stage_3_586_1"
  type: "Convolution"
  bottom: "res_3_585"
  top: "res_stage_3_586_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_586_1"
  type: "BatchNorm"
  bottom: "res_stage_3_586_1"
  top: "res_stage_3_586_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_586_1"  
  type: "Scale"
  bottom: "res_stage_3_586_1"
  top: "res_stage_3_586_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_586_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_586_1_top"
  top: "res_stage_3_586_1_top"
}
layer {
  name: "res_stage_3_586_2"
  type: "Convolution"
  bottom: "res_stage_3_586_1_top"
  top: "res_stage_3_586_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_586_2"
  type: "BatchNorm"
  bottom: "res_stage_3_586_2"
  top: "res_stage_3_586_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_586_2"  
  type: "Scale"
  bottom: "res_stage_3_586_2"
  top: "res_stage_3_586_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_586_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_586_2_top"
  top: "res_stage_3_586_2_top"
}
layer {
  name: "res_stage_3_586_3"
  type: "Convolution"
  bottom: "res_stage_3_586_2_top"
  top: "res_stage_3_586_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_586_3"
  type: "BatchNorm"
  bottom: "res_stage_3_586_3"
  top: "res_stage_3_586_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_586_3"  
  type: "Scale"
  bottom: "res_stage_3_586_3"
  top: "res_stage_3_586_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_586"
  type: "Eltwise"
  bottom: "res_3_585"
  bottom: "res_stage_3_586_3_top"
  top: "res_3_586"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_586_relu"
  type: "ReLU"
  bottom: "res_3_586"
  top: "res_3_586"
}
layer {
  name: "res_stage_3_587_1"
  type: "Convolution"
  bottom: "res_3_586"
  top: "res_stage_3_587_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_587_1"
  type: "BatchNorm"
  bottom: "res_stage_3_587_1"
  top: "res_stage_3_587_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_587_1"  
  type: "Scale"
  bottom: "res_stage_3_587_1"
  top: "res_stage_3_587_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_587_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_587_1_top"
  top: "res_stage_3_587_1_top"
}
layer {
  name: "res_stage_3_587_2"
  type: "Convolution"
  bottom: "res_stage_3_587_1_top"
  top: "res_stage_3_587_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_587_2"
  type: "BatchNorm"
  bottom: "res_stage_3_587_2"
  top: "res_stage_3_587_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_587_2"  
  type: "Scale"
  bottom: "res_stage_3_587_2"
  top: "res_stage_3_587_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_587_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_587_2_top"
  top: "res_stage_3_587_2_top"
}
layer {
  name: "res_stage_3_587_3"
  type: "Convolution"
  bottom: "res_stage_3_587_2_top"
  top: "res_stage_3_587_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_587_3"
  type: "BatchNorm"
  bottom: "res_stage_3_587_3"
  top: "res_stage_3_587_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_587_3"  
  type: "Scale"
  bottom: "res_stage_3_587_3"
  top: "res_stage_3_587_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_587"
  type: "Eltwise"
  bottom: "res_3_586"
  bottom: "res_stage_3_587_3_top"
  top: "res_3_587"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_587_relu"
  type: "ReLU"
  bottom: "res_3_587"
  top: "res_3_587"
}
layer {
  name: "res_stage_3_588_1"
  type: "Convolution"
  bottom: "res_3_587"
  top: "res_stage_3_588_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_588_1"
  type: "BatchNorm"
  bottom: "res_stage_3_588_1"
  top: "res_stage_3_588_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_588_1"  
  type: "Scale"
  bottom: "res_stage_3_588_1"
  top: "res_stage_3_588_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_588_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_588_1_top"
  top: "res_stage_3_588_1_top"
}
layer {
  name: "res_stage_3_588_2"
  type: "Convolution"
  bottom: "res_stage_3_588_1_top"
  top: "res_stage_3_588_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_588_2"
  type: "BatchNorm"
  bottom: "res_stage_3_588_2"
  top: "res_stage_3_588_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_588_2"  
  type: "Scale"
  bottom: "res_stage_3_588_2"
  top: "res_stage_3_588_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_588_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_588_2_top"
  top: "res_stage_3_588_2_top"
}
layer {
  name: "res_stage_3_588_3"
  type: "Convolution"
  bottom: "res_stage_3_588_2_top"
  top: "res_stage_3_588_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_588_3"
  type: "BatchNorm"
  bottom: "res_stage_3_588_3"
  top: "res_stage_3_588_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_588_3"  
  type: "Scale"
  bottom: "res_stage_3_588_3"
  top: "res_stage_3_588_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_588"
  type: "Eltwise"
  bottom: "res_3_587"
  bottom: "res_stage_3_588_3_top"
  top: "res_3_588"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_588_relu"
  type: "ReLU"
  bottom: "res_3_588"
  top: "res_3_588"
}
layer {
  name: "res_stage_3_589_1"
  type: "Convolution"
  bottom: "res_3_588"
  top: "res_stage_3_589_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_589_1"
  type: "BatchNorm"
  bottom: "res_stage_3_589_1"
  top: "res_stage_3_589_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_589_1"  
  type: "Scale"
  bottom: "res_stage_3_589_1"
  top: "res_stage_3_589_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_589_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_589_1_top"
  top: "res_stage_3_589_1_top"
}
layer {
  name: "res_stage_3_589_2"
  type: "Convolution"
  bottom: "res_stage_3_589_1_top"
  top: "res_stage_3_589_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_589_2"
  type: "BatchNorm"
  bottom: "res_stage_3_589_2"
  top: "res_stage_3_589_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_589_2"  
  type: "Scale"
  bottom: "res_stage_3_589_2"
  top: "res_stage_3_589_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_589_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_589_2_top"
  top: "res_stage_3_589_2_top"
}
layer {
  name: "res_stage_3_589_3"
  type: "Convolution"
  bottom: "res_stage_3_589_2_top"
  top: "res_stage_3_589_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_589_3"
  type: "BatchNorm"
  bottom: "res_stage_3_589_3"
  top: "res_stage_3_589_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_589_3"  
  type: "Scale"
  bottom: "res_stage_3_589_3"
  top: "res_stage_3_589_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_589"
  type: "Eltwise"
  bottom: "res_3_588"
  bottom: "res_stage_3_589_3_top"
  top: "res_3_589"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_589_relu"
  type: "ReLU"
  bottom: "res_3_589"
  top: "res_3_589"
}
layer {
  name: "res_stage_3_590_1"
  type: "Convolution"
  bottom: "res_3_589"
  top: "res_stage_3_590_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_590_1"
  type: "BatchNorm"
  bottom: "res_stage_3_590_1"
  top: "res_stage_3_590_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_590_1"  
  type: "Scale"
  bottom: "res_stage_3_590_1"
  top: "res_stage_3_590_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_590_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_590_1_top"
  top: "res_stage_3_590_1_top"
}
layer {
  name: "res_stage_3_590_2"
  type: "Convolution"
  bottom: "res_stage_3_590_1_top"
  top: "res_stage_3_590_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_590_2"
  type: "BatchNorm"
  bottom: "res_stage_3_590_2"
  top: "res_stage_3_590_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_590_2"  
  type: "Scale"
  bottom: "res_stage_3_590_2"
  top: "res_stage_3_590_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_590_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_590_2_top"
  top: "res_stage_3_590_2_top"
}
layer {
  name: "res_stage_3_590_3"
  type: "Convolution"
  bottom: "res_stage_3_590_2_top"
  top: "res_stage_3_590_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_590_3"
  type: "BatchNorm"
  bottom: "res_stage_3_590_3"
  top: "res_stage_3_590_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_590_3"  
  type: "Scale"
  bottom: "res_stage_3_590_3"
  top: "res_stage_3_590_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_590"
  type: "Eltwise"
  bottom: "res_3_589"
  bottom: "res_stage_3_590_3_top"
  top: "res_3_590"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_590_relu"
  type: "ReLU"
  bottom: "res_3_590"
  top: "res_3_590"
}
layer {
  name: "res_stage_3_591_1"
  type: "Convolution"
  bottom: "res_3_590"
  top: "res_stage_3_591_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_591_1"
  type: "BatchNorm"
  bottom: "res_stage_3_591_1"
  top: "res_stage_3_591_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_591_1"  
  type: "Scale"
  bottom: "res_stage_3_591_1"
  top: "res_stage_3_591_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_591_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_591_1_top"
  top: "res_stage_3_591_1_top"
}
layer {
  name: "res_stage_3_591_2"
  type: "Convolution"
  bottom: "res_stage_3_591_1_top"
  top: "res_stage_3_591_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_591_2"
  type: "BatchNorm"
  bottom: "res_stage_3_591_2"
  top: "res_stage_3_591_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_591_2"  
  type: "Scale"
  bottom: "res_stage_3_591_2"
  top: "res_stage_3_591_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_591_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_591_2_top"
  top: "res_stage_3_591_2_top"
}
layer {
  name: "res_stage_3_591_3"
  type: "Convolution"
  bottom: "res_stage_3_591_2_top"
  top: "res_stage_3_591_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_591_3"
  type: "BatchNorm"
  bottom: "res_stage_3_591_3"
  top: "res_stage_3_591_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_591_3"  
  type: "Scale"
  bottom: "res_stage_3_591_3"
  top: "res_stage_3_591_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_591"
  type: "Eltwise"
  bottom: "res_3_590"
  bottom: "res_stage_3_591_3_top"
  top: "res_3_591"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_591_relu"
  type: "ReLU"
  bottom: "res_3_591"
  top: "res_3_591"
}
layer {
  name: "res_stage_3_592_1"
  type: "Convolution"
  bottom: "res_3_591"
  top: "res_stage_3_592_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_592_1"
  type: "BatchNorm"
  bottom: "res_stage_3_592_1"
  top: "res_stage_3_592_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_592_1"  
  type: "Scale"
  bottom: "res_stage_3_592_1"
  top: "res_stage_3_592_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_592_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_592_1_top"
  top: "res_stage_3_592_1_top"
}
layer {
  name: "res_stage_3_592_2"
  type: "Convolution"
  bottom: "res_stage_3_592_1_top"
  top: "res_stage_3_592_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_592_2"
  type: "BatchNorm"
  bottom: "res_stage_3_592_2"
  top: "res_stage_3_592_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_592_2"  
  type: "Scale"
  bottom: "res_stage_3_592_2"
  top: "res_stage_3_592_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_592_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_592_2_top"
  top: "res_stage_3_592_2_top"
}
layer {
  name: "res_stage_3_592_3"
  type: "Convolution"
  bottom: "res_stage_3_592_2_top"
  top: "res_stage_3_592_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_592_3"
  type: "BatchNorm"
  bottom: "res_stage_3_592_3"
  top: "res_stage_3_592_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_592_3"  
  type: "Scale"
  bottom: "res_stage_3_592_3"
  top: "res_stage_3_592_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_592"
  type: "Eltwise"
  bottom: "res_3_591"
  bottom: "res_stage_3_592_3_top"
  top: "res_3_592"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_592_relu"
  type: "ReLU"
  bottom: "res_3_592"
  top: "res_3_592"
}
layer {
  name: "res_stage_3_593_1"
  type: "Convolution"
  bottom: "res_3_592"
  top: "res_stage_3_593_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_593_1"
  type: "BatchNorm"
  bottom: "res_stage_3_593_1"
  top: "res_stage_3_593_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_593_1"  
  type: "Scale"
  bottom: "res_stage_3_593_1"
  top: "res_stage_3_593_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_593_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_593_1_top"
  top: "res_stage_3_593_1_top"
}
layer {
  name: "res_stage_3_593_2"
  type: "Convolution"
  bottom: "res_stage_3_593_1_top"
  top: "res_stage_3_593_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_593_2"
  type: "BatchNorm"
  bottom: "res_stage_3_593_2"
  top: "res_stage_3_593_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_593_2"  
  type: "Scale"
  bottom: "res_stage_3_593_2"
  top: "res_stage_3_593_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_593_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_593_2_top"
  top: "res_stage_3_593_2_top"
}
layer {
  name: "res_stage_3_593_3"
  type: "Convolution"
  bottom: "res_stage_3_593_2_top"
  top: "res_stage_3_593_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_593_3"
  type: "BatchNorm"
  bottom: "res_stage_3_593_3"
  top: "res_stage_3_593_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_593_3"  
  type: "Scale"
  bottom: "res_stage_3_593_3"
  top: "res_stage_3_593_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_593"
  type: "Eltwise"
  bottom: "res_3_592"
  bottom: "res_stage_3_593_3_top"
  top: "res_3_593"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_593_relu"
  type: "ReLU"
  bottom: "res_3_593"
  top: "res_3_593"
}
layer {
  name: "res_stage_3_594_1"
  type: "Convolution"
  bottom: "res_3_593"
  top: "res_stage_3_594_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_594_1"
  type: "BatchNorm"
  bottom: "res_stage_3_594_1"
  top: "res_stage_3_594_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_594_1"  
  type: "Scale"
  bottom: "res_stage_3_594_1"
  top: "res_stage_3_594_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_594_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_594_1_top"
  top: "res_stage_3_594_1_top"
}
layer {
  name: "res_stage_3_594_2"
  type: "Convolution"
  bottom: "res_stage_3_594_1_top"
  top: "res_stage_3_594_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_594_2"
  type: "BatchNorm"
  bottom: "res_stage_3_594_2"
  top: "res_stage_3_594_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_594_2"  
  type: "Scale"
  bottom: "res_stage_3_594_2"
  top: "res_stage_3_594_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_594_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_594_2_top"
  top: "res_stage_3_594_2_top"
}
layer {
  name: "res_stage_3_594_3"
  type: "Convolution"
  bottom: "res_stage_3_594_2_top"
  top: "res_stage_3_594_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_594_3"
  type: "BatchNorm"
  bottom: "res_stage_3_594_3"
  top: "res_stage_3_594_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_594_3"  
  type: "Scale"
  bottom: "res_stage_3_594_3"
  top: "res_stage_3_594_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_594"
  type: "Eltwise"
  bottom: "res_3_593"
  bottom: "res_stage_3_594_3_top"
  top: "res_3_594"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_594_relu"
  type: "ReLU"
  bottom: "res_3_594"
  top: "res_3_594"
}
layer {
  name: "res_stage_3_595_1"
  type: "Convolution"
  bottom: "res_3_594"
  top: "res_stage_3_595_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_595_1"
  type: "BatchNorm"
  bottom: "res_stage_3_595_1"
  top: "res_stage_3_595_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_595_1"  
  type: "Scale"
  bottom: "res_stage_3_595_1"
  top: "res_stage_3_595_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_595_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_595_1_top"
  top: "res_stage_3_595_1_top"
}
layer {
  name: "res_stage_3_595_2"
  type: "Convolution"
  bottom: "res_stage_3_595_1_top"
  top: "res_stage_3_595_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_595_2"
  type: "BatchNorm"
  bottom: "res_stage_3_595_2"
  top: "res_stage_3_595_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_595_2"  
  type: "Scale"
  bottom: "res_stage_3_595_2"
  top: "res_stage_3_595_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_595_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_595_2_top"
  top: "res_stage_3_595_2_top"
}
layer {
  name: "res_stage_3_595_3"
  type: "Convolution"
  bottom: "res_stage_3_595_2_top"
  top: "res_stage_3_595_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_595_3"
  type: "BatchNorm"
  bottom: "res_stage_3_595_3"
  top: "res_stage_3_595_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_595_3"  
  type: "Scale"
  bottom: "res_stage_3_595_3"
  top: "res_stage_3_595_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_595"
  type: "Eltwise"
  bottom: "res_3_594"
  bottom: "res_stage_3_595_3_top"
  top: "res_3_595"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_595_relu"
  type: "ReLU"
  bottom: "res_3_595"
  top: "res_3_595"
}
layer {
  name: "res_stage_3_596_1"
  type: "Convolution"
  bottom: "res_3_595"
  top: "res_stage_3_596_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_596_1"
  type: "BatchNorm"
  bottom: "res_stage_3_596_1"
  top: "res_stage_3_596_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_596_1"  
  type: "Scale"
  bottom: "res_stage_3_596_1"
  top: "res_stage_3_596_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_596_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_596_1_top"
  top: "res_stage_3_596_1_top"
}
layer {
  name: "res_stage_3_596_2"
  type: "Convolution"
  bottom: "res_stage_3_596_1_top"
  top: "res_stage_3_596_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_596_2"
  type: "BatchNorm"
  bottom: "res_stage_3_596_2"
  top: "res_stage_3_596_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_596_2"  
  type: "Scale"
  bottom: "res_stage_3_596_2"
  top: "res_stage_3_596_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_596_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_596_2_top"
  top: "res_stage_3_596_2_top"
}
layer {
  name: "res_stage_3_596_3"
  type: "Convolution"
  bottom: "res_stage_3_596_2_top"
  top: "res_stage_3_596_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_596_3"
  type: "BatchNorm"
  bottom: "res_stage_3_596_3"
  top: "res_stage_3_596_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_596_3"  
  type: "Scale"
  bottom: "res_stage_3_596_3"
  top: "res_stage_3_596_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_596"
  type: "Eltwise"
  bottom: "res_3_595"
  bottom: "res_stage_3_596_3_top"
  top: "res_3_596"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_596_relu"
  type: "ReLU"
  bottom: "res_3_596"
  top: "res_3_596"
}
layer {
  name: "res_stage_3_597_1"
  type: "Convolution"
  bottom: "res_3_596"
  top: "res_stage_3_597_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_597_1"
  type: "BatchNorm"
  bottom: "res_stage_3_597_1"
  top: "res_stage_3_597_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_597_1"  
  type: "Scale"
  bottom: "res_stage_3_597_1"
  top: "res_stage_3_597_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_597_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_597_1_top"
  top: "res_stage_3_597_1_top"
}
layer {
  name: "res_stage_3_597_2"
  type: "Convolution"
  bottom: "res_stage_3_597_1_top"
  top: "res_stage_3_597_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_597_2"
  type: "BatchNorm"
  bottom: "res_stage_3_597_2"
  top: "res_stage_3_597_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_597_2"  
  type: "Scale"
  bottom: "res_stage_3_597_2"
  top: "res_stage_3_597_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_597_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_597_2_top"
  top: "res_stage_3_597_2_top"
}
layer {
  name: "res_stage_3_597_3"
  type: "Convolution"
  bottom: "res_stage_3_597_2_top"
  top: "res_stage_3_597_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_597_3"
  type: "BatchNorm"
  bottom: "res_stage_3_597_3"
  top: "res_stage_3_597_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_597_3"  
  type: "Scale"
  bottom: "res_stage_3_597_3"
  top: "res_stage_3_597_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_597"
  type: "Eltwise"
  bottom: "res_3_596"
  bottom: "res_stage_3_597_3_top"
  top: "res_3_597"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_597_relu"
  type: "ReLU"
  bottom: "res_3_597"
  top: "res_3_597"
}
layer {
  name: "res_stage_3_598_1"
  type: "Convolution"
  bottom: "res_3_597"
  top: "res_stage_3_598_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_598_1"
  type: "BatchNorm"
  bottom: "res_stage_3_598_1"
  top: "res_stage_3_598_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_598_1"  
  type: "Scale"
  bottom: "res_stage_3_598_1"
  top: "res_stage_3_598_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_598_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_598_1_top"
  top: "res_stage_3_598_1_top"
}
layer {
  name: "res_stage_3_598_2"
  type: "Convolution"
  bottom: "res_stage_3_598_1_top"
  top: "res_stage_3_598_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_598_2"
  type: "BatchNorm"
  bottom: "res_stage_3_598_2"
  top: "res_stage_3_598_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_598_2"  
  type: "Scale"
  bottom: "res_stage_3_598_2"
  top: "res_stage_3_598_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_598_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_598_2_top"
  top: "res_stage_3_598_2_top"
}
layer {
  name: "res_stage_3_598_3"
  type: "Convolution"
  bottom: "res_stage_3_598_2_top"
  top: "res_stage_3_598_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_598_3"
  type: "BatchNorm"
  bottom: "res_stage_3_598_3"
  top: "res_stage_3_598_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_598_3"  
  type: "Scale"
  bottom: "res_stage_3_598_3"
  top: "res_stage_3_598_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_598"
  type: "Eltwise"
  bottom: "res_3_597"
  bottom: "res_stage_3_598_3_top"
  top: "res_3_598"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_598_relu"
  type: "ReLU"
  bottom: "res_3_598"
  top: "res_3_598"
}
layer {
  name: "res_stage_3_599_1"
  type: "Convolution"
  bottom: "res_3_598"
  top: "res_stage_3_599_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_599_1"
  type: "BatchNorm"
  bottom: "res_stage_3_599_1"
  top: "res_stage_3_599_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_599_1"  
  type: "Scale"
  bottom: "res_stage_3_599_1"
  top: "res_stage_3_599_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_599_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_599_1_top"
  top: "res_stage_3_599_1_top"
}
layer {
  name: "res_stage_3_599_2"
  type: "Convolution"
  bottom: "res_stage_3_599_1_top"
  top: "res_stage_3_599_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_599_2"
  type: "BatchNorm"
  bottom: "res_stage_3_599_2"
  top: "res_stage_3_599_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_599_2"  
  type: "Scale"
  bottom: "res_stage_3_599_2"
  top: "res_stage_3_599_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_599_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_599_2_top"
  top: "res_stage_3_599_2_top"
}
layer {
  name: "res_stage_3_599_3"
  type: "Convolution"
  bottom: "res_stage_3_599_2_top"
  top: "res_stage_3_599_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_599_3"
  type: "BatchNorm"
  bottom: "res_stage_3_599_3"
  top: "res_stage_3_599_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_599_3"  
  type: "Scale"
  bottom: "res_stage_3_599_3"
  top: "res_stage_3_599_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_599"
  type: "Eltwise"
  bottom: "res_3_598"
  bottom: "res_stage_3_599_3_top"
  top: "res_3_599"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_599_relu"
  type: "ReLU"
  bottom: "res_3_599"
  top: "res_3_599"
}
layer {
  name: "res_stage_3_600_1"
  type: "Convolution"
  bottom: "res_3_599"
  top: "res_stage_3_600_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_600_1"
  type: "BatchNorm"
  bottom: "res_stage_3_600_1"
  top: "res_stage_3_600_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_600_1"  
  type: "Scale"
  bottom: "res_stage_3_600_1"
  top: "res_stage_3_600_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_600_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_600_1_top"
  top: "res_stage_3_600_1_top"
}
layer {
  name: "res_stage_3_600_2"
  type: "Convolution"
  bottom: "res_stage_3_600_1_top"
  top: "res_stage_3_600_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_600_2"
  type: "BatchNorm"
  bottom: "res_stage_3_600_2"
  top: "res_stage_3_600_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_600_2"  
  type: "Scale"
  bottom: "res_stage_3_600_2"
  top: "res_stage_3_600_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_600_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_600_2_top"
  top: "res_stage_3_600_2_top"
}
layer {
  name: "res_stage_3_600_3"
  type: "Convolution"
  bottom: "res_stage_3_600_2_top"
  top: "res_stage_3_600_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_600_3"
  type: "BatchNorm"
  bottom: "res_stage_3_600_3"
  top: "res_stage_3_600_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_600_3"  
  type: "Scale"
  bottom: "res_stage_3_600_3"
  top: "res_stage_3_600_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_600"
  type: "Eltwise"
  bottom: "res_3_599"
  bottom: "res_stage_3_600_3_top"
  top: "res_3_600"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_600_relu"
  type: "ReLU"
  bottom: "res_3_600"
  top: "res_3_600"
}
layer {
  name: "res_stage_3_601_1"
  type: "Convolution"
  bottom: "res_3_600"
  top: "res_stage_3_601_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_601_1"
  type: "BatchNorm"
  bottom: "res_stage_3_601_1"
  top: "res_stage_3_601_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_601_1"  
  type: "Scale"
  bottom: "res_stage_3_601_1"
  top: "res_stage_3_601_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_601_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_601_1_top"
  top: "res_stage_3_601_1_top"
}
layer {
  name: "res_stage_3_601_2"
  type: "Convolution"
  bottom: "res_stage_3_601_1_top"
  top: "res_stage_3_601_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_601_2"
  type: "BatchNorm"
  bottom: "res_stage_3_601_2"
  top: "res_stage_3_601_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_601_2"  
  type: "Scale"
  bottom: "res_stage_3_601_2"
  top: "res_stage_3_601_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_601_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_601_2_top"
  top: "res_stage_3_601_2_top"
}
layer {
  name: "res_stage_3_601_3"
  type: "Convolution"
  bottom: "res_stage_3_601_2_top"
  top: "res_stage_3_601_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_601_3"
  type: "BatchNorm"
  bottom: "res_stage_3_601_3"
  top: "res_stage_3_601_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_601_3"  
  type: "Scale"
  bottom: "res_stage_3_601_3"
  top: "res_stage_3_601_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_601"
  type: "Eltwise"
  bottom: "res_3_600"
  bottom: "res_stage_3_601_3_top"
  top: "res_3_601"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_601_relu"
  type: "ReLU"
  bottom: "res_3_601"
  top: "res_3_601"
}
layer {
  name: "res_stage_3_602_1"
  type: "Convolution"
  bottom: "res_3_601"
  top: "res_stage_3_602_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_602_1"
  type: "BatchNorm"
  bottom: "res_stage_3_602_1"
  top: "res_stage_3_602_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_602_1"  
  type: "Scale"
  bottom: "res_stage_3_602_1"
  top: "res_stage_3_602_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_602_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_602_1_top"
  top: "res_stage_3_602_1_top"
}
layer {
  name: "res_stage_3_602_2"
  type: "Convolution"
  bottom: "res_stage_3_602_1_top"
  top: "res_stage_3_602_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_602_2"
  type: "BatchNorm"
  bottom: "res_stage_3_602_2"
  top: "res_stage_3_602_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_602_2"  
  type: "Scale"
  bottom: "res_stage_3_602_2"
  top: "res_stage_3_602_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_602_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_602_2_top"
  top: "res_stage_3_602_2_top"
}
layer {
  name: "res_stage_3_602_3"
  type: "Convolution"
  bottom: "res_stage_3_602_2_top"
  top: "res_stage_3_602_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_602_3"
  type: "BatchNorm"
  bottom: "res_stage_3_602_3"
  top: "res_stage_3_602_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_602_3"  
  type: "Scale"
  bottom: "res_stage_3_602_3"
  top: "res_stage_3_602_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_602"
  type: "Eltwise"
  bottom: "res_3_601"
  bottom: "res_stage_3_602_3_top"
  top: "res_3_602"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_602_relu"
  type: "ReLU"
  bottom: "res_3_602"
  top: "res_3_602"
}
layer {
  name: "res_stage_3_603_1"
  type: "Convolution"
  bottom: "res_3_602"
  top: "res_stage_3_603_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_603_1"
  type: "BatchNorm"
  bottom: "res_stage_3_603_1"
  top: "res_stage_3_603_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_603_1"  
  type: "Scale"
  bottom: "res_stage_3_603_1"
  top: "res_stage_3_603_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_603_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_603_1_top"
  top: "res_stage_3_603_1_top"
}
layer {
  name: "res_stage_3_603_2"
  type: "Convolution"
  bottom: "res_stage_3_603_1_top"
  top: "res_stage_3_603_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_603_2"
  type: "BatchNorm"
  bottom: "res_stage_3_603_2"
  top: "res_stage_3_603_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_603_2"  
  type: "Scale"
  bottom: "res_stage_3_603_2"
  top: "res_stage_3_603_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_603_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_603_2_top"
  top: "res_stage_3_603_2_top"
}
layer {
  name: "res_stage_3_603_3"
  type: "Convolution"
  bottom: "res_stage_3_603_2_top"
  top: "res_stage_3_603_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_603_3"
  type: "BatchNorm"
  bottom: "res_stage_3_603_3"
  top: "res_stage_3_603_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_603_3"  
  type: "Scale"
  bottom: "res_stage_3_603_3"
  top: "res_stage_3_603_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_603"
  type: "Eltwise"
  bottom: "res_3_602"
  bottom: "res_stage_3_603_3_top"
  top: "res_3_603"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_603_relu"
  type: "ReLU"
  bottom: "res_3_603"
  top: "res_3_603"
}
layer {
  name: "res_stage_3_604_1"
  type: "Convolution"
  bottom: "res_3_603"
  top: "res_stage_3_604_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_604_1"
  type: "BatchNorm"
  bottom: "res_stage_3_604_1"
  top: "res_stage_3_604_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_604_1"  
  type: "Scale"
  bottom: "res_stage_3_604_1"
  top: "res_stage_3_604_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_604_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_604_1_top"
  top: "res_stage_3_604_1_top"
}
layer {
  name: "res_stage_3_604_2"
  type: "Convolution"
  bottom: "res_stage_3_604_1_top"
  top: "res_stage_3_604_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_604_2"
  type: "BatchNorm"
  bottom: "res_stage_3_604_2"
  top: "res_stage_3_604_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_604_2"  
  type: "Scale"
  bottom: "res_stage_3_604_2"
  top: "res_stage_3_604_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_604_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_604_2_top"
  top: "res_stage_3_604_2_top"
}
layer {
  name: "res_stage_3_604_3"
  type: "Convolution"
  bottom: "res_stage_3_604_2_top"
  top: "res_stage_3_604_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_604_3"
  type: "BatchNorm"
  bottom: "res_stage_3_604_3"
  top: "res_stage_3_604_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_604_3"  
  type: "Scale"
  bottom: "res_stage_3_604_3"
  top: "res_stage_3_604_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_604"
  type: "Eltwise"
  bottom: "res_3_603"
  bottom: "res_stage_3_604_3_top"
  top: "res_3_604"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_604_relu"
  type: "ReLU"
  bottom: "res_3_604"
  top: "res_3_604"
}
layer {
  name: "res_stage_3_605_1"
  type: "Convolution"
  bottom: "res_3_604"
  top: "res_stage_3_605_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_605_1"
  type: "BatchNorm"
  bottom: "res_stage_3_605_1"
  top: "res_stage_3_605_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_605_1"  
  type: "Scale"
  bottom: "res_stage_3_605_1"
  top: "res_stage_3_605_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_605_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_605_1_top"
  top: "res_stage_3_605_1_top"
}
layer {
  name: "res_stage_3_605_2"
  type: "Convolution"
  bottom: "res_stage_3_605_1_top"
  top: "res_stage_3_605_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_605_2"
  type: "BatchNorm"
  bottom: "res_stage_3_605_2"
  top: "res_stage_3_605_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_605_2"  
  type: "Scale"
  bottom: "res_stage_3_605_2"
  top: "res_stage_3_605_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_605_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_605_2_top"
  top: "res_stage_3_605_2_top"
}
layer {
  name: "res_stage_3_605_3"
  type: "Convolution"
  bottom: "res_stage_3_605_2_top"
  top: "res_stage_3_605_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_605_3"
  type: "BatchNorm"
  bottom: "res_stage_3_605_3"
  top: "res_stage_3_605_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_605_3"  
  type: "Scale"
  bottom: "res_stage_3_605_3"
  top: "res_stage_3_605_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_605"
  type: "Eltwise"
  bottom: "res_3_604"
  bottom: "res_stage_3_605_3_top"
  top: "res_3_605"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_605_relu"
  type: "ReLU"
  bottom: "res_3_605"
  top: "res_3_605"
}
layer {
  name: "res_stage_3_606_1"
  type: "Convolution"
  bottom: "res_3_605"
  top: "res_stage_3_606_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_606_1"
  type: "BatchNorm"
  bottom: "res_stage_3_606_1"
  top: "res_stage_3_606_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_606_1"  
  type: "Scale"
  bottom: "res_stage_3_606_1"
  top: "res_stage_3_606_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_606_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_606_1_top"
  top: "res_stage_3_606_1_top"
}
layer {
  name: "res_stage_3_606_2"
  type: "Convolution"
  bottom: "res_stage_3_606_1_top"
  top: "res_stage_3_606_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_606_2"
  type: "BatchNorm"
  bottom: "res_stage_3_606_2"
  top: "res_stage_3_606_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_606_2"  
  type: "Scale"
  bottom: "res_stage_3_606_2"
  top: "res_stage_3_606_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_606_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_606_2_top"
  top: "res_stage_3_606_2_top"
}
layer {
  name: "res_stage_3_606_3"
  type: "Convolution"
  bottom: "res_stage_3_606_2_top"
  top: "res_stage_3_606_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_606_3"
  type: "BatchNorm"
  bottom: "res_stage_3_606_3"
  top: "res_stage_3_606_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_606_3"  
  type: "Scale"
  bottom: "res_stage_3_606_3"
  top: "res_stage_3_606_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_606"
  type: "Eltwise"
  bottom: "res_3_605"
  bottom: "res_stage_3_606_3_top"
  top: "res_3_606"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_606_relu"
  type: "ReLU"
  bottom: "res_3_606"
  top: "res_3_606"
}
layer {
  name: "res_stage_3_607_1"
  type: "Convolution"
  bottom: "res_3_606"
  top: "res_stage_3_607_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_607_1"
  type: "BatchNorm"
  bottom: "res_stage_3_607_1"
  top: "res_stage_3_607_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_607_1"  
  type: "Scale"
  bottom: "res_stage_3_607_1"
  top: "res_stage_3_607_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_607_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_607_1_top"
  top: "res_stage_3_607_1_top"
}
layer {
  name: "res_stage_3_607_2"
  type: "Convolution"
  bottom: "res_stage_3_607_1_top"
  top: "res_stage_3_607_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_607_2"
  type: "BatchNorm"
  bottom: "res_stage_3_607_2"
  top: "res_stage_3_607_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_607_2"  
  type: "Scale"
  bottom: "res_stage_3_607_2"
  top: "res_stage_3_607_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_607_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_607_2_top"
  top: "res_stage_3_607_2_top"
}
layer {
  name: "res_stage_3_607_3"
  type: "Convolution"
  bottom: "res_stage_3_607_2_top"
  top: "res_stage_3_607_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_607_3"
  type: "BatchNorm"
  bottom: "res_stage_3_607_3"
  top: "res_stage_3_607_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_607_3"  
  type: "Scale"
  bottom: "res_stage_3_607_3"
  top: "res_stage_3_607_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_607"
  type: "Eltwise"
  bottom: "res_3_606"
  bottom: "res_stage_3_607_3_top"
  top: "res_3_607"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_607_relu"
  type: "ReLU"
  bottom: "res_3_607"
  top: "res_3_607"
}
layer {
  name: "res_stage_3_608_1"
  type: "Convolution"
  bottom: "res_3_607"
  top: "res_stage_3_608_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_608_1"
  type: "BatchNorm"
  bottom: "res_stage_3_608_1"
  top: "res_stage_3_608_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_608_1"  
  type: "Scale"
  bottom: "res_stage_3_608_1"
  top: "res_stage_3_608_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_608_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_608_1_top"
  top: "res_stage_3_608_1_top"
}
layer {
  name: "res_stage_3_608_2"
  type: "Convolution"
  bottom: "res_stage_3_608_1_top"
  top: "res_stage_3_608_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_608_2"
  type: "BatchNorm"
  bottom: "res_stage_3_608_2"
  top: "res_stage_3_608_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_608_2"  
  type: "Scale"
  bottom: "res_stage_3_608_2"
  top: "res_stage_3_608_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_608_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_608_2_top"
  top: "res_stage_3_608_2_top"
}
layer {
  name: "res_stage_3_608_3"
  type: "Convolution"
  bottom: "res_stage_3_608_2_top"
  top: "res_stage_3_608_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_608_3"
  type: "BatchNorm"
  bottom: "res_stage_3_608_3"
  top: "res_stage_3_608_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_608_3"  
  type: "Scale"
  bottom: "res_stage_3_608_3"
  top: "res_stage_3_608_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_608"
  type: "Eltwise"
  bottom: "res_3_607"
  bottom: "res_stage_3_608_3_top"
  top: "res_3_608"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_608_relu"
  type: "ReLU"
  bottom: "res_3_608"
  top: "res_3_608"
}
layer {
  name: "res_stage_3_609_1"
  type: "Convolution"
  bottom: "res_3_608"
  top: "res_stage_3_609_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_609_1"
  type: "BatchNorm"
  bottom: "res_stage_3_609_1"
  top: "res_stage_3_609_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_609_1"  
  type: "Scale"
  bottom: "res_stage_3_609_1"
  top: "res_stage_3_609_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_609_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_609_1_top"
  top: "res_stage_3_609_1_top"
}
layer {
  name: "res_stage_3_609_2"
  type: "Convolution"
  bottom: "res_stage_3_609_1_top"
  top: "res_stage_3_609_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_609_2"
  type: "BatchNorm"
  bottom: "res_stage_3_609_2"
  top: "res_stage_3_609_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_609_2"  
  type: "Scale"
  bottom: "res_stage_3_609_2"
  top: "res_stage_3_609_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_609_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_609_2_top"
  top: "res_stage_3_609_2_top"
}
layer {
  name: "res_stage_3_609_3"
  type: "Convolution"
  bottom: "res_stage_3_609_2_top"
  top: "res_stage_3_609_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_609_3"
  type: "BatchNorm"
  bottom: "res_stage_3_609_3"
  top: "res_stage_3_609_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_609_3"  
  type: "Scale"
  bottom: "res_stage_3_609_3"
  top: "res_stage_3_609_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_609"
  type: "Eltwise"
  bottom: "res_3_608"
  bottom: "res_stage_3_609_3_top"
  top: "res_3_609"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_609_relu"
  type: "ReLU"
  bottom: "res_3_609"
  top: "res_3_609"
}
layer {
  name: "res_stage_3_610_1"
  type: "Convolution"
  bottom: "res_3_609"
  top: "res_stage_3_610_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_610_1"
  type: "BatchNorm"
  bottom: "res_stage_3_610_1"
  top: "res_stage_3_610_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_610_1"  
  type: "Scale"
  bottom: "res_stage_3_610_1"
  top: "res_stage_3_610_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_610_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_610_1_top"
  top: "res_stage_3_610_1_top"
}
layer {
  name: "res_stage_3_610_2"
  type: "Convolution"
  bottom: "res_stage_3_610_1_top"
  top: "res_stage_3_610_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_610_2"
  type: "BatchNorm"
  bottom: "res_stage_3_610_2"
  top: "res_stage_3_610_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_610_2"  
  type: "Scale"
  bottom: "res_stage_3_610_2"
  top: "res_stage_3_610_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_610_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_610_2_top"
  top: "res_stage_3_610_2_top"
}
layer {
  name: "res_stage_3_610_3"
  type: "Convolution"
  bottom: "res_stage_3_610_2_top"
  top: "res_stage_3_610_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_610_3"
  type: "BatchNorm"
  bottom: "res_stage_3_610_3"
  top: "res_stage_3_610_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_610_3"  
  type: "Scale"
  bottom: "res_stage_3_610_3"
  top: "res_stage_3_610_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_610"
  type: "Eltwise"
  bottom: "res_3_609"
  bottom: "res_stage_3_610_3_top"
  top: "res_3_610"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_610_relu"
  type: "ReLU"
  bottom: "res_3_610"
  top: "res_3_610"
}
layer {
  name: "res_stage_3_611_1"
  type: "Convolution"
  bottom: "res_3_610"
  top: "res_stage_3_611_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_611_1"
  type: "BatchNorm"
  bottom: "res_stage_3_611_1"
  top: "res_stage_3_611_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_611_1"  
  type: "Scale"
  bottom: "res_stage_3_611_1"
  top: "res_stage_3_611_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_611_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_611_1_top"
  top: "res_stage_3_611_1_top"
}
layer {
  name: "res_stage_3_611_2"
  type: "Convolution"
  bottom: "res_stage_3_611_1_top"
  top: "res_stage_3_611_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_611_2"
  type: "BatchNorm"
  bottom: "res_stage_3_611_2"
  top: "res_stage_3_611_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_611_2"  
  type: "Scale"
  bottom: "res_stage_3_611_2"
  top: "res_stage_3_611_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_611_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_611_2_top"
  top: "res_stage_3_611_2_top"
}
layer {
  name: "res_stage_3_611_3"
  type: "Convolution"
  bottom: "res_stage_3_611_2_top"
  top: "res_stage_3_611_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_611_3"
  type: "BatchNorm"
  bottom: "res_stage_3_611_3"
  top: "res_stage_3_611_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_611_3"  
  type: "Scale"
  bottom: "res_stage_3_611_3"
  top: "res_stage_3_611_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_611"
  type: "Eltwise"
  bottom: "res_3_610"
  bottom: "res_stage_3_611_3_top"
  top: "res_3_611"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_611_relu"
  type: "ReLU"
  bottom: "res_3_611"
  top: "res_3_611"
}
layer {
  name: "res_stage_3_612_1"
  type: "Convolution"
  bottom: "res_3_611"
  top: "res_stage_3_612_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_612_1"
  type: "BatchNorm"
  bottom: "res_stage_3_612_1"
  top: "res_stage_3_612_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_612_1"  
  type: "Scale"
  bottom: "res_stage_3_612_1"
  top: "res_stage_3_612_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_612_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_612_1_top"
  top: "res_stage_3_612_1_top"
}
layer {
  name: "res_stage_3_612_2"
  type: "Convolution"
  bottom: "res_stage_3_612_1_top"
  top: "res_stage_3_612_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_612_2"
  type: "BatchNorm"
  bottom: "res_stage_3_612_2"
  top: "res_stage_3_612_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_612_2"  
  type: "Scale"
  bottom: "res_stage_3_612_2"
  top: "res_stage_3_612_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_612_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_612_2_top"
  top: "res_stage_3_612_2_top"
}
layer {
  name: "res_stage_3_612_3"
  type: "Convolution"
  bottom: "res_stage_3_612_2_top"
  top: "res_stage_3_612_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_612_3"
  type: "BatchNorm"
  bottom: "res_stage_3_612_3"
  top: "res_stage_3_612_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_612_3"  
  type: "Scale"
  bottom: "res_stage_3_612_3"
  top: "res_stage_3_612_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_612"
  type: "Eltwise"
  bottom: "res_3_611"
  bottom: "res_stage_3_612_3_top"
  top: "res_3_612"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_612_relu"
  type: "ReLU"
  bottom: "res_3_612"
  top: "res_3_612"
}
layer {
  name: "res_stage_3_613_1"
  type: "Convolution"
  bottom: "res_3_612"
  top: "res_stage_3_613_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_613_1"
  type: "BatchNorm"
  bottom: "res_stage_3_613_1"
  top: "res_stage_3_613_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_613_1"  
  type: "Scale"
  bottom: "res_stage_3_613_1"
  top: "res_stage_3_613_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_613_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_613_1_top"
  top: "res_stage_3_613_1_top"
}
layer {
  name: "res_stage_3_613_2"
  type: "Convolution"
  bottom: "res_stage_3_613_1_top"
  top: "res_stage_3_613_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_613_2"
  type: "BatchNorm"
  bottom: "res_stage_3_613_2"
  top: "res_stage_3_613_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_613_2"  
  type: "Scale"
  bottom: "res_stage_3_613_2"
  top: "res_stage_3_613_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_613_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_613_2_top"
  top: "res_stage_3_613_2_top"
}
layer {
  name: "res_stage_3_613_3"
  type: "Convolution"
  bottom: "res_stage_3_613_2_top"
  top: "res_stage_3_613_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_613_3"
  type: "BatchNorm"
  bottom: "res_stage_3_613_3"
  top: "res_stage_3_613_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_613_3"  
  type: "Scale"
  bottom: "res_stage_3_613_3"
  top: "res_stage_3_613_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_613"
  type: "Eltwise"
  bottom: "res_3_612"
  bottom: "res_stage_3_613_3_top"
  top: "res_3_613"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_613_relu"
  type: "ReLU"
  bottom: "res_3_613"
  top: "res_3_613"
}
layer {
  name: "res_stage_3_614_1"
  type: "Convolution"
  bottom: "res_3_613"
  top: "res_stage_3_614_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_614_1"
  type: "BatchNorm"
  bottom: "res_stage_3_614_1"
  top: "res_stage_3_614_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_614_1"  
  type: "Scale"
  bottom: "res_stage_3_614_1"
  top: "res_stage_3_614_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_614_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_614_1_top"
  top: "res_stage_3_614_1_top"
}
layer {
  name: "res_stage_3_614_2"
  type: "Convolution"
  bottom: "res_stage_3_614_1_top"
  top: "res_stage_3_614_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_614_2"
  type: "BatchNorm"
  bottom: "res_stage_3_614_2"
  top: "res_stage_3_614_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_614_2"  
  type: "Scale"
  bottom: "res_stage_3_614_2"
  top: "res_stage_3_614_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_614_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_614_2_top"
  top: "res_stage_3_614_2_top"
}
layer {
  name: "res_stage_3_614_3"
  type: "Convolution"
  bottom: "res_stage_3_614_2_top"
  top: "res_stage_3_614_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_614_3"
  type: "BatchNorm"
  bottom: "res_stage_3_614_3"
  top: "res_stage_3_614_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_614_3"  
  type: "Scale"
  bottom: "res_stage_3_614_3"
  top: "res_stage_3_614_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_614"
  type: "Eltwise"
  bottom: "res_3_613"
  bottom: "res_stage_3_614_3_top"
  top: "res_3_614"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_614_relu"
  type: "ReLU"
  bottom: "res_3_614"
  top: "res_3_614"
}
layer {
  name: "res_stage_3_615_1"
  type: "Convolution"
  bottom: "res_3_614"
  top: "res_stage_3_615_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_615_1"
  type: "BatchNorm"
  bottom: "res_stage_3_615_1"
  top: "res_stage_3_615_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_615_1"  
  type: "Scale"
  bottom: "res_stage_3_615_1"
  top: "res_stage_3_615_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_615_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_615_1_top"
  top: "res_stage_3_615_1_top"
}
layer {
  name: "res_stage_3_615_2"
  type: "Convolution"
  bottom: "res_stage_3_615_1_top"
  top: "res_stage_3_615_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_615_2"
  type: "BatchNorm"
  bottom: "res_stage_3_615_2"
  top: "res_stage_3_615_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_615_2"  
  type: "Scale"
  bottom: "res_stage_3_615_2"
  top: "res_stage_3_615_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_615_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_615_2_top"
  top: "res_stage_3_615_2_top"
}
layer {
  name: "res_stage_3_615_3"
  type: "Convolution"
  bottom: "res_stage_3_615_2_top"
  top: "res_stage_3_615_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_615_3"
  type: "BatchNorm"
  bottom: "res_stage_3_615_3"
  top: "res_stage_3_615_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_615_3"  
  type: "Scale"
  bottom: "res_stage_3_615_3"
  top: "res_stage_3_615_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_615"
  type: "Eltwise"
  bottom: "res_3_614"
  bottom: "res_stage_3_615_3_top"
  top: "res_3_615"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_615_relu"
  type: "ReLU"
  bottom: "res_3_615"
  top: "res_3_615"
}
layer {
  name: "res_stage_3_616_1"
  type: "Convolution"
  bottom: "res_3_615"
  top: "res_stage_3_616_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_616_1"
  type: "BatchNorm"
  bottom: "res_stage_3_616_1"
  top: "res_stage_3_616_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_616_1"  
  type: "Scale"
  bottom: "res_stage_3_616_1"
  top: "res_stage_3_616_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_616_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_616_1_top"
  top: "res_stage_3_616_1_top"
}
layer {
  name: "res_stage_3_616_2"
  type: "Convolution"
  bottom: "res_stage_3_616_1_top"
  top: "res_stage_3_616_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_616_2"
  type: "BatchNorm"
  bottom: "res_stage_3_616_2"
  top: "res_stage_3_616_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_616_2"  
  type: "Scale"
  bottom: "res_stage_3_616_2"
  top: "res_stage_3_616_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_616_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_616_2_top"
  top: "res_stage_3_616_2_top"
}
layer {
  name: "res_stage_3_616_3"
  type: "Convolution"
  bottom: "res_stage_3_616_2_top"
  top: "res_stage_3_616_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_616_3"
  type: "BatchNorm"
  bottom: "res_stage_3_616_3"
  top: "res_stage_3_616_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_616_3"  
  type: "Scale"
  bottom: "res_stage_3_616_3"
  top: "res_stage_3_616_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_616"
  type: "Eltwise"
  bottom: "res_3_615"
  bottom: "res_stage_3_616_3_top"
  top: "res_3_616"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_616_relu"
  type: "ReLU"
  bottom: "res_3_616"
  top: "res_3_616"
}
layer {
  name: "res_stage_3_617_1"
  type: "Convolution"
  bottom: "res_3_616"
  top: "res_stage_3_617_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_617_1"
  type: "BatchNorm"
  bottom: "res_stage_3_617_1"
  top: "res_stage_3_617_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_617_1"  
  type: "Scale"
  bottom: "res_stage_3_617_1"
  top: "res_stage_3_617_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_617_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_617_1_top"
  top: "res_stage_3_617_1_top"
}
layer {
  name: "res_stage_3_617_2"
  type: "Convolution"
  bottom: "res_stage_3_617_1_top"
  top: "res_stage_3_617_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_617_2"
  type: "BatchNorm"
  bottom: "res_stage_3_617_2"
  top: "res_stage_3_617_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_617_2"  
  type: "Scale"
  bottom: "res_stage_3_617_2"
  top: "res_stage_3_617_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_617_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_617_2_top"
  top: "res_stage_3_617_2_top"
}
layer {
  name: "res_stage_3_617_3"
  type: "Convolution"
  bottom: "res_stage_3_617_2_top"
  top: "res_stage_3_617_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_617_3"
  type: "BatchNorm"
  bottom: "res_stage_3_617_3"
  top: "res_stage_3_617_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_617_3"  
  type: "Scale"
  bottom: "res_stage_3_617_3"
  top: "res_stage_3_617_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_617"
  type: "Eltwise"
  bottom: "res_3_616"
  bottom: "res_stage_3_617_3_top"
  top: "res_3_617"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_617_relu"
  type: "ReLU"
  bottom: "res_3_617"
  top: "res_3_617"
}
layer {
  name: "res_stage_3_618_1"
  type: "Convolution"
  bottom: "res_3_617"
  top: "res_stage_3_618_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_618_1"
  type: "BatchNorm"
  bottom: "res_stage_3_618_1"
  top: "res_stage_3_618_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_618_1"  
  type: "Scale"
  bottom: "res_stage_3_618_1"
  top: "res_stage_3_618_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_618_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_618_1_top"
  top: "res_stage_3_618_1_top"
}
layer {
  name: "res_stage_3_618_2"
  type: "Convolution"
  bottom: "res_stage_3_618_1_top"
  top: "res_stage_3_618_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_618_2"
  type: "BatchNorm"
  bottom: "res_stage_3_618_2"
  top: "res_stage_3_618_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_618_2"  
  type: "Scale"
  bottom: "res_stage_3_618_2"
  top: "res_stage_3_618_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_618_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_618_2_top"
  top: "res_stage_3_618_2_top"
}
layer {
  name: "res_stage_3_618_3"
  type: "Convolution"
  bottom: "res_stage_3_618_2_top"
  top: "res_stage_3_618_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_618_3"
  type: "BatchNorm"
  bottom: "res_stage_3_618_3"
  top: "res_stage_3_618_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_618_3"  
  type: "Scale"
  bottom: "res_stage_3_618_3"
  top: "res_stage_3_618_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_618"
  type: "Eltwise"
  bottom: "res_3_617"
  bottom: "res_stage_3_618_3_top"
  top: "res_3_618"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_618_relu"
  type: "ReLU"
  bottom: "res_3_618"
  top: "res_3_618"
}
layer {
  name: "res_stage_3_619_1"
  type: "Convolution"
  bottom: "res_3_618"
  top: "res_stage_3_619_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_619_1"
  type: "BatchNorm"
  bottom: "res_stage_3_619_1"
  top: "res_stage_3_619_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_619_1"  
  type: "Scale"
  bottom: "res_stage_3_619_1"
  top: "res_stage_3_619_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_619_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_619_1_top"
  top: "res_stage_3_619_1_top"
}
layer {
  name: "res_stage_3_619_2"
  type: "Convolution"
  bottom: "res_stage_3_619_1_top"
  top: "res_stage_3_619_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_619_2"
  type: "BatchNorm"
  bottom: "res_stage_3_619_2"
  top: "res_stage_3_619_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_619_2"  
  type: "Scale"
  bottom: "res_stage_3_619_2"
  top: "res_stage_3_619_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_619_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_619_2_top"
  top: "res_stage_3_619_2_top"
}
layer {
  name: "res_stage_3_619_3"
  type: "Convolution"
  bottom: "res_stage_3_619_2_top"
  top: "res_stage_3_619_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_619_3"
  type: "BatchNorm"
  bottom: "res_stage_3_619_3"
  top: "res_stage_3_619_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_619_3"  
  type: "Scale"
  bottom: "res_stage_3_619_3"
  top: "res_stage_3_619_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_619"
  type: "Eltwise"
  bottom: "res_3_618"
  bottom: "res_stage_3_619_3_top"
  top: "res_3_619"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_619_relu"
  type: "ReLU"
  bottom: "res_3_619"
  top: "res_3_619"
}
layer {
  name: "res_stage_3_620_1"
  type: "Convolution"
  bottom: "res_3_619"
  top: "res_stage_3_620_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_620_1"
  type: "BatchNorm"
  bottom: "res_stage_3_620_1"
  top: "res_stage_3_620_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_620_1"  
  type: "Scale"
  bottom: "res_stage_3_620_1"
  top: "res_stage_3_620_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_620_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_620_1_top"
  top: "res_stage_3_620_1_top"
}
layer {
  name: "res_stage_3_620_2"
  type: "Convolution"
  bottom: "res_stage_3_620_1_top"
  top: "res_stage_3_620_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_620_2"
  type: "BatchNorm"
  bottom: "res_stage_3_620_2"
  top: "res_stage_3_620_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_620_2"  
  type: "Scale"
  bottom: "res_stage_3_620_2"
  top: "res_stage_3_620_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_620_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_620_2_top"
  top: "res_stage_3_620_2_top"
}
layer {
  name: "res_stage_3_620_3"
  type: "Convolution"
  bottom: "res_stage_3_620_2_top"
  top: "res_stage_3_620_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_620_3"
  type: "BatchNorm"
  bottom: "res_stage_3_620_3"
  top: "res_stage_3_620_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_620_3"  
  type: "Scale"
  bottom: "res_stage_3_620_3"
  top: "res_stage_3_620_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_620"
  type: "Eltwise"
  bottom: "res_3_619"
  bottom: "res_stage_3_620_3_top"
  top: "res_3_620"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_620_relu"
  type: "ReLU"
  bottom: "res_3_620"
  top: "res_3_620"
}
layer {
  name: "res_stage_3_621_1"
  type: "Convolution"
  bottom: "res_3_620"
  top: "res_stage_3_621_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_621_1"
  type: "BatchNorm"
  bottom: "res_stage_3_621_1"
  top: "res_stage_3_621_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_621_1"  
  type: "Scale"
  bottom: "res_stage_3_621_1"
  top: "res_stage_3_621_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_621_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_621_1_top"
  top: "res_stage_3_621_1_top"
}
layer {
  name: "res_stage_3_621_2"
  type: "Convolution"
  bottom: "res_stage_3_621_1_top"
  top: "res_stage_3_621_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_621_2"
  type: "BatchNorm"
  bottom: "res_stage_3_621_2"
  top: "res_stage_3_621_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_621_2"  
  type: "Scale"
  bottom: "res_stage_3_621_2"
  top: "res_stage_3_621_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_621_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_621_2_top"
  top: "res_stage_3_621_2_top"
}
layer {
  name: "res_stage_3_621_3"
  type: "Convolution"
  bottom: "res_stage_3_621_2_top"
  top: "res_stage_3_621_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_621_3"
  type: "BatchNorm"
  bottom: "res_stage_3_621_3"
  top: "res_stage_3_621_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_621_3"  
  type: "Scale"
  bottom: "res_stage_3_621_3"
  top: "res_stage_3_621_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_621"
  type: "Eltwise"
  bottom: "res_3_620"
  bottom: "res_stage_3_621_3_top"
  top: "res_3_621"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_621_relu"
  type: "ReLU"
  bottom: "res_3_621"
  top: "res_3_621"
}
layer {
  name: "res_stage_3_622_1"
  type: "Convolution"
  bottom: "res_3_621"
  top: "res_stage_3_622_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_622_1"
  type: "BatchNorm"
  bottom: "res_stage_3_622_1"
  top: "res_stage_3_622_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_622_1"  
  type: "Scale"
  bottom: "res_stage_3_622_1"
  top: "res_stage_3_622_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_622_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_622_1_top"
  top: "res_stage_3_622_1_top"
}
layer {
  name: "res_stage_3_622_2"
  type: "Convolution"
  bottom: "res_stage_3_622_1_top"
  top: "res_stage_3_622_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_622_2"
  type: "BatchNorm"
  bottom: "res_stage_3_622_2"
  top: "res_stage_3_622_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_622_2"  
  type: "Scale"
  bottom: "res_stage_3_622_2"
  top: "res_stage_3_622_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_622_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_622_2_top"
  top: "res_stage_3_622_2_top"
}
layer {
  name: "res_stage_3_622_3"
  type: "Convolution"
  bottom: "res_stage_3_622_2_top"
  top: "res_stage_3_622_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_622_3"
  type: "BatchNorm"
  bottom: "res_stage_3_622_3"
  top: "res_stage_3_622_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_622_3"  
  type: "Scale"
  bottom: "res_stage_3_622_3"
  top: "res_stage_3_622_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_622"
  type: "Eltwise"
  bottom: "res_3_621"
  bottom: "res_stage_3_622_3_top"
  top: "res_3_622"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_622_relu"
  type: "ReLU"
  bottom: "res_3_622"
  top: "res_3_622"
}
layer {
  name: "res_stage_3_623_1"
  type: "Convolution"
  bottom: "res_3_622"
  top: "res_stage_3_623_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_623_1"
  type: "BatchNorm"
  bottom: "res_stage_3_623_1"
  top: "res_stage_3_623_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_623_1"  
  type: "Scale"
  bottom: "res_stage_3_623_1"
  top: "res_stage_3_623_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_623_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_623_1_top"
  top: "res_stage_3_623_1_top"
}
layer {
  name: "res_stage_3_623_2"
  type: "Convolution"
  bottom: "res_stage_3_623_1_top"
  top: "res_stage_3_623_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_623_2"
  type: "BatchNorm"
  bottom: "res_stage_3_623_2"
  top: "res_stage_3_623_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_623_2"  
  type: "Scale"
  bottom: "res_stage_3_623_2"
  top: "res_stage_3_623_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_623_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_623_2_top"
  top: "res_stage_3_623_2_top"
}
layer {
  name: "res_stage_3_623_3"
  type: "Convolution"
  bottom: "res_stage_3_623_2_top"
  top: "res_stage_3_623_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_623_3"
  type: "BatchNorm"
  bottom: "res_stage_3_623_3"
  top: "res_stage_3_623_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_623_3"  
  type: "Scale"
  bottom: "res_stage_3_623_3"
  top: "res_stage_3_623_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_623"
  type: "Eltwise"
  bottom: "res_3_622"
  bottom: "res_stage_3_623_3_top"
  top: "res_3_623"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_623_relu"
  type: "ReLU"
  bottom: "res_3_623"
  top: "res_3_623"
}
layer {
  name: "res_stage_3_624_1"
  type: "Convolution"
  bottom: "res_3_623"
  top: "res_stage_3_624_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_624_1"
  type: "BatchNorm"
  bottom: "res_stage_3_624_1"
  top: "res_stage_3_624_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_624_1"  
  type: "Scale"
  bottom: "res_stage_3_624_1"
  top: "res_stage_3_624_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_624_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_624_1_top"
  top: "res_stage_3_624_1_top"
}
layer {
  name: "res_stage_3_624_2"
  type: "Convolution"
  bottom: "res_stage_3_624_1_top"
  top: "res_stage_3_624_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_624_2"
  type: "BatchNorm"
  bottom: "res_stage_3_624_2"
  top: "res_stage_3_624_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_624_2"  
  type: "Scale"
  bottom: "res_stage_3_624_2"
  top: "res_stage_3_624_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_624_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_624_2_top"
  top: "res_stage_3_624_2_top"
}
layer {
  name: "res_stage_3_624_3"
  type: "Convolution"
  bottom: "res_stage_3_624_2_top"
  top: "res_stage_3_624_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_624_3"
  type: "BatchNorm"
  bottom: "res_stage_3_624_3"
  top: "res_stage_3_624_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_624_3"  
  type: "Scale"
  bottom: "res_stage_3_624_3"
  top: "res_stage_3_624_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_624"
  type: "Eltwise"
  bottom: "res_3_623"
  bottom: "res_stage_3_624_3_top"
  top: "res_3_624"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_624_relu"
  type: "ReLU"
  bottom: "res_3_624"
  top: "res_3_624"
}
layer {
  name: "res_stage_3_625_1"
  type: "Convolution"
  bottom: "res_3_624"
  top: "res_stage_3_625_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_625_1"
  type: "BatchNorm"
  bottom: "res_stage_3_625_1"
  top: "res_stage_3_625_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_625_1"  
  type: "Scale"
  bottom: "res_stage_3_625_1"
  top: "res_stage_3_625_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_625_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_625_1_top"
  top: "res_stage_3_625_1_top"
}
layer {
  name: "res_stage_3_625_2"
  type: "Convolution"
  bottom: "res_stage_3_625_1_top"
  top: "res_stage_3_625_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_625_2"
  type: "BatchNorm"
  bottom: "res_stage_3_625_2"
  top: "res_stage_3_625_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_625_2"  
  type: "Scale"
  bottom: "res_stage_3_625_2"
  top: "res_stage_3_625_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_625_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_625_2_top"
  top: "res_stage_3_625_2_top"
}
layer {
  name: "res_stage_3_625_3"
  type: "Convolution"
  bottom: "res_stage_3_625_2_top"
  top: "res_stage_3_625_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_625_3"
  type: "BatchNorm"
  bottom: "res_stage_3_625_3"
  top: "res_stage_3_625_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_625_3"  
  type: "Scale"
  bottom: "res_stage_3_625_3"
  top: "res_stage_3_625_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_625"
  type: "Eltwise"
  bottom: "res_3_624"
  bottom: "res_stage_3_625_3_top"
  top: "res_3_625"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_625_relu"
  type: "ReLU"
  bottom: "res_3_625"
  top: "res_3_625"
}
layer {
  name: "res_stage_3_626_1"
  type: "Convolution"
  bottom: "res_3_625"
  top: "res_stage_3_626_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_626_1"
  type: "BatchNorm"
  bottom: "res_stage_3_626_1"
  top: "res_stage_3_626_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_626_1"  
  type: "Scale"
  bottom: "res_stage_3_626_1"
  top: "res_stage_3_626_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_626_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_626_1_top"
  top: "res_stage_3_626_1_top"
}
layer {
  name: "res_stage_3_626_2"
  type: "Convolution"
  bottom: "res_stage_3_626_1_top"
  top: "res_stage_3_626_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_626_2"
  type: "BatchNorm"
  bottom: "res_stage_3_626_2"
  top: "res_stage_3_626_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_626_2"  
  type: "Scale"
  bottom: "res_stage_3_626_2"
  top: "res_stage_3_626_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_626_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_626_2_top"
  top: "res_stage_3_626_2_top"
}
layer {
  name: "res_stage_3_626_3"
  type: "Convolution"
  bottom: "res_stage_3_626_2_top"
  top: "res_stage_3_626_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_626_3"
  type: "BatchNorm"
  bottom: "res_stage_3_626_3"
  top: "res_stage_3_626_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_626_3"  
  type: "Scale"
  bottom: "res_stage_3_626_3"
  top: "res_stage_3_626_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_626"
  type: "Eltwise"
  bottom: "res_3_625"
  bottom: "res_stage_3_626_3_top"
  top: "res_3_626"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_626_relu"
  type: "ReLU"
  bottom: "res_3_626"
  top: "res_3_626"
}
layer {
  name: "res_stage_3_627_1"
  type: "Convolution"
  bottom: "res_3_626"
  top: "res_stage_3_627_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_627_1"
  type: "BatchNorm"
  bottom: "res_stage_3_627_1"
  top: "res_stage_3_627_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_627_1"  
  type: "Scale"
  bottom: "res_stage_3_627_1"
  top: "res_stage_3_627_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_627_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_627_1_top"
  top: "res_stage_3_627_1_top"
}
layer {
  name: "res_stage_3_627_2"
  type: "Convolution"
  bottom: "res_stage_3_627_1_top"
  top: "res_stage_3_627_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_627_2"
  type: "BatchNorm"
  bottom: "res_stage_3_627_2"
  top: "res_stage_3_627_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_627_2"  
  type: "Scale"
  bottom: "res_stage_3_627_2"
  top: "res_stage_3_627_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_627_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_627_2_top"
  top: "res_stage_3_627_2_top"
}
layer {
  name: "res_stage_3_627_3"
  type: "Convolution"
  bottom: "res_stage_3_627_2_top"
  top: "res_stage_3_627_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_627_3"
  type: "BatchNorm"
  bottom: "res_stage_3_627_3"
  top: "res_stage_3_627_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_627_3"  
  type: "Scale"
  bottom: "res_stage_3_627_3"
  top: "res_stage_3_627_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_627"
  type: "Eltwise"
  bottom: "res_3_626"
  bottom: "res_stage_3_627_3_top"
  top: "res_3_627"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_627_relu"
  type: "ReLU"
  bottom: "res_3_627"
  top: "res_3_627"
}
layer {
  name: "res_stage_3_628_1"
  type: "Convolution"
  bottom: "res_3_627"
  top: "res_stage_3_628_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_628_1"
  type: "BatchNorm"
  bottom: "res_stage_3_628_1"
  top: "res_stage_3_628_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_628_1"  
  type: "Scale"
  bottom: "res_stage_3_628_1"
  top: "res_stage_3_628_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_628_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_628_1_top"
  top: "res_stage_3_628_1_top"
}
layer {
  name: "res_stage_3_628_2"
  type: "Convolution"
  bottom: "res_stage_3_628_1_top"
  top: "res_stage_3_628_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_628_2"
  type: "BatchNorm"
  bottom: "res_stage_3_628_2"
  top: "res_stage_3_628_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_628_2"  
  type: "Scale"
  bottom: "res_stage_3_628_2"
  top: "res_stage_3_628_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_628_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_628_2_top"
  top: "res_stage_3_628_2_top"
}
layer {
  name: "res_stage_3_628_3"
  type: "Convolution"
  bottom: "res_stage_3_628_2_top"
  top: "res_stage_3_628_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_628_3"
  type: "BatchNorm"
  bottom: "res_stage_3_628_3"
  top: "res_stage_3_628_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_628_3"  
  type: "Scale"
  bottom: "res_stage_3_628_3"
  top: "res_stage_3_628_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_628"
  type: "Eltwise"
  bottom: "res_3_627"
  bottom: "res_stage_3_628_3_top"
  top: "res_3_628"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_628_relu"
  type: "ReLU"
  bottom: "res_3_628"
  top: "res_3_628"
}
layer {
  name: "res_stage_3_629_1"
  type: "Convolution"
  bottom: "res_3_628"
  top: "res_stage_3_629_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_629_1"
  type: "BatchNorm"
  bottom: "res_stage_3_629_1"
  top: "res_stage_3_629_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_629_1"  
  type: "Scale"
  bottom: "res_stage_3_629_1"
  top: "res_stage_3_629_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_629_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_629_1_top"
  top: "res_stage_3_629_1_top"
}
layer {
  name: "res_stage_3_629_2"
  type: "Convolution"
  bottom: "res_stage_3_629_1_top"
  top: "res_stage_3_629_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_629_2"
  type: "BatchNorm"
  bottom: "res_stage_3_629_2"
  top: "res_stage_3_629_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_629_2"  
  type: "Scale"
  bottom: "res_stage_3_629_2"
  top: "res_stage_3_629_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_629_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_629_2_top"
  top: "res_stage_3_629_2_top"
}
layer {
  name: "res_stage_3_629_3"
  type: "Convolution"
  bottom: "res_stage_3_629_2_top"
  top: "res_stage_3_629_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_629_3"
  type: "BatchNorm"
  bottom: "res_stage_3_629_3"
  top: "res_stage_3_629_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_629_3"  
  type: "Scale"
  bottom: "res_stage_3_629_3"
  top: "res_stage_3_629_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_629"
  type: "Eltwise"
  bottom: "res_3_628"
  bottom: "res_stage_3_629_3_top"
  top: "res_3_629"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_629_relu"
  type: "ReLU"
  bottom: "res_3_629"
  top: "res_3_629"
}
layer {
  name: "res_stage_3_630_1"
  type: "Convolution"
  bottom: "res_3_629"
  top: "res_stage_3_630_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_630_1"
  type: "BatchNorm"
  bottom: "res_stage_3_630_1"
  top: "res_stage_3_630_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_630_1"  
  type: "Scale"
  bottom: "res_stage_3_630_1"
  top: "res_stage_3_630_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_630_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_630_1_top"
  top: "res_stage_3_630_1_top"
}
layer {
  name: "res_stage_3_630_2"
  type: "Convolution"
  bottom: "res_stage_3_630_1_top"
  top: "res_stage_3_630_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_630_2"
  type: "BatchNorm"
  bottom: "res_stage_3_630_2"
  top: "res_stage_3_630_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_630_2"  
  type: "Scale"
  bottom: "res_stage_3_630_2"
  top: "res_stage_3_630_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_630_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_630_2_top"
  top: "res_stage_3_630_2_top"
}
layer {
  name: "res_stage_3_630_3"
  type: "Convolution"
  bottom: "res_stage_3_630_2_top"
  top: "res_stage_3_630_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_630_3"
  type: "BatchNorm"
  bottom: "res_stage_3_630_3"
  top: "res_stage_3_630_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_630_3"  
  type: "Scale"
  bottom: "res_stage_3_630_3"
  top: "res_stage_3_630_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_630"
  type: "Eltwise"
  bottom: "res_3_629"
  bottom: "res_stage_3_630_3_top"
  top: "res_3_630"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_630_relu"
  type: "ReLU"
  bottom: "res_3_630"
  top: "res_3_630"
}
layer {
  name: "res_stage_3_631_1"
  type: "Convolution"
  bottom: "res_3_630"
  top: "res_stage_3_631_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_631_1"
  type: "BatchNorm"
  bottom: "res_stage_3_631_1"
  top: "res_stage_3_631_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_631_1"  
  type: "Scale"
  bottom: "res_stage_3_631_1"
  top: "res_stage_3_631_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_631_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_631_1_top"
  top: "res_stage_3_631_1_top"
}
layer {
  name: "res_stage_3_631_2"
  type: "Convolution"
  bottom: "res_stage_3_631_1_top"
  top: "res_stage_3_631_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_631_2"
  type: "BatchNorm"
  bottom: "res_stage_3_631_2"
  top: "res_stage_3_631_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_631_2"  
  type: "Scale"
  bottom: "res_stage_3_631_2"
  top: "res_stage_3_631_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_631_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_631_2_top"
  top: "res_stage_3_631_2_top"
}
layer {
  name: "res_stage_3_631_3"
  type: "Convolution"
  bottom: "res_stage_3_631_2_top"
  top: "res_stage_3_631_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_631_3"
  type: "BatchNorm"
  bottom: "res_stage_3_631_3"
  top: "res_stage_3_631_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_631_3"  
  type: "Scale"
  bottom: "res_stage_3_631_3"
  top: "res_stage_3_631_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_631"
  type: "Eltwise"
  bottom: "res_3_630"
  bottom: "res_stage_3_631_3_top"
  top: "res_3_631"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_631_relu"
  type: "ReLU"
  bottom: "res_3_631"
  top: "res_3_631"
}
layer {
  name: "res_stage_3_632_1"
  type: "Convolution"
  bottom: "res_3_631"
  top: "res_stage_3_632_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_632_1"
  type: "BatchNorm"
  bottom: "res_stage_3_632_1"
  top: "res_stage_3_632_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_632_1"  
  type: "Scale"
  bottom: "res_stage_3_632_1"
  top: "res_stage_3_632_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_632_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_632_1_top"
  top: "res_stage_3_632_1_top"
}
layer {
  name: "res_stage_3_632_2"
  type: "Convolution"
  bottom: "res_stage_3_632_1_top"
  top: "res_stage_3_632_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_632_2"
  type: "BatchNorm"
  bottom: "res_stage_3_632_2"
  top: "res_stage_3_632_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_632_2"  
  type: "Scale"
  bottom: "res_stage_3_632_2"
  top: "res_stage_3_632_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_632_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_632_2_top"
  top: "res_stage_3_632_2_top"
}
layer {
  name: "res_stage_3_632_3"
  type: "Convolution"
  bottom: "res_stage_3_632_2_top"
  top: "res_stage_3_632_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_632_3"
  type: "BatchNorm"
  bottom: "res_stage_3_632_3"
  top: "res_stage_3_632_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_632_3"  
  type: "Scale"
  bottom: "res_stage_3_632_3"
  top: "res_stage_3_632_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_632"
  type: "Eltwise"
  bottom: "res_3_631"
  bottom: "res_stage_3_632_3_top"
  top: "res_3_632"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_632_relu"
  type: "ReLU"
  bottom: "res_3_632"
  top: "res_3_632"
}
layer {
  name: "res_stage_3_633_1"
  type: "Convolution"
  bottom: "res_3_632"
  top: "res_stage_3_633_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_633_1"
  type: "BatchNorm"
  bottom: "res_stage_3_633_1"
  top: "res_stage_3_633_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_633_1"  
  type: "Scale"
  bottom: "res_stage_3_633_1"
  top: "res_stage_3_633_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_633_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_633_1_top"
  top: "res_stage_3_633_1_top"
}
layer {
  name: "res_stage_3_633_2"
  type: "Convolution"
  bottom: "res_stage_3_633_1_top"
  top: "res_stage_3_633_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_633_2"
  type: "BatchNorm"
  bottom: "res_stage_3_633_2"
  top: "res_stage_3_633_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_633_2"  
  type: "Scale"
  bottom: "res_stage_3_633_2"
  top: "res_stage_3_633_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_633_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_633_2_top"
  top: "res_stage_3_633_2_top"
}
layer {
  name: "res_stage_3_633_3"
  type: "Convolution"
  bottom: "res_stage_3_633_2_top"
  top: "res_stage_3_633_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_633_3"
  type: "BatchNorm"
  bottom: "res_stage_3_633_3"
  top: "res_stage_3_633_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_633_3"  
  type: "Scale"
  bottom: "res_stage_3_633_3"
  top: "res_stage_3_633_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_633"
  type: "Eltwise"
  bottom: "res_3_632"
  bottom: "res_stage_3_633_3_top"
  top: "res_3_633"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_633_relu"
  type: "ReLU"
  bottom: "res_3_633"
  top: "res_3_633"
}
layer {
  name: "res_stage_3_634_1"
  type: "Convolution"
  bottom: "res_3_633"
  top: "res_stage_3_634_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_634_1"
  type: "BatchNorm"
  bottom: "res_stage_3_634_1"
  top: "res_stage_3_634_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_634_1"  
  type: "Scale"
  bottom: "res_stage_3_634_1"
  top: "res_stage_3_634_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_634_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_634_1_top"
  top: "res_stage_3_634_1_top"
}
layer {
  name: "res_stage_3_634_2"
  type: "Convolution"
  bottom: "res_stage_3_634_1_top"
  top: "res_stage_3_634_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_634_2"
  type: "BatchNorm"
  bottom: "res_stage_3_634_2"
  top: "res_stage_3_634_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_634_2"  
  type: "Scale"
  bottom: "res_stage_3_634_2"
  top: "res_stage_3_634_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_634_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_634_2_top"
  top: "res_stage_3_634_2_top"
}
layer {
  name: "res_stage_3_634_3"
  type: "Convolution"
  bottom: "res_stage_3_634_2_top"
  top: "res_stage_3_634_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_634_3"
  type: "BatchNorm"
  bottom: "res_stage_3_634_3"
  top: "res_stage_3_634_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_634_3"  
  type: "Scale"
  bottom: "res_stage_3_634_3"
  top: "res_stage_3_634_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_634"
  type: "Eltwise"
  bottom: "res_3_633"
  bottom: "res_stage_3_634_3_top"
  top: "res_3_634"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_634_relu"
  type: "ReLU"
  bottom: "res_3_634"
  top: "res_3_634"
}
layer {
  name: "res_stage_3_635_1"
  type: "Convolution"
  bottom: "res_3_634"
  top: "res_stage_3_635_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_635_1"
  type: "BatchNorm"
  bottom: "res_stage_3_635_1"
  top: "res_stage_3_635_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_635_1"  
  type: "Scale"
  bottom: "res_stage_3_635_1"
  top: "res_stage_3_635_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_635_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_635_1_top"
  top: "res_stage_3_635_1_top"
}
layer {
  name: "res_stage_3_635_2"
  type: "Convolution"
  bottom: "res_stage_3_635_1_top"
  top: "res_stage_3_635_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_635_2"
  type: "BatchNorm"
  bottom: "res_stage_3_635_2"
  top: "res_stage_3_635_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_635_2"  
  type: "Scale"
  bottom: "res_stage_3_635_2"
  top: "res_stage_3_635_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_635_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_635_2_top"
  top: "res_stage_3_635_2_top"
}
layer {
  name: "res_stage_3_635_3"
  type: "Convolution"
  bottom: "res_stage_3_635_2_top"
  top: "res_stage_3_635_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_635_3"
  type: "BatchNorm"
  bottom: "res_stage_3_635_3"
  top: "res_stage_3_635_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_635_3"  
  type: "Scale"
  bottom: "res_stage_3_635_3"
  top: "res_stage_3_635_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_635"
  type: "Eltwise"
  bottom: "res_3_634"
  bottom: "res_stage_3_635_3_top"
  top: "res_3_635"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_635_relu"
  type: "ReLU"
  bottom: "res_3_635"
  top: "res_3_635"
}
layer {
  name: "res_stage_3_636_1"
  type: "Convolution"
  bottom: "res_3_635"
  top: "res_stage_3_636_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_636_1"
  type: "BatchNorm"
  bottom: "res_stage_3_636_1"
  top: "res_stage_3_636_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_636_1"  
  type: "Scale"
  bottom: "res_stage_3_636_1"
  top: "res_stage_3_636_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_636_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_636_1_top"
  top: "res_stage_3_636_1_top"
}
layer {
  name: "res_stage_3_636_2"
  type: "Convolution"
  bottom: "res_stage_3_636_1_top"
  top: "res_stage_3_636_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_636_2"
  type: "BatchNorm"
  bottom: "res_stage_3_636_2"
  top: "res_stage_3_636_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_636_2"  
  type: "Scale"
  bottom: "res_stage_3_636_2"
  top: "res_stage_3_636_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_636_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_636_2_top"
  top: "res_stage_3_636_2_top"
}
layer {
  name: "res_stage_3_636_3"
  type: "Convolution"
  bottom: "res_stage_3_636_2_top"
  top: "res_stage_3_636_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_636_3"
  type: "BatchNorm"
  bottom: "res_stage_3_636_3"
  top: "res_stage_3_636_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_636_3"  
  type: "Scale"
  bottom: "res_stage_3_636_3"
  top: "res_stage_3_636_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_636"
  type: "Eltwise"
  bottom: "res_3_635"
  bottom: "res_stage_3_636_3_top"
  top: "res_3_636"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_636_relu"
  type: "ReLU"
  bottom: "res_3_636"
  top: "res_3_636"
}
layer {
  name: "res_stage_3_637_1"
  type: "Convolution"
  bottom: "res_3_636"
  top: "res_stage_3_637_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_637_1"
  type: "BatchNorm"
  bottom: "res_stage_3_637_1"
  top: "res_stage_3_637_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_637_1"  
  type: "Scale"
  bottom: "res_stage_3_637_1"
  top: "res_stage_3_637_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_637_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_637_1_top"
  top: "res_stage_3_637_1_top"
}
layer {
  name: "res_stage_3_637_2"
  type: "Convolution"
  bottom: "res_stage_3_637_1_top"
  top: "res_stage_3_637_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_637_2"
  type: "BatchNorm"
  bottom: "res_stage_3_637_2"
  top: "res_stage_3_637_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_637_2"  
  type: "Scale"
  bottom: "res_stage_3_637_2"
  top: "res_stage_3_637_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_637_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_637_2_top"
  top: "res_stage_3_637_2_top"
}
layer {
  name: "res_stage_3_637_3"
  type: "Convolution"
  bottom: "res_stage_3_637_2_top"
  top: "res_stage_3_637_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_637_3"
  type: "BatchNorm"
  bottom: "res_stage_3_637_3"
  top: "res_stage_3_637_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_637_3"  
  type: "Scale"
  bottom: "res_stage_3_637_3"
  top: "res_stage_3_637_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_637"
  type: "Eltwise"
  bottom: "res_3_636"
  bottom: "res_stage_3_637_3_top"
  top: "res_3_637"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_637_relu"
  type: "ReLU"
  bottom: "res_3_637"
  top: "res_3_637"
}
layer {
  name: "res_stage_3_638_1"
  type: "Convolution"
  bottom: "res_3_637"
  top: "res_stage_3_638_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_638_1"
  type: "BatchNorm"
  bottom: "res_stage_3_638_1"
  top: "res_stage_3_638_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_638_1"  
  type: "Scale"
  bottom: "res_stage_3_638_1"
  top: "res_stage_3_638_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_638_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_638_1_top"
  top: "res_stage_3_638_1_top"
}
layer {
  name: "res_stage_3_638_2"
  type: "Convolution"
  bottom: "res_stage_3_638_1_top"
  top: "res_stage_3_638_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_638_2"
  type: "BatchNorm"
  bottom: "res_stage_3_638_2"
  top: "res_stage_3_638_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_638_2"  
  type: "Scale"
  bottom: "res_stage_3_638_2"
  top: "res_stage_3_638_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_638_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_638_2_top"
  top: "res_stage_3_638_2_top"
}
layer {
  name: "res_stage_3_638_3"
  type: "Convolution"
  bottom: "res_stage_3_638_2_top"
  top: "res_stage_3_638_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_638_3"
  type: "BatchNorm"
  bottom: "res_stage_3_638_3"
  top: "res_stage_3_638_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_638_3"  
  type: "Scale"
  bottom: "res_stage_3_638_3"
  top: "res_stage_3_638_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_638"
  type: "Eltwise"
  bottom: "res_3_637"
  bottom: "res_stage_3_638_3_top"
  top: "res_3_638"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_638_relu"
  type: "ReLU"
  bottom: "res_3_638"
  top: "res_3_638"
}
layer {
  name: "res_stage_3_639_1"
  type: "Convolution"
  bottom: "res_3_638"
  top: "res_stage_3_639_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_639_1"
  type: "BatchNorm"
  bottom: "res_stage_3_639_1"
  top: "res_stage_3_639_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_639_1"  
  type: "Scale"
  bottom: "res_stage_3_639_1"
  top: "res_stage_3_639_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_639_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_639_1_top"
  top: "res_stage_3_639_1_top"
}
layer {
  name: "res_stage_3_639_2"
  type: "Convolution"
  bottom: "res_stage_3_639_1_top"
  top: "res_stage_3_639_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_639_2"
  type: "BatchNorm"
  bottom: "res_stage_3_639_2"
  top: "res_stage_3_639_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_639_2"  
  type: "Scale"
  bottom: "res_stage_3_639_2"
  top: "res_stage_3_639_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_639_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_639_2_top"
  top: "res_stage_3_639_2_top"
}
layer {
  name: "res_stage_3_639_3"
  type: "Convolution"
  bottom: "res_stage_3_639_2_top"
  top: "res_stage_3_639_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_639_3"
  type: "BatchNorm"
  bottom: "res_stage_3_639_3"
  top: "res_stage_3_639_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_639_3"  
  type: "Scale"
  bottom: "res_stage_3_639_3"
  top: "res_stage_3_639_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_639"
  type: "Eltwise"
  bottom: "res_3_638"
  bottom: "res_stage_3_639_3_top"
  top: "res_3_639"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_639_relu"
  type: "ReLU"
  bottom: "res_3_639"
  top: "res_3_639"
}
layer {
  name: "res_stage_3_640_1"
  type: "Convolution"
  bottom: "res_3_639"
  top: "res_stage_3_640_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_640_1"
  type: "BatchNorm"
  bottom: "res_stage_3_640_1"
  top: "res_stage_3_640_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_640_1"  
  type: "Scale"
  bottom: "res_stage_3_640_1"
  top: "res_stage_3_640_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_640_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_640_1_top"
  top: "res_stage_3_640_1_top"
}
layer {
  name: "res_stage_3_640_2"
  type: "Convolution"
  bottom: "res_stage_3_640_1_top"
  top: "res_stage_3_640_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_640_2"
  type: "BatchNorm"
  bottom: "res_stage_3_640_2"
  top: "res_stage_3_640_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_640_2"  
  type: "Scale"
  bottom: "res_stage_3_640_2"
  top: "res_stage_3_640_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_640_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_640_2_top"
  top: "res_stage_3_640_2_top"
}
layer {
  name: "res_stage_3_640_3"
  type: "Convolution"
  bottom: "res_stage_3_640_2_top"
  top: "res_stage_3_640_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_640_3"
  type: "BatchNorm"
  bottom: "res_stage_3_640_3"
  top: "res_stage_3_640_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_640_3"  
  type: "Scale"
  bottom: "res_stage_3_640_3"
  top: "res_stage_3_640_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_640"
  type: "Eltwise"
  bottom: "res_3_639"
  bottom: "res_stage_3_640_3_top"
  top: "res_3_640"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_640_relu"
  type: "ReLU"
  bottom: "res_3_640"
  top: "res_3_640"
}
layer {
  name: "res_stage_3_641_1"
  type: "Convolution"
  bottom: "res_3_640"
  top: "res_stage_3_641_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_641_1"
  type: "BatchNorm"
  bottom: "res_stage_3_641_1"
  top: "res_stage_3_641_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_641_1"  
  type: "Scale"
  bottom: "res_stage_3_641_1"
  top: "res_stage_3_641_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_641_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_641_1_top"
  top: "res_stage_3_641_1_top"
}
layer {
  name: "res_stage_3_641_2"
  type: "Convolution"
  bottom: "res_stage_3_641_1_top"
  top: "res_stage_3_641_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_641_2"
  type: "BatchNorm"
  bottom: "res_stage_3_641_2"
  top: "res_stage_3_641_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_641_2"  
  type: "Scale"
  bottom: "res_stage_3_641_2"
  top: "res_stage_3_641_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_641_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_641_2_top"
  top: "res_stage_3_641_2_top"
}
layer {
  name: "res_stage_3_641_3"
  type: "Convolution"
  bottom: "res_stage_3_641_2_top"
  top: "res_stage_3_641_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_641_3"
  type: "BatchNorm"
  bottom: "res_stage_3_641_3"
  top: "res_stage_3_641_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_641_3"  
  type: "Scale"
  bottom: "res_stage_3_641_3"
  top: "res_stage_3_641_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_641"
  type: "Eltwise"
  bottom: "res_3_640"
  bottom: "res_stage_3_641_3_top"
  top: "res_3_641"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_641_relu"
  type: "ReLU"
  bottom: "res_3_641"
  top: "res_3_641"
}
layer {
  name: "res_stage_3_642_1"
  type: "Convolution"
  bottom: "res_3_641"
  top: "res_stage_3_642_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_642_1"
  type: "BatchNorm"
  bottom: "res_stage_3_642_1"
  top: "res_stage_3_642_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_642_1"  
  type: "Scale"
  bottom: "res_stage_3_642_1"
  top: "res_stage_3_642_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_642_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_642_1_top"
  top: "res_stage_3_642_1_top"
}
layer {
  name: "res_stage_3_642_2"
  type: "Convolution"
  bottom: "res_stage_3_642_1_top"
  top: "res_stage_3_642_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_642_2"
  type: "BatchNorm"
  bottom: "res_stage_3_642_2"
  top: "res_stage_3_642_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_642_2"  
  type: "Scale"
  bottom: "res_stage_3_642_2"
  top: "res_stage_3_642_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_642_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_642_2_top"
  top: "res_stage_3_642_2_top"
}
layer {
  name: "res_stage_3_642_3"
  type: "Convolution"
  bottom: "res_stage_3_642_2_top"
  top: "res_stage_3_642_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_642_3"
  type: "BatchNorm"
  bottom: "res_stage_3_642_3"
  top: "res_stage_3_642_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_642_3"  
  type: "Scale"
  bottom: "res_stage_3_642_3"
  top: "res_stage_3_642_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_642"
  type: "Eltwise"
  bottom: "res_3_641"
  bottom: "res_stage_3_642_3_top"
  top: "res_3_642"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_642_relu"
  type: "ReLU"
  bottom: "res_3_642"
  top: "res_3_642"
}
layer {
  name: "res_stage_3_643_1"
  type: "Convolution"
  bottom: "res_3_642"
  top: "res_stage_3_643_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_643_1"
  type: "BatchNorm"
  bottom: "res_stage_3_643_1"
  top: "res_stage_3_643_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_643_1"  
  type: "Scale"
  bottom: "res_stage_3_643_1"
  top: "res_stage_3_643_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_643_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_643_1_top"
  top: "res_stage_3_643_1_top"
}
layer {
  name: "res_stage_3_643_2"
  type: "Convolution"
  bottom: "res_stage_3_643_1_top"
  top: "res_stage_3_643_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_643_2"
  type: "BatchNorm"
  bottom: "res_stage_3_643_2"
  top: "res_stage_3_643_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_643_2"  
  type: "Scale"
  bottom: "res_stage_3_643_2"
  top: "res_stage_3_643_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_643_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_643_2_top"
  top: "res_stage_3_643_2_top"
}
layer {
  name: "res_stage_3_643_3"
  type: "Convolution"
  bottom: "res_stage_3_643_2_top"
  top: "res_stage_3_643_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_643_3"
  type: "BatchNorm"
  bottom: "res_stage_3_643_3"
  top: "res_stage_3_643_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_643_3"  
  type: "Scale"
  bottom: "res_stage_3_643_3"
  top: "res_stage_3_643_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_643"
  type: "Eltwise"
  bottom: "res_3_642"
  bottom: "res_stage_3_643_3_top"
  top: "res_3_643"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_643_relu"
  type: "ReLU"
  bottom: "res_3_643"
  top: "res_3_643"
}
layer {
  name: "res_stage_3_644_1"
  type: "Convolution"
  bottom: "res_3_643"
  top: "res_stage_3_644_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_644_1"
  type: "BatchNorm"
  bottom: "res_stage_3_644_1"
  top: "res_stage_3_644_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_644_1"  
  type: "Scale"
  bottom: "res_stage_3_644_1"
  top: "res_stage_3_644_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_644_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_644_1_top"
  top: "res_stage_3_644_1_top"
}
layer {
  name: "res_stage_3_644_2"
  type: "Convolution"
  bottom: "res_stage_3_644_1_top"
  top: "res_stage_3_644_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_644_2"
  type: "BatchNorm"
  bottom: "res_stage_3_644_2"
  top: "res_stage_3_644_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_644_2"  
  type: "Scale"
  bottom: "res_stage_3_644_2"
  top: "res_stage_3_644_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_644_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_644_2_top"
  top: "res_stage_3_644_2_top"
}
layer {
  name: "res_stage_3_644_3"
  type: "Convolution"
  bottom: "res_stage_3_644_2_top"
  top: "res_stage_3_644_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_644_3"
  type: "BatchNorm"
  bottom: "res_stage_3_644_3"
  top: "res_stage_3_644_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_644_3"  
  type: "Scale"
  bottom: "res_stage_3_644_3"
  top: "res_stage_3_644_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_644"
  type: "Eltwise"
  bottom: "res_3_643"
  bottom: "res_stage_3_644_3_top"
  top: "res_3_644"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_644_relu"
  type: "ReLU"
  bottom: "res_3_644"
  top: "res_3_644"
}
layer {
  name: "res_stage_3_645_1"
  type: "Convolution"
  bottom: "res_3_644"
  top: "res_stage_3_645_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_645_1"
  type: "BatchNorm"
  bottom: "res_stage_3_645_1"
  top: "res_stage_3_645_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_645_1"  
  type: "Scale"
  bottom: "res_stage_3_645_1"
  top: "res_stage_3_645_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_645_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_645_1_top"
  top: "res_stage_3_645_1_top"
}
layer {
  name: "res_stage_3_645_2"
  type: "Convolution"
  bottom: "res_stage_3_645_1_top"
  top: "res_stage_3_645_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_645_2"
  type: "BatchNorm"
  bottom: "res_stage_3_645_2"
  top: "res_stage_3_645_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_645_2"  
  type: "Scale"
  bottom: "res_stage_3_645_2"
  top: "res_stage_3_645_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_645_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_645_2_top"
  top: "res_stage_3_645_2_top"
}
layer {
  name: "res_stage_3_645_3"
  type: "Convolution"
  bottom: "res_stage_3_645_2_top"
  top: "res_stage_3_645_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_645_3"
  type: "BatchNorm"
  bottom: "res_stage_3_645_3"
  top: "res_stage_3_645_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_645_3"  
  type: "Scale"
  bottom: "res_stage_3_645_3"
  top: "res_stage_3_645_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_645"
  type: "Eltwise"
  bottom: "res_3_644"
  bottom: "res_stage_3_645_3_top"
  top: "res_3_645"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_645_relu"
  type: "ReLU"
  bottom: "res_3_645"
  top: "res_3_645"
}
layer {
  name: "res_stage_3_646_1"
  type: "Convolution"
  bottom: "res_3_645"
  top: "res_stage_3_646_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_646_1"
  type: "BatchNorm"
  bottom: "res_stage_3_646_1"
  top: "res_stage_3_646_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_646_1"  
  type: "Scale"
  bottom: "res_stage_3_646_1"
  top: "res_stage_3_646_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_646_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_646_1_top"
  top: "res_stage_3_646_1_top"
}
layer {
  name: "res_stage_3_646_2"
  type: "Convolution"
  bottom: "res_stage_3_646_1_top"
  top: "res_stage_3_646_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_646_2"
  type: "BatchNorm"
  bottom: "res_stage_3_646_2"
  top: "res_stage_3_646_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_646_2"  
  type: "Scale"
  bottom: "res_stage_3_646_2"
  top: "res_stage_3_646_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_646_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_646_2_top"
  top: "res_stage_3_646_2_top"
}
layer {
  name: "res_stage_3_646_3"
  type: "Convolution"
  bottom: "res_stage_3_646_2_top"
  top: "res_stage_3_646_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_646_3"
  type: "BatchNorm"
  bottom: "res_stage_3_646_3"
  top: "res_stage_3_646_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_646_3"  
  type: "Scale"
  bottom: "res_stage_3_646_3"
  top: "res_stage_3_646_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_646"
  type: "Eltwise"
  bottom: "res_3_645"
  bottom: "res_stage_3_646_3_top"
  top: "res_3_646"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_646_relu"
  type: "ReLU"
  bottom: "res_3_646"
  top: "res_3_646"
}
layer {
  name: "res_stage_3_647_1"
  type: "Convolution"
  bottom: "res_3_646"
  top: "res_stage_3_647_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_647_1"
  type: "BatchNorm"
  bottom: "res_stage_3_647_1"
  top: "res_stage_3_647_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_647_1"  
  type: "Scale"
  bottom: "res_stage_3_647_1"
  top: "res_stage_3_647_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_647_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_647_1_top"
  top: "res_stage_3_647_1_top"
}
layer {
  name: "res_stage_3_647_2"
  type: "Convolution"
  bottom: "res_stage_3_647_1_top"
  top: "res_stage_3_647_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_647_2"
  type: "BatchNorm"
  bottom: "res_stage_3_647_2"
  top: "res_stage_3_647_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_647_2"  
  type: "Scale"
  bottom: "res_stage_3_647_2"
  top: "res_stage_3_647_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_647_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_647_2_top"
  top: "res_stage_3_647_2_top"
}
layer {
  name: "res_stage_3_647_3"
  type: "Convolution"
  bottom: "res_stage_3_647_2_top"
  top: "res_stage_3_647_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_647_3"
  type: "BatchNorm"
  bottom: "res_stage_3_647_3"
  top: "res_stage_3_647_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_647_3"  
  type: "Scale"
  bottom: "res_stage_3_647_3"
  top: "res_stage_3_647_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_647"
  type: "Eltwise"
  bottom: "res_3_646"
  bottom: "res_stage_3_647_3_top"
  top: "res_3_647"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_647_relu"
  type: "ReLU"
  bottom: "res_3_647"
  top: "res_3_647"
}
layer {
  name: "res_stage_3_648_1"
  type: "Convolution"
  bottom: "res_3_647"
  top: "res_stage_3_648_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_648_1"
  type: "BatchNorm"
  bottom: "res_stage_3_648_1"
  top: "res_stage_3_648_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_648_1"  
  type: "Scale"
  bottom: "res_stage_3_648_1"
  top: "res_stage_3_648_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_648_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_648_1_top"
  top: "res_stage_3_648_1_top"
}
layer {
  name: "res_stage_3_648_2"
  type: "Convolution"
  bottom: "res_stage_3_648_1_top"
  top: "res_stage_3_648_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_648_2"
  type: "BatchNorm"
  bottom: "res_stage_3_648_2"
  top: "res_stage_3_648_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_648_2"  
  type: "Scale"
  bottom: "res_stage_3_648_2"
  top: "res_stage_3_648_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_648_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_648_2_top"
  top: "res_stage_3_648_2_top"
}
layer {
  name: "res_stage_3_648_3"
  type: "Convolution"
  bottom: "res_stage_3_648_2_top"
  top: "res_stage_3_648_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_648_3"
  type: "BatchNorm"
  bottom: "res_stage_3_648_3"
  top: "res_stage_3_648_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_648_3"  
  type: "Scale"
  bottom: "res_stage_3_648_3"
  top: "res_stage_3_648_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_648"
  type: "Eltwise"
  bottom: "res_3_647"
  bottom: "res_stage_3_648_3_top"
  top: "res_3_648"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_648_relu"
  type: "ReLU"
  bottom: "res_3_648"
  top: "res_3_648"
}
layer {
  name: "res_stage_3_649_1"
  type: "Convolution"
  bottom: "res_3_648"
  top: "res_stage_3_649_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_649_1"
  type: "BatchNorm"
  bottom: "res_stage_3_649_1"
  top: "res_stage_3_649_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_649_1"  
  type: "Scale"
  bottom: "res_stage_3_649_1"
  top: "res_stage_3_649_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_649_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_649_1_top"
  top: "res_stage_3_649_1_top"
}
layer {
  name: "res_stage_3_649_2"
  type: "Convolution"
  bottom: "res_stage_3_649_1_top"
  top: "res_stage_3_649_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_649_2"
  type: "BatchNorm"
  bottom: "res_stage_3_649_2"
  top: "res_stage_3_649_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_649_2"  
  type: "Scale"
  bottom: "res_stage_3_649_2"
  top: "res_stage_3_649_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_649_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_649_2_top"
  top: "res_stage_3_649_2_top"
}
layer {
  name: "res_stage_3_649_3"
  type: "Convolution"
  bottom: "res_stage_3_649_2_top"
  top: "res_stage_3_649_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_649_3"
  type: "BatchNorm"
  bottom: "res_stage_3_649_3"
  top: "res_stage_3_649_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_649_3"  
  type: "Scale"
  bottom: "res_stage_3_649_3"
  top: "res_stage_3_649_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_649"
  type: "Eltwise"
  bottom: "res_3_648"
  bottom: "res_stage_3_649_3_top"
  top: "res_3_649"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_649_relu"
  type: "ReLU"
  bottom: "res_3_649"
  top: "res_3_649"
}
layer {
  name: "res_stage_3_650_1"
  type: "Convolution"
  bottom: "res_3_649"
  top: "res_stage_3_650_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_650_1"
  type: "BatchNorm"
  bottom: "res_stage_3_650_1"
  top: "res_stage_3_650_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_650_1"  
  type: "Scale"
  bottom: "res_stage_3_650_1"
  top: "res_stage_3_650_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_650_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_650_1_top"
  top: "res_stage_3_650_1_top"
}
layer {
  name: "res_stage_3_650_2"
  type: "Convolution"
  bottom: "res_stage_3_650_1_top"
  top: "res_stage_3_650_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_650_2"
  type: "BatchNorm"
  bottom: "res_stage_3_650_2"
  top: "res_stage_3_650_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_650_2"  
  type: "Scale"
  bottom: "res_stage_3_650_2"
  top: "res_stage_3_650_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_650_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_650_2_top"
  top: "res_stage_3_650_2_top"
}
layer {
  name: "res_stage_3_650_3"
  type: "Convolution"
  bottom: "res_stage_3_650_2_top"
  top: "res_stage_3_650_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_650_3"
  type: "BatchNorm"
  bottom: "res_stage_3_650_3"
  top: "res_stage_3_650_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_650_3"  
  type: "Scale"
  bottom: "res_stage_3_650_3"
  top: "res_stage_3_650_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_650"
  type: "Eltwise"
  bottom: "res_3_649"
  bottom: "res_stage_3_650_3_top"
  top: "res_3_650"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_650_relu"
  type: "ReLU"
  bottom: "res_3_650"
  top: "res_3_650"
}
layer {
  name: "res_stage_3_651_1"
  type: "Convolution"
  bottom: "res_3_650"
  top: "res_stage_3_651_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_651_1"
  type: "BatchNorm"
  bottom: "res_stage_3_651_1"
  top: "res_stage_3_651_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_651_1"  
  type: "Scale"
  bottom: "res_stage_3_651_1"
  top: "res_stage_3_651_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_651_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_651_1_top"
  top: "res_stage_3_651_1_top"
}
layer {
  name: "res_stage_3_651_2"
  type: "Convolution"
  bottom: "res_stage_3_651_1_top"
  top: "res_stage_3_651_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_651_2"
  type: "BatchNorm"
  bottom: "res_stage_3_651_2"
  top: "res_stage_3_651_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_651_2"  
  type: "Scale"
  bottom: "res_stage_3_651_2"
  top: "res_stage_3_651_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_651_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_651_2_top"
  top: "res_stage_3_651_2_top"
}
layer {
  name: "res_stage_3_651_3"
  type: "Convolution"
  bottom: "res_stage_3_651_2_top"
  top: "res_stage_3_651_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_651_3"
  type: "BatchNorm"
  bottom: "res_stage_3_651_3"
  top: "res_stage_3_651_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_651_3"  
  type: "Scale"
  bottom: "res_stage_3_651_3"
  top: "res_stage_3_651_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_651"
  type: "Eltwise"
  bottom: "res_3_650"
  bottom: "res_stage_3_651_3_top"
  top: "res_3_651"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_651_relu"
  type: "ReLU"
  bottom: "res_3_651"
  top: "res_3_651"
}
layer {
  name: "res_stage_3_652_1"
  type: "Convolution"
  bottom: "res_3_651"
  top: "res_stage_3_652_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_652_1"
  type: "BatchNorm"
  bottom: "res_stage_3_652_1"
  top: "res_stage_3_652_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_652_1"  
  type: "Scale"
  bottom: "res_stage_3_652_1"
  top: "res_stage_3_652_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_652_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_652_1_top"
  top: "res_stage_3_652_1_top"
}
layer {
  name: "res_stage_3_652_2"
  type: "Convolution"
  bottom: "res_stage_3_652_1_top"
  top: "res_stage_3_652_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_652_2"
  type: "BatchNorm"
  bottom: "res_stage_3_652_2"
  top: "res_stage_3_652_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_652_2"  
  type: "Scale"
  bottom: "res_stage_3_652_2"
  top: "res_stage_3_652_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_652_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_652_2_top"
  top: "res_stage_3_652_2_top"
}
layer {
  name: "res_stage_3_652_3"
  type: "Convolution"
  bottom: "res_stage_3_652_2_top"
  top: "res_stage_3_652_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_652_3"
  type: "BatchNorm"
  bottom: "res_stage_3_652_3"
  top: "res_stage_3_652_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_652_3"  
  type: "Scale"
  bottom: "res_stage_3_652_3"
  top: "res_stage_3_652_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_652"
  type: "Eltwise"
  bottom: "res_3_651"
  bottom: "res_stage_3_652_3_top"
  top: "res_3_652"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_652_relu"
  type: "ReLU"
  bottom: "res_3_652"
  top: "res_3_652"
}
layer {
  name: "res_stage_3_653_1"
  type: "Convolution"
  bottom: "res_3_652"
  top: "res_stage_3_653_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_653_1"
  type: "BatchNorm"
  bottom: "res_stage_3_653_1"
  top: "res_stage_3_653_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_653_1"  
  type: "Scale"
  bottom: "res_stage_3_653_1"
  top: "res_stage_3_653_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_653_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_653_1_top"
  top: "res_stage_3_653_1_top"
}
layer {
  name: "res_stage_3_653_2"
  type: "Convolution"
  bottom: "res_stage_3_653_1_top"
  top: "res_stage_3_653_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_653_2"
  type: "BatchNorm"
  bottom: "res_stage_3_653_2"
  top: "res_stage_3_653_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_653_2"  
  type: "Scale"
  bottom: "res_stage_3_653_2"
  top: "res_stage_3_653_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_653_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_653_2_top"
  top: "res_stage_3_653_2_top"
}
layer {
  name: "res_stage_3_653_3"
  type: "Convolution"
  bottom: "res_stage_3_653_2_top"
  top: "res_stage_3_653_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_653_3"
  type: "BatchNorm"
  bottom: "res_stage_3_653_3"
  top: "res_stage_3_653_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_653_3"  
  type: "Scale"
  bottom: "res_stage_3_653_3"
  top: "res_stage_3_653_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_653"
  type: "Eltwise"
  bottom: "res_3_652"
  bottom: "res_stage_3_653_3_top"
  top: "res_3_653"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_653_relu"
  type: "ReLU"
  bottom: "res_3_653"
  top: "res_3_653"
}
layer {
  name: "res_stage_3_654_1"
  type: "Convolution"
  bottom: "res_3_653"
  top: "res_stage_3_654_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_654_1"
  type: "BatchNorm"
  bottom: "res_stage_3_654_1"
  top: "res_stage_3_654_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_654_1"  
  type: "Scale"
  bottom: "res_stage_3_654_1"
  top: "res_stage_3_654_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_654_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_654_1_top"
  top: "res_stage_3_654_1_top"
}
layer {
  name: "res_stage_3_654_2"
  type: "Convolution"
  bottom: "res_stage_3_654_1_top"
  top: "res_stage_3_654_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_654_2"
  type: "BatchNorm"
  bottom: "res_stage_3_654_2"
  top: "res_stage_3_654_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_654_2"  
  type: "Scale"
  bottom: "res_stage_3_654_2"
  top: "res_stage_3_654_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_654_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_654_2_top"
  top: "res_stage_3_654_2_top"
}
layer {
  name: "res_stage_3_654_3"
  type: "Convolution"
  bottom: "res_stage_3_654_2_top"
  top: "res_stage_3_654_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_654_3"
  type: "BatchNorm"
  bottom: "res_stage_3_654_3"
  top: "res_stage_3_654_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_654_3"  
  type: "Scale"
  bottom: "res_stage_3_654_3"
  top: "res_stage_3_654_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_654"
  type: "Eltwise"
  bottom: "res_3_653"
  bottom: "res_stage_3_654_3_top"
  top: "res_3_654"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_654_relu"
  type: "ReLU"
  bottom: "res_3_654"
  top: "res_3_654"
}
layer {
  name: "res_stage_3_655_1"
  type: "Convolution"
  bottom: "res_3_654"
  top: "res_stage_3_655_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_655_1"
  type: "BatchNorm"
  bottom: "res_stage_3_655_1"
  top: "res_stage_3_655_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_655_1"  
  type: "Scale"
  bottom: "res_stage_3_655_1"
  top: "res_stage_3_655_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_655_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_655_1_top"
  top: "res_stage_3_655_1_top"
}
layer {
  name: "res_stage_3_655_2"
  type: "Convolution"
  bottom: "res_stage_3_655_1_top"
  top: "res_stage_3_655_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_655_2"
  type: "BatchNorm"
  bottom: "res_stage_3_655_2"
  top: "res_stage_3_655_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_655_2"  
  type: "Scale"
  bottom: "res_stage_3_655_2"
  top: "res_stage_3_655_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_655_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_655_2_top"
  top: "res_stage_3_655_2_top"
}
layer {
  name: "res_stage_3_655_3"
  type: "Convolution"
  bottom: "res_stage_3_655_2_top"
  top: "res_stage_3_655_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_655_3"
  type: "BatchNorm"
  bottom: "res_stage_3_655_3"
  top: "res_stage_3_655_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_655_3"  
  type: "Scale"
  bottom: "res_stage_3_655_3"
  top: "res_stage_3_655_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_655"
  type: "Eltwise"
  bottom: "res_3_654"
  bottom: "res_stage_3_655_3_top"
  top: "res_3_655"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_655_relu"
  type: "ReLU"
  bottom: "res_3_655"
  top: "res_3_655"
}
layer {
  name: "res_stage_3_656_1"
  type: "Convolution"
  bottom: "res_3_655"
  top: "res_stage_3_656_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_656_1"
  type: "BatchNorm"
  bottom: "res_stage_3_656_1"
  top: "res_stage_3_656_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_656_1"  
  type: "Scale"
  bottom: "res_stage_3_656_1"
  top: "res_stage_3_656_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_656_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_656_1_top"
  top: "res_stage_3_656_1_top"
}
layer {
  name: "res_stage_3_656_2"
  type: "Convolution"
  bottom: "res_stage_3_656_1_top"
  top: "res_stage_3_656_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_656_2"
  type: "BatchNorm"
  bottom: "res_stage_3_656_2"
  top: "res_stage_3_656_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_656_2"  
  type: "Scale"
  bottom: "res_stage_3_656_2"
  top: "res_stage_3_656_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_656_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_656_2_top"
  top: "res_stage_3_656_2_top"
}
layer {
  name: "res_stage_3_656_3"
  type: "Convolution"
  bottom: "res_stage_3_656_2_top"
  top: "res_stage_3_656_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_656_3"
  type: "BatchNorm"
  bottom: "res_stage_3_656_3"
  top: "res_stage_3_656_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_656_3"  
  type: "Scale"
  bottom: "res_stage_3_656_3"
  top: "res_stage_3_656_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_656"
  type: "Eltwise"
  bottom: "res_3_655"
  bottom: "res_stage_3_656_3_top"
  top: "res_3_656"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_656_relu"
  type: "ReLU"
  bottom: "res_3_656"
  top: "res_3_656"
}
layer {
  name: "res_stage_3_657_1"
  type: "Convolution"
  bottom: "res_3_656"
  top: "res_stage_3_657_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_657_1"
  type: "BatchNorm"
  bottom: "res_stage_3_657_1"
  top: "res_stage_3_657_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_657_1"  
  type: "Scale"
  bottom: "res_stage_3_657_1"
  top: "res_stage_3_657_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_657_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_657_1_top"
  top: "res_stage_3_657_1_top"
}
layer {
  name: "res_stage_3_657_2"
  type: "Convolution"
  bottom: "res_stage_3_657_1_top"
  top: "res_stage_3_657_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_657_2"
  type: "BatchNorm"
  bottom: "res_stage_3_657_2"
  top: "res_stage_3_657_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_657_2"  
  type: "Scale"
  bottom: "res_stage_3_657_2"
  top: "res_stage_3_657_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_657_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_657_2_top"
  top: "res_stage_3_657_2_top"
}
layer {
  name: "res_stage_3_657_3"
  type: "Convolution"
  bottom: "res_stage_3_657_2_top"
  top: "res_stage_3_657_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_657_3"
  type: "BatchNorm"
  bottom: "res_stage_3_657_3"
  top: "res_stage_3_657_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_657_3"  
  type: "Scale"
  bottom: "res_stage_3_657_3"
  top: "res_stage_3_657_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_657"
  type: "Eltwise"
  bottom: "res_3_656"
  bottom: "res_stage_3_657_3_top"
  top: "res_3_657"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_657_relu"
  type: "ReLU"
  bottom: "res_3_657"
  top: "res_3_657"
}
layer {
  name: "res_stage_3_658_1"
  type: "Convolution"
  bottom: "res_3_657"
  top: "res_stage_3_658_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_658_1"
  type: "BatchNorm"
  bottom: "res_stage_3_658_1"
  top: "res_stage_3_658_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_658_1"  
  type: "Scale"
  bottom: "res_stage_3_658_1"
  top: "res_stage_3_658_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_658_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_658_1_top"
  top: "res_stage_3_658_1_top"
}
layer {
  name: "res_stage_3_658_2"
  type: "Convolution"
  bottom: "res_stage_3_658_1_top"
  top: "res_stage_3_658_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_658_2"
  type: "BatchNorm"
  bottom: "res_stage_3_658_2"
  top: "res_stage_3_658_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_658_2"  
  type: "Scale"
  bottom: "res_stage_3_658_2"
  top: "res_stage_3_658_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_658_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_658_2_top"
  top: "res_stage_3_658_2_top"
}
layer {
  name: "res_stage_3_658_3"
  type: "Convolution"
  bottom: "res_stage_3_658_2_top"
  top: "res_stage_3_658_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_658_3"
  type: "BatchNorm"
  bottom: "res_stage_3_658_3"
  top: "res_stage_3_658_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_658_3"  
  type: "Scale"
  bottom: "res_stage_3_658_3"
  top: "res_stage_3_658_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_658"
  type: "Eltwise"
  bottom: "res_3_657"
  bottom: "res_stage_3_658_3_top"
  top: "res_3_658"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_658_relu"
  type: "ReLU"
  bottom: "res_3_658"
  top: "res_3_658"
}
layer {
  name: "res_stage_3_659_1"
  type: "Convolution"
  bottom: "res_3_658"
  top: "res_stage_3_659_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_659_1"
  type: "BatchNorm"
  bottom: "res_stage_3_659_1"
  top: "res_stage_3_659_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_659_1"  
  type: "Scale"
  bottom: "res_stage_3_659_1"
  top: "res_stage_3_659_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_659_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_659_1_top"
  top: "res_stage_3_659_1_top"
}
layer {
  name: "res_stage_3_659_2"
  type: "Convolution"
  bottom: "res_stage_3_659_1_top"
  top: "res_stage_3_659_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_659_2"
  type: "BatchNorm"
  bottom: "res_stage_3_659_2"
  top: "res_stage_3_659_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_659_2"  
  type: "Scale"
  bottom: "res_stage_3_659_2"
  top: "res_stage_3_659_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_659_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_659_2_top"
  top: "res_stage_3_659_2_top"
}
layer {
  name: "res_stage_3_659_3"
  type: "Convolution"
  bottom: "res_stage_3_659_2_top"
  top: "res_stage_3_659_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_659_3"
  type: "BatchNorm"
  bottom: "res_stage_3_659_3"
  top: "res_stage_3_659_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_659_3"  
  type: "Scale"
  bottom: "res_stage_3_659_3"
  top: "res_stage_3_659_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_659"
  type: "Eltwise"
  bottom: "res_3_658"
  bottom: "res_stage_3_659_3_top"
  top: "res_3_659"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_659_relu"
  type: "ReLU"
  bottom: "res_3_659"
  top: "res_3_659"
}
layer {
  name: "res_stage_3_660_1"
  type: "Convolution"
  bottom: "res_3_659"
  top: "res_stage_3_660_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_660_1"
  type: "BatchNorm"
  bottom: "res_stage_3_660_1"
  top: "res_stage_3_660_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_660_1"  
  type: "Scale"
  bottom: "res_stage_3_660_1"
  top: "res_stage_3_660_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_660_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_660_1_top"
  top: "res_stage_3_660_1_top"
}
layer {
  name: "res_stage_3_660_2"
  type: "Convolution"
  bottom: "res_stage_3_660_1_top"
  top: "res_stage_3_660_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_660_2"
  type: "BatchNorm"
  bottom: "res_stage_3_660_2"
  top: "res_stage_3_660_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_660_2"  
  type: "Scale"
  bottom: "res_stage_3_660_2"
  top: "res_stage_3_660_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_660_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_660_2_top"
  top: "res_stage_3_660_2_top"
}
layer {
  name: "res_stage_3_660_3"
  type: "Convolution"
  bottom: "res_stage_3_660_2_top"
  top: "res_stage_3_660_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_660_3"
  type: "BatchNorm"
  bottom: "res_stage_3_660_3"
  top: "res_stage_3_660_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_660_3"  
  type: "Scale"
  bottom: "res_stage_3_660_3"
  top: "res_stage_3_660_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_660"
  type: "Eltwise"
  bottom: "res_3_659"
  bottom: "res_stage_3_660_3_top"
  top: "res_3_660"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_660_relu"
  type: "ReLU"
  bottom: "res_3_660"
  top: "res_3_660"
}
layer {
  name: "res_stage_3_661_1"
  type: "Convolution"
  bottom: "res_3_660"
  top: "res_stage_3_661_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_661_1"
  type: "BatchNorm"
  bottom: "res_stage_3_661_1"
  top: "res_stage_3_661_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_661_1"  
  type: "Scale"
  bottom: "res_stage_3_661_1"
  top: "res_stage_3_661_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_661_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_661_1_top"
  top: "res_stage_3_661_1_top"
}
layer {
  name: "res_stage_3_661_2"
  type: "Convolution"
  bottom: "res_stage_3_661_1_top"
  top: "res_stage_3_661_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_661_2"
  type: "BatchNorm"
  bottom: "res_stage_3_661_2"
  top: "res_stage_3_661_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_661_2"  
  type: "Scale"
  bottom: "res_stage_3_661_2"
  top: "res_stage_3_661_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_661_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_661_2_top"
  top: "res_stage_3_661_2_top"
}
layer {
  name: "res_stage_3_661_3"
  type: "Convolution"
  bottom: "res_stage_3_661_2_top"
  top: "res_stage_3_661_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_661_3"
  type: "BatchNorm"
  bottom: "res_stage_3_661_3"
  top: "res_stage_3_661_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_661_3"  
  type: "Scale"
  bottom: "res_stage_3_661_3"
  top: "res_stage_3_661_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_661"
  type: "Eltwise"
  bottom: "res_3_660"
  bottom: "res_stage_3_661_3_top"
  top: "res_3_661"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_661_relu"
  type: "ReLU"
  bottom: "res_3_661"
  top: "res_3_661"
}
layer {
  name: "res_stage_3_662_1"
  type: "Convolution"
  bottom: "res_3_661"
  top: "res_stage_3_662_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_662_1"
  type: "BatchNorm"
  bottom: "res_stage_3_662_1"
  top: "res_stage_3_662_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_662_1"  
  type: "Scale"
  bottom: "res_stage_3_662_1"
  top: "res_stage_3_662_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_662_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_662_1_top"
  top: "res_stage_3_662_1_top"
}
layer {
  name: "res_stage_3_662_2"
  type: "Convolution"
  bottom: "res_stage_3_662_1_top"
  top: "res_stage_3_662_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_662_2"
  type: "BatchNorm"
  bottom: "res_stage_3_662_2"
  top: "res_stage_3_662_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_662_2"  
  type: "Scale"
  bottom: "res_stage_3_662_2"
  top: "res_stage_3_662_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_662_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_662_2_top"
  top: "res_stage_3_662_2_top"
}
layer {
  name: "res_stage_3_662_3"
  type: "Convolution"
  bottom: "res_stage_3_662_2_top"
  top: "res_stage_3_662_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_662_3"
  type: "BatchNorm"
  bottom: "res_stage_3_662_3"
  top: "res_stage_3_662_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_662_3"  
  type: "Scale"
  bottom: "res_stage_3_662_3"
  top: "res_stage_3_662_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_662"
  type: "Eltwise"
  bottom: "res_3_661"
  bottom: "res_stage_3_662_3_top"
  top: "res_3_662"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_662_relu"
  type: "ReLU"
  bottom: "res_3_662"
  top: "res_3_662"
}
layer {
  name: "res_stage_3_663_1"
  type: "Convolution"
  bottom: "res_3_662"
  top: "res_stage_3_663_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_663_1"
  type: "BatchNorm"
  bottom: "res_stage_3_663_1"
  top: "res_stage_3_663_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_663_1"  
  type: "Scale"
  bottom: "res_stage_3_663_1"
  top: "res_stage_3_663_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_663_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_663_1_top"
  top: "res_stage_3_663_1_top"
}
layer {
  name: "res_stage_3_663_2"
  type: "Convolution"
  bottom: "res_stage_3_663_1_top"
  top: "res_stage_3_663_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_663_2"
  type: "BatchNorm"
  bottom: "res_stage_3_663_2"
  top: "res_stage_3_663_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_663_2"  
  type: "Scale"
  bottom: "res_stage_3_663_2"
  top: "res_stage_3_663_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_663_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_663_2_top"
  top: "res_stage_3_663_2_top"
}
layer {
  name: "res_stage_3_663_3"
  type: "Convolution"
  bottom: "res_stage_3_663_2_top"
  top: "res_stage_3_663_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_663_3"
  type: "BatchNorm"
  bottom: "res_stage_3_663_3"
  top: "res_stage_3_663_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_663_3"  
  type: "Scale"
  bottom: "res_stage_3_663_3"
  top: "res_stage_3_663_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_663"
  type: "Eltwise"
  bottom: "res_3_662"
  bottom: "res_stage_3_663_3_top"
  top: "res_3_663"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_663_relu"
  type: "ReLU"
  bottom: "res_3_663"
  top: "res_3_663"
}
layer {
  name: "res_stage_3_664_1"
  type: "Convolution"
  bottom: "res_3_663"
  top: "res_stage_3_664_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_664_1"
  type: "BatchNorm"
  bottom: "res_stage_3_664_1"
  top: "res_stage_3_664_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_664_1"  
  type: "Scale"
  bottom: "res_stage_3_664_1"
  top: "res_stage_3_664_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_664_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_664_1_top"
  top: "res_stage_3_664_1_top"
}
layer {
  name: "res_stage_3_664_2"
  type: "Convolution"
  bottom: "res_stage_3_664_1_top"
  top: "res_stage_3_664_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_664_2"
  type: "BatchNorm"
  bottom: "res_stage_3_664_2"
  top: "res_stage_3_664_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_664_2"  
  type: "Scale"
  bottom: "res_stage_3_664_2"
  top: "res_stage_3_664_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_664_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_664_2_top"
  top: "res_stage_3_664_2_top"
}
layer {
  name: "res_stage_3_664_3"
  type: "Convolution"
  bottom: "res_stage_3_664_2_top"
  top: "res_stage_3_664_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_664_3"
  type: "BatchNorm"
  bottom: "res_stage_3_664_3"
  top: "res_stage_3_664_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_664_3"  
  type: "Scale"
  bottom: "res_stage_3_664_3"
  top: "res_stage_3_664_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_664"
  type: "Eltwise"
  bottom: "res_3_663"
  bottom: "res_stage_3_664_3_top"
  top: "res_3_664"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_664_relu"
  type: "ReLU"
  bottom: "res_3_664"
  top: "res_3_664"
}
layer {
  name: "res_stage_3_665_1"
  type: "Convolution"
  bottom: "res_3_664"
  top: "res_stage_3_665_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_665_1"
  type: "BatchNorm"
  bottom: "res_stage_3_665_1"
  top: "res_stage_3_665_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_665_1"  
  type: "Scale"
  bottom: "res_stage_3_665_1"
  top: "res_stage_3_665_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_665_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_665_1_top"
  top: "res_stage_3_665_1_top"
}
layer {
  name: "res_stage_3_665_2"
  type: "Convolution"
  bottom: "res_stage_3_665_1_top"
  top: "res_stage_3_665_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_665_2"
  type: "BatchNorm"
  bottom: "res_stage_3_665_2"
  top: "res_stage_3_665_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_665_2"  
  type: "Scale"
  bottom: "res_stage_3_665_2"
  top: "res_stage_3_665_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_665_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_665_2_top"
  top: "res_stage_3_665_2_top"
}
layer {
  name: "res_stage_3_665_3"
  type: "Convolution"
  bottom: "res_stage_3_665_2_top"
  top: "res_stage_3_665_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_665_3"
  type: "BatchNorm"
  bottom: "res_stage_3_665_3"
  top: "res_stage_3_665_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_665_3"  
  type: "Scale"
  bottom: "res_stage_3_665_3"
  top: "res_stage_3_665_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_665"
  type: "Eltwise"
  bottom: "res_3_664"
  bottom: "res_stage_3_665_3_top"
  top: "res_3_665"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_665_relu"
  type: "ReLU"
  bottom: "res_3_665"
  top: "res_3_665"
}
layer {
  name: "res_stage_3_666_1"
  type: "Convolution"
  bottom: "res_3_665"
  top: "res_stage_3_666_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_666_1"
  type: "BatchNorm"
  bottom: "res_stage_3_666_1"
  top: "res_stage_3_666_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_666_1"  
  type: "Scale"
  bottom: "res_stage_3_666_1"
  top: "res_stage_3_666_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_666_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_666_1_top"
  top: "res_stage_3_666_1_top"
}
layer {
  name: "res_stage_3_666_2"
  type: "Convolution"
  bottom: "res_stage_3_666_1_top"
  top: "res_stage_3_666_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_666_2"
  type: "BatchNorm"
  bottom: "res_stage_3_666_2"
  top: "res_stage_3_666_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_666_2"  
  type: "Scale"
  bottom: "res_stage_3_666_2"
  top: "res_stage_3_666_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_666_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_666_2_top"
  top: "res_stage_3_666_2_top"
}
layer {
  name: "res_stage_3_666_3"
  type: "Convolution"
  bottom: "res_stage_3_666_2_top"
  top: "res_stage_3_666_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_666_3"
  type: "BatchNorm"
  bottom: "res_stage_3_666_3"
  top: "res_stage_3_666_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_666_3"  
  type: "Scale"
  bottom: "res_stage_3_666_3"
  top: "res_stage_3_666_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_666"
  type: "Eltwise"
  bottom: "res_3_665"
  bottom: "res_stage_3_666_3_top"
  top: "res_3_666"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_666_relu"
  type: "ReLU"
  bottom: "res_3_666"
  top: "res_3_666"
}
layer {
  name: "res_stage_3_667_1"
  type: "Convolution"
  bottom: "res_3_666"
  top: "res_stage_3_667_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_667_1"
  type: "BatchNorm"
  bottom: "res_stage_3_667_1"
  top: "res_stage_3_667_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_667_1"  
  type: "Scale"
  bottom: "res_stage_3_667_1"
  top: "res_stage_3_667_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_667_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_667_1_top"
  top: "res_stage_3_667_1_top"
}
layer {
  name: "res_stage_3_667_2"
  type: "Convolution"
  bottom: "res_stage_3_667_1_top"
  top: "res_stage_3_667_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_667_2"
  type: "BatchNorm"
  bottom: "res_stage_3_667_2"
  top: "res_stage_3_667_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_667_2"  
  type: "Scale"
  bottom: "res_stage_3_667_2"
  top: "res_stage_3_667_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_667_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_667_2_top"
  top: "res_stage_3_667_2_top"
}
layer {
  name: "res_stage_3_667_3"
  type: "Convolution"
  bottom: "res_stage_3_667_2_top"
  top: "res_stage_3_667_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_667_3"
  type: "BatchNorm"
  bottom: "res_stage_3_667_3"
  top: "res_stage_3_667_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_667_3"  
  type: "Scale"
  bottom: "res_stage_3_667_3"
  top: "res_stage_3_667_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_667"
  type: "Eltwise"
  bottom: "res_3_666"
  bottom: "res_stage_3_667_3_top"
  top: "res_3_667"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_667_relu"
  type: "ReLU"
  bottom: "res_3_667"
  top: "res_3_667"
}
layer {
  name: "res_stage_3_668_1"
  type: "Convolution"
  bottom: "res_3_667"
  top: "res_stage_3_668_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_668_1"
  type: "BatchNorm"
  bottom: "res_stage_3_668_1"
  top: "res_stage_3_668_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_668_1"  
  type: "Scale"
  bottom: "res_stage_3_668_1"
  top: "res_stage_3_668_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_668_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_668_1_top"
  top: "res_stage_3_668_1_top"
}
layer {
  name: "res_stage_3_668_2"
  type: "Convolution"
  bottom: "res_stage_3_668_1_top"
  top: "res_stage_3_668_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_668_2"
  type: "BatchNorm"
  bottom: "res_stage_3_668_2"
  top: "res_stage_3_668_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_668_2"  
  type: "Scale"
  bottom: "res_stage_3_668_2"
  top: "res_stage_3_668_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_668_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_668_2_top"
  top: "res_stage_3_668_2_top"
}
layer {
  name: "res_stage_3_668_3"
  type: "Convolution"
  bottom: "res_stage_3_668_2_top"
  top: "res_stage_3_668_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_668_3"
  type: "BatchNorm"
  bottom: "res_stage_3_668_3"
  top: "res_stage_3_668_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_668_3"  
  type: "Scale"
  bottom: "res_stage_3_668_3"
  top: "res_stage_3_668_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_668"
  type: "Eltwise"
  bottom: "res_3_667"
  bottom: "res_stage_3_668_3_top"
  top: "res_3_668"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_668_relu"
  type: "ReLU"
  bottom: "res_3_668"
  top: "res_3_668"
}
layer {
  name: "res_stage_3_669_1"
  type: "Convolution"
  bottom: "res_3_668"
  top: "res_stage_3_669_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_669_1"
  type: "BatchNorm"
  bottom: "res_stage_3_669_1"
  top: "res_stage_3_669_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_669_1"  
  type: "Scale"
  bottom: "res_stage_3_669_1"
  top: "res_stage_3_669_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_669_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_669_1_top"
  top: "res_stage_3_669_1_top"
}
layer {
  name: "res_stage_3_669_2"
  type: "Convolution"
  bottom: "res_stage_3_669_1_top"
  top: "res_stage_3_669_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_669_2"
  type: "BatchNorm"
  bottom: "res_stage_3_669_2"
  top: "res_stage_3_669_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_669_2"  
  type: "Scale"
  bottom: "res_stage_3_669_2"
  top: "res_stage_3_669_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_669_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_669_2_top"
  top: "res_stage_3_669_2_top"
}
layer {
  name: "res_stage_3_669_3"
  type: "Convolution"
  bottom: "res_stage_3_669_2_top"
  top: "res_stage_3_669_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_669_3"
  type: "BatchNorm"
  bottom: "res_stage_3_669_3"
  top: "res_stage_3_669_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_669_3"  
  type: "Scale"
  bottom: "res_stage_3_669_3"
  top: "res_stage_3_669_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_669"
  type: "Eltwise"
  bottom: "res_3_668"
  bottom: "res_stage_3_669_3_top"
  top: "res_3_669"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_669_relu"
  type: "ReLU"
  bottom: "res_3_669"
  top: "res_3_669"
}
layer {
  name: "res_stage_3_670_1"
  type: "Convolution"
  bottom: "res_3_669"
  top: "res_stage_3_670_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_670_1"
  type: "BatchNorm"
  bottom: "res_stage_3_670_1"
  top: "res_stage_3_670_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_670_1"  
  type: "Scale"
  bottom: "res_stage_3_670_1"
  top: "res_stage_3_670_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_670_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_670_1_top"
  top: "res_stage_3_670_1_top"
}
layer {
  name: "res_stage_3_670_2"
  type: "Convolution"
  bottom: "res_stage_3_670_1_top"
  top: "res_stage_3_670_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_670_2"
  type: "BatchNorm"
  bottom: "res_stage_3_670_2"
  top: "res_stage_3_670_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_670_2"  
  type: "Scale"
  bottom: "res_stage_3_670_2"
  top: "res_stage_3_670_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_670_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_670_2_top"
  top: "res_stage_3_670_2_top"
}
layer {
  name: "res_stage_3_670_3"
  type: "Convolution"
  bottom: "res_stage_3_670_2_top"
  top: "res_stage_3_670_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_670_3"
  type: "BatchNorm"
  bottom: "res_stage_3_670_3"
  top: "res_stage_3_670_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_670_3"  
  type: "Scale"
  bottom: "res_stage_3_670_3"
  top: "res_stage_3_670_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_670"
  type: "Eltwise"
  bottom: "res_3_669"
  bottom: "res_stage_3_670_3_top"
  top: "res_3_670"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_670_relu"
  type: "ReLU"
  bottom: "res_3_670"
  top: "res_3_670"
}
layer {
  name: "res_stage_3_671_1"
  type: "Convolution"
  bottom: "res_3_670"
  top: "res_stage_3_671_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_671_1"
  type: "BatchNorm"
  bottom: "res_stage_3_671_1"
  top: "res_stage_3_671_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_671_1"  
  type: "Scale"
  bottom: "res_stage_3_671_1"
  top: "res_stage_3_671_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_671_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_671_1_top"
  top: "res_stage_3_671_1_top"
}
layer {
  name: "res_stage_3_671_2"
  type: "Convolution"
  bottom: "res_stage_3_671_1_top"
  top: "res_stage_3_671_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_671_2"
  type: "BatchNorm"
  bottom: "res_stage_3_671_2"
  top: "res_stage_3_671_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_671_2"  
  type: "Scale"
  bottom: "res_stage_3_671_2"
  top: "res_stage_3_671_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_671_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_671_2_top"
  top: "res_stage_3_671_2_top"
}
layer {
  name: "res_stage_3_671_3"
  type: "Convolution"
  bottom: "res_stage_3_671_2_top"
  top: "res_stage_3_671_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_671_3"
  type: "BatchNorm"
  bottom: "res_stage_3_671_3"
  top: "res_stage_3_671_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_671_3"  
  type: "Scale"
  bottom: "res_stage_3_671_3"
  top: "res_stage_3_671_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_671"
  type: "Eltwise"
  bottom: "res_3_670"
  bottom: "res_stage_3_671_3_top"
  top: "res_3_671"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_671_relu"
  type: "ReLU"
  bottom: "res_3_671"
  top: "res_3_671"
}
layer {
  name: "res_stage_3_672_1"
  type: "Convolution"
  bottom: "res_3_671"
  top: "res_stage_3_672_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_672_1"
  type: "BatchNorm"
  bottom: "res_stage_3_672_1"
  top: "res_stage_3_672_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_672_1"  
  type: "Scale"
  bottom: "res_stage_3_672_1"
  top: "res_stage_3_672_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_672_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_672_1_top"
  top: "res_stage_3_672_1_top"
}
layer {
  name: "res_stage_3_672_2"
  type: "Convolution"
  bottom: "res_stage_3_672_1_top"
  top: "res_stage_3_672_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_672_2"
  type: "BatchNorm"
  bottom: "res_stage_3_672_2"
  top: "res_stage_3_672_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_672_2"  
  type: "Scale"
  bottom: "res_stage_3_672_2"
  top: "res_stage_3_672_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_672_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_672_2_top"
  top: "res_stage_3_672_2_top"
}
layer {
  name: "res_stage_3_672_3"
  type: "Convolution"
  bottom: "res_stage_3_672_2_top"
  top: "res_stage_3_672_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_672_3"
  type: "BatchNorm"
  bottom: "res_stage_3_672_3"
  top: "res_stage_3_672_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_672_3"  
  type: "Scale"
  bottom: "res_stage_3_672_3"
  top: "res_stage_3_672_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_672"
  type: "Eltwise"
  bottom: "res_3_671"
  bottom: "res_stage_3_672_3_top"
  top: "res_3_672"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_672_relu"
  type: "ReLU"
  bottom: "res_3_672"
  top: "res_3_672"
}
layer {
  name: "res_stage_3_673_1"
  type: "Convolution"
  bottom: "res_3_672"
  top: "res_stage_3_673_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_673_1"
  type: "BatchNorm"
  bottom: "res_stage_3_673_1"
  top: "res_stage_3_673_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_673_1"  
  type: "Scale"
  bottom: "res_stage_3_673_1"
  top: "res_stage_3_673_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_673_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_673_1_top"
  top: "res_stage_3_673_1_top"
}
layer {
  name: "res_stage_3_673_2"
  type: "Convolution"
  bottom: "res_stage_3_673_1_top"
  top: "res_stage_3_673_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_673_2"
  type: "BatchNorm"
  bottom: "res_stage_3_673_2"
  top: "res_stage_3_673_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_673_2"  
  type: "Scale"
  bottom: "res_stage_3_673_2"
  top: "res_stage_3_673_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_673_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_673_2_top"
  top: "res_stage_3_673_2_top"
}
layer {
  name: "res_stage_3_673_3"
  type: "Convolution"
  bottom: "res_stage_3_673_2_top"
  top: "res_stage_3_673_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_673_3"
  type: "BatchNorm"
  bottom: "res_stage_3_673_3"
  top: "res_stage_3_673_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_673_3"  
  type: "Scale"
  bottom: "res_stage_3_673_3"
  top: "res_stage_3_673_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_673"
  type: "Eltwise"
  bottom: "res_3_672"
  bottom: "res_stage_3_673_3_top"
  top: "res_3_673"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_673_relu"
  type: "ReLU"
  bottom: "res_3_673"
  top: "res_3_673"
}
layer {
  name: "res_stage_3_674_1"
  type: "Convolution"
  bottom: "res_3_673"
  top: "res_stage_3_674_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_674_1"
  type: "BatchNorm"
  bottom: "res_stage_3_674_1"
  top: "res_stage_3_674_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_674_1"  
  type: "Scale"
  bottom: "res_stage_3_674_1"
  top: "res_stage_3_674_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_674_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_674_1_top"
  top: "res_stage_3_674_1_top"
}
layer {
  name: "res_stage_3_674_2"
  type: "Convolution"
  bottom: "res_stage_3_674_1_top"
  top: "res_stage_3_674_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_674_2"
  type: "BatchNorm"
  bottom: "res_stage_3_674_2"
  top: "res_stage_3_674_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_674_2"  
  type: "Scale"
  bottom: "res_stage_3_674_2"
  top: "res_stage_3_674_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_674_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_674_2_top"
  top: "res_stage_3_674_2_top"
}
layer {
  name: "res_stage_3_674_3"
  type: "Convolution"
  bottom: "res_stage_3_674_2_top"
  top: "res_stage_3_674_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_674_3"
  type: "BatchNorm"
  bottom: "res_stage_3_674_3"
  top: "res_stage_3_674_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_674_3"  
  type: "Scale"
  bottom: "res_stage_3_674_3"
  top: "res_stage_3_674_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_674"
  type: "Eltwise"
  bottom: "res_3_673"
  bottom: "res_stage_3_674_3_top"
  top: "res_3_674"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_674_relu"
  type: "ReLU"
  bottom: "res_3_674"
  top: "res_3_674"
}
layer {
  name: "res_stage_3_675_1"
  type: "Convolution"
  bottom: "res_3_674"
  top: "res_stage_3_675_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_675_1"
  type: "BatchNorm"
  bottom: "res_stage_3_675_1"
  top: "res_stage_3_675_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_675_1"  
  type: "Scale"
  bottom: "res_stage_3_675_1"
  top: "res_stage_3_675_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_675_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_675_1_top"
  top: "res_stage_3_675_1_top"
}
layer {
  name: "res_stage_3_675_2"
  type: "Convolution"
  bottom: "res_stage_3_675_1_top"
  top: "res_stage_3_675_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_675_2"
  type: "BatchNorm"
  bottom: "res_stage_3_675_2"
  top: "res_stage_3_675_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_675_2"  
  type: "Scale"
  bottom: "res_stage_3_675_2"
  top: "res_stage_3_675_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_675_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_675_2_top"
  top: "res_stage_3_675_2_top"
}
layer {
  name: "res_stage_3_675_3"
  type: "Convolution"
  bottom: "res_stage_3_675_2_top"
  top: "res_stage_3_675_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_675_3"
  type: "BatchNorm"
  bottom: "res_stage_3_675_3"
  top: "res_stage_3_675_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_675_3"  
  type: "Scale"
  bottom: "res_stage_3_675_3"
  top: "res_stage_3_675_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_675"
  type: "Eltwise"
  bottom: "res_3_674"
  bottom: "res_stage_3_675_3_top"
  top: "res_3_675"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_675_relu"
  type: "ReLU"
  bottom: "res_3_675"
  top: "res_3_675"
}
layer {
  name: "res_stage_3_676_1"
  type: "Convolution"
  bottom: "res_3_675"
  top: "res_stage_3_676_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_676_1"
  type: "BatchNorm"
  bottom: "res_stage_3_676_1"
  top: "res_stage_3_676_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_676_1"  
  type: "Scale"
  bottom: "res_stage_3_676_1"
  top: "res_stage_3_676_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_676_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_676_1_top"
  top: "res_stage_3_676_1_top"
}
layer {
  name: "res_stage_3_676_2"
  type: "Convolution"
  bottom: "res_stage_3_676_1_top"
  top: "res_stage_3_676_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_676_2"
  type: "BatchNorm"
  bottom: "res_stage_3_676_2"
  top: "res_stage_3_676_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_676_2"  
  type: "Scale"
  bottom: "res_stage_3_676_2"
  top: "res_stage_3_676_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_676_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_676_2_top"
  top: "res_stage_3_676_2_top"
}
layer {
  name: "res_stage_3_676_3"
  type: "Convolution"
  bottom: "res_stage_3_676_2_top"
  top: "res_stage_3_676_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_676_3"
  type: "BatchNorm"
  bottom: "res_stage_3_676_3"
  top: "res_stage_3_676_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_676_3"  
  type: "Scale"
  bottom: "res_stage_3_676_3"
  top: "res_stage_3_676_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_676"
  type: "Eltwise"
  bottom: "res_3_675"
  bottom: "res_stage_3_676_3_top"
  top: "res_3_676"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_676_relu"
  type: "ReLU"
  bottom: "res_3_676"
  top: "res_3_676"
}
layer {
  name: "res_stage_3_677_1"
  type: "Convolution"
  bottom: "res_3_676"
  top: "res_stage_3_677_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_677_1"
  type: "BatchNorm"
  bottom: "res_stage_3_677_1"
  top: "res_stage_3_677_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_677_1"  
  type: "Scale"
  bottom: "res_stage_3_677_1"
  top: "res_stage_3_677_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_677_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_677_1_top"
  top: "res_stage_3_677_1_top"
}
layer {
  name: "res_stage_3_677_2"
  type: "Convolution"
  bottom: "res_stage_3_677_1_top"
  top: "res_stage_3_677_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_677_2"
  type: "BatchNorm"
  bottom: "res_stage_3_677_2"
  top: "res_stage_3_677_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_677_2"  
  type: "Scale"
  bottom: "res_stage_3_677_2"
  top: "res_stage_3_677_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_677_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_677_2_top"
  top: "res_stage_3_677_2_top"
}
layer {
  name: "res_stage_3_677_3"
  type: "Convolution"
  bottom: "res_stage_3_677_2_top"
  top: "res_stage_3_677_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_677_3"
  type: "BatchNorm"
  bottom: "res_stage_3_677_3"
  top: "res_stage_3_677_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_677_3"  
  type: "Scale"
  bottom: "res_stage_3_677_3"
  top: "res_stage_3_677_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_677"
  type: "Eltwise"
  bottom: "res_3_676"
  bottom: "res_stage_3_677_3_top"
  top: "res_3_677"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_677_relu"
  type: "ReLU"
  bottom: "res_3_677"
  top: "res_3_677"
}
layer {
  name: "res_stage_3_678_1"
  type: "Convolution"
  bottom: "res_3_677"
  top: "res_stage_3_678_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_678_1"
  type: "BatchNorm"
  bottom: "res_stage_3_678_1"
  top: "res_stage_3_678_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_678_1"  
  type: "Scale"
  bottom: "res_stage_3_678_1"
  top: "res_stage_3_678_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_678_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_678_1_top"
  top: "res_stage_3_678_1_top"
}
layer {
  name: "res_stage_3_678_2"
  type: "Convolution"
  bottom: "res_stage_3_678_1_top"
  top: "res_stage_3_678_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_678_2"
  type: "BatchNorm"
  bottom: "res_stage_3_678_2"
  top: "res_stage_3_678_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_678_2"  
  type: "Scale"
  bottom: "res_stage_3_678_2"
  top: "res_stage_3_678_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_678_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_678_2_top"
  top: "res_stage_3_678_2_top"
}
layer {
  name: "res_stage_3_678_3"
  type: "Convolution"
  bottom: "res_stage_3_678_2_top"
  top: "res_stage_3_678_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_678_3"
  type: "BatchNorm"
  bottom: "res_stage_3_678_3"
  top: "res_stage_3_678_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_678_3"  
  type: "Scale"
  bottom: "res_stage_3_678_3"
  top: "res_stage_3_678_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_678"
  type: "Eltwise"
  bottom: "res_3_677"
  bottom: "res_stage_3_678_3_top"
  top: "res_3_678"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_678_relu"
  type: "ReLU"
  bottom: "res_3_678"
  top: "res_3_678"
}
layer {
  name: "res_stage_3_679_1"
  type: "Convolution"
  bottom: "res_3_678"
  top: "res_stage_3_679_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_679_1"
  type: "BatchNorm"
  bottom: "res_stage_3_679_1"
  top: "res_stage_3_679_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_679_1"  
  type: "Scale"
  bottom: "res_stage_3_679_1"
  top: "res_stage_3_679_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_679_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_679_1_top"
  top: "res_stage_3_679_1_top"
}
layer {
  name: "res_stage_3_679_2"
  type: "Convolution"
  bottom: "res_stage_3_679_1_top"
  top: "res_stage_3_679_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_679_2"
  type: "BatchNorm"
  bottom: "res_stage_3_679_2"
  top: "res_stage_3_679_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_679_2"  
  type: "Scale"
  bottom: "res_stage_3_679_2"
  top: "res_stage_3_679_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_679_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_679_2_top"
  top: "res_stage_3_679_2_top"
}
layer {
  name: "res_stage_3_679_3"
  type: "Convolution"
  bottom: "res_stage_3_679_2_top"
  top: "res_stage_3_679_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_679_3"
  type: "BatchNorm"
  bottom: "res_stage_3_679_3"
  top: "res_stage_3_679_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_679_3"  
  type: "Scale"
  bottom: "res_stage_3_679_3"
  top: "res_stage_3_679_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_679"
  type: "Eltwise"
  bottom: "res_3_678"
  bottom: "res_stage_3_679_3_top"
  top: "res_3_679"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_679_relu"
  type: "ReLU"
  bottom: "res_3_679"
  top: "res_3_679"
}
layer {
  name: "res_stage_3_680_1"
  type: "Convolution"
  bottom: "res_3_679"
  top: "res_stage_3_680_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_680_1"
  type: "BatchNorm"
  bottom: "res_stage_3_680_1"
  top: "res_stage_3_680_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_680_1"  
  type: "Scale"
  bottom: "res_stage_3_680_1"
  top: "res_stage_3_680_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_680_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_680_1_top"
  top: "res_stage_3_680_1_top"
}
layer {
  name: "res_stage_3_680_2"
  type: "Convolution"
  bottom: "res_stage_3_680_1_top"
  top: "res_stage_3_680_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_680_2"
  type: "BatchNorm"
  bottom: "res_stage_3_680_2"
  top: "res_stage_3_680_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_680_2"  
  type: "Scale"
  bottom: "res_stage_3_680_2"
  top: "res_stage_3_680_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_680_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_680_2_top"
  top: "res_stage_3_680_2_top"
}
layer {
  name: "res_stage_3_680_3"
  type: "Convolution"
  bottom: "res_stage_3_680_2_top"
  top: "res_stage_3_680_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_680_3"
  type: "BatchNorm"
  bottom: "res_stage_3_680_3"
  top: "res_stage_3_680_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_680_3"  
  type: "Scale"
  bottom: "res_stage_3_680_3"
  top: "res_stage_3_680_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_680"
  type: "Eltwise"
  bottom: "res_3_679"
  bottom: "res_stage_3_680_3_top"
  top: "res_3_680"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_680_relu"
  type: "ReLU"
  bottom: "res_3_680"
  top: "res_3_680"
}
layer {
  name: "res_stage_3_681_1"
  type: "Convolution"
  bottom: "res_3_680"
  top: "res_stage_3_681_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_681_1"
  type: "BatchNorm"
  bottom: "res_stage_3_681_1"
  top: "res_stage_3_681_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_681_1"  
  type: "Scale"
  bottom: "res_stage_3_681_1"
  top: "res_stage_3_681_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_681_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_681_1_top"
  top: "res_stage_3_681_1_top"
}
layer {
  name: "res_stage_3_681_2"
  type: "Convolution"
  bottom: "res_stage_3_681_1_top"
  top: "res_stage_3_681_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_681_2"
  type: "BatchNorm"
  bottom: "res_stage_3_681_2"
  top: "res_stage_3_681_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_681_2"  
  type: "Scale"
  bottom: "res_stage_3_681_2"
  top: "res_stage_3_681_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_681_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_681_2_top"
  top: "res_stage_3_681_2_top"
}
layer {
  name: "res_stage_3_681_3"
  type: "Convolution"
  bottom: "res_stage_3_681_2_top"
  top: "res_stage_3_681_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_681_3"
  type: "BatchNorm"
  bottom: "res_stage_3_681_3"
  top: "res_stage_3_681_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_681_3"  
  type: "Scale"
  bottom: "res_stage_3_681_3"
  top: "res_stage_3_681_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_681"
  type: "Eltwise"
  bottom: "res_3_680"
  bottom: "res_stage_3_681_3_top"
  top: "res_3_681"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_681_relu"
  type: "ReLU"
  bottom: "res_3_681"
  top: "res_3_681"
}
layer {
  name: "res_stage_3_682_1"
  type: "Convolution"
  bottom: "res_3_681"
  top: "res_stage_3_682_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_682_1"
  type: "BatchNorm"
  bottom: "res_stage_3_682_1"
  top: "res_stage_3_682_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_682_1"  
  type: "Scale"
  bottom: "res_stage_3_682_1"
  top: "res_stage_3_682_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_682_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_682_1_top"
  top: "res_stage_3_682_1_top"
}
layer {
  name: "res_stage_3_682_2"
  type: "Convolution"
  bottom: "res_stage_3_682_1_top"
  top: "res_stage_3_682_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_682_2"
  type: "BatchNorm"
  bottom: "res_stage_3_682_2"
  top: "res_stage_3_682_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_682_2"  
  type: "Scale"
  bottom: "res_stage_3_682_2"
  top: "res_stage_3_682_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_682_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_682_2_top"
  top: "res_stage_3_682_2_top"
}
layer {
  name: "res_stage_3_682_3"
  type: "Convolution"
  bottom: "res_stage_3_682_2_top"
  top: "res_stage_3_682_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_682_3"
  type: "BatchNorm"
  bottom: "res_stage_3_682_3"
  top: "res_stage_3_682_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_682_3"  
  type: "Scale"
  bottom: "res_stage_3_682_3"
  top: "res_stage_3_682_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_682"
  type: "Eltwise"
  bottom: "res_3_681"
  bottom: "res_stage_3_682_3_top"
  top: "res_3_682"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_682_relu"
  type: "ReLU"
  bottom: "res_3_682"
  top: "res_3_682"
}
layer {
  name: "res_stage_3_683_1"
  type: "Convolution"
  bottom: "res_3_682"
  top: "res_stage_3_683_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_683_1"
  type: "BatchNorm"
  bottom: "res_stage_3_683_1"
  top: "res_stage_3_683_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_683_1"  
  type: "Scale"
  bottom: "res_stage_3_683_1"
  top: "res_stage_3_683_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_683_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_683_1_top"
  top: "res_stage_3_683_1_top"
}
layer {
  name: "res_stage_3_683_2"
  type: "Convolution"
  bottom: "res_stage_3_683_1_top"
  top: "res_stage_3_683_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_683_2"
  type: "BatchNorm"
  bottom: "res_stage_3_683_2"
  top: "res_stage_3_683_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_683_2"  
  type: "Scale"
  bottom: "res_stage_3_683_2"
  top: "res_stage_3_683_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_683_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_683_2_top"
  top: "res_stage_3_683_2_top"
}
layer {
  name: "res_stage_3_683_3"
  type: "Convolution"
  bottom: "res_stage_3_683_2_top"
  top: "res_stage_3_683_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_683_3"
  type: "BatchNorm"
  bottom: "res_stage_3_683_3"
  top: "res_stage_3_683_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_683_3"  
  type: "Scale"
  bottom: "res_stage_3_683_3"
  top: "res_stage_3_683_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_683"
  type: "Eltwise"
  bottom: "res_3_682"
  bottom: "res_stage_3_683_3_top"
  top: "res_3_683"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_683_relu"
  type: "ReLU"
  bottom: "res_3_683"
  top: "res_3_683"
}
layer {
  name: "res_stage_3_684_1"
  type: "Convolution"
  bottom: "res_3_683"
  top: "res_stage_3_684_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_684_1"
  type: "BatchNorm"
  bottom: "res_stage_3_684_1"
  top: "res_stage_3_684_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_684_1"  
  type: "Scale"
  bottom: "res_stage_3_684_1"
  top: "res_stage_3_684_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_684_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_684_1_top"
  top: "res_stage_3_684_1_top"
}
layer {
  name: "res_stage_3_684_2"
  type: "Convolution"
  bottom: "res_stage_3_684_1_top"
  top: "res_stage_3_684_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_684_2"
  type: "BatchNorm"
  bottom: "res_stage_3_684_2"
  top: "res_stage_3_684_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_684_2"  
  type: "Scale"
  bottom: "res_stage_3_684_2"
  top: "res_stage_3_684_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_684_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_684_2_top"
  top: "res_stage_3_684_2_top"
}
layer {
  name: "res_stage_3_684_3"
  type: "Convolution"
  bottom: "res_stage_3_684_2_top"
  top: "res_stage_3_684_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_684_3"
  type: "BatchNorm"
  bottom: "res_stage_3_684_3"
  top: "res_stage_3_684_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_684_3"  
  type: "Scale"
  bottom: "res_stage_3_684_3"
  top: "res_stage_3_684_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_684"
  type: "Eltwise"
  bottom: "res_3_683"
  bottom: "res_stage_3_684_3_top"
  top: "res_3_684"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_684_relu"
  type: "ReLU"
  bottom: "res_3_684"
  top: "res_3_684"
}
layer {
  name: "res_stage_3_685_1"
  type: "Convolution"
  bottom: "res_3_684"
  top: "res_stage_3_685_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_685_1"
  type: "BatchNorm"
  bottom: "res_stage_3_685_1"
  top: "res_stage_3_685_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_685_1"  
  type: "Scale"
  bottom: "res_stage_3_685_1"
  top: "res_stage_3_685_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_685_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_685_1_top"
  top: "res_stage_3_685_1_top"
}
layer {
  name: "res_stage_3_685_2"
  type: "Convolution"
  bottom: "res_stage_3_685_1_top"
  top: "res_stage_3_685_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_685_2"
  type: "BatchNorm"
  bottom: "res_stage_3_685_2"
  top: "res_stage_3_685_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_685_2"  
  type: "Scale"
  bottom: "res_stage_3_685_2"
  top: "res_stage_3_685_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_685_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_685_2_top"
  top: "res_stage_3_685_2_top"
}
layer {
  name: "res_stage_3_685_3"
  type: "Convolution"
  bottom: "res_stage_3_685_2_top"
  top: "res_stage_3_685_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_685_3"
  type: "BatchNorm"
  bottom: "res_stage_3_685_3"
  top: "res_stage_3_685_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_685_3"  
  type: "Scale"
  bottom: "res_stage_3_685_3"
  top: "res_stage_3_685_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_685"
  type: "Eltwise"
  bottom: "res_3_684"
  bottom: "res_stage_3_685_3_top"
  top: "res_3_685"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_685_relu"
  type: "ReLU"
  bottom: "res_3_685"
  top: "res_3_685"
}
layer {
  name: "res_stage_3_686_1"
  type: "Convolution"
  bottom: "res_3_685"
  top: "res_stage_3_686_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_686_1"
  type: "BatchNorm"
  bottom: "res_stage_3_686_1"
  top: "res_stage_3_686_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_686_1"  
  type: "Scale"
  bottom: "res_stage_3_686_1"
  top: "res_stage_3_686_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_686_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_686_1_top"
  top: "res_stage_3_686_1_top"
}
layer {
  name: "res_stage_3_686_2"
  type: "Convolution"
  bottom: "res_stage_3_686_1_top"
  top: "res_stage_3_686_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_686_2"
  type: "BatchNorm"
  bottom: "res_stage_3_686_2"
  top: "res_stage_3_686_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_686_2"  
  type: "Scale"
  bottom: "res_stage_3_686_2"
  top: "res_stage_3_686_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_686_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_686_2_top"
  top: "res_stage_3_686_2_top"
}
layer {
  name: "res_stage_3_686_3"
  type: "Convolution"
  bottom: "res_stage_3_686_2_top"
  top: "res_stage_3_686_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_686_3"
  type: "BatchNorm"
  bottom: "res_stage_3_686_3"
  top: "res_stage_3_686_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_686_3"  
  type: "Scale"
  bottom: "res_stage_3_686_3"
  top: "res_stage_3_686_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_686"
  type: "Eltwise"
  bottom: "res_3_685"
  bottom: "res_stage_3_686_3_top"
  top: "res_3_686"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_686_relu"
  type: "ReLU"
  bottom: "res_3_686"
  top: "res_3_686"
}
layer {
  name: "res_stage_3_687_1"
  type: "Convolution"
  bottom: "res_3_686"
  top: "res_stage_3_687_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_687_1"
  type: "BatchNorm"
  bottom: "res_stage_3_687_1"
  top: "res_stage_3_687_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_687_1"  
  type: "Scale"
  bottom: "res_stage_3_687_1"
  top: "res_stage_3_687_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_687_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_687_1_top"
  top: "res_stage_3_687_1_top"
}
layer {
  name: "res_stage_3_687_2"
  type: "Convolution"
  bottom: "res_stage_3_687_1_top"
  top: "res_stage_3_687_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_687_2"
  type: "BatchNorm"
  bottom: "res_stage_3_687_2"
  top: "res_stage_3_687_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_687_2"  
  type: "Scale"
  bottom: "res_stage_3_687_2"
  top: "res_stage_3_687_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_687_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_687_2_top"
  top: "res_stage_3_687_2_top"
}
layer {
  name: "res_stage_3_687_3"
  type: "Convolution"
  bottom: "res_stage_3_687_2_top"
  top: "res_stage_3_687_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_687_3"
  type: "BatchNorm"
  bottom: "res_stage_3_687_3"
  top: "res_stage_3_687_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_687_3"  
  type: "Scale"
  bottom: "res_stage_3_687_3"
  top: "res_stage_3_687_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_687"
  type: "Eltwise"
  bottom: "res_3_686"
  bottom: "res_stage_3_687_3_top"
  top: "res_3_687"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_687_relu"
  type: "ReLU"
  bottom: "res_3_687"
  top: "res_3_687"
}
layer {
  name: "res_stage_3_688_1"
  type: "Convolution"
  bottom: "res_3_687"
  top: "res_stage_3_688_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_688_1"
  type: "BatchNorm"
  bottom: "res_stage_3_688_1"
  top: "res_stage_3_688_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_688_1"  
  type: "Scale"
  bottom: "res_stage_3_688_1"
  top: "res_stage_3_688_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_688_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_688_1_top"
  top: "res_stage_3_688_1_top"
}
layer {
  name: "res_stage_3_688_2"
  type: "Convolution"
  bottom: "res_stage_3_688_1_top"
  top: "res_stage_3_688_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_688_2"
  type: "BatchNorm"
  bottom: "res_stage_3_688_2"
  top: "res_stage_3_688_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_688_2"  
  type: "Scale"
  bottom: "res_stage_3_688_2"
  top: "res_stage_3_688_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_688_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_688_2_top"
  top: "res_stage_3_688_2_top"
}
layer {
  name: "res_stage_3_688_3"
  type: "Convolution"
  bottom: "res_stage_3_688_2_top"
  top: "res_stage_3_688_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_688_3"
  type: "BatchNorm"
  bottom: "res_stage_3_688_3"
  top: "res_stage_3_688_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_688_3"  
  type: "Scale"
  bottom: "res_stage_3_688_3"
  top: "res_stage_3_688_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_688"
  type: "Eltwise"
  bottom: "res_3_687"
  bottom: "res_stage_3_688_3_top"
  top: "res_3_688"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_688_relu"
  type: "ReLU"
  bottom: "res_3_688"
  top: "res_3_688"
}
layer {
  name: "res_stage_3_689_1"
  type: "Convolution"
  bottom: "res_3_688"
  top: "res_stage_3_689_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_689_1"
  type: "BatchNorm"
  bottom: "res_stage_3_689_1"
  top: "res_stage_3_689_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_689_1"  
  type: "Scale"
  bottom: "res_stage_3_689_1"
  top: "res_stage_3_689_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_689_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_689_1_top"
  top: "res_stage_3_689_1_top"
}
layer {
  name: "res_stage_3_689_2"
  type: "Convolution"
  bottom: "res_stage_3_689_1_top"
  top: "res_stage_3_689_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_689_2"
  type: "BatchNorm"
  bottom: "res_stage_3_689_2"
  top: "res_stage_3_689_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_689_2"  
  type: "Scale"
  bottom: "res_stage_3_689_2"
  top: "res_stage_3_689_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_689_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_689_2_top"
  top: "res_stage_3_689_2_top"
}
layer {
  name: "res_stage_3_689_3"
  type: "Convolution"
  bottom: "res_stage_3_689_2_top"
  top: "res_stage_3_689_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_689_3"
  type: "BatchNorm"
  bottom: "res_stage_3_689_3"
  top: "res_stage_3_689_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_689_3"  
  type: "Scale"
  bottom: "res_stage_3_689_3"
  top: "res_stage_3_689_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_689"
  type: "Eltwise"
  bottom: "res_3_688"
  bottom: "res_stage_3_689_3_top"
  top: "res_3_689"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_689_relu"
  type: "ReLU"
  bottom: "res_3_689"
  top: "res_3_689"
}
layer {
  name: "res_stage_3_690_1"
  type: "Convolution"
  bottom: "res_3_689"
  top: "res_stage_3_690_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_690_1"
  type: "BatchNorm"
  bottom: "res_stage_3_690_1"
  top: "res_stage_3_690_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_690_1"  
  type: "Scale"
  bottom: "res_stage_3_690_1"
  top: "res_stage_3_690_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_690_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_690_1_top"
  top: "res_stage_3_690_1_top"
}
layer {
  name: "res_stage_3_690_2"
  type: "Convolution"
  bottom: "res_stage_3_690_1_top"
  top: "res_stage_3_690_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_690_2"
  type: "BatchNorm"
  bottom: "res_stage_3_690_2"
  top: "res_stage_3_690_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_690_2"  
  type: "Scale"
  bottom: "res_stage_3_690_2"
  top: "res_stage_3_690_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_690_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_690_2_top"
  top: "res_stage_3_690_2_top"
}
layer {
  name: "res_stage_3_690_3"
  type: "Convolution"
  bottom: "res_stage_3_690_2_top"
  top: "res_stage_3_690_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_690_3"
  type: "BatchNorm"
  bottom: "res_stage_3_690_3"
  top: "res_stage_3_690_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_690_3"  
  type: "Scale"
  bottom: "res_stage_3_690_3"
  top: "res_stage_3_690_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_690"
  type: "Eltwise"
  bottom: "res_3_689"
  bottom: "res_stage_3_690_3_top"
  top: "res_3_690"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_690_relu"
  type: "ReLU"
  bottom: "res_3_690"
  top: "res_3_690"
}
layer {
  name: "res_stage_3_691_1"
  type: "Convolution"
  bottom: "res_3_690"
  top: "res_stage_3_691_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_691_1"
  type: "BatchNorm"
  bottom: "res_stage_3_691_1"
  top: "res_stage_3_691_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_691_1"  
  type: "Scale"
  bottom: "res_stage_3_691_1"
  top: "res_stage_3_691_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_691_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_691_1_top"
  top: "res_stage_3_691_1_top"
}
layer {
  name: "res_stage_3_691_2"
  type: "Convolution"
  bottom: "res_stage_3_691_1_top"
  top: "res_stage_3_691_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_691_2"
  type: "BatchNorm"
  bottom: "res_stage_3_691_2"
  top: "res_stage_3_691_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_691_2"  
  type: "Scale"
  bottom: "res_stage_3_691_2"
  top: "res_stage_3_691_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_691_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_691_2_top"
  top: "res_stage_3_691_2_top"
}
layer {
  name: "res_stage_3_691_3"
  type: "Convolution"
  bottom: "res_stage_3_691_2_top"
  top: "res_stage_3_691_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_691_3"
  type: "BatchNorm"
  bottom: "res_stage_3_691_3"
  top: "res_stage_3_691_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_691_3"  
  type: "Scale"
  bottom: "res_stage_3_691_3"
  top: "res_stage_3_691_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_691"
  type: "Eltwise"
  bottom: "res_3_690"
  bottom: "res_stage_3_691_3_top"
  top: "res_3_691"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_691_relu"
  type: "ReLU"
  bottom: "res_3_691"
  top: "res_3_691"
}
layer {
  name: "res_stage_3_692_1"
  type: "Convolution"
  bottom: "res_3_691"
  top: "res_stage_3_692_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_692_1"
  type: "BatchNorm"
  bottom: "res_stage_3_692_1"
  top: "res_stage_3_692_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_692_1"  
  type: "Scale"
  bottom: "res_stage_3_692_1"
  top: "res_stage_3_692_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_692_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_692_1_top"
  top: "res_stage_3_692_1_top"
}
layer {
  name: "res_stage_3_692_2"
  type: "Convolution"
  bottom: "res_stage_3_692_1_top"
  top: "res_stage_3_692_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_692_2"
  type: "BatchNorm"
  bottom: "res_stage_3_692_2"
  top: "res_stage_3_692_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_692_2"  
  type: "Scale"
  bottom: "res_stage_3_692_2"
  top: "res_stage_3_692_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_692_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_692_2_top"
  top: "res_stage_3_692_2_top"
}
layer {
  name: "res_stage_3_692_3"
  type: "Convolution"
  bottom: "res_stage_3_692_2_top"
  top: "res_stage_3_692_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_692_3"
  type: "BatchNorm"
  bottom: "res_stage_3_692_3"
  top: "res_stage_3_692_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_692_3"  
  type: "Scale"
  bottom: "res_stage_3_692_3"
  top: "res_stage_3_692_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_692"
  type: "Eltwise"
  bottom: "res_3_691"
  bottom: "res_stage_3_692_3_top"
  top: "res_3_692"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_692_relu"
  type: "ReLU"
  bottom: "res_3_692"
  top: "res_3_692"
}
layer {
  name: "res_stage_3_693_1"
  type: "Convolution"
  bottom: "res_3_692"
  top: "res_stage_3_693_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_693_1"
  type: "BatchNorm"
  bottom: "res_stage_3_693_1"
  top: "res_stage_3_693_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_693_1"  
  type: "Scale"
  bottom: "res_stage_3_693_1"
  top: "res_stage_3_693_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_693_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_693_1_top"
  top: "res_stage_3_693_1_top"
}
layer {
  name: "res_stage_3_693_2"
  type: "Convolution"
  bottom: "res_stage_3_693_1_top"
  top: "res_stage_3_693_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_693_2"
  type: "BatchNorm"
  bottom: "res_stage_3_693_2"
  top: "res_stage_3_693_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_693_2"  
  type: "Scale"
  bottom: "res_stage_3_693_2"
  top: "res_stage_3_693_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_693_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_693_2_top"
  top: "res_stage_3_693_2_top"
}
layer {
  name: "res_stage_3_693_3"
  type: "Convolution"
  bottom: "res_stage_3_693_2_top"
  top: "res_stage_3_693_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_693_3"
  type: "BatchNorm"
  bottom: "res_stage_3_693_3"
  top: "res_stage_3_693_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_693_3"  
  type: "Scale"
  bottom: "res_stage_3_693_3"
  top: "res_stage_3_693_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_693"
  type: "Eltwise"
  bottom: "res_3_692"
  bottom: "res_stage_3_693_3_top"
  top: "res_3_693"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_693_relu"
  type: "ReLU"
  bottom: "res_3_693"
  top: "res_3_693"
}
layer {
  name: "res_stage_3_694_1"
  type: "Convolution"
  bottom: "res_3_693"
  top: "res_stage_3_694_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_694_1"
  type: "BatchNorm"
  bottom: "res_stage_3_694_1"
  top: "res_stage_3_694_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_694_1"  
  type: "Scale"
  bottom: "res_stage_3_694_1"
  top: "res_stage_3_694_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_694_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_694_1_top"
  top: "res_stage_3_694_1_top"
}
layer {
  name: "res_stage_3_694_2"
  type: "Convolution"
  bottom: "res_stage_3_694_1_top"
  top: "res_stage_3_694_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_694_2"
  type: "BatchNorm"
  bottom: "res_stage_3_694_2"
  top: "res_stage_3_694_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_694_2"  
  type: "Scale"
  bottom: "res_stage_3_694_2"
  top: "res_stage_3_694_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_694_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_694_2_top"
  top: "res_stage_3_694_2_top"
}
layer {
  name: "res_stage_3_694_3"
  type: "Convolution"
  bottom: "res_stage_3_694_2_top"
  top: "res_stage_3_694_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_694_3"
  type: "BatchNorm"
  bottom: "res_stage_3_694_3"
  top: "res_stage_3_694_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_694_3"  
  type: "Scale"
  bottom: "res_stage_3_694_3"
  top: "res_stage_3_694_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_694"
  type: "Eltwise"
  bottom: "res_3_693"
  bottom: "res_stage_3_694_3_top"
  top: "res_3_694"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_694_relu"
  type: "ReLU"
  bottom: "res_3_694"
  top: "res_3_694"
}
layer {
  name: "res_stage_3_695_1"
  type: "Convolution"
  bottom: "res_3_694"
  top: "res_stage_3_695_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_695_1"
  type: "BatchNorm"
  bottom: "res_stage_3_695_1"
  top: "res_stage_3_695_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_695_1"  
  type: "Scale"
  bottom: "res_stage_3_695_1"
  top: "res_stage_3_695_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_695_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_695_1_top"
  top: "res_stage_3_695_1_top"
}
layer {
  name: "res_stage_3_695_2"
  type: "Convolution"
  bottom: "res_stage_3_695_1_top"
  top: "res_stage_3_695_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_695_2"
  type: "BatchNorm"
  bottom: "res_stage_3_695_2"
  top: "res_stage_3_695_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_695_2"  
  type: "Scale"
  bottom: "res_stage_3_695_2"
  top: "res_stage_3_695_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_695_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_695_2_top"
  top: "res_stage_3_695_2_top"
}
layer {
  name: "res_stage_3_695_3"
  type: "Convolution"
  bottom: "res_stage_3_695_2_top"
  top: "res_stage_3_695_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_695_3"
  type: "BatchNorm"
  bottom: "res_stage_3_695_3"
  top: "res_stage_3_695_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_695_3"  
  type: "Scale"
  bottom: "res_stage_3_695_3"
  top: "res_stage_3_695_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_695"
  type: "Eltwise"
  bottom: "res_3_694"
  bottom: "res_stage_3_695_3_top"
  top: "res_3_695"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_695_relu"
  type: "ReLU"
  bottom: "res_3_695"
  top: "res_3_695"
}
layer {
  name: "res_stage_3_696_1"
  type: "Convolution"
  bottom: "res_3_695"
  top: "res_stage_3_696_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_696_1"
  type: "BatchNorm"
  bottom: "res_stage_3_696_1"
  top: "res_stage_3_696_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_696_1"  
  type: "Scale"
  bottom: "res_stage_3_696_1"
  top: "res_stage_3_696_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_696_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_696_1_top"
  top: "res_stage_3_696_1_top"
}
layer {
  name: "res_stage_3_696_2"
  type: "Convolution"
  bottom: "res_stage_3_696_1_top"
  top: "res_stage_3_696_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_696_2"
  type: "BatchNorm"
  bottom: "res_stage_3_696_2"
  top: "res_stage_3_696_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_696_2"  
  type: "Scale"
  bottom: "res_stage_3_696_2"
  top: "res_stage_3_696_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_696_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_696_2_top"
  top: "res_stage_3_696_2_top"
}
layer {
  name: "res_stage_3_696_3"
  type: "Convolution"
  bottom: "res_stage_3_696_2_top"
  top: "res_stage_3_696_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_696_3"
  type: "BatchNorm"
  bottom: "res_stage_3_696_3"
  top: "res_stage_3_696_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_696_3"  
  type: "Scale"
  bottom: "res_stage_3_696_3"
  top: "res_stage_3_696_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_696"
  type: "Eltwise"
  bottom: "res_3_695"
  bottom: "res_stage_3_696_3_top"
  top: "res_3_696"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_696_relu"
  type: "ReLU"
  bottom: "res_3_696"
  top: "res_3_696"
}
layer {
  name: "res_stage_3_697_1"
  type: "Convolution"
  bottom: "res_3_696"
  top: "res_stage_3_697_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_697_1"
  type: "BatchNorm"
  bottom: "res_stage_3_697_1"
  top: "res_stage_3_697_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_697_1"  
  type: "Scale"
  bottom: "res_stage_3_697_1"
  top: "res_stage_3_697_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_697_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_697_1_top"
  top: "res_stage_3_697_1_top"
}
layer {
  name: "res_stage_3_697_2"
  type: "Convolution"
  bottom: "res_stage_3_697_1_top"
  top: "res_stage_3_697_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_697_2"
  type: "BatchNorm"
  bottom: "res_stage_3_697_2"
  top: "res_stage_3_697_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_697_2"  
  type: "Scale"
  bottom: "res_stage_3_697_2"
  top: "res_stage_3_697_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_697_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_697_2_top"
  top: "res_stage_3_697_2_top"
}
layer {
  name: "res_stage_3_697_3"
  type: "Convolution"
  bottom: "res_stage_3_697_2_top"
  top: "res_stage_3_697_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_697_3"
  type: "BatchNorm"
  bottom: "res_stage_3_697_3"
  top: "res_stage_3_697_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_697_3"  
  type: "Scale"
  bottom: "res_stage_3_697_3"
  top: "res_stage_3_697_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_697"
  type: "Eltwise"
  bottom: "res_3_696"
  bottom: "res_stage_3_697_3_top"
  top: "res_3_697"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_697_relu"
  type: "ReLU"
  bottom: "res_3_697"
  top: "res_3_697"
}
layer {
  name: "res_stage_3_698_1"
  type: "Convolution"
  bottom: "res_3_697"
  top: "res_stage_3_698_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_698_1"
  type: "BatchNorm"
  bottom: "res_stage_3_698_1"
  top: "res_stage_3_698_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_698_1"  
  type: "Scale"
  bottom: "res_stage_3_698_1"
  top: "res_stage_3_698_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_698_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_698_1_top"
  top: "res_stage_3_698_1_top"
}
layer {
  name: "res_stage_3_698_2"
  type: "Convolution"
  bottom: "res_stage_3_698_1_top"
  top: "res_stage_3_698_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_698_2"
  type: "BatchNorm"
  bottom: "res_stage_3_698_2"
  top: "res_stage_3_698_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_698_2"  
  type: "Scale"
  bottom: "res_stage_3_698_2"
  top: "res_stage_3_698_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_698_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_698_2_top"
  top: "res_stage_3_698_2_top"
}
layer {
  name: "res_stage_3_698_3"
  type: "Convolution"
  bottom: "res_stage_3_698_2_top"
  top: "res_stage_3_698_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_698_3"
  type: "BatchNorm"
  bottom: "res_stage_3_698_3"
  top: "res_stage_3_698_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_698_3"  
  type: "Scale"
  bottom: "res_stage_3_698_3"
  top: "res_stage_3_698_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_698"
  type: "Eltwise"
  bottom: "res_3_697"
  bottom: "res_stage_3_698_3_top"
  top: "res_3_698"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_698_relu"
  type: "ReLU"
  bottom: "res_3_698"
  top: "res_3_698"
}
layer {
  name: "res_stage_3_699_1"
  type: "Convolution"
  bottom: "res_3_698"
  top: "res_stage_3_699_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_699_1"
  type: "BatchNorm"
  bottom: "res_stage_3_699_1"
  top: "res_stage_3_699_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_699_1"  
  type: "Scale"
  bottom: "res_stage_3_699_1"
  top: "res_stage_3_699_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_699_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_699_1_top"
  top: "res_stage_3_699_1_top"
}
layer {
  name: "res_stage_3_699_2"
  type: "Convolution"
  bottom: "res_stage_3_699_1_top"
  top: "res_stage_3_699_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_699_2"
  type: "BatchNorm"
  bottom: "res_stage_3_699_2"
  top: "res_stage_3_699_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_699_2"  
  type: "Scale"
  bottom: "res_stage_3_699_2"
  top: "res_stage_3_699_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_699_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_699_2_top"
  top: "res_stage_3_699_2_top"
}
layer {
  name: "res_stage_3_699_3"
  type: "Convolution"
  bottom: "res_stage_3_699_2_top"
  top: "res_stage_3_699_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_699_3"
  type: "BatchNorm"
  bottom: "res_stage_3_699_3"
  top: "res_stage_3_699_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_699_3"  
  type: "Scale"
  bottom: "res_stage_3_699_3"
  top: "res_stage_3_699_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_699"
  type: "Eltwise"
  bottom: "res_3_698"
  bottom: "res_stage_3_699_3_top"
  top: "res_3_699"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_699_relu"
  type: "ReLU"
  bottom: "res_3_699"
  top: "res_3_699"
}
layer {
  name: "res_stage_3_700_1"
  type: "Convolution"
  bottom: "res_3_699"
  top: "res_stage_3_700_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_700_1"
  type: "BatchNorm"
  bottom: "res_stage_3_700_1"
  top: "res_stage_3_700_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_700_1"  
  type: "Scale"
  bottom: "res_stage_3_700_1"
  top: "res_stage_3_700_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_700_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_700_1_top"
  top: "res_stage_3_700_1_top"
}
layer {
  name: "res_stage_3_700_2"
  type: "Convolution"
  bottom: "res_stage_3_700_1_top"
  top: "res_stage_3_700_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_700_2"
  type: "BatchNorm"
  bottom: "res_stage_3_700_2"
  top: "res_stage_3_700_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_700_2"  
  type: "Scale"
  bottom: "res_stage_3_700_2"
  top: "res_stage_3_700_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_700_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_700_2_top"
  top: "res_stage_3_700_2_top"
}
layer {
  name: "res_stage_3_700_3"
  type: "Convolution"
  bottom: "res_stage_3_700_2_top"
  top: "res_stage_3_700_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_700_3"
  type: "BatchNorm"
  bottom: "res_stage_3_700_3"
  top: "res_stage_3_700_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_700_3"  
  type: "Scale"
  bottom: "res_stage_3_700_3"
  top: "res_stage_3_700_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_700"
  type: "Eltwise"
  bottom: "res_3_699"
  bottom: "res_stage_3_700_3_top"
  top: "res_3_700"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_700_relu"
  type: "ReLU"
  bottom: "res_3_700"
  top: "res_3_700"
}
layer {
  name: "res_stage_3_701_1"
  type: "Convolution"
  bottom: "res_3_700"
  top: "res_stage_3_701_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_701_1"
  type: "BatchNorm"
  bottom: "res_stage_3_701_1"
  top: "res_stage_3_701_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_701_1"  
  type: "Scale"
  bottom: "res_stage_3_701_1"
  top: "res_stage_3_701_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_701_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_701_1_top"
  top: "res_stage_3_701_1_top"
}
layer {
  name: "res_stage_3_701_2"
  type: "Convolution"
  bottom: "res_stage_3_701_1_top"
  top: "res_stage_3_701_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_701_2"
  type: "BatchNorm"
  bottom: "res_stage_3_701_2"
  top: "res_stage_3_701_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_701_2"  
  type: "Scale"
  bottom: "res_stage_3_701_2"
  top: "res_stage_3_701_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_701_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_701_2_top"
  top: "res_stage_3_701_2_top"
}
layer {
  name: "res_stage_3_701_3"
  type: "Convolution"
  bottom: "res_stage_3_701_2_top"
  top: "res_stage_3_701_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_701_3"
  type: "BatchNorm"
  bottom: "res_stage_3_701_3"
  top: "res_stage_3_701_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_701_3"  
  type: "Scale"
  bottom: "res_stage_3_701_3"
  top: "res_stage_3_701_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_701"
  type: "Eltwise"
  bottom: "res_3_700"
  bottom: "res_stage_3_701_3_top"
  top: "res_3_701"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_701_relu"
  type: "ReLU"
  bottom: "res_3_701"
  top: "res_3_701"
}
layer {
  name: "res_stage_3_702_1"
  type: "Convolution"
  bottom: "res_3_701"
  top: "res_stage_3_702_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_702_1"
  type: "BatchNorm"
  bottom: "res_stage_3_702_1"
  top: "res_stage_3_702_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_702_1"  
  type: "Scale"
  bottom: "res_stage_3_702_1"
  top: "res_stage_3_702_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_702_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_702_1_top"
  top: "res_stage_3_702_1_top"
}
layer {
  name: "res_stage_3_702_2"
  type: "Convolution"
  bottom: "res_stage_3_702_1_top"
  top: "res_stage_3_702_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_702_2"
  type: "BatchNorm"
  bottom: "res_stage_3_702_2"
  top: "res_stage_3_702_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_702_2"  
  type: "Scale"
  bottom: "res_stage_3_702_2"
  top: "res_stage_3_702_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_702_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_702_2_top"
  top: "res_stage_3_702_2_top"
}
layer {
  name: "res_stage_3_702_3"
  type: "Convolution"
  bottom: "res_stage_3_702_2_top"
  top: "res_stage_3_702_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_702_3"
  type: "BatchNorm"
  bottom: "res_stage_3_702_3"
  top: "res_stage_3_702_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_702_3"  
  type: "Scale"
  bottom: "res_stage_3_702_3"
  top: "res_stage_3_702_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_702"
  type: "Eltwise"
  bottom: "res_3_701"
  bottom: "res_stage_3_702_3_top"
  top: "res_3_702"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_702_relu"
  type: "ReLU"
  bottom: "res_3_702"
  top: "res_3_702"
}
layer {
  name: "res_stage_3_703_1"
  type: "Convolution"
  bottom: "res_3_702"
  top: "res_stage_3_703_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_703_1"
  type: "BatchNorm"
  bottom: "res_stage_3_703_1"
  top: "res_stage_3_703_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_703_1"  
  type: "Scale"
  bottom: "res_stage_3_703_1"
  top: "res_stage_3_703_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_703_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_703_1_top"
  top: "res_stage_3_703_1_top"
}
layer {
  name: "res_stage_3_703_2"
  type: "Convolution"
  bottom: "res_stage_3_703_1_top"
  top: "res_stage_3_703_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_703_2"
  type: "BatchNorm"
  bottom: "res_stage_3_703_2"
  top: "res_stage_3_703_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_703_2"  
  type: "Scale"
  bottom: "res_stage_3_703_2"
  top: "res_stage_3_703_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_703_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_703_2_top"
  top: "res_stage_3_703_2_top"
}
layer {
  name: "res_stage_3_703_3"
  type: "Convolution"
  bottom: "res_stage_3_703_2_top"
  top: "res_stage_3_703_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_703_3"
  type: "BatchNorm"
  bottom: "res_stage_3_703_3"
  top: "res_stage_3_703_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_703_3"  
  type: "Scale"
  bottom: "res_stage_3_703_3"
  top: "res_stage_3_703_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_703"
  type: "Eltwise"
  bottom: "res_3_702"
  bottom: "res_stage_3_703_3_top"
  top: "res_3_703"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_703_relu"
  type: "ReLU"
  bottom: "res_3_703"
  top: "res_3_703"
}
layer {
  name: "res_stage_3_704_1"
  type: "Convolution"
  bottom: "res_3_703"
  top: "res_stage_3_704_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_704_1"
  type: "BatchNorm"
  bottom: "res_stage_3_704_1"
  top: "res_stage_3_704_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_704_1"  
  type: "Scale"
  bottom: "res_stage_3_704_1"
  top: "res_stage_3_704_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_704_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_704_1_top"
  top: "res_stage_3_704_1_top"
}
layer {
  name: "res_stage_3_704_2"
  type: "Convolution"
  bottom: "res_stage_3_704_1_top"
  top: "res_stage_3_704_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_704_2"
  type: "BatchNorm"
  bottom: "res_stage_3_704_2"
  top: "res_stage_3_704_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_704_2"  
  type: "Scale"
  bottom: "res_stage_3_704_2"
  top: "res_stage_3_704_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_704_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_704_2_top"
  top: "res_stage_3_704_2_top"
}
layer {
  name: "res_stage_3_704_3"
  type: "Convolution"
  bottom: "res_stage_3_704_2_top"
  top: "res_stage_3_704_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_704_3"
  type: "BatchNorm"
  bottom: "res_stage_3_704_3"
  top: "res_stage_3_704_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_704_3"  
  type: "Scale"
  bottom: "res_stage_3_704_3"
  top: "res_stage_3_704_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_704"
  type: "Eltwise"
  bottom: "res_3_703"
  bottom: "res_stage_3_704_3_top"
  top: "res_3_704"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_704_relu"
  type: "ReLU"
  bottom: "res_3_704"
  top: "res_3_704"
}
layer {
  name: "res_stage_3_705_1"
  type: "Convolution"
  bottom: "res_3_704"
  top: "res_stage_3_705_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_705_1"
  type: "BatchNorm"
  bottom: "res_stage_3_705_1"
  top: "res_stage_3_705_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_705_1"  
  type: "Scale"
  bottom: "res_stage_3_705_1"
  top: "res_stage_3_705_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_705_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_705_1_top"
  top: "res_stage_3_705_1_top"
}
layer {
  name: "res_stage_3_705_2"
  type: "Convolution"
  bottom: "res_stage_3_705_1_top"
  top: "res_stage_3_705_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_705_2"
  type: "BatchNorm"
  bottom: "res_stage_3_705_2"
  top: "res_stage_3_705_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_705_2"  
  type: "Scale"
  bottom: "res_stage_3_705_2"
  top: "res_stage_3_705_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_705_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_705_2_top"
  top: "res_stage_3_705_2_top"
}
layer {
  name: "res_stage_3_705_3"
  type: "Convolution"
  bottom: "res_stage_3_705_2_top"
  top: "res_stage_3_705_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_705_3"
  type: "BatchNorm"
  bottom: "res_stage_3_705_3"
  top: "res_stage_3_705_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_705_3"  
  type: "Scale"
  bottom: "res_stage_3_705_3"
  top: "res_stage_3_705_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_705"
  type: "Eltwise"
  bottom: "res_3_704"
  bottom: "res_stage_3_705_3_top"
  top: "res_3_705"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_705_relu"
  type: "ReLU"
  bottom: "res_3_705"
  top: "res_3_705"
}
layer {
  name: "res_stage_3_706_1"
  type: "Convolution"
  bottom: "res_3_705"
  top: "res_stage_3_706_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_706_1"
  type: "BatchNorm"
  bottom: "res_stage_3_706_1"
  top: "res_stage_3_706_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_706_1"  
  type: "Scale"
  bottom: "res_stage_3_706_1"
  top: "res_stage_3_706_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_706_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_706_1_top"
  top: "res_stage_3_706_1_top"
}
layer {
  name: "res_stage_3_706_2"
  type: "Convolution"
  bottom: "res_stage_3_706_1_top"
  top: "res_stage_3_706_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_706_2"
  type: "BatchNorm"
  bottom: "res_stage_3_706_2"
  top: "res_stage_3_706_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_706_2"  
  type: "Scale"
  bottom: "res_stage_3_706_2"
  top: "res_stage_3_706_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_706_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_706_2_top"
  top: "res_stage_3_706_2_top"
}
layer {
  name: "res_stage_3_706_3"
  type: "Convolution"
  bottom: "res_stage_3_706_2_top"
  top: "res_stage_3_706_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_706_3"
  type: "BatchNorm"
  bottom: "res_stage_3_706_3"
  top: "res_stage_3_706_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_706_3"  
  type: "Scale"
  bottom: "res_stage_3_706_3"
  top: "res_stage_3_706_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_706"
  type: "Eltwise"
  bottom: "res_3_705"
  bottom: "res_stage_3_706_3_top"
  top: "res_3_706"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_706_relu"
  type: "ReLU"
  bottom: "res_3_706"
  top: "res_3_706"
}
layer {
  name: "res_stage_3_707_1"
  type: "Convolution"
  bottom: "res_3_706"
  top: "res_stage_3_707_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_707_1"
  type: "BatchNorm"
  bottom: "res_stage_3_707_1"
  top: "res_stage_3_707_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_707_1"  
  type: "Scale"
  bottom: "res_stage_3_707_1"
  top: "res_stage_3_707_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_707_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_707_1_top"
  top: "res_stage_3_707_1_top"
}
layer {
  name: "res_stage_3_707_2"
  type: "Convolution"
  bottom: "res_stage_3_707_1_top"
  top: "res_stage_3_707_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_707_2"
  type: "BatchNorm"
  bottom: "res_stage_3_707_2"
  top: "res_stage_3_707_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_707_2"  
  type: "Scale"
  bottom: "res_stage_3_707_2"
  top: "res_stage_3_707_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_707_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_707_2_top"
  top: "res_stage_3_707_2_top"
}
layer {
  name: "res_stage_3_707_3"
  type: "Convolution"
  bottom: "res_stage_3_707_2_top"
  top: "res_stage_3_707_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_707_3"
  type: "BatchNorm"
  bottom: "res_stage_3_707_3"
  top: "res_stage_3_707_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_707_3"  
  type: "Scale"
  bottom: "res_stage_3_707_3"
  top: "res_stage_3_707_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_707"
  type: "Eltwise"
  bottom: "res_3_706"
  bottom: "res_stage_3_707_3_top"
  top: "res_3_707"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_707_relu"
  type: "ReLU"
  bottom: "res_3_707"
  top: "res_3_707"
}
layer {
  name: "res_stage_3_708_1"
  type: "Convolution"
  bottom: "res_3_707"
  top: "res_stage_3_708_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_708_1"
  type: "BatchNorm"
  bottom: "res_stage_3_708_1"
  top: "res_stage_3_708_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_708_1"  
  type: "Scale"
  bottom: "res_stage_3_708_1"
  top: "res_stage_3_708_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_708_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_708_1_top"
  top: "res_stage_3_708_1_top"
}
layer {
  name: "res_stage_3_708_2"
  type: "Convolution"
  bottom: "res_stage_3_708_1_top"
  top: "res_stage_3_708_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_708_2"
  type: "BatchNorm"
  bottom: "res_stage_3_708_2"
  top: "res_stage_3_708_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_708_2"  
  type: "Scale"
  bottom: "res_stage_3_708_2"
  top: "res_stage_3_708_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_708_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_708_2_top"
  top: "res_stage_3_708_2_top"
}
layer {
  name: "res_stage_3_708_3"
  type: "Convolution"
  bottom: "res_stage_3_708_2_top"
  top: "res_stage_3_708_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_708_3"
  type: "BatchNorm"
  bottom: "res_stage_3_708_3"
  top: "res_stage_3_708_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_708_3"  
  type: "Scale"
  bottom: "res_stage_3_708_3"
  top: "res_stage_3_708_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_708"
  type: "Eltwise"
  bottom: "res_3_707"
  bottom: "res_stage_3_708_3_top"
  top: "res_3_708"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_708_relu"
  type: "ReLU"
  bottom: "res_3_708"
  top: "res_3_708"
}
layer {
  name: "res_stage_3_709_1"
  type: "Convolution"
  bottom: "res_3_708"
  top: "res_stage_3_709_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_709_1"
  type: "BatchNorm"
  bottom: "res_stage_3_709_1"
  top: "res_stage_3_709_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_709_1"  
  type: "Scale"
  bottom: "res_stage_3_709_1"
  top: "res_stage_3_709_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_709_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_709_1_top"
  top: "res_stage_3_709_1_top"
}
layer {
  name: "res_stage_3_709_2"
  type: "Convolution"
  bottom: "res_stage_3_709_1_top"
  top: "res_stage_3_709_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_709_2"
  type: "BatchNorm"
  bottom: "res_stage_3_709_2"
  top: "res_stage_3_709_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_709_2"  
  type: "Scale"
  bottom: "res_stage_3_709_2"
  top: "res_stage_3_709_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_709_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_709_2_top"
  top: "res_stage_3_709_2_top"
}
layer {
  name: "res_stage_3_709_3"
  type: "Convolution"
  bottom: "res_stage_3_709_2_top"
  top: "res_stage_3_709_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_709_3"
  type: "BatchNorm"
  bottom: "res_stage_3_709_3"
  top: "res_stage_3_709_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_709_3"  
  type: "Scale"
  bottom: "res_stage_3_709_3"
  top: "res_stage_3_709_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_709"
  type: "Eltwise"
  bottom: "res_3_708"
  bottom: "res_stage_3_709_3_top"
  top: "res_3_709"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_709_relu"
  type: "ReLU"
  bottom: "res_3_709"
  top: "res_3_709"
}
layer {
  name: "res_stage_3_710_1"
  type: "Convolution"
  bottom: "res_3_709"
  top: "res_stage_3_710_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_710_1"
  type: "BatchNorm"
  bottom: "res_stage_3_710_1"
  top: "res_stage_3_710_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_710_1"  
  type: "Scale"
  bottom: "res_stage_3_710_1"
  top: "res_stage_3_710_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_710_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_710_1_top"
  top: "res_stage_3_710_1_top"
}
layer {
  name: "res_stage_3_710_2"
  type: "Convolution"
  bottom: "res_stage_3_710_1_top"
  top: "res_stage_3_710_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_710_2"
  type: "BatchNorm"
  bottom: "res_stage_3_710_2"
  top: "res_stage_3_710_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_710_2"  
  type: "Scale"
  bottom: "res_stage_3_710_2"
  top: "res_stage_3_710_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_710_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_710_2_top"
  top: "res_stage_3_710_2_top"
}
layer {
  name: "res_stage_3_710_3"
  type: "Convolution"
  bottom: "res_stage_3_710_2_top"
  top: "res_stage_3_710_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_710_3"
  type: "BatchNorm"
  bottom: "res_stage_3_710_3"
  top: "res_stage_3_710_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_710_3"  
  type: "Scale"
  bottom: "res_stage_3_710_3"
  top: "res_stage_3_710_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_710"
  type: "Eltwise"
  bottom: "res_3_709"
  bottom: "res_stage_3_710_3_top"
  top: "res_3_710"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_710_relu"
  type: "ReLU"
  bottom: "res_3_710"
  top: "res_3_710"
}
layer {
  name: "res_stage_3_711_1"
  type: "Convolution"
  bottom: "res_3_710"
  top: "res_stage_3_711_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_711_1"
  type: "BatchNorm"
  bottom: "res_stage_3_711_1"
  top: "res_stage_3_711_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_711_1"  
  type: "Scale"
  bottom: "res_stage_3_711_1"
  top: "res_stage_3_711_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_711_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_711_1_top"
  top: "res_stage_3_711_1_top"
}
layer {
  name: "res_stage_3_711_2"
  type: "Convolution"
  bottom: "res_stage_3_711_1_top"
  top: "res_stage_3_711_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_711_2"
  type: "BatchNorm"
  bottom: "res_stage_3_711_2"
  top: "res_stage_3_711_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_711_2"  
  type: "Scale"
  bottom: "res_stage_3_711_2"
  top: "res_stage_3_711_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_711_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_711_2_top"
  top: "res_stage_3_711_2_top"
}
layer {
  name: "res_stage_3_711_3"
  type: "Convolution"
  bottom: "res_stage_3_711_2_top"
  top: "res_stage_3_711_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_711_3"
  type: "BatchNorm"
  bottom: "res_stage_3_711_3"
  top: "res_stage_3_711_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_711_3"  
  type: "Scale"
  bottom: "res_stage_3_711_3"
  top: "res_stage_3_711_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_711"
  type: "Eltwise"
  bottom: "res_3_710"
  bottom: "res_stage_3_711_3_top"
  top: "res_3_711"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_711_relu"
  type: "ReLU"
  bottom: "res_3_711"
  top: "res_3_711"
}
layer {
  name: "res_stage_3_712_1"
  type: "Convolution"
  bottom: "res_3_711"
  top: "res_stage_3_712_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_712_1"
  type: "BatchNorm"
  bottom: "res_stage_3_712_1"
  top: "res_stage_3_712_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_712_1"  
  type: "Scale"
  bottom: "res_stage_3_712_1"
  top: "res_stage_3_712_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_712_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_712_1_top"
  top: "res_stage_3_712_1_top"
}
layer {
  name: "res_stage_3_712_2"
  type: "Convolution"
  bottom: "res_stage_3_712_1_top"
  top: "res_stage_3_712_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_712_2"
  type: "BatchNorm"
  bottom: "res_stage_3_712_2"
  top: "res_stage_3_712_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_712_2"  
  type: "Scale"
  bottom: "res_stage_3_712_2"
  top: "res_stage_3_712_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_712_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_712_2_top"
  top: "res_stage_3_712_2_top"
}
layer {
  name: "res_stage_3_712_3"
  type: "Convolution"
  bottom: "res_stage_3_712_2_top"
  top: "res_stage_3_712_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_712_3"
  type: "BatchNorm"
  bottom: "res_stage_3_712_3"
  top: "res_stage_3_712_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_712_3"  
  type: "Scale"
  bottom: "res_stage_3_712_3"
  top: "res_stage_3_712_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_712"
  type: "Eltwise"
  bottom: "res_3_711"
  bottom: "res_stage_3_712_3_top"
  top: "res_3_712"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_712_relu"
  type: "ReLU"
  bottom: "res_3_712"
  top: "res_3_712"
}
layer {
  name: "res_stage_3_713_1"
  type: "Convolution"
  bottom: "res_3_712"
  top: "res_stage_3_713_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_713_1"
  type: "BatchNorm"
  bottom: "res_stage_3_713_1"
  top: "res_stage_3_713_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_713_1"  
  type: "Scale"
  bottom: "res_stage_3_713_1"
  top: "res_stage_3_713_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_713_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_713_1_top"
  top: "res_stage_3_713_1_top"
}
layer {
  name: "res_stage_3_713_2"
  type: "Convolution"
  bottom: "res_stage_3_713_1_top"
  top: "res_stage_3_713_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_713_2"
  type: "BatchNorm"
  bottom: "res_stage_3_713_2"
  top: "res_stage_3_713_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_713_2"  
  type: "Scale"
  bottom: "res_stage_3_713_2"
  top: "res_stage_3_713_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_713_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_713_2_top"
  top: "res_stage_3_713_2_top"
}
layer {
  name: "res_stage_3_713_3"
  type: "Convolution"
  bottom: "res_stage_3_713_2_top"
  top: "res_stage_3_713_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_713_3"
  type: "BatchNorm"
  bottom: "res_stage_3_713_3"
  top: "res_stage_3_713_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_713_3"  
  type: "Scale"
  bottom: "res_stage_3_713_3"
  top: "res_stage_3_713_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_713"
  type: "Eltwise"
  bottom: "res_3_712"
  bottom: "res_stage_3_713_3_top"
  top: "res_3_713"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_713_relu"
  type: "ReLU"
  bottom: "res_3_713"
  top: "res_3_713"
}
layer {
  name: "res_stage_3_714_1"
  type: "Convolution"
  bottom: "res_3_713"
  top: "res_stage_3_714_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_714_1"
  type: "BatchNorm"
  bottom: "res_stage_3_714_1"
  top: "res_stage_3_714_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_714_1"  
  type: "Scale"
  bottom: "res_stage_3_714_1"
  top: "res_stage_3_714_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_714_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_714_1_top"
  top: "res_stage_3_714_1_top"
}
layer {
  name: "res_stage_3_714_2"
  type: "Convolution"
  bottom: "res_stage_3_714_1_top"
  top: "res_stage_3_714_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_714_2"
  type: "BatchNorm"
  bottom: "res_stage_3_714_2"
  top: "res_stage_3_714_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_714_2"  
  type: "Scale"
  bottom: "res_stage_3_714_2"
  top: "res_stage_3_714_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_714_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_714_2_top"
  top: "res_stage_3_714_2_top"
}
layer {
  name: "res_stage_3_714_3"
  type: "Convolution"
  bottom: "res_stage_3_714_2_top"
  top: "res_stage_3_714_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_714_3"
  type: "BatchNorm"
  bottom: "res_stage_3_714_3"
  top: "res_stage_3_714_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_714_3"  
  type: "Scale"
  bottom: "res_stage_3_714_3"
  top: "res_stage_3_714_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_714"
  type: "Eltwise"
  bottom: "res_3_713"
  bottom: "res_stage_3_714_3_top"
  top: "res_3_714"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_714_relu"
  type: "ReLU"
  bottom: "res_3_714"
  top: "res_3_714"
}
layer {
  name: "res_stage_3_715_1"
  type: "Convolution"
  bottom: "res_3_714"
  top: "res_stage_3_715_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_715_1"
  type: "BatchNorm"
  bottom: "res_stage_3_715_1"
  top: "res_stage_3_715_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_715_1"  
  type: "Scale"
  bottom: "res_stage_3_715_1"
  top: "res_stage_3_715_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_715_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_715_1_top"
  top: "res_stage_3_715_1_top"
}
layer {
  name: "res_stage_3_715_2"
  type: "Convolution"
  bottom: "res_stage_3_715_1_top"
  top: "res_stage_3_715_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_715_2"
  type: "BatchNorm"
  bottom: "res_stage_3_715_2"
  top: "res_stage_3_715_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_715_2"  
  type: "Scale"
  bottom: "res_stage_3_715_2"
  top: "res_stage_3_715_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_715_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_715_2_top"
  top: "res_stage_3_715_2_top"
}
layer {
  name: "res_stage_3_715_3"
  type: "Convolution"
  bottom: "res_stage_3_715_2_top"
  top: "res_stage_3_715_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_715_3"
  type: "BatchNorm"
  bottom: "res_stage_3_715_3"
  top: "res_stage_3_715_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_715_3"  
  type: "Scale"
  bottom: "res_stage_3_715_3"
  top: "res_stage_3_715_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_715"
  type: "Eltwise"
  bottom: "res_3_714"
  bottom: "res_stage_3_715_3_top"
  top: "res_3_715"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_715_relu"
  type: "ReLU"
  bottom: "res_3_715"
  top: "res_3_715"
}
layer {
  name: "res_stage_3_716_1"
  type: "Convolution"
  bottom: "res_3_715"
  top: "res_stage_3_716_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_716_1"
  type: "BatchNorm"
  bottom: "res_stage_3_716_1"
  top: "res_stage_3_716_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_716_1"  
  type: "Scale"
  bottom: "res_stage_3_716_1"
  top: "res_stage_3_716_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_716_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_716_1_top"
  top: "res_stage_3_716_1_top"
}
layer {
  name: "res_stage_3_716_2"
  type: "Convolution"
  bottom: "res_stage_3_716_1_top"
  top: "res_stage_3_716_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_716_2"
  type: "BatchNorm"
  bottom: "res_stage_3_716_2"
  top: "res_stage_3_716_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_716_2"  
  type: "Scale"
  bottom: "res_stage_3_716_2"
  top: "res_stage_3_716_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_716_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_716_2_top"
  top: "res_stage_3_716_2_top"
}
layer {
  name: "res_stage_3_716_3"
  type: "Convolution"
  bottom: "res_stage_3_716_2_top"
  top: "res_stage_3_716_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_716_3"
  type: "BatchNorm"
  bottom: "res_stage_3_716_3"
  top: "res_stage_3_716_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_716_3"  
  type: "Scale"
  bottom: "res_stage_3_716_3"
  top: "res_stage_3_716_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_716"
  type: "Eltwise"
  bottom: "res_3_715"
  bottom: "res_stage_3_716_3_top"
  top: "res_3_716"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_716_relu"
  type: "ReLU"
  bottom: "res_3_716"
  top: "res_3_716"
}
layer {
  name: "res_stage_3_717_1"
  type: "Convolution"
  bottom: "res_3_716"
  top: "res_stage_3_717_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_717_1"
  type: "BatchNorm"
  bottom: "res_stage_3_717_1"
  top: "res_stage_3_717_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_717_1"  
  type: "Scale"
  bottom: "res_stage_3_717_1"
  top: "res_stage_3_717_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_717_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_717_1_top"
  top: "res_stage_3_717_1_top"
}
layer {
  name: "res_stage_3_717_2"
  type: "Convolution"
  bottom: "res_stage_3_717_1_top"
  top: "res_stage_3_717_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_717_2"
  type: "BatchNorm"
  bottom: "res_stage_3_717_2"
  top: "res_stage_3_717_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_717_2"  
  type: "Scale"
  bottom: "res_stage_3_717_2"
  top: "res_stage_3_717_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_717_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_717_2_top"
  top: "res_stage_3_717_2_top"
}
layer {
  name: "res_stage_3_717_3"
  type: "Convolution"
  bottom: "res_stage_3_717_2_top"
  top: "res_stage_3_717_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_717_3"
  type: "BatchNorm"
  bottom: "res_stage_3_717_3"
  top: "res_stage_3_717_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_717_3"  
  type: "Scale"
  bottom: "res_stage_3_717_3"
  top: "res_stage_3_717_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_717"
  type: "Eltwise"
  bottom: "res_3_716"
  bottom: "res_stage_3_717_3_top"
  top: "res_3_717"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_717_relu"
  type: "ReLU"
  bottom: "res_3_717"
  top: "res_3_717"
}
layer {
  name: "res_stage_3_718_1"
  type: "Convolution"
  bottom: "res_3_717"
  top: "res_stage_3_718_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_718_1"
  type: "BatchNorm"
  bottom: "res_stage_3_718_1"
  top: "res_stage_3_718_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_718_1"  
  type: "Scale"
  bottom: "res_stage_3_718_1"
  top: "res_stage_3_718_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_718_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_718_1_top"
  top: "res_stage_3_718_1_top"
}
layer {
  name: "res_stage_3_718_2"
  type: "Convolution"
  bottom: "res_stage_3_718_1_top"
  top: "res_stage_3_718_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_718_2"
  type: "BatchNorm"
  bottom: "res_stage_3_718_2"
  top: "res_stage_3_718_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_718_2"  
  type: "Scale"
  bottom: "res_stage_3_718_2"
  top: "res_stage_3_718_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_718_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_718_2_top"
  top: "res_stage_3_718_2_top"
}
layer {
  name: "res_stage_3_718_3"
  type: "Convolution"
  bottom: "res_stage_3_718_2_top"
  top: "res_stage_3_718_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_718_3"
  type: "BatchNorm"
  bottom: "res_stage_3_718_3"
  top: "res_stage_3_718_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_718_3"  
  type: "Scale"
  bottom: "res_stage_3_718_3"
  top: "res_stage_3_718_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_718"
  type: "Eltwise"
  bottom: "res_3_717"
  bottom: "res_stage_3_718_3_top"
  top: "res_3_718"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_718_relu"
  type: "ReLU"
  bottom: "res_3_718"
  top: "res_3_718"
}
layer {
  name: "res_stage_3_719_1"
  type: "Convolution"
  bottom: "res_3_718"
  top: "res_stage_3_719_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_719_1"
  type: "BatchNorm"
  bottom: "res_stage_3_719_1"
  top: "res_stage_3_719_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_719_1"  
  type: "Scale"
  bottom: "res_stage_3_719_1"
  top: "res_stage_3_719_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_719_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_719_1_top"
  top: "res_stage_3_719_1_top"
}
layer {
  name: "res_stage_3_719_2"
  type: "Convolution"
  bottom: "res_stage_3_719_1_top"
  top: "res_stage_3_719_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_719_2"
  type: "BatchNorm"
  bottom: "res_stage_3_719_2"
  top: "res_stage_3_719_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_719_2"  
  type: "Scale"
  bottom: "res_stage_3_719_2"
  top: "res_stage_3_719_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_719_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_719_2_top"
  top: "res_stage_3_719_2_top"
}
layer {
  name: "res_stage_3_719_3"
  type: "Convolution"
  bottom: "res_stage_3_719_2_top"
  top: "res_stage_3_719_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_719_3"
  type: "BatchNorm"
  bottom: "res_stage_3_719_3"
  top: "res_stage_3_719_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_719_3"  
  type: "Scale"
  bottom: "res_stage_3_719_3"
  top: "res_stage_3_719_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_719"
  type: "Eltwise"
  bottom: "res_3_718"
  bottom: "res_stage_3_719_3_top"
  top: "res_3_719"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_719_relu"
  type: "ReLU"
  bottom: "res_3_719"
  top: "res_3_719"
}
layer {
  name: "res_stage_3_720_1"
  type: "Convolution"
  bottom: "res_3_719"
  top: "res_stage_3_720_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_720_1"
  type: "BatchNorm"
  bottom: "res_stage_3_720_1"
  top: "res_stage_3_720_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_720_1"  
  type: "Scale"
  bottom: "res_stage_3_720_1"
  top: "res_stage_3_720_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_720_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_720_1_top"
  top: "res_stage_3_720_1_top"
}
layer {
  name: "res_stage_3_720_2"
  type: "Convolution"
  bottom: "res_stage_3_720_1_top"
  top: "res_stage_3_720_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_720_2"
  type: "BatchNorm"
  bottom: "res_stage_3_720_2"
  top: "res_stage_3_720_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_720_2"  
  type: "Scale"
  bottom: "res_stage_3_720_2"
  top: "res_stage_3_720_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_720_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_720_2_top"
  top: "res_stage_3_720_2_top"
}
layer {
  name: "res_stage_3_720_3"
  type: "Convolution"
  bottom: "res_stage_3_720_2_top"
  top: "res_stage_3_720_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_720_3"
  type: "BatchNorm"
  bottom: "res_stage_3_720_3"
  top: "res_stage_3_720_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_720_3"  
  type: "Scale"
  bottom: "res_stage_3_720_3"
  top: "res_stage_3_720_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_720"
  type: "Eltwise"
  bottom: "res_3_719"
  bottom: "res_stage_3_720_3_top"
  top: "res_3_720"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_720_relu"
  type: "ReLU"
  bottom: "res_3_720"
  top: "res_3_720"
}
layer {
  name: "res_stage_3_721_1"
  type: "Convolution"
  bottom: "res_3_720"
  top: "res_stage_3_721_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_721_1"
  type: "BatchNorm"
  bottom: "res_stage_3_721_1"
  top: "res_stage_3_721_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_721_1"  
  type: "Scale"
  bottom: "res_stage_3_721_1"
  top: "res_stage_3_721_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_721_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_721_1_top"
  top: "res_stage_3_721_1_top"
}
layer {
  name: "res_stage_3_721_2"
  type: "Convolution"
  bottom: "res_stage_3_721_1_top"
  top: "res_stage_3_721_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_721_2"
  type: "BatchNorm"
  bottom: "res_stage_3_721_2"
  top: "res_stage_3_721_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_721_2"  
  type: "Scale"
  bottom: "res_stage_3_721_2"
  top: "res_stage_3_721_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_721_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_721_2_top"
  top: "res_stage_3_721_2_top"
}
layer {
  name: "res_stage_3_721_3"
  type: "Convolution"
  bottom: "res_stage_3_721_2_top"
  top: "res_stage_3_721_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_721_3"
  type: "BatchNorm"
  bottom: "res_stage_3_721_3"
  top: "res_stage_3_721_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_721_3"  
  type: "Scale"
  bottom: "res_stage_3_721_3"
  top: "res_stage_3_721_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_721"
  type: "Eltwise"
  bottom: "res_3_720"
  bottom: "res_stage_3_721_3_top"
  top: "res_3_721"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_721_relu"
  type: "ReLU"
  bottom: "res_3_721"
  top: "res_3_721"
}
layer {
  name: "res_stage_3_722_1"
  type: "Convolution"
  bottom: "res_3_721"
  top: "res_stage_3_722_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_722_1"
  type: "BatchNorm"
  bottom: "res_stage_3_722_1"
  top: "res_stage_3_722_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_722_1"  
  type: "Scale"
  bottom: "res_stage_3_722_1"
  top: "res_stage_3_722_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_722_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_722_1_top"
  top: "res_stage_3_722_1_top"
}
layer {
  name: "res_stage_3_722_2"
  type: "Convolution"
  bottom: "res_stage_3_722_1_top"
  top: "res_stage_3_722_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_722_2"
  type: "BatchNorm"
  bottom: "res_stage_3_722_2"
  top: "res_stage_3_722_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_722_2"  
  type: "Scale"
  bottom: "res_stage_3_722_2"
  top: "res_stage_3_722_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_722_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_722_2_top"
  top: "res_stage_3_722_2_top"
}
layer {
  name: "res_stage_3_722_3"
  type: "Convolution"
  bottom: "res_stage_3_722_2_top"
  top: "res_stage_3_722_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_722_3"
  type: "BatchNorm"
  bottom: "res_stage_3_722_3"
  top: "res_stage_3_722_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_722_3"  
  type: "Scale"
  bottom: "res_stage_3_722_3"
  top: "res_stage_3_722_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_722"
  type: "Eltwise"
  bottom: "res_3_721"
  bottom: "res_stage_3_722_3_top"
  top: "res_3_722"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_722_relu"
  type: "ReLU"
  bottom: "res_3_722"
  top: "res_3_722"
}
layer {
  name: "res_stage_3_723_1"
  type: "Convolution"
  bottom: "res_3_722"
  top: "res_stage_3_723_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_723_1"
  type: "BatchNorm"
  bottom: "res_stage_3_723_1"
  top: "res_stage_3_723_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_723_1"  
  type: "Scale"
  bottom: "res_stage_3_723_1"
  top: "res_stage_3_723_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_723_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_723_1_top"
  top: "res_stage_3_723_1_top"
}
layer {
  name: "res_stage_3_723_2"
  type: "Convolution"
  bottom: "res_stage_3_723_1_top"
  top: "res_stage_3_723_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_723_2"
  type: "BatchNorm"
  bottom: "res_stage_3_723_2"
  top: "res_stage_3_723_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_723_2"  
  type: "Scale"
  bottom: "res_stage_3_723_2"
  top: "res_stage_3_723_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_723_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_723_2_top"
  top: "res_stage_3_723_2_top"
}
layer {
  name: "res_stage_3_723_3"
  type: "Convolution"
  bottom: "res_stage_3_723_2_top"
  top: "res_stage_3_723_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_723_3"
  type: "BatchNorm"
  bottom: "res_stage_3_723_3"
  top: "res_stage_3_723_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_723_3"  
  type: "Scale"
  bottom: "res_stage_3_723_3"
  top: "res_stage_3_723_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_723"
  type: "Eltwise"
  bottom: "res_3_722"
  bottom: "res_stage_3_723_3_top"
  top: "res_3_723"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_723_relu"
  type: "ReLU"
  bottom: "res_3_723"
  top: "res_3_723"
}
layer {
  name: "res_stage_3_724_1"
  type: "Convolution"
  bottom: "res_3_723"
  top: "res_stage_3_724_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_724_1"
  type: "BatchNorm"
  bottom: "res_stage_3_724_1"
  top: "res_stage_3_724_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_724_1"  
  type: "Scale"
  bottom: "res_stage_3_724_1"
  top: "res_stage_3_724_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_724_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_724_1_top"
  top: "res_stage_3_724_1_top"
}
layer {
  name: "res_stage_3_724_2"
  type: "Convolution"
  bottom: "res_stage_3_724_1_top"
  top: "res_stage_3_724_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_724_2"
  type: "BatchNorm"
  bottom: "res_stage_3_724_2"
  top: "res_stage_3_724_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_724_2"  
  type: "Scale"
  bottom: "res_stage_3_724_2"
  top: "res_stage_3_724_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_724_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_724_2_top"
  top: "res_stage_3_724_2_top"
}
layer {
  name: "res_stage_3_724_3"
  type: "Convolution"
  bottom: "res_stage_3_724_2_top"
  top: "res_stage_3_724_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_724_3"
  type: "BatchNorm"
  bottom: "res_stage_3_724_3"
  top: "res_stage_3_724_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_724_3"  
  type: "Scale"
  bottom: "res_stage_3_724_3"
  top: "res_stage_3_724_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_724"
  type: "Eltwise"
  bottom: "res_3_723"
  bottom: "res_stage_3_724_3_top"
  top: "res_3_724"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_724_relu"
  type: "ReLU"
  bottom: "res_3_724"
  top: "res_3_724"
}
layer {
  name: "res_stage_3_725_1"
  type: "Convolution"
  bottom: "res_3_724"
  top: "res_stage_3_725_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_725_1"
  type: "BatchNorm"
  bottom: "res_stage_3_725_1"
  top: "res_stage_3_725_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_725_1"  
  type: "Scale"
  bottom: "res_stage_3_725_1"
  top: "res_stage_3_725_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_725_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_725_1_top"
  top: "res_stage_3_725_1_top"
}
layer {
  name: "res_stage_3_725_2"
  type: "Convolution"
  bottom: "res_stage_3_725_1_top"
  top: "res_stage_3_725_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_725_2"
  type: "BatchNorm"
  bottom: "res_stage_3_725_2"
  top: "res_stage_3_725_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_725_2"  
  type: "Scale"
  bottom: "res_stage_3_725_2"
  top: "res_stage_3_725_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_725_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_725_2_top"
  top: "res_stage_3_725_2_top"
}
layer {
  name: "res_stage_3_725_3"
  type: "Convolution"
  bottom: "res_stage_3_725_2_top"
  top: "res_stage_3_725_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_725_3"
  type: "BatchNorm"
  bottom: "res_stage_3_725_3"
  top: "res_stage_3_725_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_725_3"  
  type: "Scale"
  bottom: "res_stage_3_725_3"
  top: "res_stage_3_725_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_725"
  type: "Eltwise"
  bottom: "res_3_724"
  bottom: "res_stage_3_725_3_top"
  top: "res_3_725"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_725_relu"
  type: "ReLU"
  bottom: "res_3_725"
  top: "res_3_725"
}
layer {
  name: "res_stage_3_726_1"
  type: "Convolution"
  bottom: "res_3_725"
  top: "res_stage_3_726_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_726_1"
  type: "BatchNorm"
  bottom: "res_stage_3_726_1"
  top: "res_stage_3_726_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_726_1"  
  type: "Scale"
  bottom: "res_stage_3_726_1"
  top: "res_stage_3_726_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_726_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_726_1_top"
  top: "res_stage_3_726_1_top"
}
layer {
  name: "res_stage_3_726_2"
  type: "Convolution"
  bottom: "res_stage_3_726_1_top"
  top: "res_stage_3_726_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_726_2"
  type: "BatchNorm"
  bottom: "res_stage_3_726_2"
  top: "res_stage_3_726_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_726_2"  
  type: "Scale"
  bottom: "res_stage_3_726_2"
  top: "res_stage_3_726_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_726_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_726_2_top"
  top: "res_stage_3_726_2_top"
}
layer {
  name: "res_stage_3_726_3"
  type: "Convolution"
  bottom: "res_stage_3_726_2_top"
  top: "res_stage_3_726_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_726_3"
  type: "BatchNorm"
  bottom: "res_stage_3_726_3"
  top: "res_stage_3_726_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_726_3"  
  type: "Scale"
  bottom: "res_stage_3_726_3"
  top: "res_stage_3_726_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_726"
  type: "Eltwise"
  bottom: "res_3_725"
  bottom: "res_stage_3_726_3_top"
  top: "res_3_726"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_726_relu"
  type: "ReLU"
  bottom: "res_3_726"
  top: "res_3_726"
}
layer {
  name: "res_stage_3_727_1"
  type: "Convolution"
  bottom: "res_3_726"
  top: "res_stage_3_727_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_727_1"
  type: "BatchNorm"
  bottom: "res_stage_3_727_1"
  top: "res_stage_3_727_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_727_1"  
  type: "Scale"
  bottom: "res_stage_3_727_1"
  top: "res_stage_3_727_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_727_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_727_1_top"
  top: "res_stage_3_727_1_top"
}
layer {
  name: "res_stage_3_727_2"
  type: "Convolution"
  bottom: "res_stage_3_727_1_top"
  top: "res_stage_3_727_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_727_2"
  type: "BatchNorm"
  bottom: "res_stage_3_727_2"
  top: "res_stage_3_727_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_727_2"  
  type: "Scale"
  bottom: "res_stage_3_727_2"
  top: "res_stage_3_727_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_727_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_727_2_top"
  top: "res_stage_3_727_2_top"
}
layer {
  name: "res_stage_3_727_3"
  type: "Convolution"
  bottom: "res_stage_3_727_2_top"
  top: "res_stage_3_727_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_727_3"
  type: "BatchNorm"
  bottom: "res_stage_3_727_3"
  top: "res_stage_3_727_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_727_3"  
  type: "Scale"
  bottom: "res_stage_3_727_3"
  top: "res_stage_3_727_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_727"
  type: "Eltwise"
  bottom: "res_3_726"
  bottom: "res_stage_3_727_3_top"
  top: "res_3_727"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_727_relu"
  type: "ReLU"
  bottom: "res_3_727"
  top: "res_3_727"
}
layer {
  name: "res_stage_3_728_1"
  type: "Convolution"
  bottom: "res_3_727"
  top: "res_stage_3_728_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_728_1"
  type: "BatchNorm"
  bottom: "res_stage_3_728_1"
  top: "res_stage_3_728_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_728_1"  
  type: "Scale"
  bottom: "res_stage_3_728_1"
  top: "res_stage_3_728_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_728_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_728_1_top"
  top: "res_stage_3_728_1_top"
}
layer {
  name: "res_stage_3_728_2"
  type: "Convolution"
  bottom: "res_stage_3_728_1_top"
  top: "res_stage_3_728_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_728_2"
  type: "BatchNorm"
  bottom: "res_stage_3_728_2"
  top: "res_stage_3_728_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_728_2"  
  type: "Scale"
  bottom: "res_stage_3_728_2"
  top: "res_stage_3_728_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_728_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_728_2_top"
  top: "res_stage_3_728_2_top"
}
layer {
  name: "res_stage_3_728_3"
  type: "Convolution"
  bottom: "res_stage_3_728_2_top"
  top: "res_stage_3_728_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_728_3"
  type: "BatchNorm"
  bottom: "res_stage_3_728_3"
  top: "res_stage_3_728_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_728_3"  
  type: "Scale"
  bottom: "res_stage_3_728_3"
  top: "res_stage_3_728_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_728"
  type: "Eltwise"
  bottom: "res_3_727"
  bottom: "res_stage_3_728_3_top"
  top: "res_3_728"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_728_relu"
  type: "ReLU"
  bottom: "res_3_728"
  top: "res_3_728"
}
layer {
  name: "res_stage_3_729_1"
  type: "Convolution"
  bottom: "res_3_728"
  top: "res_stage_3_729_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_729_1"
  type: "BatchNorm"
  bottom: "res_stage_3_729_1"
  top: "res_stage_3_729_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_729_1"  
  type: "Scale"
  bottom: "res_stage_3_729_1"
  top: "res_stage_3_729_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_729_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_729_1_top"
  top: "res_stage_3_729_1_top"
}
layer {
  name: "res_stage_3_729_2"
  type: "Convolution"
  bottom: "res_stage_3_729_1_top"
  top: "res_stage_3_729_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_729_2"
  type: "BatchNorm"
  bottom: "res_stage_3_729_2"
  top: "res_stage_3_729_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_729_2"  
  type: "Scale"
  bottom: "res_stage_3_729_2"
  top: "res_stage_3_729_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_729_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_729_2_top"
  top: "res_stage_3_729_2_top"
}
layer {
  name: "res_stage_3_729_3"
  type: "Convolution"
  bottom: "res_stage_3_729_2_top"
  top: "res_stage_3_729_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_729_3"
  type: "BatchNorm"
  bottom: "res_stage_3_729_3"
  top: "res_stage_3_729_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_729_3"  
  type: "Scale"
  bottom: "res_stage_3_729_3"
  top: "res_stage_3_729_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_729"
  type: "Eltwise"
  bottom: "res_3_728"
  bottom: "res_stage_3_729_3_top"
  top: "res_3_729"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_729_relu"
  type: "ReLU"
  bottom: "res_3_729"
  top: "res_3_729"
}
layer {
  name: "res_stage_3_730_1"
  type: "Convolution"
  bottom: "res_3_729"
  top: "res_stage_3_730_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_730_1"
  type: "BatchNorm"
  bottom: "res_stage_3_730_1"
  top: "res_stage_3_730_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_730_1"  
  type: "Scale"
  bottom: "res_stage_3_730_1"
  top: "res_stage_3_730_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_730_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_730_1_top"
  top: "res_stage_3_730_1_top"
}
layer {
  name: "res_stage_3_730_2"
  type: "Convolution"
  bottom: "res_stage_3_730_1_top"
  top: "res_stage_3_730_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_730_2"
  type: "BatchNorm"
  bottom: "res_stage_3_730_2"
  top: "res_stage_3_730_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_730_2"  
  type: "Scale"
  bottom: "res_stage_3_730_2"
  top: "res_stage_3_730_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_730_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_730_2_top"
  top: "res_stage_3_730_2_top"
}
layer {
  name: "res_stage_3_730_3"
  type: "Convolution"
  bottom: "res_stage_3_730_2_top"
  top: "res_stage_3_730_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_730_3"
  type: "BatchNorm"
  bottom: "res_stage_3_730_3"
  top: "res_stage_3_730_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_730_3"  
  type: "Scale"
  bottom: "res_stage_3_730_3"
  top: "res_stage_3_730_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_730"
  type: "Eltwise"
  bottom: "res_3_729"
  bottom: "res_stage_3_730_3_top"
  top: "res_3_730"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_730_relu"
  type: "ReLU"
  bottom: "res_3_730"
  top: "res_3_730"
}
layer {
  name: "res_stage_3_731_1"
  type: "Convolution"
  bottom: "res_3_730"
  top: "res_stage_3_731_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_731_1"
  type: "BatchNorm"
  bottom: "res_stage_3_731_1"
  top: "res_stage_3_731_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_731_1"  
  type: "Scale"
  bottom: "res_stage_3_731_1"
  top: "res_stage_3_731_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_731_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_731_1_top"
  top: "res_stage_3_731_1_top"
}
layer {
  name: "res_stage_3_731_2"
  type: "Convolution"
  bottom: "res_stage_3_731_1_top"
  top: "res_stage_3_731_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_731_2"
  type: "BatchNorm"
  bottom: "res_stage_3_731_2"
  top: "res_stage_3_731_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_731_2"  
  type: "Scale"
  bottom: "res_stage_3_731_2"
  top: "res_stage_3_731_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_731_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_731_2_top"
  top: "res_stage_3_731_2_top"
}
layer {
  name: "res_stage_3_731_3"
  type: "Convolution"
  bottom: "res_stage_3_731_2_top"
  top: "res_stage_3_731_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_731_3"
  type: "BatchNorm"
  bottom: "res_stage_3_731_3"
  top: "res_stage_3_731_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_731_3"  
  type: "Scale"
  bottom: "res_stage_3_731_3"
  top: "res_stage_3_731_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_731"
  type: "Eltwise"
  bottom: "res_3_730"
  bottom: "res_stage_3_731_3_top"
  top: "res_3_731"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_731_relu"
  type: "ReLU"
  bottom: "res_3_731"
  top: "res_3_731"
}
layer {
  name: "res_stage_3_732_1"
  type: "Convolution"
  bottom: "res_3_731"
  top: "res_stage_3_732_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_732_1"
  type: "BatchNorm"
  bottom: "res_stage_3_732_1"
  top: "res_stage_3_732_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_732_1"  
  type: "Scale"
  bottom: "res_stage_3_732_1"
  top: "res_stage_3_732_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_732_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_732_1_top"
  top: "res_stage_3_732_1_top"
}
layer {
  name: "res_stage_3_732_2"
  type: "Convolution"
  bottom: "res_stage_3_732_1_top"
  top: "res_stage_3_732_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_732_2"
  type: "BatchNorm"
  bottom: "res_stage_3_732_2"
  top: "res_stage_3_732_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_732_2"  
  type: "Scale"
  bottom: "res_stage_3_732_2"
  top: "res_stage_3_732_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_732_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_732_2_top"
  top: "res_stage_3_732_2_top"
}
layer {
  name: "res_stage_3_732_3"
  type: "Convolution"
  bottom: "res_stage_3_732_2_top"
  top: "res_stage_3_732_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_732_3"
  type: "BatchNorm"
  bottom: "res_stage_3_732_3"
  top: "res_stage_3_732_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_732_3"  
  type: "Scale"
  bottom: "res_stage_3_732_3"
  top: "res_stage_3_732_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_732"
  type: "Eltwise"
  bottom: "res_3_731"
  bottom: "res_stage_3_732_3_top"
  top: "res_3_732"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_732_relu"
  type: "ReLU"
  bottom: "res_3_732"
  top: "res_3_732"
}
layer {
  name: "res_stage_3_733_1"
  type: "Convolution"
  bottom: "res_3_732"
  top: "res_stage_3_733_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_733_1"
  type: "BatchNorm"
  bottom: "res_stage_3_733_1"
  top: "res_stage_3_733_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_733_1"  
  type: "Scale"
  bottom: "res_stage_3_733_1"
  top: "res_stage_3_733_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_733_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_733_1_top"
  top: "res_stage_3_733_1_top"
}
layer {
  name: "res_stage_3_733_2"
  type: "Convolution"
  bottom: "res_stage_3_733_1_top"
  top: "res_stage_3_733_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_733_2"
  type: "BatchNorm"
  bottom: "res_stage_3_733_2"
  top: "res_stage_3_733_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_733_2"  
  type: "Scale"
  bottom: "res_stage_3_733_2"
  top: "res_stage_3_733_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_733_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_733_2_top"
  top: "res_stage_3_733_2_top"
}
layer {
  name: "res_stage_3_733_3"
  type: "Convolution"
  bottom: "res_stage_3_733_2_top"
  top: "res_stage_3_733_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_733_3"
  type: "BatchNorm"
  bottom: "res_stage_3_733_3"
  top: "res_stage_3_733_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_733_3"  
  type: "Scale"
  bottom: "res_stage_3_733_3"
  top: "res_stage_3_733_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_733"
  type: "Eltwise"
  bottom: "res_3_732"
  bottom: "res_stage_3_733_3_top"
  top: "res_3_733"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_733_relu"
  type: "ReLU"
  bottom: "res_3_733"
  top: "res_3_733"
}
layer {
  name: "res_stage_3_734_1"
  type: "Convolution"
  bottom: "res_3_733"
  top: "res_stage_3_734_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_734_1"
  type: "BatchNorm"
  bottom: "res_stage_3_734_1"
  top: "res_stage_3_734_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_734_1"  
  type: "Scale"
  bottom: "res_stage_3_734_1"
  top: "res_stage_3_734_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_734_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_734_1_top"
  top: "res_stage_3_734_1_top"
}
layer {
  name: "res_stage_3_734_2"
  type: "Convolution"
  bottom: "res_stage_3_734_1_top"
  top: "res_stage_3_734_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_734_2"
  type: "BatchNorm"
  bottom: "res_stage_3_734_2"
  top: "res_stage_3_734_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_734_2"  
  type: "Scale"
  bottom: "res_stage_3_734_2"
  top: "res_stage_3_734_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_734_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_734_2_top"
  top: "res_stage_3_734_2_top"
}
layer {
  name: "res_stage_3_734_3"
  type: "Convolution"
  bottom: "res_stage_3_734_2_top"
  top: "res_stage_3_734_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_734_3"
  type: "BatchNorm"
  bottom: "res_stage_3_734_3"
  top: "res_stage_3_734_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_734_3"  
  type: "Scale"
  bottom: "res_stage_3_734_3"
  top: "res_stage_3_734_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_734"
  type: "Eltwise"
  bottom: "res_3_733"
  bottom: "res_stage_3_734_3_top"
  top: "res_3_734"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_734_relu"
  type: "ReLU"
  bottom: "res_3_734"
  top: "res_3_734"
}
layer {
  name: "res_stage_3_735_1"
  type: "Convolution"
  bottom: "res_3_734"
  top: "res_stage_3_735_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_735_1"
  type: "BatchNorm"
  bottom: "res_stage_3_735_1"
  top: "res_stage_3_735_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_735_1"  
  type: "Scale"
  bottom: "res_stage_3_735_1"
  top: "res_stage_3_735_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_735_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_735_1_top"
  top: "res_stage_3_735_1_top"
}
layer {
  name: "res_stage_3_735_2"
  type: "Convolution"
  bottom: "res_stage_3_735_1_top"
  top: "res_stage_3_735_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_735_2"
  type: "BatchNorm"
  bottom: "res_stage_3_735_2"
  top: "res_stage_3_735_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_735_2"  
  type: "Scale"
  bottom: "res_stage_3_735_2"
  top: "res_stage_3_735_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_735_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_735_2_top"
  top: "res_stage_3_735_2_top"
}
layer {
  name: "res_stage_3_735_3"
  type: "Convolution"
  bottom: "res_stage_3_735_2_top"
  top: "res_stage_3_735_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_735_3"
  type: "BatchNorm"
  bottom: "res_stage_3_735_3"
  top: "res_stage_3_735_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_735_3"  
  type: "Scale"
  bottom: "res_stage_3_735_3"
  top: "res_stage_3_735_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_735"
  type: "Eltwise"
  bottom: "res_3_734"
  bottom: "res_stage_3_735_3_top"
  top: "res_3_735"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_735_relu"
  type: "ReLU"
  bottom: "res_3_735"
  top: "res_3_735"
}
layer {
  name: "res_stage_3_736_1"
  type: "Convolution"
  bottom: "res_3_735"
  top: "res_stage_3_736_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_736_1"
  type: "BatchNorm"
  bottom: "res_stage_3_736_1"
  top: "res_stage_3_736_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_736_1"  
  type: "Scale"
  bottom: "res_stage_3_736_1"
  top: "res_stage_3_736_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_736_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_736_1_top"
  top: "res_stage_3_736_1_top"
}
layer {
  name: "res_stage_3_736_2"
  type: "Convolution"
  bottom: "res_stage_3_736_1_top"
  top: "res_stage_3_736_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_736_2"
  type: "BatchNorm"
  bottom: "res_stage_3_736_2"
  top: "res_stage_3_736_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_736_2"  
  type: "Scale"
  bottom: "res_stage_3_736_2"
  top: "res_stage_3_736_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_736_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_736_2_top"
  top: "res_stage_3_736_2_top"
}
layer {
  name: "res_stage_3_736_3"
  type: "Convolution"
  bottom: "res_stage_3_736_2_top"
  top: "res_stage_3_736_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_736_3"
  type: "BatchNorm"
  bottom: "res_stage_3_736_3"
  top: "res_stage_3_736_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_736_3"  
  type: "Scale"
  bottom: "res_stage_3_736_3"
  top: "res_stage_3_736_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_736"
  type: "Eltwise"
  bottom: "res_3_735"
  bottom: "res_stage_3_736_3_top"
  top: "res_3_736"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_736_relu"
  type: "ReLU"
  bottom: "res_3_736"
  top: "res_3_736"
}
layer {
  name: "res_stage_3_737_1"
  type: "Convolution"
  bottom: "res_3_736"
  top: "res_stage_3_737_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_737_1"
  type: "BatchNorm"
  bottom: "res_stage_3_737_1"
  top: "res_stage_3_737_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_737_1"  
  type: "Scale"
  bottom: "res_stage_3_737_1"
  top: "res_stage_3_737_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_737_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_737_1_top"
  top: "res_stage_3_737_1_top"
}
layer {
  name: "res_stage_3_737_2"
  type: "Convolution"
  bottom: "res_stage_3_737_1_top"
  top: "res_stage_3_737_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_737_2"
  type: "BatchNorm"
  bottom: "res_stage_3_737_2"
  top: "res_stage_3_737_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_737_2"  
  type: "Scale"
  bottom: "res_stage_3_737_2"
  top: "res_stage_3_737_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_737_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_737_2_top"
  top: "res_stage_3_737_2_top"
}
layer {
  name: "res_stage_3_737_3"
  type: "Convolution"
  bottom: "res_stage_3_737_2_top"
  top: "res_stage_3_737_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_737_3"
  type: "BatchNorm"
  bottom: "res_stage_3_737_3"
  top: "res_stage_3_737_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_737_3"  
  type: "Scale"
  bottom: "res_stage_3_737_3"
  top: "res_stage_3_737_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_737"
  type: "Eltwise"
  bottom: "res_3_736"
  bottom: "res_stage_3_737_3_top"
  top: "res_3_737"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_737_relu"
  type: "ReLU"
  bottom: "res_3_737"
  top: "res_3_737"
}
layer {
  name: "res_stage_3_738_1"
  type: "Convolution"
  bottom: "res_3_737"
  top: "res_stage_3_738_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_738_1"
  type: "BatchNorm"
  bottom: "res_stage_3_738_1"
  top: "res_stage_3_738_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_738_1"  
  type: "Scale"
  bottom: "res_stage_3_738_1"
  top: "res_stage_3_738_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_738_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_738_1_top"
  top: "res_stage_3_738_1_top"
}
layer {
  name: "res_stage_3_738_2"
  type: "Convolution"
  bottom: "res_stage_3_738_1_top"
  top: "res_stage_3_738_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_738_2"
  type: "BatchNorm"
  bottom: "res_stage_3_738_2"
  top: "res_stage_3_738_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_738_2"  
  type: "Scale"
  bottom: "res_stage_3_738_2"
  top: "res_stage_3_738_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_738_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_738_2_top"
  top: "res_stage_3_738_2_top"
}
layer {
  name: "res_stage_3_738_3"
  type: "Convolution"
  bottom: "res_stage_3_738_2_top"
  top: "res_stage_3_738_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_738_3"
  type: "BatchNorm"
  bottom: "res_stage_3_738_3"
  top: "res_stage_3_738_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_738_3"  
  type: "Scale"
  bottom: "res_stage_3_738_3"
  top: "res_stage_3_738_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_738"
  type: "Eltwise"
  bottom: "res_3_737"
  bottom: "res_stage_3_738_3_top"
  top: "res_3_738"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_738_relu"
  type: "ReLU"
  bottom: "res_3_738"
  top: "res_3_738"
}
layer {
  name: "res_stage_3_739_1"
  type: "Convolution"
  bottom: "res_3_738"
  top: "res_stage_3_739_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_739_1"
  type: "BatchNorm"
  bottom: "res_stage_3_739_1"
  top: "res_stage_3_739_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_739_1"  
  type: "Scale"
  bottom: "res_stage_3_739_1"
  top: "res_stage_3_739_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_739_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_739_1_top"
  top: "res_stage_3_739_1_top"
}
layer {
  name: "res_stage_3_739_2"
  type: "Convolution"
  bottom: "res_stage_3_739_1_top"
  top: "res_stage_3_739_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_739_2"
  type: "BatchNorm"
  bottom: "res_stage_3_739_2"
  top: "res_stage_3_739_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_739_2"  
  type: "Scale"
  bottom: "res_stage_3_739_2"
  top: "res_stage_3_739_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_739_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_739_2_top"
  top: "res_stage_3_739_2_top"
}
layer {
  name: "res_stage_3_739_3"
  type: "Convolution"
  bottom: "res_stage_3_739_2_top"
  top: "res_stage_3_739_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_739_3"
  type: "BatchNorm"
  bottom: "res_stage_3_739_3"
  top: "res_stage_3_739_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_739_3"  
  type: "Scale"
  bottom: "res_stage_3_739_3"
  top: "res_stage_3_739_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_739"
  type: "Eltwise"
  bottom: "res_3_738"
  bottom: "res_stage_3_739_3_top"
  top: "res_3_739"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_739_relu"
  type: "ReLU"
  bottom: "res_3_739"
  top: "res_3_739"
}
layer {
  name: "res_stage_3_740_1"
  type: "Convolution"
  bottom: "res_3_739"
  top: "res_stage_3_740_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_740_1"
  type: "BatchNorm"
  bottom: "res_stage_3_740_1"
  top: "res_stage_3_740_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_740_1"  
  type: "Scale"
  bottom: "res_stage_3_740_1"
  top: "res_stage_3_740_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_740_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_740_1_top"
  top: "res_stage_3_740_1_top"
}
layer {
  name: "res_stage_3_740_2"
  type: "Convolution"
  bottom: "res_stage_3_740_1_top"
  top: "res_stage_3_740_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_740_2"
  type: "BatchNorm"
  bottom: "res_stage_3_740_2"
  top: "res_stage_3_740_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_740_2"  
  type: "Scale"
  bottom: "res_stage_3_740_2"
  top: "res_stage_3_740_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_740_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_740_2_top"
  top: "res_stage_3_740_2_top"
}
layer {
  name: "res_stage_3_740_3"
  type: "Convolution"
  bottom: "res_stage_3_740_2_top"
  top: "res_stage_3_740_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_740_3"
  type: "BatchNorm"
  bottom: "res_stage_3_740_3"
  top: "res_stage_3_740_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_740_3"  
  type: "Scale"
  bottom: "res_stage_3_740_3"
  top: "res_stage_3_740_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_740"
  type: "Eltwise"
  bottom: "res_3_739"
  bottom: "res_stage_3_740_3_top"
  top: "res_3_740"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_740_relu"
  type: "ReLU"
  bottom: "res_3_740"
  top: "res_3_740"
}
layer {
  name: "res_stage_3_741_1"
  type: "Convolution"
  bottom: "res_3_740"
  top: "res_stage_3_741_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_741_1"
  type: "BatchNorm"
  bottom: "res_stage_3_741_1"
  top: "res_stage_3_741_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_741_1"  
  type: "Scale"
  bottom: "res_stage_3_741_1"
  top: "res_stage_3_741_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_741_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_741_1_top"
  top: "res_stage_3_741_1_top"
}
layer {
  name: "res_stage_3_741_2"
  type: "Convolution"
  bottom: "res_stage_3_741_1_top"
  top: "res_stage_3_741_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_741_2"
  type: "BatchNorm"
  bottom: "res_stage_3_741_2"
  top: "res_stage_3_741_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_741_2"  
  type: "Scale"
  bottom: "res_stage_3_741_2"
  top: "res_stage_3_741_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_741_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_741_2_top"
  top: "res_stage_3_741_2_top"
}
layer {
  name: "res_stage_3_741_3"
  type: "Convolution"
  bottom: "res_stage_3_741_2_top"
  top: "res_stage_3_741_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_741_3"
  type: "BatchNorm"
  bottom: "res_stage_3_741_3"
  top: "res_stage_3_741_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_741_3"  
  type: "Scale"
  bottom: "res_stage_3_741_3"
  top: "res_stage_3_741_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_741"
  type: "Eltwise"
  bottom: "res_3_740"
  bottom: "res_stage_3_741_3_top"
  top: "res_3_741"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_741_relu"
  type: "ReLU"
  bottom: "res_3_741"
  top: "res_3_741"
}
layer {
  name: "res_stage_3_742_1"
  type: "Convolution"
  bottom: "res_3_741"
  top: "res_stage_3_742_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_742_1"
  type: "BatchNorm"
  bottom: "res_stage_3_742_1"
  top: "res_stage_3_742_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_742_1"  
  type: "Scale"
  bottom: "res_stage_3_742_1"
  top: "res_stage_3_742_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_742_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_742_1_top"
  top: "res_stage_3_742_1_top"
}
layer {
  name: "res_stage_3_742_2"
  type: "Convolution"
  bottom: "res_stage_3_742_1_top"
  top: "res_stage_3_742_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_742_2"
  type: "BatchNorm"
  bottom: "res_stage_3_742_2"
  top: "res_stage_3_742_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_742_2"  
  type: "Scale"
  bottom: "res_stage_3_742_2"
  top: "res_stage_3_742_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_742_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_742_2_top"
  top: "res_stage_3_742_2_top"
}
layer {
  name: "res_stage_3_742_3"
  type: "Convolution"
  bottom: "res_stage_3_742_2_top"
  top: "res_stage_3_742_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_742_3"
  type: "BatchNorm"
  bottom: "res_stage_3_742_3"
  top: "res_stage_3_742_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_742_3"  
  type: "Scale"
  bottom: "res_stage_3_742_3"
  top: "res_stage_3_742_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_742"
  type: "Eltwise"
  bottom: "res_3_741"
  bottom: "res_stage_3_742_3_top"
  top: "res_3_742"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_742_relu"
  type: "ReLU"
  bottom: "res_3_742"
  top: "res_3_742"
}
layer {
  name: "res_stage_3_743_1"
  type: "Convolution"
  bottom: "res_3_742"
  top: "res_stage_3_743_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_743_1"
  type: "BatchNorm"
  bottom: "res_stage_3_743_1"
  top: "res_stage_3_743_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_743_1"  
  type: "Scale"
  bottom: "res_stage_3_743_1"
  top: "res_stage_3_743_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_743_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_743_1_top"
  top: "res_stage_3_743_1_top"
}
layer {
  name: "res_stage_3_743_2"
  type: "Convolution"
  bottom: "res_stage_3_743_1_top"
  top: "res_stage_3_743_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_743_2"
  type: "BatchNorm"
  bottom: "res_stage_3_743_2"
  top: "res_stage_3_743_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_743_2"  
  type: "Scale"
  bottom: "res_stage_3_743_2"
  top: "res_stage_3_743_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_743_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_743_2_top"
  top: "res_stage_3_743_2_top"
}
layer {
  name: "res_stage_3_743_3"
  type: "Convolution"
  bottom: "res_stage_3_743_2_top"
  top: "res_stage_3_743_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_743_3"
  type: "BatchNorm"
  bottom: "res_stage_3_743_3"
  top: "res_stage_3_743_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_743_3"  
  type: "Scale"
  bottom: "res_stage_3_743_3"
  top: "res_stage_3_743_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_743"
  type: "Eltwise"
  bottom: "res_3_742"
  bottom: "res_stage_3_743_3_top"
  top: "res_3_743"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_743_relu"
  type: "ReLU"
  bottom: "res_3_743"
  top: "res_3_743"
}
layer {
  name: "res_stage_3_744_1"
  type: "Convolution"
  bottom: "res_3_743"
  top: "res_stage_3_744_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_744_1"
  type: "BatchNorm"
  bottom: "res_stage_3_744_1"
  top: "res_stage_3_744_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_744_1"  
  type: "Scale"
  bottom: "res_stage_3_744_1"
  top: "res_stage_3_744_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_744_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_744_1_top"
  top: "res_stage_3_744_1_top"
}
layer {
  name: "res_stage_3_744_2"
  type: "Convolution"
  bottom: "res_stage_3_744_1_top"
  top: "res_stage_3_744_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_744_2"
  type: "BatchNorm"
  bottom: "res_stage_3_744_2"
  top: "res_stage_3_744_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_744_2"  
  type: "Scale"
  bottom: "res_stage_3_744_2"
  top: "res_stage_3_744_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_744_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_744_2_top"
  top: "res_stage_3_744_2_top"
}
layer {
  name: "res_stage_3_744_3"
  type: "Convolution"
  bottom: "res_stage_3_744_2_top"
  top: "res_stage_3_744_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_744_3"
  type: "BatchNorm"
  bottom: "res_stage_3_744_3"
  top: "res_stage_3_744_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_744_3"  
  type: "Scale"
  bottom: "res_stage_3_744_3"
  top: "res_stage_3_744_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_744"
  type: "Eltwise"
  bottom: "res_3_743"
  bottom: "res_stage_3_744_3_top"
  top: "res_3_744"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_744_relu"
  type: "ReLU"
  bottom: "res_3_744"
  top: "res_3_744"
}
layer {
  name: "res_stage_3_745_1"
  type: "Convolution"
  bottom: "res_3_744"
  top: "res_stage_3_745_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_745_1"
  type: "BatchNorm"
  bottom: "res_stage_3_745_1"
  top: "res_stage_3_745_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_745_1"  
  type: "Scale"
  bottom: "res_stage_3_745_1"
  top: "res_stage_3_745_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_745_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_745_1_top"
  top: "res_stage_3_745_1_top"
}
layer {
  name: "res_stage_3_745_2"
  type: "Convolution"
  bottom: "res_stage_3_745_1_top"
  top: "res_stage_3_745_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_745_2"
  type: "BatchNorm"
  bottom: "res_stage_3_745_2"
  top: "res_stage_3_745_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_745_2"  
  type: "Scale"
  bottom: "res_stage_3_745_2"
  top: "res_stage_3_745_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_745_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_745_2_top"
  top: "res_stage_3_745_2_top"
}
layer {
  name: "res_stage_3_745_3"
  type: "Convolution"
  bottom: "res_stage_3_745_2_top"
  top: "res_stage_3_745_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_745_3"
  type: "BatchNorm"
  bottom: "res_stage_3_745_3"
  top: "res_stage_3_745_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_745_3"  
  type: "Scale"
  bottom: "res_stage_3_745_3"
  top: "res_stage_3_745_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_745"
  type: "Eltwise"
  bottom: "res_3_744"
  bottom: "res_stage_3_745_3_top"
  top: "res_3_745"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_745_relu"
  type: "ReLU"
  bottom: "res_3_745"
  top: "res_3_745"
}
layer {
  name: "res_stage_3_746_1"
  type: "Convolution"
  bottom: "res_3_745"
  top: "res_stage_3_746_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_746_1"
  type: "BatchNorm"
  bottom: "res_stage_3_746_1"
  top: "res_stage_3_746_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_746_1"  
  type: "Scale"
  bottom: "res_stage_3_746_1"
  top: "res_stage_3_746_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_746_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_746_1_top"
  top: "res_stage_3_746_1_top"
}
layer {
  name: "res_stage_3_746_2"
  type: "Convolution"
  bottom: "res_stage_3_746_1_top"
  top: "res_stage_3_746_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_746_2"
  type: "BatchNorm"
  bottom: "res_stage_3_746_2"
  top: "res_stage_3_746_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_746_2"  
  type: "Scale"
  bottom: "res_stage_3_746_2"
  top: "res_stage_3_746_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_746_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_746_2_top"
  top: "res_stage_3_746_2_top"
}
layer {
  name: "res_stage_3_746_3"
  type: "Convolution"
  bottom: "res_stage_3_746_2_top"
  top: "res_stage_3_746_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_746_3"
  type: "BatchNorm"
  bottom: "res_stage_3_746_3"
  top: "res_stage_3_746_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_746_3"  
  type: "Scale"
  bottom: "res_stage_3_746_3"
  top: "res_stage_3_746_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_746"
  type: "Eltwise"
  bottom: "res_3_745"
  bottom: "res_stage_3_746_3_top"
  top: "res_3_746"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_746_relu"
  type: "ReLU"
  bottom: "res_3_746"
  top: "res_3_746"
}
layer {
  name: "res_stage_3_747_1"
  type: "Convolution"
  bottom: "res_3_746"
  top: "res_stage_3_747_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_747_1"
  type: "BatchNorm"
  bottom: "res_stage_3_747_1"
  top: "res_stage_3_747_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_747_1"  
  type: "Scale"
  bottom: "res_stage_3_747_1"
  top: "res_stage_3_747_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_747_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_747_1_top"
  top: "res_stage_3_747_1_top"
}
layer {
  name: "res_stage_3_747_2"
  type: "Convolution"
  bottom: "res_stage_3_747_1_top"
  top: "res_stage_3_747_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_747_2"
  type: "BatchNorm"
  bottom: "res_stage_3_747_2"
  top: "res_stage_3_747_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_747_2"  
  type: "Scale"
  bottom: "res_stage_3_747_2"
  top: "res_stage_3_747_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_747_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_747_2_top"
  top: "res_stage_3_747_2_top"
}
layer {
  name: "res_stage_3_747_3"
  type: "Convolution"
  bottom: "res_stage_3_747_2_top"
  top: "res_stage_3_747_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_747_3"
  type: "BatchNorm"
  bottom: "res_stage_3_747_3"
  top: "res_stage_3_747_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_747_3"  
  type: "Scale"
  bottom: "res_stage_3_747_3"
  top: "res_stage_3_747_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_747"
  type: "Eltwise"
  bottom: "res_3_746"
  bottom: "res_stage_3_747_3_top"
  top: "res_3_747"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_747_relu"
  type: "ReLU"
  bottom: "res_3_747"
  top: "res_3_747"
}
layer {
  name: "res_stage_3_748_1"
  type: "Convolution"
  bottom: "res_3_747"
  top: "res_stage_3_748_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_748_1"
  type: "BatchNorm"
  bottom: "res_stage_3_748_1"
  top: "res_stage_3_748_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_748_1"  
  type: "Scale"
  bottom: "res_stage_3_748_1"
  top: "res_stage_3_748_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_748_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_748_1_top"
  top: "res_stage_3_748_1_top"
}
layer {
  name: "res_stage_3_748_2"
  type: "Convolution"
  bottom: "res_stage_3_748_1_top"
  top: "res_stage_3_748_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_748_2"
  type: "BatchNorm"
  bottom: "res_stage_3_748_2"
  top: "res_stage_3_748_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_748_2"  
  type: "Scale"
  bottom: "res_stage_3_748_2"
  top: "res_stage_3_748_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_748_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_748_2_top"
  top: "res_stage_3_748_2_top"
}
layer {
  name: "res_stage_3_748_3"
  type: "Convolution"
  bottom: "res_stage_3_748_2_top"
  top: "res_stage_3_748_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_748_3"
  type: "BatchNorm"
  bottom: "res_stage_3_748_3"
  top: "res_stage_3_748_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_748_3"  
  type: "Scale"
  bottom: "res_stage_3_748_3"
  top: "res_stage_3_748_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_748"
  type: "Eltwise"
  bottom: "res_3_747"
  bottom: "res_stage_3_748_3_top"
  top: "res_3_748"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_748_relu"
  type: "ReLU"
  bottom: "res_3_748"
  top: "res_3_748"
}
layer {
  name: "res_stage_3_749_1"
  type: "Convolution"
  bottom: "res_3_748"
  top: "res_stage_3_749_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_749_1"
  type: "BatchNorm"
  bottom: "res_stage_3_749_1"
  top: "res_stage_3_749_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_749_1"  
  type: "Scale"
  bottom: "res_stage_3_749_1"
  top: "res_stage_3_749_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_749_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_749_1_top"
  top: "res_stage_3_749_1_top"
}
layer {
  name: "res_stage_3_749_2"
  type: "Convolution"
  bottom: "res_stage_3_749_1_top"
  top: "res_stage_3_749_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_749_2"
  type: "BatchNorm"
  bottom: "res_stage_3_749_2"
  top: "res_stage_3_749_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_749_2"  
  type: "Scale"
  bottom: "res_stage_3_749_2"
  top: "res_stage_3_749_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_749_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_749_2_top"
  top: "res_stage_3_749_2_top"
}
layer {
  name: "res_stage_3_749_3"
  type: "Convolution"
  bottom: "res_stage_3_749_2_top"
  top: "res_stage_3_749_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_749_3"
  type: "BatchNorm"
  bottom: "res_stage_3_749_3"
  top: "res_stage_3_749_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_749_3"  
  type: "Scale"
  bottom: "res_stage_3_749_3"
  top: "res_stage_3_749_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_749"
  type: "Eltwise"
  bottom: "res_3_748"
  bottom: "res_stage_3_749_3_top"
  top: "res_3_749"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_749_relu"
  type: "ReLU"
  bottom: "res_3_749"
  top: "res_3_749"
}
layer {
  name: "res_stage_3_750_1"
  type: "Convolution"
  bottom: "res_3_749"
  top: "res_stage_3_750_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_750_1"
  type: "BatchNorm"
  bottom: "res_stage_3_750_1"
  top: "res_stage_3_750_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_750_1"  
  type: "Scale"
  bottom: "res_stage_3_750_1"
  top: "res_stage_3_750_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_750_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_750_1_top"
  top: "res_stage_3_750_1_top"
}
layer {
  name: "res_stage_3_750_2"
  type: "Convolution"
  bottom: "res_stage_3_750_1_top"
  top: "res_stage_3_750_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_750_2"
  type: "BatchNorm"
  bottom: "res_stage_3_750_2"
  top: "res_stage_3_750_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_750_2"  
  type: "Scale"
  bottom: "res_stage_3_750_2"
  top: "res_stage_3_750_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_750_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_750_2_top"
  top: "res_stage_3_750_2_top"
}
layer {
  name: "res_stage_3_750_3"
  type: "Convolution"
  bottom: "res_stage_3_750_2_top"
  top: "res_stage_3_750_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_750_3"
  type: "BatchNorm"
  bottom: "res_stage_3_750_3"
  top: "res_stage_3_750_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_750_3"  
  type: "Scale"
  bottom: "res_stage_3_750_3"
  top: "res_stage_3_750_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_750"
  type: "Eltwise"
  bottom: "res_3_749"
  bottom: "res_stage_3_750_3_top"
  top: "res_3_750"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_750_relu"
  type: "ReLU"
  bottom: "res_3_750"
  top: "res_3_750"
}
layer {
  name: "res_stage_3_751_1"
  type: "Convolution"
  bottom: "res_3_750"
  top: "res_stage_3_751_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_751_1"
  type: "BatchNorm"
  bottom: "res_stage_3_751_1"
  top: "res_stage_3_751_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_751_1"  
  type: "Scale"
  bottom: "res_stage_3_751_1"
  top: "res_stage_3_751_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_751_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_751_1_top"
  top: "res_stage_3_751_1_top"
}
layer {
  name: "res_stage_3_751_2"
  type: "Convolution"
  bottom: "res_stage_3_751_1_top"
  top: "res_stage_3_751_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_751_2"
  type: "BatchNorm"
  bottom: "res_stage_3_751_2"
  top: "res_stage_3_751_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_751_2"  
  type: "Scale"
  bottom: "res_stage_3_751_2"
  top: "res_stage_3_751_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_751_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_751_2_top"
  top: "res_stage_3_751_2_top"
}
layer {
  name: "res_stage_3_751_3"
  type: "Convolution"
  bottom: "res_stage_3_751_2_top"
  top: "res_stage_3_751_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_751_3"
  type: "BatchNorm"
  bottom: "res_stage_3_751_3"
  top: "res_stage_3_751_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_751_3"  
  type: "Scale"
  bottom: "res_stage_3_751_3"
  top: "res_stage_3_751_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_751"
  type: "Eltwise"
  bottom: "res_3_750"
  bottom: "res_stage_3_751_3_top"
  top: "res_3_751"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_751_relu"
  type: "ReLU"
  bottom: "res_3_751"
  top: "res_3_751"
}
layer {
  name: "res_stage_3_752_1"
  type: "Convolution"
  bottom: "res_3_751"
  top: "res_stage_3_752_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_752_1"
  type: "BatchNorm"
  bottom: "res_stage_3_752_1"
  top: "res_stage_3_752_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_752_1"  
  type: "Scale"
  bottom: "res_stage_3_752_1"
  top: "res_stage_3_752_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_752_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_752_1_top"
  top: "res_stage_3_752_1_top"
}
layer {
  name: "res_stage_3_752_2"
  type: "Convolution"
  bottom: "res_stage_3_752_1_top"
  top: "res_stage_3_752_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_752_2"
  type: "BatchNorm"
  bottom: "res_stage_3_752_2"
  top: "res_stage_3_752_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_752_2"  
  type: "Scale"
  bottom: "res_stage_3_752_2"
  top: "res_stage_3_752_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_752_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_752_2_top"
  top: "res_stage_3_752_2_top"
}
layer {
  name: "res_stage_3_752_3"
  type: "Convolution"
  bottom: "res_stage_3_752_2_top"
  top: "res_stage_3_752_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_752_3"
  type: "BatchNorm"
  bottom: "res_stage_3_752_3"
  top: "res_stage_3_752_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_752_3"  
  type: "Scale"
  bottom: "res_stage_3_752_3"
  top: "res_stage_3_752_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_752"
  type: "Eltwise"
  bottom: "res_3_751"
  bottom: "res_stage_3_752_3_top"
  top: "res_3_752"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_752_relu"
  type: "ReLU"
  bottom: "res_3_752"
  top: "res_3_752"
}
layer {
  name: "res_stage_3_753_1"
  type: "Convolution"
  bottom: "res_3_752"
  top: "res_stage_3_753_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_753_1"
  type: "BatchNorm"
  bottom: "res_stage_3_753_1"
  top: "res_stage_3_753_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_753_1"  
  type: "Scale"
  bottom: "res_stage_3_753_1"
  top: "res_stage_3_753_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_753_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_753_1_top"
  top: "res_stage_3_753_1_top"
}
layer {
  name: "res_stage_3_753_2"
  type: "Convolution"
  bottom: "res_stage_3_753_1_top"
  top: "res_stage_3_753_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_753_2"
  type: "BatchNorm"
  bottom: "res_stage_3_753_2"
  top: "res_stage_3_753_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_753_2"  
  type: "Scale"
  bottom: "res_stage_3_753_2"
  top: "res_stage_3_753_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_753_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_753_2_top"
  top: "res_stage_3_753_2_top"
}
layer {
  name: "res_stage_3_753_3"
  type: "Convolution"
  bottom: "res_stage_3_753_2_top"
  top: "res_stage_3_753_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_753_3"
  type: "BatchNorm"
  bottom: "res_stage_3_753_3"
  top: "res_stage_3_753_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_753_3"  
  type: "Scale"
  bottom: "res_stage_3_753_3"
  top: "res_stage_3_753_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_753"
  type: "Eltwise"
  bottom: "res_3_752"
  bottom: "res_stage_3_753_3_top"
  top: "res_3_753"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_753_relu"
  type: "ReLU"
  bottom: "res_3_753"
  top: "res_3_753"
}
layer {
  name: "res_stage_3_754_1"
  type: "Convolution"
  bottom: "res_3_753"
  top: "res_stage_3_754_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_754_1"
  type: "BatchNorm"
  bottom: "res_stage_3_754_1"
  top: "res_stage_3_754_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_754_1"  
  type: "Scale"
  bottom: "res_stage_3_754_1"
  top: "res_stage_3_754_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_754_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_754_1_top"
  top: "res_stage_3_754_1_top"
}
layer {
  name: "res_stage_3_754_2"
  type: "Convolution"
  bottom: "res_stage_3_754_1_top"
  top: "res_stage_3_754_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_754_2"
  type: "BatchNorm"
  bottom: "res_stage_3_754_2"
  top: "res_stage_3_754_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_754_2"  
  type: "Scale"
  bottom: "res_stage_3_754_2"
  top: "res_stage_3_754_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_754_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_754_2_top"
  top: "res_stage_3_754_2_top"
}
layer {
  name: "res_stage_3_754_3"
  type: "Convolution"
  bottom: "res_stage_3_754_2_top"
  top: "res_stage_3_754_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_754_3"
  type: "BatchNorm"
  bottom: "res_stage_3_754_3"
  top: "res_stage_3_754_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_754_3"  
  type: "Scale"
  bottom: "res_stage_3_754_3"
  top: "res_stage_3_754_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_754"
  type: "Eltwise"
  bottom: "res_3_753"
  bottom: "res_stage_3_754_3_top"
  top: "res_3_754"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_754_relu"
  type: "ReLU"
  bottom: "res_3_754"
  top: "res_3_754"
}
layer {
  name: "res_stage_3_755_1"
  type: "Convolution"
  bottom: "res_3_754"
  top: "res_stage_3_755_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_755_1"
  type: "BatchNorm"
  bottom: "res_stage_3_755_1"
  top: "res_stage_3_755_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_755_1"  
  type: "Scale"
  bottom: "res_stage_3_755_1"
  top: "res_stage_3_755_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_755_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_755_1_top"
  top: "res_stage_3_755_1_top"
}
layer {
  name: "res_stage_3_755_2"
  type: "Convolution"
  bottom: "res_stage_3_755_1_top"
  top: "res_stage_3_755_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_755_2"
  type: "BatchNorm"
  bottom: "res_stage_3_755_2"
  top: "res_stage_3_755_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_755_2"  
  type: "Scale"
  bottom: "res_stage_3_755_2"
  top: "res_stage_3_755_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_755_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_755_2_top"
  top: "res_stage_3_755_2_top"
}
layer {
  name: "res_stage_3_755_3"
  type: "Convolution"
  bottom: "res_stage_3_755_2_top"
  top: "res_stage_3_755_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_755_3"
  type: "BatchNorm"
  bottom: "res_stage_3_755_3"
  top: "res_stage_3_755_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_755_3"  
  type: "Scale"
  bottom: "res_stage_3_755_3"
  top: "res_stage_3_755_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_755"
  type: "Eltwise"
  bottom: "res_3_754"
  bottom: "res_stage_3_755_3_top"
  top: "res_3_755"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_755_relu"
  type: "ReLU"
  bottom: "res_3_755"
  top: "res_3_755"
}
layer {
  name: "res_stage_3_756_1"
  type: "Convolution"
  bottom: "res_3_755"
  top: "res_stage_3_756_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_756_1"
  type: "BatchNorm"
  bottom: "res_stage_3_756_1"
  top: "res_stage_3_756_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_756_1"  
  type: "Scale"
  bottom: "res_stage_3_756_1"
  top: "res_stage_3_756_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_756_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_756_1_top"
  top: "res_stage_3_756_1_top"
}
layer {
  name: "res_stage_3_756_2"
  type: "Convolution"
  bottom: "res_stage_3_756_1_top"
  top: "res_stage_3_756_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_756_2"
  type: "BatchNorm"
  bottom: "res_stage_3_756_2"
  top: "res_stage_3_756_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_756_2"  
  type: "Scale"
  bottom: "res_stage_3_756_2"
  top: "res_stage_3_756_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_756_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_756_2_top"
  top: "res_stage_3_756_2_top"
}
layer {
  name: "res_stage_3_756_3"
  type: "Convolution"
  bottom: "res_stage_3_756_2_top"
  top: "res_stage_3_756_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_756_3"
  type: "BatchNorm"
  bottom: "res_stage_3_756_3"
  top: "res_stage_3_756_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_756_3"  
  type: "Scale"
  bottom: "res_stage_3_756_3"
  top: "res_stage_3_756_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_756"
  type: "Eltwise"
  bottom: "res_3_755"
  bottom: "res_stage_3_756_3_top"
  top: "res_3_756"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_756_relu"
  type: "ReLU"
  bottom: "res_3_756"
  top: "res_3_756"
}
layer {
  name: "res_stage_3_757_1"
  type: "Convolution"
  bottom: "res_3_756"
  top: "res_stage_3_757_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_757_1"
  type: "BatchNorm"
  bottom: "res_stage_3_757_1"
  top: "res_stage_3_757_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_757_1"  
  type: "Scale"
  bottom: "res_stage_3_757_1"
  top: "res_stage_3_757_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_757_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_757_1_top"
  top: "res_stage_3_757_1_top"
}
layer {
  name: "res_stage_3_757_2"
  type: "Convolution"
  bottom: "res_stage_3_757_1_top"
  top: "res_stage_3_757_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_757_2"
  type: "BatchNorm"
  bottom: "res_stage_3_757_2"
  top: "res_stage_3_757_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_757_2"  
  type: "Scale"
  bottom: "res_stage_3_757_2"
  top: "res_stage_3_757_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_757_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_757_2_top"
  top: "res_stage_3_757_2_top"
}
layer {
  name: "res_stage_3_757_3"
  type: "Convolution"
  bottom: "res_stage_3_757_2_top"
  top: "res_stage_3_757_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_757_3"
  type: "BatchNorm"
  bottom: "res_stage_3_757_3"
  top: "res_stage_3_757_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_757_3"  
  type: "Scale"
  bottom: "res_stage_3_757_3"
  top: "res_stage_3_757_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_757"
  type: "Eltwise"
  bottom: "res_3_756"
  bottom: "res_stage_3_757_3_top"
  top: "res_3_757"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_757_relu"
  type: "ReLU"
  bottom: "res_3_757"
  top: "res_3_757"
}
layer {
  name: "res_stage_3_758_1"
  type: "Convolution"
  bottom: "res_3_757"
  top: "res_stage_3_758_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_758_1"
  type: "BatchNorm"
  bottom: "res_stage_3_758_1"
  top: "res_stage_3_758_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_758_1"  
  type: "Scale"
  bottom: "res_stage_3_758_1"
  top: "res_stage_3_758_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_758_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_758_1_top"
  top: "res_stage_3_758_1_top"
}
layer {
  name: "res_stage_3_758_2"
  type: "Convolution"
  bottom: "res_stage_3_758_1_top"
  top: "res_stage_3_758_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_758_2"
  type: "BatchNorm"
  bottom: "res_stage_3_758_2"
  top: "res_stage_3_758_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_758_2"  
  type: "Scale"
  bottom: "res_stage_3_758_2"
  top: "res_stage_3_758_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_758_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_758_2_top"
  top: "res_stage_3_758_2_top"
}
layer {
  name: "res_stage_3_758_3"
  type: "Convolution"
  bottom: "res_stage_3_758_2_top"
  top: "res_stage_3_758_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_758_3"
  type: "BatchNorm"
  bottom: "res_stage_3_758_3"
  top: "res_stage_3_758_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_758_3"  
  type: "Scale"
  bottom: "res_stage_3_758_3"
  top: "res_stage_3_758_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_758"
  type: "Eltwise"
  bottom: "res_3_757"
  bottom: "res_stage_3_758_3_top"
  top: "res_3_758"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_758_relu"
  type: "ReLU"
  bottom: "res_3_758"
  top: "res_3_758"
}
layer {
  name: "res_stage_3_759_1"
  type: "Convolution"
  bottom: "res_3_758"
  top: "res_stage_3_759_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_759_1"
  type: "BatchNorm"
  bottom: "res_stage_3_759_1"
  top: "res_stage_3_759_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_759_1"  
  type: "Scale"
  bottom: "res_stage_3_759_1"
  top: "res_stage_3_759_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_759_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_759_1_top"
  top: "res_stage_3_759_1_top"
}
layer {
  name: "res_stage_3_759_2"
  type: "Convolution"
  bottom: "res_stage_3_759_1_top"
  top: "res_stage_3_759_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_759_2"
  type: "BatchNorm"
  bottom: "res_stage_3_759_2"
  top: "res_stage_3_759_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_759_2"  
  type: "Scale"
  bottom: "res_stage_3_759_2"
  top: "res_stage_3_759_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_759_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_759_2_top"
  top: "res_stage_3_759_2_top"
}
layer {
  name: "res_stage_3_759_3"
  type: "Convolution"
  bottom: "res_stage_3_759_2_top"
  top: "res_stage_3_759_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_759_3"
  type: "BatchNorm"
  bottom: "res_stage_3_759_3"
  top: "res_stage_3_759_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_759_3"  
  type: "Scale"
  bottom: "res_stage_3_759_3"
  top: "res_stage_3_759_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_759"
  type: "Eltwise"
  bottom: "res_3_758"
  bottom: "res_stage_3_759_3_top"
  top: "res_3_759"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_759_relu"
  type: "ReLU"
  bottom: "res_3_759"
  top: "res_3_759"
}
layer {
  name: "res_stage_3_760_1"
  type: "Convolution"
  bottom: "res_3_759"
  top: "res_stage_3_760_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_760_1"
  type: "BatchNorm"
  bottom: "res_stage_3_760_1"
  top: "res_stage_3_760_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_760_1"  
  type: "Scale"
  bottom: "res_stage_3_760_1"
  top: "res_stage_3_760_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_760_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_760_1_top"
  top: "res_stage_3_760_1_top"
}
layer {
  name: "res_stage_3_760_2"
  type: "Convolution"
  bottom: "res_stage_3_760_1_top"
  top: "res_stage_3_760_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_760_2"
  type: "BatchNorm"
  bottom: "res_stage_3_760_2"
  top: "res_stage_3_760_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_760_2"  
  type: "Scale"
  bottom: "res_stage_3_760_2"
  top: "res_stage_3_760_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_760_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_760_2_top"
  top: "res_stage_3_760_2_top"
}
layer {
  name: "res_stage_3_760_3"
  type: "Convolution"
  bottom: "res_stage_3_760_2_top"
  top: "res_stage_3_760_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_760_3"
  type: "BatchNorm"
  bottom: "res_stage_3_760_3"
  top: "res_stage_3_760_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_760_3"  
  type: "Scale"
  bottom: "res_stage_3_760_3"
  top: "res_stage_3_760_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_760"
  type: "Eltwise"
  bottom: "res_3_759"
  bottom: "res_stage_3_760_3_top"
  top: "res_3_760"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_760_relu"
  type: "ReLU"
  bottom: "res_3_760"
  top: "res_3_760"
}
layer {
  name: "res_stage_3_761_1"
  type: "Convolution"
  bottom: "res_3_760"
  top: "res_stage_3_761_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_761_1"
  type: "BatchNorm"
  bottom: "res_stage_3_761_1"
  top: "res_stage_3_761_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_761_1"  
  type: "Scale"
  bottom: "res_stage_3_761_1"
  top: "res_stage_3_761_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_761_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_761_1_top"
  top: "res_stage_3_761_1_top"
}
layer {
  name: "res_stage_3_761_2"
  type: "Convolution"
  bottom: "res_stage_3_761_1_top"
  top: "res_stage_3_761_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_761_2"
  type: "BatchNorm"
  bottom: "res_stage_3_761_2"
  top: "res_stage_3_761_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_761_2"  
  type: "Scale"
  bottom: "res_stage_3_761_2"
  top: "res_stage_3_761_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_761_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_761_2_top"
  top: "res_stage_3_761_2_top"
}
layer {
  name: "res_stage_3_761_3"
  type: "Convolution"
  bottom: "res_stage_3_761_2_top"
  top: "res_stage_3_761_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_761_3"
  type: "BatchNorm"
  bottom: "res_stage_3_761_3"
  top: "res_stage_3_761_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_761_3"  
  type: "Scale"
  bottom: "res_stage_3_761_3"
  top: "res_stage_3_761_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_761"
  type: "Eltwise"
  bottom: "res_3_760"
  bottom: "res_stage_3_761_3_top"
  top: "res_3_761"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_761_relu"
  type: "ReLU"
  bottom: "res_3_761"
  top: "res_3_761"
}
layer {
  name: "res_stage_3_762_1"
  type: "Convolution"
  bottom: "res_3_761"
  top: "res_stage_3_762_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_762_1"
  type: "BatchNorm"
  bottom: "res_stage_3_762_1"
  top: "res_stage_3_762_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_762_1"  
  type: "Scale"
  bottom: "res_stage_3_762_1"
  top: "res_stage_3_762_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_762_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_762_1_top"
  top: "res_stage_3_762_1_top"
}
layer {
  name: "res_stage_3_762_2"
  type: "Convolution"
  bottom: "res_stage_3_762_1_top"
  top: "res_stage_3_762_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_762_2"
  type: "BatchNorm"
  bottom: "res_stage_3_762_2"
  top: "res_stage_3_762_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_762_2"  
  type: "Scale"
  bottom: "res_stage_3_762_2"
  top: "res_stage_3_762_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_762_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_762_2_top"
  top: "res_stage_3_762_2_top"
}
layer {
  name: "res_stage_3_762_3"
  type: "Convolution"
  bottom: "res_stage_3_762_2_top"
  top: "res_stage_3_762_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_762_3"
  type: "BatchNorm"
  bottom: "res_stage_3_762_3"
  top: "res_stage_3_762_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_762_3"  
  type: "Scale"
  bottom: "res_stage_3_762_3"
  top: "res_stage_3_762_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_762"
  type: "Eltwise"
  bottom: "res_3_761"
  bottom: "res_stage_3_762_3_top"
  top: "res_3_762"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_762_relu"
  type: "ReLU"
  bottom: "res_3_762"
  top: "res_3_762"
}
layer {
  name: "res_stage_3_763_1"
  type: "Convolution"
  bottom: "res_3_762"
  top: "res_stage_3_763_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_763_1"
  type: "BatchNorm"
  bottom: "res_stage_3_763_1"
  top: "res_stage_3_763_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_763_1"  
  type: "Scale"
  bottom: "res_stage_3_763_1"
  top: "res_stage_3_763_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_763_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_763_1_top"
  top: "res_stage_3_763_1_top"
}
layer {
  name: "res_stage_3_763_2"
  type: "Convolution"
  bottom: "res_stage_3_763_1_top"
  top: "res_stage_3_763_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_763_2"
  type: "BatchNorm"
  bottom: "res_stage_3_763_2"
  top: "res_stage_3_763_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_763_2"  
  type: "Scale"
  bottom: "res_stage_3_763_2"
  top: "res_stage_3_763_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_763_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_763_2_top"
  top: "res_stage_3_763_2_top"
}
layer {
  name: "res_stage_3_763_3"
  type: "Convolution"
  bottom: "res_stage_3_763_2_top"
  top: "res_stage_3_763_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_763_3"
  type: "BatchNorm"
  bottom: "res_stage_3_763_3"
  top: "res_stage_3_763_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_763_3"  
  type: "Scale"
  bottom: "res_stage_3_763_3"
  top: "res_stage_3_763_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_763"
  type: "Eltwise"
  bottom: "res_3_762"
  bottom: "res_stage_3_763_3_top"
  top: "res_3_763"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_763_relu"
  type: "ReLU"
  bottom: "res_3_763"
  top: "res_3_763"
}
layer {
  name: "res_stage_3_764_1"
  type: "Convolution"
  bottom: "res_3_763"
  top: "res_stage_3_764_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_764_1"
  type: "BatchNorm"
  bottom: "res_stage_3_764_1"
  top: "res_stage_3_764_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_764_1"  
  type: "Scale"
  bottom: "res_stage_3_764_1"
  top: "res_stage_3_764_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_764_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_764_1_top"
  top: "res_stage_3_764_1_top"
}
layer {
  name: "res_stage_3_764_2"
  type: "Convolution"
  bottom: "res_stage_3_764_1_top"
  top: "res_stage_3_764_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_764_2"
  type: "BatchNorm"
  bottom: "res_stage_3_764_2"
  top: "res_stage_3_764_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_764_2"  
  type: "Scale"
  bottom: "res_stage_3_764_2"
  top: "res_stage_3_764_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_764_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_764_2_top"
  top: "res_stage_3_764_2_top"
}
layer {
  name: "res_stage_3_764_3"
  type: "Convolution"
  bottom: "res_stage_3_764_2_top"
  top: "res_stage_3_764_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_764_3"
  type: "BatchNorm"
  bottom: "res_stage_3_764_3"
  top: "res_stage_3_764_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_764_3"  
  type: "Scale"
  bottom: "res_stage_3_764_3"
  top: "res_stage_3_764_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_764"
  type: "Eltwise"
  bottom: "res_3_763"
  bottom: "res_stage_3_764_3_top"
  top: "res_3_764"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_764_relu"
  type: "ReLU"
  bottom: "res_3_764"
  top: "res_3_764"
}
layer {
  name: "res_stage_3_765_1"
  type: "Convolution"
  bottom: "res_3_764"
  top: "res_stage_3_765_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_765_1"
  type: "BatchNorm"
  bottom: "res_stage_3_765_1"
  top: "res_stage_3_765_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_765_1"  
  type: "Scale"
  bottom: "res_stage_3_765_1"
  top: "res_stage_3_765_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_765_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_765_1_top"
  top: "res_stage_3_765_1_top"
}
layer {
  name: "res_stage_3_765_2"
  type: "Convolution"
  bottom: "res_stage_3_765_1_top"
  top: "res_stage_3_765_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_765_2"
  type: "BatchNorm"
  bottom: "res_stage_3_765_2"
  top: "res_stage_3_765_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_765_2"  
  type: "Scale"
  bottom: "res_stage_3_765_2"
  top: "res_stage_3_765_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_765_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_765_2_top"
  top: "res_stage_3_765_2_top"
}
layer {
  name: "res_stage_3_765_3"
  type: "Convolution"
  bottom: "res_stage_3_765_2_top"
  top: "res_stage_3_765_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_765_3"
  type: "BatchNorm"
  bottom: "res_stage_3_765_3"
  top: "res_stage_3_765_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_765_3"  
  type: "Scale"
  bottom: "res_stage_3_765_3"
  top: "res_stage_3_765_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_765"
  type: "Eltwise"
  bottom: "res_3_764"
  bottom: "res_stage_3_765_3_top"
  top: "res_3_765"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_765_relu"
  type: "ReLU"
  bottom: "res_3_765"
  top: "res_3_765"
}
layer {
  name: "res_stage_3_766_1"
  type: "Convolution"
  bottom: "res_3_765"
  top: "res_stage_3_766_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_766_1"
  type: "BatchNorm"
  bottom: "res_stage_3_766_1"
  top: "res_stage_3_766_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_766_1"  
  type: "Scale"
  bottom: "res_stage_3_766_1"
  top: "res_stage_3_766_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_766_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_766_1_top"
  top: "res_stage_3_766_1_top"
}
layer {
  name: "res_stage_3_766_2"
  type: "Convolution"
  bottom: "res_stage_3_766_1_top"
  top: "res_stage_3_766_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_766_2"
  type: "BatchNorm"
  bottom: "res_stage_3_766_2"
  top: "res_stage_3_766_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_766_2"  
  type: "Scale"
  bottom: "res_stage_3_766_2"
  top: "res_stage_3_766_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_766_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_766_2_top"
  top: "res_stage_3_766_2_top"
}
layer {
  name: "res_stage_3_766_3"
  type: "Convolution"
  bottom: "res_stage_3_766_2_top"
  top: "res_stage_3_766_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_766_3"
  type: "BatchNorm"
  bottom: "res_stage_3_766_3"
  top: "res_stage_3_766_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_766_3"  
  type: "Scale"
  bottom: "res_stage_3_766_3"
  top: "res_stage_3_766_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_766"
  type: "Eltwise"
  bottom: "res_3_765"
  bottom: "res_stage_3_766_3_top"
  top: "res_3_766"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_766_relu"
  type: "ReLU"
  bottom: "res_3_766"
  top: "res_3_766"
}
layer {
  name: "res_stage_3_767_1"
  type: "Convolution"
  bottom: "res_3_766"
  top: "res_stage_3_767_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_767_1"
  type: "BatchNorm"
  bottom: "res_stage_3_767_1"
  top: "res_stage_3_767_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_767_1"  
  type: "Scale"
  bottom: "res_stage_3_767_1"
  top: "res_stage_3_767_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_767_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_767_1_top"
  top: "res_stage_3_767_1_top"
}
layer {
  name: "res_stage_3_767_2"
  type: "Convolution"
  bottom: "res_stage_3_767_1_top"
  top: "res_stage_3_767_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_767_2"
  type: "BatchNorm"
  bottom: "res_stage_3_767_2"
  top: "res_stage_3_767_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_767_2"  
  type: "Scale"
  bottom: "res_stage_3_767_2"
  top: "res_stage_3_767_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_767_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_767_2_top"
  top: "res_stage_3_767_2_top"
}
layer {
  name: "res_stage_3_767_3"
  type: "Convolution"
  bottom: "res_stage_3_767_2_top"
  top: "res_stage_3_767_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_767_3"
  type: "BatchNorm"
  bottom: "res_stage_3_767_3"
  top: "res_stage_3_767_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_767_3"  
  type: "Scale"
  bottom: "res_stage_3_767_3"
  top: "res_stage_3_767_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_767"
  type: "Eltwise"
  bottom: "res_3_766"
  bottom: "res_stage_3_767_3_top"
  top: "res_3_767"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_767_relu"
  type: "ReLU"
  bottom: "res_3_767"
  top: "res_3_767"
}
layer {
  name: "res_stage_3_768_1"
  type: "Convolution"
  bottom: "res_3_767"
  top: "res_stage_3_768_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_768_1"
  type: "BatchNorm"
  bottom: "res_stage_3_768_1"
  top: "res_stage_3_768_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_768_1"  
  type: "Scale"
  bottom: "res_stage_3_768_1"
  top: "res_stage_3_768_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_768_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_768_1_top"
  top: "res_stage_3_768_1_top"
}
layer {
  name: "res_stage_3_768_2"
  type: "Convolution"
  bottom: "res_stage_3_768_1_top"
  top: "res_stage_3_768_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_768_2"
  type: "BatchNorm"
  bottom: "res_stage_3_768_2"
  top: "res_stage_3_768_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_768_2"  
  type: "Scale"
  bottom: "res_stage_3_768_2"
  top: "res_stage_3_768_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_768_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_768_2_top"
  top: "res_stage_3_768_2_top"
}
layer {
  name: "res_stage_3_768_3"
  type: "Convolution"
  bottom: "res_stage_3_768_2_top"
  top: "res_stage_3_768_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_768_3"
  type: "BatchNorm"
  bottom: "res_stage_3_768_3"
  top: "res_stage_3_768_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_768_3"  
  type: "Scale"
  bottom: "res_stage_3_768_3"
  top: "res_stage_3_768_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_768"
  type: "Eltwise"
  bottom: "res_3_767"
  bottom: "res_stage_3_768_3_top"
  top: "res_3_768"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_768_relu"
  type: "ReLU"
  bottom: "res_3_768"
  top: "res_3_768"
}
layer {
  name: "res_stage_3_769_1"
  type: "Convolution"
  bottom: "res_3_768"
  top: "res_stage_3_769_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_769_1"
  type: "BatchNorm"
  bottom: "res_stage_3_769_1"
  top: "res_stage_3_769_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_769_1"  
  type: "Scale"
  bottom: "res_stage_3_769_1"
  top: "res_stage_3_769_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_769_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_769_1_top"
  top: "res_stage_3_769_1_top"
}
layer {
  name: "res_stage_3_769_2"
  type: "Convolution"
  bottom: "res_stage_3_769_1_top"
  top: "res_stage_3_769_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_769_2"
  type: "BatchNorm"
  bottom: "res_stage_3_769_2"
  top: "res_stage_3_769_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_769_2"  
  type: "Scale"
  bottom: "res_stage_3_769_2"
  top: "res_stage_3_769_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_769_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_769_2_top"
  top: "res_stage_3_769_2_top"
}
layer {
  name: "res_stage_3_769_3"
  type: "Convolution"
  bottom: "res_stage_3_769_2_top"
  top: "res_stage_3_769_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_769_3"
  type: "BatchNorm"
  bottom: "res_stage_3_769_3"
  top: "res_stage_3_769_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_769_3"  
  type: "Scale"
  bottom: "res_stage_3_769_3"
  top: "res_stage_3_769_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_769"
  type: "Eltwise"
  bottom: "res_3_768"
  bottom: "res_stage_3_769_3_top"
  top: "res_3_769"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_769_relu"
  type: "ReLU"
  bottom: "res_3_769"
  top: "res_3_769"
}
layer {
  name: "res_stage_3_770_1"
  type: "Convolution"
  bottom: "res_3_769"
  top: "res_stage_3_770_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_770_1"
  type: "BatchNorm"
  bottom: "res_stage_3_770_1"
  top: "res_stage_3_770_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_770_1"  
  type: "Scale"
  bottom: "res_stage_3_770_1"
  top: "res_stage_3_770_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_770_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_770_1_top"
  top: "res_stage_3_770_1_top"
}
layer {
  name: "res_stage_3_770_2"
  type: "Convolution"
  bottom: "res_stage_3_770_1_top"
  top: "res_stage_3_770_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_770_2"
  type: "BatchNorm"
  bottom: "res_stage_3_770_2"
  top: "res_stage_3_770_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_770_2"  
  type: "Scale"
  bottom: "res_stage_3_770_2"
  top: "res_stage_3_770_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_770_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_770_2_top"
  top: "res_stage_3_770_2_top"
}
layer {
  name: "res_stage_3_770_3"
  type: "Convolution"
  bottom: "res_stage_3_770_2_top"
  top: "res_stage_3_770_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_770_3"
  type: "BatchNorm"
  bottom: "res_stage_3_770_3"
  top: "res_stage_3_770_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_770_3"  
  type: "Scale"
  bottom: "res_stage_3_770_3"
  top: "res_stage_3_770_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_770"
  type: "Eltwise"
  bottom: "res_3_769"
  bottom: "res_stage_3_770_3_top"
  top: "res_3_770"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_770_relu"
  type: "ReLU"
  bottom: "res_3_770"
  top: "res_3_770"
}
layer {
  name: "res_stage_3_771_1"
  type: "Convolution"
  bottom: "res_3_770"
  top: "res_stage_3_771_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_771_1"
  type: "BatchNorm"
  bottom: "res_stage_3_771_1"
  top: "res_stage_3_771_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_771_1"  
  type: "Scale"
  bottom: "res_stage_3_771_1"
  top: "res_stage_3_771_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_771_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_771_1_top"
  top: "res_stage_3_771_1_top"
}
layer {
  name: "res_stage_3_771_2"
  type: "Convolution"
  bottom: "res_stage_3_771_1_top"
  top: "res_stage_3_771_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_771_2"
  type: "BatchNorm"
  bottom: "res_stage_3_771_2"
  top: "res_stage_3_771_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_771_2"  
  type: "Scale"
  bottom: "res_stage_3_771_2"
  top: "res_stage_3_771_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_771_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_771_2_top"
  top: "res_stage_3_771_2_top"
}
layer {
  name: "res_stage_3_771_3"
  type: "Convolution"
  bottom: "res_stage_3_771_2_top"
  top: "res_stage_3_771_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_771_3"
  type: "BatchNorm"
  bottom: "res_stage_3_771_3"
  top: "res_stage_3_771_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_771_3"  
  type: "Scale"
  bottom: "res_stage_3_771_3"
  top: "res_stage_3_771_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_771"
  type: "Eltwise"
  bottom: "res_3_770"
  bottom: "res_stage_3_771_3_top"
  top: "res_3_771"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_771_relu"
  type: "ReLU"
  bottom: "res_3_771"
  top: "res_3_771"
}
layer {
  name: "res_stage_3_772_1"
  type: "Convolution"
  bottom: "res_3_771"
  top: "res_stage_3_772_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_772_1"
  type: "BatchNorm"
  bottom: "res_stage_3_772_1"
  top: "res_stage_3_772_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_772_1"  
  type: "Scale"
  bottom: "res_stage_3_772_1"
  top: "res_stage_3_772_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_772_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_772_1_top"
  top: "res_stage_3_772_1_top"
}
layer {
  name: "res_stage_3_772_2"
  type: "Convolution"
  bottom: "res_stage_3_772_1_top"
  top: "res_stage_3_772_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_772_2"
  type: "BatchNorm"
  bottom: "res_stage_3_772_2"
  top: "res_stage_3_772_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_772_2"  
  type: "Scale"
  bottom: "res_stage_3_772_2"
  top: "res_stage_3_772_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_772_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_772_2_top"
  top: "res_stage_3_772_2_top"
}
layer {
  name: "res_stage_3_772_3"
  type: "Convolution"
  bottom: "res_stage_3_772_2_top"
  top: "res_stage_3_772_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_772_3"
  type: "BatchNorm"
  bottom: "res_stage_3_772_3"
  top: "res_stage_3_772_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_772_3"  
  type: "Scale"
  bottom: "res_stage_3_772_3"
  top: "res_stage_3_772_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_772"
  type: "Eltwise"
  bottom: "res_3_771"
  bottom: "res_stage_3_772_3_top"
  top: "res_3_772"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_772_relu"
  type: "ReLU"
  bottom: "res_3_772"
  top: "res_3_772"
}
layer {
  name: "res_stage_3_773_1"
  type: "Convolution"
  bottom: "res_3_772"
  top: "res_stage_3_773_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_773_1"
  type: "BatchNorm"
  bottom: "res_stage_3_773_1"
  top: "res_stage_3_773_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_773_1"  
  type: "Scale"
  bottom: "res_stage_3_773_1"
  top: "res_stage_3_773_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_773_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_773_1_top"
  top: "res_stage_3_773_1_top"
}
layer {
  name: "res_stage_3_773_2"
  type: "Convolution"
  bottom: "res_stage_3_773_1_top"
  top: "res_stage_3_773_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_773_2"
  type: "BatchNorm"
  bottom: "res_stage_3_773_2"
  top: "res_stage_3_773_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_773_2"  
  type: "Scale"
  bottom: "res_stage_3_773_2"
  top: "res_stage_3_773_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_773_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_773_2_top"
  top: "res_stage_3_773_2_top"
}
layer {
  name: "res_stage_3_773_3"
  type: "Convolution"
  bottom: "res_stage_3_773_2_top"
  top: "res_stage_3_773_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_773_3"
  type: "BatchNorm"
  bottom: "res_stage_3_773_3"
  top: "res_stage_3_773_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_773_3"  
  type: "Scale"
  bottom: "res_stage_3_773_3"
  top: "res_stage_3_773_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_773"
  type: "Eltwise"
  bottom: "res_3_772"
  bottom: "res_stage_3_773_3_top"
  top: "res_3_773"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_773_relu"
  type: "ReLU"
  bottom: "res_3_773"
  top: "res_3_773"
}
layer {
  name: "res_stage_3_774_1"
  type: "Convolution"
  bottom: "res_3_773"
  top: "res_stage_3_774_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_774_1"
  type: "BatchNorm"
  bottom: "res_stage_3_774_1"
  top: "res_stage_3_774_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_774_1"  
  type: "Scale"
  bottom: "res_stage_3_774_1"
  top: "res_stage_3_774_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_774_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_774_1_top"
  top: "res_stage_3_774_1_top"
}
layer {
  name: "res_stage_3_774_2"
  type: "Convolution"
  bottom: "res_stage_3_774_1_top"
  top: "res_stage_3_774_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_774_2"
  type: "BatchNorm"
  bottom: "res_stage_3_774_2"
  top: "res_stage_3_774_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_774_2"  
  type: "Scale"
  bottom: "res_stage_3_774_2"
  top: "res_stage_3_774_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_774_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_774_2_top"
  top: "res_stage_3_774_2_top"
}
layer {
  name: "res_stage_3_774_3"
  type: "Convolution"
  bottom: "res_stage_3_774_2_top"
  top: "res_stage_3_774_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_774_3"
  type: "BatchNorm"
  bottom: "res_stage_3_774_3"
  top: "res_stage_3_774_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_774_3"  
  type: "Scale"
  bottom: "res_stage_3_774_3"
  top: "res_stage_3_774_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_774"
  type: "Eltwise"
  bottom: "res_3_773"
  bottom: "res_stage_3_774_3_top"
  top: "res_3_774"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_774_relu"
  type: "ReLU"
  bottom: "res_3_774"
  top: "res_3_774"
}
layer {
  name: "res_stage_3_775_1"
  type: "Convolution"
  bottom: "res_3_774"
  top: "res_stage_3_775_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_775_1"
  type: "BatchNorm"
  bottom: "res_stage_3_775_1"
  top: "res_stage_3_775_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_775_1"  
  type: "Scale"
  bottom: "res_stage_3_775_1"
  top: "res_stage_3_775_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_775_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_775_1_top"
  top: "res_stage_3_775_1_top"
}
layer {
  name: "res_stage_3_775_2"
  type: "Convolution"
  bottom: "res_stage_3_775_1_top"
  top: "res_stage_3_775_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_775_2"
  type: "BatchNorm"
  bottom: "res_stage_3_775_2"
  top: "res_stage_3_775_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_775_2"  
  type: "Scale"
  bottom: "res_stage_3_775_2"
  top: "res_stage_3_775_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_775_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_775_2_top"
  top: "res_stage_3_775_2_top"
}
layer {
  name: "res_stage_3_775_3"
  type: "Convolution"
  bottom: "res_stage_3_775_2_top"
  top: "res_stage_3_775_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_775_3"
  type: "BatchNorm"
  bottom: "res_stage_3_775_3"
  top: "res_stage_3_775_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_775_3"  
  type: "Scale"
  bottom: "res_stage_3_775_3"
  top: "res_stage_3_775_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_775"
  type: "Eltwise"
  bottom: "res_3_774"
  bottom: "res_stage_3_775_3_top"
  top: "res_3_775"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_775_relu"
  type: "ReLU"
  bottom: "res_3_775"
  top: "res_3_775"
}
layer {
  name: "res_stage_3_776_1"
  type: "Convolution"
  bottom: "res_3_775"
  top: "res_stage_3_776_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_776_1"
  type: "BatchNorm"
  bottom: "res_stage_3_776_1"
  top: "res_stage_3_776_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_776_1"  
  type: "Scale"
  bottom: "res_stage_3_776_1"
  top: "res_stage_3_776_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_776_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_776_1_top"
  top: "res_stage_3_776_1_top"
}
layer {
  name: "res_stage_3_776_2"
  type: "Convolution"
  bottom: "res_stage_3_776_1_top"
  top: "res_stage_3_776_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_776_2"
  type: "BatchNorm"
  bottom: "res_stage_3_776_2"
  top: "res_stage_3_776_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_776_2"  
  type: "Scale"
  bottom: "res_stage_3_776_2"
  top: "res_stage_3_776_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_776_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_776_2_top"
  top: "res_stage_3_776_2_top"
}
layer {
  name: "res_stage_3_776_3"
  type: "Convolution"
  bottom: "res_stage_3_776_2_top"
  top: "res_stage_3_776_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_776_3"
  type: "BatchNorm"
  bottom: "res_stage_3_776_3"
  top: "res_stage_3_776_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_776_3"  
  type: "Scale"
  bottom: "res_stage_3_776_3"
  top: "res_stage_3_776_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_776"
  type: "Eltwise"
  bottom: "res_3_775"
  bottom: "res_stage_3_776_3_top"
  top: "res_3_776"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_776_relu"
  type: "ReLU"
  bottom: "res_3_776"
  top: "res_3_776"
}
layer {
  name: "res_stage_3_777_1"
  type: "Convolution"
  bottom: "res_3_776"
  top: "res_stage_3_777_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_777_1"
  type: "BatchNorm"
  bottom: "res_stage_3_777_1"
  top: "res_stage_3_777_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_777_1"  
  type: "Scale"
  bottom: "res_stage_3_777_1"
  top: "res_stage_3_777_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_777_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_777_1_top"
  top: "res_stage_3_777_1_top"
}
layer {
  name: "res_stage_3_777_2"
  type: "Convolution"
  bottom: "res_stage_3_777_1_top"
  top: "res_stage_3_777_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_777_2"
  type: "BatchNorm"
  bottom: "res_stage_3_777_2"
  top: "res_stage_3_777_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_777_2"  
  type: "Scale"
  bottom: "res_stage_3_777_2"
  top: "res_stage_3_777_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_777_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_777_2_top"
  top: "res_stage_3_777_2_top"
}
layer {
  name: "res_stage_3_777_3"
  type: "Convolution"
  bottom: "res_stage_3_777_2_top"
  top: "res_stage_3_777_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_777_3"
  type: "BatchNorm"
  bottom: "res_stage_3_777_3"
  top: "res_stage_3_777_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_777_3"  
  type: "Scale"
  bottom: "res_stage_3_777_3"
  top: "res_stage_3_777_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_777"
  type: "Eltwise"
  bottom: "res_3_776"
  bottom: "res_stage_3_777_3_top"
  top: "res_3_777"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_777_relu"
  type: "ReLU"
  bottom: "res_3_777"
  top: "res_3_777"
}
layer {
  name: "res_stage_3_778_1"
  type: "Convolution"
  bottom: "res_3_777"
  top: "res_stage_3_778_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_778_1"
  type: "BatchNorm"
  bottom: "res_stage_3_778_1"
  top: "res_stage_3_778_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_778_1"  
  type: "Scale"
  bottom: "res_stage_3_778_1"
  top: "res_stage_3_778_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_778_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_778_1_top"
  top: "res_stage_3_778_1_top"
}
layer {
  name: "res_stage_3_778_2"
  type: "Convolution"
  bottom: "res_stage_3_778_1_top"
  top: "res_stage_3_778_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_778_2"
  type: "BatchNorm"
  bottom: "res_stage_3_778_2"
  top: "res_stage_3_778_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_778_2"  
  type: "Scale"
  bottom: "res_stage_3_778_2"
  top: "res_stage_3_778_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_778_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_778_2_top"
  top: "res_stage_3_778_2_top"
}
layer {
  name: "res_stage_3_778_3"
  type: "Convolution"
  bottom: "res_stage_3_778_2_top"
  top: "res_stage_3_778_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_778_3"
  type: "BatchNorm"
  bottom: "res_stage_3_778_3"
  top: "res_stage_3_778_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_778_3"  
  type: "Scale"
  bottom: "res_stage_3_778_3"
  top: "res_stage_3_778_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_778"
  type: "Eltwise"
  bottom: "res_3_777"
  bottom: "res_stage_3_778_3_top"
  top: "res_3_778"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_778_relu"
  type: "ReLU"
  bottom: "res_3_778"
  top: "res_3_778"
}
layer {
  name: "res_stage_3_779_1"
  type: "Convolution"
  bottom: "res_3_778"
  top: "res_stage_3_779_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_779_1"
  type: "BatchNorm"
  bottom: "res_stage_3_779_1"
  top: "res_stage_3_779_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_779_1"  
  type: "Scale"
  bottom: "res_stage_3_779_1"
  top: "res_stage_3_779_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_779_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_779_1_top"
  top: "res_stage_3_779_1_top"
}
layer {
  name: "res_stage_3_779_2"
  type: "Convolution"
  bottom: "res_stage_3_779_1_top"
  top: "res_stage_3_779_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_779_2"
  type: "BatchNorm"
  bottom: "res_stage_3_779_2"
  top: "res_stage_3_779_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_779_2"  
  type: "Scale"
  bottom: "res_stage_3_779_2"
  top: "res_stage_3_779_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_779_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_779_2_top"
  top: "res_stage_3_779_2_top"
}
layer {
  name: "res_stage_3_779_3"
  type: "Convolution"
  bottom: "res_stage_3_779_2_top"
  top: "res_stage_3_779_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_779_3"
  type: "BatchNorm"
  bottom: "res_stage_3_779_3"
  top: "res_stage_3_779_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_779_3"  
  type: "Scale"
  bottom: "res_stage_3_779_3"
  top: "res_stage_3_779_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_779"
  type: "Eltwise"
  bottom: "res_3_778"
  bottom: "res_stage_3_779_3_top"
  top: "res_3_779"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_779_relu"
  type: "ReLU"
  bottom: "res_3_779"
  top: "res_3_779"
}
layer {
  name: "res_stage_3_780_1"
  type: "Convolution"
  bottom: "res_3_779"
  top: "res_stage_3_780_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_780_1"
  type: "BatchNorm"
  bottom: "res_stage_3_780_1"
  top: "res_stage_3_780_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_780_1"  
  type: "Scale"
  bottom: "res_stage_3_780_1"
  top: "res_stage_3_780_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_780_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_780_1_top"
  top: "res_stage_3_780_1_top"
}
layer {
  name: "res_stage_3_780_2"
  type: "Convolution"
  bottom: "res_stage_3_780_1_top"
  top: "res_stage_3_780_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_780_2"
  type: "BatchNorm"
  bottom: "res_stage_3_780_2"
  top: "res_stage_3_780_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_780_2"  
  type: "Scale"
  bottom: "res_stage_3_780_2"
  top: "res_stage_3_780_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_780_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_780_2_top"
  top: "res_stage_3_780_2_top"
}
layer {
  name: "res_stage_3_780_3"
  type: "Convolution"
  bottom: "res_stage_3_780_2_top"
  top: "res_stage_3_780_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_780_3"
  type: "BatchNorm"
  bottom: "res_stage_3_780_3"
  top: "res_stage_3_780_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_780_3"  
  type: "Scale"
  bottom: "res_stage_3_780_3"
  top: "res_stage_3_780_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_780"
  type: "Eltwise"
  bottom: "res_3_779"
  bottom: "res_stage_3_780_3_top"
  top: "res_3_780"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_780_relu"
  type: "ReLU"
  bottom: "res_3_780"
  top: "res_3_780"
}
layer {
  name: "res_stage_3_781_1"
  type: "Convolution"
  bottom: "res_3_780"
  top: "res_stage_3_781_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_781_1"
  type: "BatchNorm"
  bottom: "res_stage_3_781_1"
  top: "res_stage_3_781_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_781_1"  
  type: "Scale"
  bottom: "res_stage_3_781_1"
  top: "res_stage_3_781_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_781_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_781_1_top"
  top: "res_stage_3_781_1_top"
}
layer {
  name: "res_stage_3_781_2"
  type: "Convolution"
  bottom: "res_stage_3_781_1_top"
  top: "res_stage_3_781_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_781_2"
  type: "BatchNorm"
  bottom: "res_stage_3_781_2"
  top: "res_stage_3_781_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_781_2"  
  type: "Scale"
  bottom: "res_stage_3_781_2"
  top: "res_stage_3_781_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_781_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_781_2_top"
  top: "res_stage_3_781_2_top"
}
layer {
  name: "res_stage_3_781_3"
  type: "Convolution"
  bottom: "res_stage_3_781_2_top"
  top: "res_stage_3_781_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_781_3"
  type: "BatchNorm"
  bottom: "res_stage_3_781_3"
  top: "res_stage_3_781_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_781_3"  
  type: "Scale"
  bottom: "res_stage_3_781_3"
  top: "res_stage_3_781_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_781"
  type: "Eltwise"
  bottom: "res_3_780"
  bottom: "res_stage_3_781_3_top"
  top: "res_3_781"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_781_relu"
  type: "ReLU"
  bottom: "res_3_781"
  top: "res_3_781"
}
layer {
  name: "res_stage_3_782_1"
  type: "Convolution"
  bottom: "res_3_781"
  top: "res_stage_3_782_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_782_1"
  type: "BatchNorm"
  bottom: "res_stage_3_782_1"
  top: "res_stage_3_782_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_782_1"  
  type: "Scale"
  bottom: "res_stage_3_782_1"
  top: "res_stage_3_782_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_782_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_782_1_top"
  top: "res_stage_3_782_1_top"
}
layer {
  name: "res_stage_3_782_2"
  type: "Convolution"
  bottom: "res_stage_3_782_1_top"
  top: "res_stage_3_782_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_782_2"
  type: "BatchNorm"
  bottom: "res_stage_3_782_2"
  top: "res_stage_3_782_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_782_2"  
  type: "Scale"
  bottom: "res_stage_3_782_2"
  top: "res_stage_3_782_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_782_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_782_2_top"
  top: "res_stage_3_782_2_top"
}
layer {
  name: "res_stage_3_782_3"
  type: "Convolution"
  bottom: "res_stage_3_782_2_top"
  top: "res_stage_3_782_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_782_3"
  type: "BatchNorm"
  bottom: "res_stage_3_782_3"
  top: "res_stage_3_782_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_782_3"  
  type: "Scale"
  bottom: "res_stage_3_782_3"
  top: "res_stage_3_782_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_782"
  type: "Eltwise"
  bottom: "res_3_781"
  bottom: "res_stage_3_782_3_top"
  top: "res_3_782"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_782_relu"
  type: "ReLU"
  bottom: "res_3_782"
  top: "res_3_782"
}
layer {
  name: "res_stage_3_783_1"
  type: "Convolution"
  bottom: "res_3_782"
  top: "res_stage_3_783_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_783_1"
  type: "BatchNorm"
  bottom: "res_stage_3_783_1"
  top: "res_stage_3_783_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_783_1"  
  type: "Scale"
  bottom: "res_stage_3_783_1"
  top: "res_stage_3_783_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_783_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_783_1_top"
  top: "res_stage_3_783_1_top"
}
layer {
  name: "res_stage_3_783_2"
  type: "Convolution"
  bottom: "res_stage_3_783_1_top"
  top: "res_stage_3_783_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_783_2"
  type: "BatchNorm"
  bottom: "res_stage_3_783_2"
  top: "res_stage_3_783_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_783_2"  
  type: "Scale"
  bottom: "res_stage_3_783_2"
  top: "res_stage_3_783_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_783_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_783_2_top"
  top: "res_stage_3_783_2_top"
}
layer {
  name: "res_stage_3_783_3"
  type: "Convolution"
  bottom: "res_stage_3_783_2_top"
  top: "res_stage_3_783_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_783_3"
  type: "BatchNorm"
  bottom: "res_stage_3_783_3"
  top: "res_stage_3_783_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_783_3"  
  type: "Scale"
  bottom: "res_stage_3_783_3"
  top: "res_stage_3_783_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_783"
  type: "Eltwise"
  bottom: "res_3_782"
  bottom: "res_stage_3_783_3_top"
  top: "res_3_783"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_783_relu"
  type: "ReLU"
  bottom: "res_3_783"
  top: "res_3_783"
}
layer {
  name: "res_stage_3_784_1"
  type: "Convolution"
  bottom: "res_3_783"
  top: "res_stage_3_784_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_784_1"
  type: "BatchNorm"
  bottom: "res_stage_3_784_1"
  top: "res_stage_3_784_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_784_1"  
  type: "Scale"
  bottom: "res_stage_3_784_1"
  top: "res_stage_3_784_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_784_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_784_1_top"
  top: "res_stage_3_784_1_top"
}
layer {
  name: "res_stage_3_784_2"
  type: "Convolution"
  bottom: "res_stage_3_784_1_top"
  top: "res_stage_3_784_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_784_2"
  type: "BatchNorm"
  bottom: "res_stage_3_784_2"
  top: "res_stage_3_784_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_784_2"  
  type: "Scale"
  bottom: "res_stage_3_784_2"
  top: "res_stage_3_784_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_784_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_784_2_top"
  top: "res_stage_3_784_2_top"
}
layer {
  name: "res_stage_3_784_3"
  type: "Convolution"
  bottom: "res_stage_3_784_2_top"
  top: "res_stage_3_784_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_784_3"
  type: "BatchNorm"
  bottom: "res_stage_3_784_3"
  top: "res_stage_3_784_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_784_3"  
  type: "Scale"
  bottom: "res_stage_3_784_3"
  top: "res_stage_3_784_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_784"
  type: "Eltwise"
  bottom: "res_3_783"
  bottom: "res_stage_3_784_3_top"
  top: "res_3_784"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_784_relu"
  type: "ReLU"
  bottom: "res_3_784"
  top: "res_3_784"
}
layer {
  name: "res_stage_3_785_1"
  type: "Convolution"
  bottom: "res_3_784"
  top: "res_stage_3_785_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_785_1"
  type: "BatchNorm"
  bottom: "res_stage_3_785_1"
  top: "res_stage_3_785_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_785_1"  
  type: "Scale"
  bottom: "res_stage_3_785_1"
  top: "res_stage_3_785_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_785_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_785_1_top"
  top: "res_stage_3_785_1_top"
}
layer {
  name: "res_stage_3_785_2"
  type: "Convolution"
  bottom: "res_stage_3_785_1_top"
  top: "res_stage_3_785_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_785_2"
  type: "BatchNorm"
  bottom: "res_stage_3_785_2"
  top: "res_stage_3_785_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_785_2"  
  type: "Scale"
  bottom: "res_stage_3_785_2"
  top: "res_stage_3_785_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_785_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_785_2_top"
  top: "res_stage_3_785_2_top"
}
layer {
  name: "res_stage_3_785_3"
  type: "Convolution"
  bottom: "res_stage_3_785_2_top"
  top: "res_stage_3_785_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_785_3"
  type: "BatchNorm"
  bottom: "res_stage_3_785_3"
  top: "res_stage_3_785_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_785_3"  
  type: "Scale"
  bottom: "res_stage_3_785_3"
  top: "res_stage_3_785_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_785"
  type: "Eltwise"
  bottom: "res_3_784"
  bottom: "res_stage_3_785_3_top"
  top: "res_3_785"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_785_relu"
  type: "ReLU"
  bottom: "res_3_785"
  top: "res_3_785"
}
layer {
  name: "res_stage_3_786_1"
  type: "Convolution"
  bottom: "res_3_785"
  top: "res_stage_3_786_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_786_1"
  type: "BatchNorm"
  bottom: "res_stage_3_786_1"
  top: "res_stage_3_786_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_786_1"  
  type: "Scale"
  bottom: "res_stage_3_786_1"
  top: "res_stage_3_786_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_786_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_786_1_top"
  top: "res_stage_3_786_1_top"
}
layer {
  name: "res_stage_3_786_2"
  type: "Convolution"
  bottom: "res_stage_3_786_1_top"
  top: "res_stage_3_786_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_786_2"
  type: "BatchNorm"
  bottom: "res_stage_3_786_2"
  top: "res_stage_3_786_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_786_2"  
  type: "Scale"
  bottom: "res_stage_3_786_2"
  top: "res_stage_3_786_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_786_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_786_2_top"
  top: "res_stage_3_786_2_top"
}
layer {
  name: "res_stage_3_786_3"
  type: "Convolution"
  bottom: "res_stage_3_786_2_top"
  top: "res_stage_3_786_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_786_3"
  type: "BatchNorm"
  bottom: "res_stage_3_786_3"
  top: "res_stage_3_786_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_786_3"  
  type: "Scale"
  bottom: "res_stage_3_786_3"
  top: "res_stage_3_786_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_786"
  type: "Eltwise"
  bottom: "res_3_785"
  bottom: "res_stage_3_786_3_top"
  top: "res_3_786"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_786_relu"
  type: "ReLU"
  bottom: "res_3_786"
  top: "res_3_786"
}
layer {
  name: "res_stage_3_787_1"
  type: "Convolution"
  bottom: "res_3_786"
  top: "res_stage_3_787_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_787_1"
  type: "BatchNorm"
  bottom: "res_stage_3_787_1"
  top: "res_stage_3_787_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_787_1"  
  type: "Scale"
  bottom: "res_stage_3_787_1"
  top: "res_stage_3_787_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_787_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_787_1_top"
  top: "res_stage_3_787_1_top"
}
layer {
  name: "res_stage_3_787_2"
  type: "Convolution"
  bottom: "res_stage_3_787_1_top"
  top: "res_stage_3_787_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_787_2"
  type: "BatchNorm"
  bottom: "res_stage_3_787_2"
  top: "res_stage_3_787_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_787_2"  
  type: "Scale"
  bottom: "res_stage_3_787_2"
  top: "res_stage_3_787_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_787_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_787_2_top"
  top: "res_stage_3_787_2_top"
}
layer {
  name: "res_stage_3_787_3"
  type: "Convolution"
  bottom: "res_stage_3_787_2_top"
  top: "res_stage_3_787_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_787_3"
  type: "BatchNorm"
  bottom: "res_stage_3_787_3"
  top: "res_stage_3_787_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_787_3"  
  type: "Scale"
  bottom: "res_stage_3_787_3"
  top: "res_stage_3_787_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_787"
  type: "Eltwise"
  bottom: "res_3_786"
  bottom: "res_stage_3_787_3_top"
  top: "res_3_787"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_787_relu"
  type: "ReLU"
  bottom: "res_3_787"
  top: "res_3_787"
}
layer {
  name: "res_stage_3_788_1"
  type: "Convolution"
  bottom: "res_3_787"
  top: "res_stage_3_788_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_788_1"
  type: "BatchNorm"
  bottom: "res_stage_3_788_1"
  top: "res_stage_3_788_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_788_1"  
  type: "Scale"
  bottom: "res_stage_3_788_1"
  top: "res_stage_3_788_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_788_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_788_1_top"
  top: "res_stage_3_788_1_top"
}
layer {
  name: "res_stage_3_788_2"
  type: "Convolution"
  bottom: "res_stage_3_788_1_top"
  top: "res_stage_3_788_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_788_2"
  type: "BatchNorm"
  bottom: "res_stage_3_788_2"
  top: "res_stage_3_788_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_788_2"  
  type: "Scale"
  bottom: "res_stage_3_788_2"
  top: "res_stage_3_788_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_788_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_788_2_top"
  top: "res_stage_3_788_2_top"
}
layer {
  name: "res_stage_3_788_3"
  type: "Convolution"
  bottom: "res_stage_3_788_2_top"
  top: "res_stage_3_788_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_788_3"
  type: "BatchNorm"
  bottom: "res_stage_3_788_3"
  top: "res_stage_3_788_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_788_3"  
  type: "Scale"
  bottom: "res_stage_3_788_3"
  top: "res_stage_3_788_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_788"
  type: "Eltwise"
  bottom: "res_3_787"
  bottom: "res_stage_3_788_3_top"
  top: "res_3_788"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_788_relu"
  type: "ReLU"
  bottom: "res_3_788"
  top: "res_3_788"
}
layer {
  name: "res_stage_3_789_1"
  type: "Convolution"
  bottom: "res_3_788"
  top: "res_stage_3_789_1"
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_789_1"
  type: "BatchNorm"
  bottom: "res_stage_3_789_1"
  top: "res_stage_3_789_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_789_1"  
  type: "Scale"
  bottom: "res_stage_3_789_1"
  top: "res_stage_3_789_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_789_1_relu"
  type: "ReLU"
  bottom: "res_stage_3_789_1_top"
  top: "res_stage_3_789_1_top"
}
layer {
  name: "res_stage_3_789_2"
  type: "Convolution"
  bottom: "res_stage_3_789_1_top"
  top: "res_stage_3_789_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_789_2"
  type: "BatchNorm"
  bottom: "res_stage_3_789_2"
  top: "res_stage_3_789_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_789_2"  
  type: "Scale"
  bottom: "res_stage_3_789_2"
  top: "res_stage_3_789_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_3_789_2_relu"
  type: "ReLU"
  bottom: "res_stage_3_789_2_top"
  top: "res_stage_3_789_2_top"
}
layer {
  name: "res_stage_3_789_3"
  type: "Convolution"
  bottom: "res_stage_3_789_2_top"
  top: "res_stage_3_789_3"
  convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_3_789_3"
  type: "BatchNorm"
  bottom: "res_stage_3_789_3"
  top: "res_stage_3_789_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_3_789_3"  
  type: "Scale"
  bottom: "res_stage_3_789_3"
  top: "res_stage_3_789_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_3_789"
  type: "Eltwise"
  bottom: "res_3_788"
  bottom: "res_stage_3_789_3_top"
  top: "res_3_789"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_3_789_relu"
  type: "ReLU"
  bottom: "res_3_789"
  top: "res_3_789"
}
layer {
  name: "res_4_branch1"
  type: "Convolution"
  bottom: "res_3_789"
  top: "res_4_branch1"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_4_branch1"
  type: "BatchNorm"
  bottom: "res_4_branch1"
  top: "res_4_branch1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_4_branch1"  
  type: "Scale"
  bottom: "res_4_branch1"
  top: "res_4_branch1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_1_1"
  type: "Convolution"
  bottom: "res_3_789"
  top: "res_stage_4_1_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_1_1"
  type: "BatchNorm"
  bottom: "res_stage_4_1_1"
  top: "res_stage_4_1_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_1_1"  
  type: "Scale"
  bottom: "res_stage_4_1_1"
  top: "res_stage_4_1_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_1_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_1_1_top"
  top: "res_stage_4_1_1_top"
}
layer {
  name: "res_stage_4_1_2"
  type: "Convolution"
  bottom: "res_stage_4_1_1_top"
  top: "res_stage_4_1_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_1_2"
  type: "BatchNorm"
  bottom: "res_stage_4_1_2"
  top: "res_stage_4_1_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_1_2"  
  type: "Scale"
  bottom: "res_stage_4_1_2"
  top: "res_stage_4_1_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_1_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_1_2_top"
  top: "res_stage_4_1_2_top"
}
layer {
  name: "res_stage_4_1_3"
  type: "Convolution"
  bottom: "res_stage_4_1_2_top"
  top: "res_stage_4_1_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_1_3"
  type: "BatchNorm"
  bottom: "res_stage_4_1_3"
  top: "res_stage_4_1_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_1_3"  
  type: "Scale"
  bottom: "res_stage_4_1_3"
  top: "res_stage_4_1_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_1"
  type: "Eltwise"
  bottom: "res_4_branch1_top"
  bottom: "res_stage_4_1_3_top"
  top: "res_4_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_1_relu"
  type: "ReLU"
  bottom: "res_4_1"
  top: "res_4_1"
}
layer {
  name: "res_stage_4_2_1"
  type: "Convolution"
  bottom: "res_4_1"
  top: "res_stage_4_2_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_2_1"
  type: "BatchNorm"
  bottom: "res_stage_4_2_1"
  top: "res_stage_4_2_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_2_1"  
  type: "Scale"
  bottom: "res_stage_4_2_1"
  top: "res_stage_4_2_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_2_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_2_1_top"
  top: "res_stage_4_2_1_top"
}
layer {
  name: "res_stage_4_2_2"
  type: "Convolution"
  bottom: "res_stage_4_2_1_top"
  top: "res_stage_4_2_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_2_2"
  type: "BatchNorm"
  bottom: "res_stage_4_2_2"
  top: "res_stage_4_2_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_2_2"  
  type: "Scale"
  bottom: "res_stage_4_2_2"
  top: "res_stage_4_2_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_2_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_2_2_top"
  top: "res_stage_4_2_2_top"
}
layer {
  name: "res_stage_4_2_3"
  type: "Convolution"
  bottom: "res_stage_4_2_2_top"
  top: "res_stage_4_2_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_2_3"
  type: "BatchNorm"
  bottom: "res_stage_4_2_3"
  top: "res_stage_4_2_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_2_3"  
  type: "Scale"
  bottom: "res_stage_4_2_3"
  top: "res_stage_4_2_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_2"
  type: "Eltwise"
  bottom: "res_4_1"
  bottom: "res_stage_4_2_3_top"
  top: "res_4_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_2_relu"
  type: "ReLU"
  bottom: "res_4_2"
  top: "res_4_2"
}
layer {
  name: "res_stage_4_3_1"
  type: "Convolution"
  bottom: "res_4_2"
  top: "res_stage_4_3_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_3_1"
  type: "BatchNorm"
  bottom: "res_stage_4_3_1"
  top: "res_stage_4_3_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_3_1"  
  type: "Scale"
  bottom: "res_stage_4_3_1"
  top: "res_stage_4_3_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_3_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_3_1_top"
  top: "res_stage_4_3_1_top"
}
layer {
  name: "res_stage_4_3_2"
  type: "Convolution"
  bottom: "res_stage_4_3_1_top"
  top: "res_stage_4_3_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_3_2"
  type: "BatchNorm"
  bottom: "res_stage_4_3_2"
  top: "res_stage_4_3_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_3_2"  
  type: "Scale"
  bottom: "res_stage_4_3_2"
  top: "res_stage_4_3_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_3_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_3_2_top"
  top: "res_stage_4_3_2_top"
}
layer {
  name: "res_stage_4_3_3"
  type: "Convolution"
  bottom: "res_stage_4_3_2_top"
  top: "res_stage_4_3_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_3_3"
  type: "BatchNorm"
  bottom: "res_stage_4_3_3"
  top: "res_stage_4_3_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_3_3"  
  type: "Scale"
  bottom: "res_stage_4_3_3"
  top: "res_stage_4_3_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_3"
  type: "Eltwise"
  bottom: "res_4_2"
  bottom: "res_stage_4_3_3_top"
  top: "res_4_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_3_relu"
  type: "ReLU"
  bottom: "res_4_3"
  top: "res_4_3"
}
layer {
  name: "res_stage_4_4_1"
  type: "Convolution"
  bottom: "res_4_3"
  top: "res_stage_4_4_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_4_1"
  type: "BatchNorm"
  bottom: "res_stage_4_4_1"
  top: "res_stage_4_4_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_4_1"  
  type: "Scale"
  bottom: "res_stage_4_4_1"
  top: "res_stage_4_4_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_4_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_4_1_top"
  top: "res_stage_4_4_1_top"
}
layer {
  name: "res_stage_4_4_2"
  type: "Convolution"
  bottom: "res_stage_4_4_1_top"
  top: "res_stage_4_4_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_4_2"
  type: "BatchNorm"
  bottom: "res_stage_4_4_2"
  top: "res_stage_4_4_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_4_2"  
  type: "Scale"
  bottom: "res_stage_4_4_2"
  top: "res_stage_4_4_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_4_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_4_2_top"
  top: "res_stage_4_4_2_top"
}
layer {
  name: "res_stage_4_4_3"
  type: "Convolution"
  bottom: "res_stage_4_4_2_top"
  top: "res_stage_4_4_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_4_3"
  type: "BatchNorm"
  bottom: "res_stage_4_4_3"
  top: "res_stage_4_4_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_4_3"  
  type: "Scale"
  bottom: "res_stage_4_4_3"
  top: "res_stage_4_4_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_4"
  type: "Eltwise"
  bottom: "res_4_3"
  bottom: "res_stage_4_4_3_top"
  top: "res_4_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_4_relu"
  type: "ReLU"
  bottom: "res_4_4"
  top: "res_4_4"
}
layer {
  name: "res_stage_4_5_1"
  type: "Convolution"
  bottom: "res_4_4"
  top: "res_stage_4_5_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_5_1"
  type: "BatchNorm"
  bottom: "res_stage_4_5_1"
  top: "res_stage_4_5_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_5_1"  
  type: "Scale"
  bottom: "res_stage_4_5_1"
  top: "res_stage_4_5_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_5_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_5_1_top"
  top: "res_stage_4_5_1_top"
}
layer {
  name: "res_stage_4_5_2"
  type: "Convolution"
  bottom: "res_stage_4_5_1_top"
  top: "res_stage_4_5_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_5_2"
  type: "BatchNorm"
  bottom: "res_stage_4_5_2"
  top: "res_stage_4_5_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_5_2"  
  type: "Scale"
  bottom: "res_stage_4_5_2"
  top: "res_stage_4_5_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_5_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_5_2_top"
  top: "res_stage_4_5_2_top"
}
layer {
  name: "res_stage_4_5_3"
  type: "Convolution"
  bottom: "res_stage_4_5_2_top"
  top: "res_stage_4_5_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_5_3"
  type: "BatchNorm"
  bottom: "res_stage_4_5_3"
  top: "res_stage_4_5_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_5_3"  
  type: "Scale"
  bottom: "res_stage_4_5_3"
  top: "res_stage_4_5_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_5"
  type: "Eltwise"
  bottom: "res_4_4"
  bottom: "res_stage_4_5_3_top"
  top: "res_4_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_5_relu"
  type: "ReLU"
  bottom: "res_4_5"
  top: "res_4_5"
}
layer {
  name: "res_stage_4_6_1"
  type: "Convolution"
  bottom: "res_4_5"
  top: "res_stage_4_6_1"
  convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_6_1"
  type: "BatchNorm"
  bottom: "res_stage_4_6_1"
  top: "res_stage_4_6_1"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_6_1"  
  type: "Scale"
  bottom: "res_stage_4_6_1"
  top: "res_stage_4_6_1_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_6_1_relu"
  type: "ReLU"
  bottom: "res_stage_4_6_1_top"
  top: "res_stage_4_6_1_top"
}
layer {
  name: "res_stage_4_6_2"
  type: "Convolution"
  bottom: "res_stage_4_6_1_top"
  top: "res_stage_4_6_2"
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_6_2"
  type: "BatchNorm"
  bottom: "res_stage_4_6_2"
  top: "res_stage_4_6_2"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_6_2"  
  type: "Scale"
  bottom: "res_stage_4_6_2"
  top: "res_stage_4_6_2_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_stage_4_6_2_relu"
  type: "ReLU"
  bottom: "res_stage_4_6_2_top"
  top: "res_stage_4_6_2_top"
}
layer {
  name: "res_stage_4_6_3"
  type: "Convolution"
  bottom: "res_stage_4_6_2_top"
  top: "res_stage_4_6_3"
  convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_term: false
  }
}
layer {
  name: "bn_stage_4_6_3"
  type: "BatchNorm"
  bottom: "res_stage_4_6_3"
  top: "res_stage_4_6_3"
  batch_norm_param {
      use_global_stats: false
  }
}
layer {
  name: "scale_stage_4_6_3"  
  type: "Scale"
  bottom: "res_stage_4_6_3"
  top: "res_stage_4_6_3_top"
  scale_param {
	bias_term: true
  }
}
 layer {
  name: "res_4_6"
  type: "Eltwise"
  bottom: "res_4_5"
  bottom: "res_stage_4_6_3_top"
  top: "res_4_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res_4_6_relu"
  type: "ReLU"
  bottom: "res_4_6"
  top: "res_4_6"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res_4_6"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc1000"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc1000"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
     num_output: 1000
     weight_filler {
       type: "msra"
     }
     bias_filler {
       type: "constant"
       value: 0
     }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1000"
  bottom: "label"
  top: "loss"
}

layer {
  name: "acc/top-1"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "acc/top-1"
  include {
    phase: TEST
  }
}

layer {
  name: "acc/top-5"
  type: "Accuracy"
  bottom: "fc1000"
  bottom: "label"
  top: "acc/top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
